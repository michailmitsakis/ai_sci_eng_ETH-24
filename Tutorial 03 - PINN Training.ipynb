{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6u_j73SUfQxG"
      },
      "source": [
        "## Physics Informed Neural Networks to Approximate Solution of PDEs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S41Q3MRbgNMB",
        "outputId": "8bcb5c18-b061-4666-995d-ec0e835719b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f90b410a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from drive.MyDrive.DLSC.Common import NeuralNet, MultiVariatePoly\n",
        "import time\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "torch.manual_seed(128)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOPdRWmOfQxI",
        "outputId": "7e48ccf5-8b35-43b2-fa3c-ebf973323f50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the one-dimensional heat equation:\n",
        "\n",
        "$$\n",
        "u_t(t, x) = u_{xx}(t, x), \\quad t\\in[0,T], ~x\\in [-1,1]\n",
        "$$\n",
        "\n",
        "\n",
        "with zero Dirichlet boundary conditions\n",
        "\n",
        "$$\n",
        "u_b(t, -1)=u_b(t,1)=0,\n",
        "$$\n",
        "\n",
        "and initial condition\n",
        "\n",
        "$$\n",
        "u(x, 0) = u_0(x) = - \\sin(\\pi x)\n",
        "$$\n",
        "\n",
        "We want to obtain an approximate solution of the heat equation $u : [0,T]\\times[-1,1] \\mapsto \\mathbb{R}$ with physics informed neural networks (PINNs).\n",
        "\n",
        "To do so, we approximate the underlying solution with a feedforward dense neural network with tunable parameters $\\theta$:\n",
        "\n",
        "$$\n",
        "u_\\theta(t,x) \\approx u(t,x)\n",
        "$$\n",
        "Define the following residuals:\n",
        "\n",
        "   - Interior residual given by,\n",
        "\n",
        "   $$r_{int,\\theta}(t, x):=  u_{\\theta, t}(x,t) - u_{\\theta, xx}(x,t), \\quad \\forall ~t \\in [0,T],~ x \\in [-1,1].$$\n",
        "   \n",
        "        \n",
        "      \n",
        "        \n",
        "   - Spatial boundary residual given by,\n",
        "   \n",
        "        $$r_{sb,\\theta}(t,-1):= u_{\\theta}(t,-1)- u_b(t,-1), \\quad r_{sb,\\theta}(t,1):= u_{\\theta}(t,1)- u_b(t,1), \\quad \\forall t \\in (0,T].$$\n",
        "        \n",
        "   - Temporal boundary residual given by,\n",
        "   \n",
        "        $$r_{tb,\\theta}(x):= u_{\\theta}(x,0) - u_0(x), \\quad \\forall x \\in [-1,1].$$\n",
        "\n",
        "and compute the corresponding loss functions:\n",
        "\n",
        "$$\n",
        "L_{int}(\\theta) = \\int_{[0,T]\\times[-1,1]}r_{int,\\theta}^2(t, x) dtdx, \\quad\n",
        "L_{sb}(\\theta) = \\int_{[0,T]}r_{sb,\\theta}^2(t,-1) dt + \\int_{[0,T]}r_{sb,\\theta}^2(t,1)dt, \\quad\n",
        "L_{tb}(\\theta) = \\int_{[-1,1]}r_{tb,\\theta}^2(x) dx\n",
        "$$\n",
        "\n",
        "The loss functions include integrals that can be approximated by suitable quadrature rule. We use quasi Monte-Carlo and accordingly define the following training sets\n",
        "\n",
        "$$\n",
        "S_{int} =\\{y_n\\}, \\quad 1 \\leq n \\leq N_{int},\\quad y_n = (x,t)_n \\in D_T,\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{sb, -1} =\\{t_n, u_b(t_n,-1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{sb, 1} =\\{t_n, u_b(t_n,1) \\}, \\quad1 \\leq n \\leq N_{sb}, t_n \\in [0,T],\n",
        "$$\n",
        "\n",
        "$$\n",
        "S_{tb}=\\{x_n, u_0(x_n)\\}\\quad  1 \\leq n \\leq N_{tb}, x_n \\in [-1,1].\n",
        "$$\n",
        "\n",
        "with the training inputs points corresponding to low-discrepancy Sobol sequences.\n",
        "\n",
        "$$\n",
        "L_{int}(\\theta) = \\frac{1}{N_{int}}\\sum_{i=1}^{N_{int}}r_{int,\\theta}^2(y_n), \\quad\n",
        "L_{sb}(\\theta) = \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,-1) + \\frac{1}{N_{sb}}\\sum_{i=1}^{N_{sb}}r_{sb,\\theta}^2(t_n,1), \\quad\n",
        "L_{tb}(\\theta) = \\frac{1}{N_{tb}}\\sum_{i=1}^{N_{tb}}r_{tb,\\theta}^2(x_n)\n",
        "$$\n",
        "\n",
        "and solve the following minimization problem\n",
        "\n",
        "$$\n",
        "\\theta^\\ast = argmin_{\\theta} \\Big(L_{int}(\\theta) + \\lambda_u L_u(\\theta)\\Big)\n",
        "$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "L_u(\\theta) = L_{tb}(\\theta) + L_{sb}(\\theta)\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kM0O07h0fQxJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Pinns:\n",
        "    def __init__(self, n_int_, n_sb_, n_tb_):\n",
        "        self.n_int = n_int_\n",
        "        self.n_sb = n_sb_\n",
        "        self.n_tb = n_tb_\n",
        "\n",
        "        # Extrema of the solution domain (t,x) in [0,0.1]x[-1,1]\n",
        "        self.domain_extrema = torch.tensor([[0, 0.6],  # Time dimension\n",
        "                                            [-1, 1]])  # Space dimension\n",
        "\n",
        "        # Number of space dimensions\n",
        "        self.space_dimensions = 1\n",
        "\n",
        "        # Parameter to balance role of data and PDE\n",
        "        self.lambda_u = 10\n",
        "\n",
        "        # F Dense NN to approximate the solution of the underlying heat equation\n",
        "        self.approximate_solution = NeuralNet(input_dimension=self.domain_extrema.shape[0], output_dimension=1,\n",
        "                                              n_hidden_layers=4,\n",
        "                                              neurons=20,\n",
        "                                              regularization_param=0.,\n",
        "                                              regularization_exp=2.,\n",
        "                                              retrain_seed=42)\n",
        "        '''self.approximate_solution = MultiVariatePoly(self.domain_extrema.shape[0], 3)'''\n",
        "\n",
        "        # Generator of Sobol sequences\n",
        "        self.soboleng = torch.quasirandom.SobolEngine(dimension=self.domain_extrema.shape[0])\n",
        "\n",
        "        # Training sets S_sb, S_tb, S_int as torch dataloader\n",
        "        self.training_set_sb, self.training_set_tb, self.training_set_int = self.assemble_datasets()\n",
        "\n",
        "    ################################################################################################\n",
        "    # Function to linearly transform a tensor whose value are between 0 and 1\n",
        "    # to a tensor whose values are between the domain extrema\n",
        "    def convert(self, tens):\n",
        "        assert (tens.shape[1] == self.domain_extrema.shape[0])\n",
        "        return tens * (self.domain_extrema[:, 1] - self.domain_extrema[:, 0]) + self.domain_extrema[:, 0]\n",
        "\n",
        "    # Initial condition to solve the heat equation u0(x)=-sin(pi x)\n",
        "    def initial_condition(self, x):\n",
        "        return -torch.sin(np.pi * x)\n",
        "\n",
        "    # Exact solution for the heat equation ut = u_xx with the IC above\n",
        "    def exact_solution(self, inputs):\n",
        "        t = inputs[:, 0]\n",
        "        x = inputs[:, 1]\n",
        "\n",
        "        u = -torch.exp(-np.pi ** 2 * t) * torch.sin(np.pi * x)\n",
        "        return u\n",
        "\n",
        "    ################################################################################################\n",
        "    # Function returning the input-output tensor required to assemble the training set S_tb corresponding to the temporal boundary\n",
        "    def add_temporal_boundary_points(self):\n",
        "        t0 = self.domain_extrema[0, 0]\n",
        "        input_tb = self.convert(self.soboleng.draw(self.n_tb))\n",
        "        input_tb[:, 0] = torch.full(input_tb[:, 0].shape, t0)\n",
        "        output_tb = self.initial_condition(input_tb[:, 1]).reshape(-1, 1)\n",
        "\n",
        "        return input_tb, output_tb\n",
        "\n",
        "    # Function returning the input-output tensor required to assemble the training set S_sb corresponding to the spatial boundary\n",
        "    def add_spatial_boundary_points(self):\n",
        "        x0 = self.domain_extrema[1, 0]\n",
        "        xL = self.domain_extrema[1, 1]\n",
        "\n",
        "        input_sb = self.convert(self.soboleng.draw(self.n_sb))\n",
        "\n",
        "        input_sb_0 = torch.clone(input_sb)\n",
        "        input_sb_0[:, 1] = torch.full(input_sb_0[:, 1].shape, x0)\n",
        "\n",
        "        input_sb_L = torch.clone(input_sb)\n",
        "        input_sb_L[:, 1] = torch.full(input_sb_L[:, 1].shape, xL)\n",
        "\n",
        "        output_sb_0 = torch.zeros((input_sb.shape[0], 1))\n",
        "        output_sb_L = torch.zeros((input_sb.shape[0], 1))\n",
        "\n",
        "        return torch.cat([input_sb_0, input_sb_L], 0), torch.cat([output_sb_0, output_sb_L], 0)\n",
        "\n",
        "    #  Function returning the input-output tensor required to assemble the training set S_int corresponding to the interior domain where the PDE is enforced\n",
        "    def add_interior_points(self):\n",
        "        input_int = self.convert(self.soboleng.draw(self.n_int))\n",
        "        output_int = torch.zeros((input_int.shape[0], 1))\n",
        "        return input_int, output_int\n",
        "\n",
        "    # Function returning the training sets S_sb, S_tb, S_int as dataloader\n",
        "    def assemble_datasets(self):\n",
        "        input_sb, output_sb = self.add_spatial_boundary_points()   # S_sb\n",
        "        input_tb, output_tb = self.add_temporal_boundary_points()  # S_tb\n",
        "        input_int, output_int = self.add_interior_points()         # S_int\n",
        "\n",
        "        training_set_sb = DataLoader(torch.utils.data.TensorDataset(input_sb, output_sb), batch_size=2*self.space_dimensions*self.n_sb, shuffle=False)\n",
        "        training_set_tb = DataLoader(torch.utils.data.TensorDataset(input_tb, output_tb), batch_size=self.n_tb, shuffle=False)\n",
        "        training_set_int = DataLoader(torch.utils.data.TensorDataset(input_int, output_int), batch_size=self.n_int, shuffle=False)\n",
        "\n",
        "        return training_set_sb, training_set_tb, training_set_int\n",
        "\n",
        "    ################################################################################################\n",
        "    # Function to compute the terms required in the definition of the TEMPORAL boundary residual\n",
        "    def apply_initial_condition(self, input_tb):\n",
        "        u_pred_tb = self.approximate_solution(input_tb)\n",
        "        return u_pred_tb\n",
        "\n",
        "    # Function to compute the terms required in the definition of the SPATIAL boundary residual\n",
        "    def apply_boundary_conditions(self, input_sb):\n",
        "        u_pred_sb = self.approximate_solution(input_sb)\n",
        "\n",
        "        return u_pred_sb\n",
        "\n",
        "    # Function to compute the PDE residuals\n",
        "    def compute_pde_residual(self, input_int):\n",
        "        input_int.requires_grad = True\n",
        "        u = self.approximate_solution(input_int)\n",
        "\n",
        "        # grad compute the gradient of a \"SCALAR\" function L with respect to some input nxm TENSOR Z=[[x1, y1],[x2,y2],[x3,y3],...,[xn,yn]], m=2\n",
        "        # it returns grad_L = [[dL/dx1, dL/dy1],[dL/dx2, dL/dy2],[dL/dx3, dL/dy3],...,[dL/dxn, dL/dyn]]\n",
        "        # Note: pytorch considers a tensor [u1, u2,u3, ... ,un] a vectorial function\n",
        "        # whereas sum_u = u1 + u2 + u3 + u4 + ... + un as a \"scalar\" one\n",
        "\n",
        "        # In our case ui = u(xi), therefore the line below returns:\n",
        "        # grad_u = [[dsum_u/dx1, dsum_u/dy1],[dsum_u/dx2, dsum_u/dy2], [dsum_u/dx3, dL/dy3],...,[dsum_u/dxm, dsum_u/dyn]]\n",
        "        # and dsum_u/dxi = d(u1 + u2 + u3 + u4 + ... + un)/dxi = d(u(x1) + u(x2) u3(x3) + u4(x4) + ... + u(xn))/dxi = dui/dxi\n",
        "        grad_u = torch.autograd.grad(u.sum(), input_int, create_graph=True)[0]\n",
        "        grad_u_t = grad_u[:, 0]\n",
        "        grad_u_x = grad_u[:, 1]\n",
        "        grad_u_xx = torch.autograd.grad(grad_u_x.sum(), input_int, create_graph=True)[0][:, 1]\n",
        "\n",
        "        grad_u_sq_x = torch.autograd.grad(u_sq.sum(), input_int, create_graph=True)[0][:,1]\n",
        "\n",
        "        residual = grad_u_t - grad_u_xx\n",
        "        return residual.reshape(-1, )\n",
        "\n",
        "    # Function to compute the total loss (weighted sum of spatial boundary loss, temporal boundary loss and interior loss)\n",
        "    def compute_loss(self, inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=True):\n",
        "        u_pred_sb = self.apply_boundary_conditions(inp_train_sb)\n",
        "        u_pred_tb = self.apply_initial_condition(inp_train_tb)\n",
        "\n",
        "        assert (u_pred_sb.shape[1] == u_train_sb.shape[1])\n",
        "        assert (u_pred_tb.shape[1] == u_train_tb.shape[1])\n",
        "\n",
        "\n",
        "        r_int = self.compute_pde_residual(inp_train_int)\n",
        "        r_sb = u_train_sb - u_pred_sb\n",
        "        r_tb = u_train_tb - u_pred_tb\n",
        "\n",
        "        loss_sb = torch.mean(abs(r_sb) ** 2)\n",
        "        loss_tb = torch.mean(abs(r_tb) ** 2)\n",
        "        loss_int = torch.mean(abs(r_int) ** 2)\n",
        "\n",
        "        loss_u = loss_sb + loss_tb\n",
        "\n",
        "        loss = torch.log10(self.lambda_u * (loss_sb + loss_tb) + loss_int)\n",
        "        if verbose: print(\"Total loss: \", round(loss.item(), 4), \"| PDE Loss: \", round(torch.log10(loss_u).item(), 4), \"| Function Loss: \", round(torch.log10(loss_int).item(), 4))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    ################################################################################################\n",
        "    def fit(self, num_epochs, optimizer, verbose=True):\n",
        "        history = list()\n",
        "\n",
        "        # Loop over epochs\n",
        "        for epoch in range(num_epochs):\n",
        "            if verbose: print(\"################################ \", epoch, \" ################################\")\n",
        "\n",
        "            for j, ((inp_train_sb, u_train_sb), (inp_train_tb, u_train_tb), (inp_train_int, u_train_int)) in enumerate(zip(self.training_set_sb, self.training_set_tb, self.training_set_int)):\n",
        "                def closure():\n",
        "                    optimizer.zero_grad()\n",
        "                    loss = self.compute_loss(inp_train_sb, u_train_sb, inp_train_tb, u_train_tb, inp_train_int, verbose=verbose)\n",
        "                    loss.backward()\n",
        "\n",
        "                    history.append(loss.item())\n",
        "                    return loss\n",
        "\n",
        "                optimizer.step(closure=closure)\n",
        "\n",
        "        print('Final Loss: ', history[-1])\n",
        "\n",
        "        return history\n",
        "\n",
        "    ################################################################################################\n",
        "    def plotting(self):\n",
        "        inputs = self.soboleng.draw(100000)\n",
        "        inputs = self.convert(inputs)\n",
        "\n",
        "        output = self.approximate_solution(inputs).reshape(-1, )\n",
        "        exact_output = self.exact_solution(inputs).reshape(-1, )\n",
        "\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
        "        im1 = axs[0].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=exact_output.detach(), cmap=\"jet\")\n",
        "        axs[0].set_xlabel(\"x\")\n",
        "        axs[0].set_ylabel(\"t\")\n",
        "        plt.colorbar(im1, ax=axs[0])\n",
        "        axs[0].grid(True, which=\"both\", ls=\":\")\n",
        "        im2 = axs[1].scatter(inputs[:, 1].detach(), inputs[:, 0].detach(), c=output.detach(), cmap=\"jet\")\n",
        "        axs[1].set_xlabel(\"x\")\n",
        "        axs[1].set_ylabel(\"t\")\n",
        "        plt.colorbar(im2, ax=axs[1])\n",
        "        axs[1].grid(True, which=\"both\", ls=\":\")\n",
        "        axs[0].set_title(\"Exact Solution\")\n",
        "        axs[1].set_title(\"Approximate Solution\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        err = (torch.mean((output - exact_output) ** 2) / torch.mean(exact_output ** 2)) ** 0.5 * 100\n",
        "        print(\"L2 Relative Error Norm: \", err.item(), \"%\")\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HgRzd8_wfQxK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "M3ug4ztBfQxM"
      },
      "outputs": [],
      "source": [
        "# Solve the heat equation:\n",
        "# u_t = u_xx, (t,x) in [0, 0.1]x[-1,1]\n",
        "# with zero dirichlet BC and\n",
        "# u(x,0)= -sin(pi x)\n",
        "\n",
        "n_int = 256\n",
        "n_sb = 64\n",
        "n_tb = 64\n",
        "\n",
        "pinn = Pinns(n_int, n_sb, n_tb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "l4gxwi51fQxM",
        "outputId": "048a7506-4f92-447d-e58d-e39f05548b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x1200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB7sAAAPmCAYAAACVU/tdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABcSAAAXEgFnn9JSAAEAAElEQVR4nOzdfXwU9b3+/2uSLEkkQQW5UQkExJuGasVw1wNGQtVCa5RK5FTRQCnHWm31K6WVlmNpqqcatSj1HP1ZLSUUxWJUNPWmp4CIt4Q7WyXWck+wyk3Q00QJbDb7+2PYCCQbZic7uzOzr+fjwWN1dz67H0gIyb5nrssIh8MCAAAAAAAAAAAAAMBL0pK9AQAAAAAAAAAAAAAAYsWwGwAAAAAAAAAAAADgOQy7AQAAAAAAAAAAAACew7AbAAAAAAAAAAAAAOA5DLsBAAAAAAAAAAAAAJ7DsBsAAAAAAAAAAAAA4DkMuwEAAAAAAAAAAAAAnsOwGwAAAAAAAAAAAADgOQy7AQAAAAAAAAAAAACew7AbAAAAAAAAAAAAAOA5DLsBAAAAAAAAAAAAAJ7DsBsAAAAAAAAAAAAA4DkZyd4AojMM42NJJ0iqS/ZeAAAAAAAAAAAAACDO8iR9Hg6H+9hZbITD4TjvB/FiGMa/MjMzc88444xkbwUAAAAAAAAAAAAA4mrLli06ePBgQzgc7mZnPVd2u1vdGWecUbBx48Zk7wMAAAAAAAAAAAAA4mrw4MGqra21nXJNZzcAAAAAAAAAAAAAwHMYdgMAAAAAAAAAAAAAPIdhNwAAAAAAAAAAAADAcxh2AwAAAAAAAAAAAAA8h2E3AAAAAAAAAAAAAMBzGHYDAAAAAAAAAAAAADyHYTcAAAAAAAAAAAAAwHMykr0BAAAAAID3hMNhhcPhZG8DgEWGYcgwjGRvAwAAAADiimE3AAAAAMCSUCik+vp6NTQ06NChQ8neDoAYpaen64QTTlC3bt2Um5vL8BsAAACA5zHsBgAAAAAcVygU0s6dO9XU1JTsrQCwKRQKqaGhQQ0NDTrppJPUu3dvpaXRcAcAAADAuxh2AwAAAACOq76+Xk1NTUpPT1fv3r3VtWtXhmSAh4TDYR08eFANDQ3av3+/Pv30U2VlZenkk09O9tYAAAAAwDaG3QAAAACA42poaJAk9e7dWyeeeGKSdwPAjhNOOEEnnHCCMjIytGfPHn3yyScMuwEAAAB4GqfhAwAAAAA6FA6HWzu6u3btmuTdAOisbt26SZIOHjyocDic5N0AAAAAgH0MuwEAAAAAHTpyGEZ0OeB96enprf/NsBsAAACAl/EuBQAAAAAAAAAAAADAcxh2AwAAAAAAAAAAAAA8h2E3AAAAAAAAAAAAAMBzGHYDAAAAAAAAAAAAADyHYTcAAAAAADYZhtHmVyAQ0GmnnaaJEyfqzTffTPYW42rlypUyDENTp05N9lZisn379jYfp/T0dJ1yyim69NJL9fTTT3f6NaZOnSrDMLRy5crObxgAAAAAYElGsjcAAAAAAIDXTZkypfW/Gxoa9Ne//lXPPPOMnn32WS1atEjXXHNNEneHiK5du6q0tFSSFAwG9f777+svf/mL/vKXv+i2227T3XffneQdmsaMGaNXX31V27ZtU35+frK3AwAAAACuxbAbAAAAAOAqexsO6o9rdmr1tv1qPNisnMwMjRzYQ5OG5qlnbmayt9euBQsWHPX/LS0t+tnPfqaKigrdfPPNuuqqqxQIBJKzObQ65ZRT2nysFixYoO985zu65557NHnyZJ177rm2nvuuu+7SrFmz1K9fvzjsFAAAAABgBTHmAAAAAABXaAqG9NNn/qZ/u3u57vvff+i1Tfu0Yeenem3TPt375w/0b3cv10+feVdNwVCyt3pcaWlp+uUvf6mMjAzV19dr48aNyd4Sopg6daqKi4sVDof13HPP2X6eU089Veecc45OOOGEOO4OAAAAANARht0AAAAAgKRrCoY0ZX6NFtfUKRgKt3tMMBTW4pqdmjK/xhMD7y5duujEE0+UJDU3N7d5vK6uTt/73vfUv39/ZWZmqlevXrryyiu1Zs2aNscerys7Wl+0YRjKz89XKBRSRUWFzjrrLGVmZiovL0+33XabDh482O7zbdy4URMmTNDJJ5+s3NxcXXjhhXr55Zej/l4/+ugj3XPPPbrooot0+umnq0uXLurTp0/U348k5efnyzAMhcNhPfjgg/rKV76iE044Qeeff76qqqpkGEaH8e/XX3+9DMPQ73//+6jHWDVkyBBJ5sckorm5WQ8++KAKCwuVk5OjnJwcDR8+XA8//LBCobaff9E+BpHfpyQ99thjOu+885Sdna0+ffroe9/7nj799NPWYyPd4q+++qokacCAAUf1jEccOnRIDz30kIYNG6YePXrohBNOUH5+vi677DI9+eSTnf7zAAAAAACvIMYcAAAAAJB05dUbtXrbfkvHrt62X+XVtbrrSntx04mybds21dfXKxAIaNCgQUc99u6772rs2LHat2+fzj77bF155ZXauXOnnn32WVVXV+uJJ57QVVddFbe9XHPNNXrxxRc1ZswYnX322Xrttdd0zz336MMPP9SiRYuOOnbt2rUqLi5WY2OjvvzlL+vLX/6yNm3apG984xv6/ve/3+7zP/fcc7rtttt09tln67zzzlO3bt20adMmPfvss/rTn/6kP/3pT7r00kvbXXvDDTfo97//vS666CJ96Utf0qFDh3TFFVeoT58+euaZZ1RfX68ePXoctaaxsVGLFy9Wt27d9O///u+d/vNpaGiQJGVmmjH5oVBIV1xxhV588UV169ZNl1xyicLhsFasWKEbb7xRf/nLX1RVVaW0NOvXEPzkJz/RvHnzNGbMGA0aNEhvvPGGfvvb3+r999/Xq6++KsMwlJOToylTpujll1/W7t27NXHiROXk5LR5rsmTJ6uqqqr1RIRu3brpww8/1Ouvv67GxkZ9+9vf7vSfCQAAAAB4AcNuAAAAAEBS7WloUtW6XTGtqVpXpxmXnOXKDu/Gxka98847uvXWWyVJ3//+93XSSSe1Ph4OhzV58mTt27dPP/nJT3T33Xe3XrX79NNPa9KkSZo2bZpGjx6tU089tdP72bFjh0444QRt2rRJffr0kWQO4i+44AI9/vjjKi8v1xlnnNG6tylTpqixsVE///nPVV5e3vo8Dz30kG666aZ2X2PUqFF67733NHjw4KPu//Of/6zLL79cN954ozZt2nTU1ckRzzzzjDZs2NBm7bRp0/SrX/1Kf/jDH/T//t//O+qxJ598Uo2Njfr+97/f6djwpqYm/eUvf5EknXfeeZKkBx54QC+++KIGDx6s5cuXq3fv3pLMK9iLi4v17LPP6qGHHtIPfvADy6/zhz/8QX/729909tlnS5L27dunr371q3rttdf0yiuvaOzYsa2d4mPGjNHu3bt13333KT8//6jn2bZtm6qqqtS/f3+tW7fuqBMBmpqatGHDhs78cQAAAACApxBjDgAAAABIqiVrokeXRxMMhbVkbd3xD0yQI6OmI1fbfvDBB3rwwQf1wAMPHHXsypUr9e6776pfv3668847jxoAT5w4URMmTFBjY6Pmz58ft/395je/aR10S2Y89rXXXitJeu21147aW21trQYOHKif//znRz3HjTfeqBEjRrT7/Oeee26bYbUkff3rX9dVV12lLVu26L333mt37W233dbu2uuvv15paWl69NFH2zz22GOPSZL+4z/+o93ntCIYDOrdd99VaWmptm/frh49erReTf+b3/xGkjR37tzWQbdk9nLfe++9kqR58+bF9Hp33HFH66Bbkk455RTdcMMNkqRVq1ZZfp69e/dKMqPXj73iPSsrS1/96ldj2hcAAAAAeBlXdgMAAAAAkspqfPmx3t5ar5uKBx3/wASYMmVK638fPHhQO3bs0OrVq/XLX/5SZ5xxhsaPH9/6eGS4PGnSJAUCgTbPdd111+mZZ545agjdGYFAQMXFxW3uP+ussySZVysfu7fS0lKlp6e3WXP11Vdr9erV7b7OwYMH9fLLL6umpkZ79+7VoUOHJJmR7ZK0adMmnXtu2+j5yy+/vN3n69+/v8aNG6cXX3xRb775pv7t3/6t9flWr16toUOHtnZtW7Vjx452ry7v3bu3nn76aZ144onauXOndu7cqZ49e7YbvX7ZZZfppJNO0ubNm/Xxxx8fdRJBR9p7rvY+BsdzzjnnqGvXrnrhhRd07733avLkyTrttNMsrwcAAAAAP2HYDQAAAABIqsaDzQld54QFCxa0uW/Dhg266KKLdPnll+u9995rvar3n//8pyS1iaeOiNz/4YcfxmVvffr0aXdwnZubK8kcUkdE9ta/f/8O93asd999V5dffrm2b98edR+RXuxj9evXL+qaG264QS+++KIeffTR1mF35EpvO1d1d+3aVaWlpZKk9PR0nXTSSbrgggv0rW99qzUO/Xh/BoZhqH///vr000/14YcfWh529+3bt8197X0Mjqdbt2569NFHdf311+snP/mJfvKTn+iss85ScXGxrrvuOo0aNcrycwEAAACA1xFjDgAAAABIqpxMe+dh212XKEOGDNH3vvc9NTc36+GHH7a8rr0rj4+npaUl6mNpac7+6B8OhzVp0iRt375dN9xwg9555x3961//UktLi8LhsH7605+2HteerKysqM/9jW98Q3l5eVqyZIn+9a9/qampSYsWLVJOTo6uvvrqmPca6cResGCBfve73+nXv/61Jk+eHHPvt52PUTw/DldffbW2bt2qRx99VFdddZU+/fRTPfLIIxo9erR+9KMfxe11AAAAAMDtGHYDAAAAAJJqxIDuttaNHNjj+Acl2YABAySZEd4RkcjpHTt2tLsmcnX06aef3npfly5dJEmNjY3trqmri09/+amnntrh3tq7/+9//7v+/ve/a+jQoXr44Yf1la98Rbm5ua0D4a1bt9reT3p6uv7jP/5Dn3/+uR5//HE9/fTT+uSTT/Ttb3+79aroeDvex+fIx478GCVaz549NX36dC1ZskQff/yxXnrpJXXr1k1z587Vxo0bk7YvAAAAAEgkht0AAAAAgKSaNCxPgfTYrpQNpBuaNDTPoR3FT2TQm5OT03rfhRdeKEl66qmnFAqF2qxZtGjRUcdJXwyh//GPf7Q5fv/+/Vq/fn1c9ht5zaeffrrdq8WffPLJNvd98sknktqP6f7kk0/0l7/8pVN7mj59ujIyMvToo492KsLcqn79+qlfv37au3evli9f3ubxF154QZ988okGDRpkOcI8VpGTG5qbrUX1G4ahcePG6Zvf/KYkMewGAAAAkDI8Pew2DCPbMIxfGobxD8MwmgzD+KdhGPMNw4jp1GrDMC4yDGOOYRgvGIax1zCMsGEY2y2sSzcM41bDMN41DOPA4bVLDMP4ku3fFAAAAACkmF65WSotbDso7UhpYZ565mY6tKP42LBhg377299KMuO4I8aMGaNzzz1X27dv189//vOj4r2fffZZPfPMM8rJydG0adNa7x8wYID69eund999V88991zr/Z999pmuv/56/etf/4rLnseMGaNzzjlHW7Zs0Z133nnUY4888ojeeuutNmsGDRqktLQ0rVix4qgr2JuamnTDDTdo//79ndrTqaeeqssvv1wbNmzQq6++qvPOO0/Dhw/v1HMezw9/+ENJ0owZM7R3797W+z/++GP9+Mc/liTdcsstjr1+5OryDz74oM1jGzZs0DPPPKNDhw4ddf/+/fu1evVqSVJenvtPBAEAAACAeHB3wVkHDMPIkrRC0khJH0l6TlK+pO9IuswwjJHhcNhqVto8SV+J8fXTJD0l6VuSPpX0gqRTJJVK+qZhGMXhcLgmlucEAABo1bhHWl8pbX9DOtQodcmR8kdLF5RJOb2SvTsAiLs5JYO1de9nWr3t+IPREQO6a05JQQJ2Zd3UqVNb//vQoUPasWOH3n77bbW0tKikpETXXXdd6+OGYejxxx9XcXGxfvWrX+nZZ5/V+eefr507d+qNN95QRkaGfve737VezR0xZ84cffe739XEiRNVVFSknJwc1dTUqFu3brriiiuOGoLblZaWpgULFuhrX/ua5syZo6qqKn35y1/W5s2btXbtWt1444166KGHjlrTq1cvffe739Wjjz6qr3zlKxo7dqyys7P12muvKRQKaerUqVqwYEGn9nXDDTfomWeekSRdf/31nXouK2699VatWLFCL730ks4880yNHTtW4XBYy5cvV0NDgyZMmKAbb7zRsde//PLLVVlZqWuuuUaXXnqpTjzxREnSY489ph07dmjixIk68cQTNXToUPXp00effvqpVq1apYaGBpWUlOirX/2qY3sDAAAAADfx7LBb0n/KHHS/JenScDjcKEmGYcyQ9GtJ8yWNsfhc/ytzcL1G0i5JVvK+pskcdG+SdGE4HN59+PUnSqqS9LhhGF8Kh8PWMscAAAAkKXhAeuk26Z0npJbg0Y9tfUVaebc0ZLI0rkIKZCVnjwDggKxAuiqnDVd5da2q1tUpGAq3OSaQbqi0ME9zSgqUFUhPwi6jq6ysbP3vtLQ0nXTSSSoqKtJ1112nqVOnKi3t6GC1c889V+vXr9edd96pl19+WVVVVTrxxBM1YcIE/fSnP233yuVp06YpLS1Nv/71r/XGG2/o5JNPVklJie6++2796Ec/itvvZcSIEXrrrbc0e/ZsrVq1Slu3btV5552n6upqde3atc2wW5IefvhhnXPOOfrd736n5cuX68QTT9TFF1+s//qv/9Lvf//7Tu/pwgsvVCAQUEZGhiZPntzp5zue9PR0Pf/883rooYe0YMEC/fnPf5YkFRQU6Dvf+Y6+973vtfmYxtOVV16p+++/X48++qiqq6t18OBBSeawe+TIkbrzzju1YsUKffDBB3rttdd08skn67zzztN3v/tdXXvttY7tCwAAAADcxjgyLs0rDMPoImmPpBMlXRAOhzcc8/hfJZ0naWg4HF4X43P3kXml+I5wOJzfwXG1kr4k6VvhcHjpMY89J+lySaXhcPjpWF7/mOfZWFBQUEDXFgAAKSJ4QFpUKu14/fjH9h8tXVslBbKd3xeAlNfS0tIap3z22Wc7OuSTpL0NB7VkbZ3e3lqvxoPNysnM0MiBPTRpqPujy+GMxYsX65prrtGUKVM6fZU4Ev93GgAAAACiGTx4sGpra2vD4fBgO+u9emX3KJmD7i3HDroPq5I57C6RFNOw2wrDMAbIHHQfkBlf3t7rX3749W0PuwEAQIp56TZrg27JPO7lWVLJPGf3BABJ0DM3UzcVD9JNxYOSvRW4QDAYVEVFhSTppptuSvJuAACdQl0TAACIM68OuyP92uujPB65/zyHX/+9cDgcbOdxp18fMdrbcFB/XLNTq7ft58oQAIA7New2o8tjseFxqXg2bwoBAHzp+eef19KlS1VTU6ONGzdqwoQJGjZsWLK3BQCwg7omAIAPMGtyJ68Ou/sdvt0V5fHI/f298PqGYUTLKT8jlk2hraZgSOXVG1W1blebzr/XNu3TA8v+4drOPwBAitmwsO2bPsfTEpTWL5SKZjqzJwAAkmj9+vX6/e9/r5NPPlnXXHONHnzwwWRvCQBgh5W6ppagtG6BtG8zdU0AANdh1uRuXi1lyjl8+3mUxz87fJvr09eHBU3BkKbMr9Himro2X3wigqGwFtfs1JT5NWoKhhK8QwAAjrD9DZvrLMaeAwDgMb/4xS8UDoe1f/9+Pf744+revXuytwQAsMNOXRMAAC7BrMn9vDrs9pVwODy4vV+StiR7b15WXr1Rq7ftt3Ts6m37VV5d6/COAADowKHGxK4DAAAAAKfZrWtq3OPMfgCgI417pFX3SgsnSI9dbN6uuo+vSSmOWZP7eXXYHXlX94Qoj3c9fNvg09fHcexpaFLVumgp8+2rWlenvQ0HHdoRAADH0SXn+MfEcx0AAAAAOK0zdU0AkCjBA9LzN0tzC6QVd0pbX5F2rTFvV9xh3l99ixRsSvZOkWDMmrzBq8PunYdv+0Z5PHL/Dp++Po5jyZrocRLRBENhLVlb59COAAA4jvxRNteNju8+AAAAACBeqGsC4HbBA9KiUml9ZfSTc1qC0roF0qKJ5vFIGcyavMGrw+6/Hr69IMrjkfv/5vDrf9kwjEASXh/HYTVS4lhvb62P807gasTSAHCTIWVSWnvfVnQgLSBdUObMfgAAAACgs6hrAuB2L90m7bB4gs2O16WXZzm7H7gKsyZv8Oqw+w1J/yfpDMMwzm/n8dLDt9VOvHg4HN4m6X1J2ZK+mejXx/E1HmxO6Dp4DLE0ANwot7d0/jWxrRkyWcrp5cx+AAAAAKCzqGsC4GYNu6V3nohtzYbHuVgqhTBr8gZPDrvD4fAhSf99+H//xzCMSEe2DMOYIek8Sa+Gw+F1R9z/A8Mw/m4Yxl1x2sbcw7f3GIbR+i6zYRhXSrpc0mZJz8XptRCjnMyMhK6DhxBLA8DNxldI/S3GkvcfLY2rcHY/AAAAANAZ1DUBcLMNC6O/RxxNS1Bav9CZ/cB1mDV5gyeH3YfdKWm1pH+TtMkwjD8ahvG2pF9L2itp2jHHnyLpbEmnHvtEhmFMNwzj7cPrXzh896mR+w7/OjYyfb6kZyWdKenvhmE8ZRjGK5KqJB2QdG04HObUjSQZMaC7rXUjB/aI807gOsTSAHCzQLZ0bZVUODV6pHlawHz82qelQFYidwcAAOwKBaWGj6V9m6W9H5i3DR+b9wOAn1HXBMDNtr9hc53F95fhecyavMGzw+5wONwkqVjSHZI+lzRBUn9JCyRdEA6Ht8bwdH0ljTj8KzLU7nLEfSMkdTvm9VskXSXpR5L+KekySedKelrS0HA4vNrGbwtxMmlYngLpRkxrAumGJg3Nc2hHcAViaQB4QSBbKpknzaiVxt4uDSyW+g4zb8febt5fMo9BNwAAXtDSIn26U9q9UWr4SDrUIAU/N28bPjLv/3SneRwA+BF1TQDc7FBjYtfBc5g1eYOnr6MPh8MHJP388K/jHfsLSb+I9bHjPGdIZpz53OMdi8TqlZul0sK+WlxTZ3lNaWGeeuZmOrgrJF1nYmmKZjqzJwCIJqeX+bWHrz8AAHhTS4u0f8tx3gwNS5/XS80Hpe5nSGmevSYBAKIbXyHVb7GWtEddE4BE6pKT2HXwHGZN3sBPUfCtOSWDLUdMjBjQXXNKChzeEZKOWBoAAADvcXn8s2EYMozYzvR3k5UrV8owDE2dOjWp+1iwYEHrn2XkVyAQUN++fXX11Vdr/fr1nX6N/Pz8xH6s/rXL+lU/hxrN4wHAj6hrAuBW+aNsrhsd333A1Zg1uR/DbvhWViBdldOG6+rh/ZSR1v4bGhlphq4e3k+V04YrK5Ce4B0i4YilAQAA8I4UjH82DEP5+fnJ3kZSnXHGGZoyZYqmTJmiK664QhkZGXryySc1cuRIPf/888neXqvjfqxCQenz/bE96ef7XXMSBwDEHXVNANxoSFn0k3CiSQtIF5Q5sx+4ErMm9/N0jDlgTfjwr2iPIWUQSwMAAOANxD8nzPDhw/X+++/rxBNPTPZWJEmjR4/WggULWv8/GAzqxhtv1GOPPaYbbrhB48aNU5cuXWw99/LlyxUMJmiY/Hm9Yv958/DndG4fJ3YEAO5AXRMAN8ntLZ1/jbS+0vqaIZPNr2VIQcya3IphN3yrKRjSlPk1Wr0t+tn0zS3S4pqd2rq3kTNuUkH+KGnrKzbWEUsDAACQUB+9I21YJH30V/Nq7sAJ0mnnS2d/QzrhmPi4SPzzSf2SsVPPO+GEE3TOOeckextRBQIBPfDAA3ryySf10UcfqaamRqNH2/v+/Iwzzojz7jpw0GY61MFGKTe+WwEAAEAHxldI9VukHRaqLPuPlsZVOL8nuAqzJvfj1Hf4Vnn1xg6/+Bxp9bb9Kq+udXhHSDpiadC4R1p1r7RwgvTYxebtqvvM+wEAQPIFD0jP/UD63SXS2t9JH66V9tSat2sek56YJK36tXk195FcFv+8fft2GYahMWPG6MCBA5o1a5b69++vzMxMDRo0SBUVFQqHvzjzP9JXLUk7duw4qrd6zJgxRz33559/rrvuuktDhgxRTk6OcnJyNHLkSFVWtn81SiRu+9ChQ/rlL3+pc845R5mZmZowYYKkjju7m5ub9eCDD6qwsLD1tYYPH66HH35YoVCozfFjxoyRYRjavn27nnjiCY0cOVK5ubk66aSTbP05RnTt2lVnnXWWJKmurq71/vr6ev34xz/WmWeeqaysLHXv3l3jxo3T//7v/7b7PO11djv1sdq7d69m/eo3KhgzUTlnjtKJ5xTprNETVHbz7arZ8F7032y47Z8rAAAAHBTIlq6tkgqnRn/vOC1gPn7t09QtpCBmTe7Hld3wpT0NTapatyumNVXr6jTjkrPUMzfToV0h6YilSV3BA9JLt0nvPCG1HPNG+NZXpJV3mx/rcRV8wwoAQLIED0iLSju+oqKlWfp7tfR/O6Xx90gZke/d3Rn/fOjQIV166aWqra3VmDFj9Nlnn+nVV1/VrFmz1NDQoDvvvFOSNGjQIE2ZMkWVlZXq2rWrSktLW5/jyKuu9+zZo0suuUR/+9vf1KdPH1100UUKh8N68803NXXqVK1du1YPPvhgm320tLRowoQJWrVqlS666CKdd9556tGjR4d7D4VCuuKKK/Tiiy+qW7duuuSSSxQOh7VixQrdeOON+stf/qKqqiqltRMff9ddd+mxxx7TqFGjdNlllx01oLaroaFBkpSZaX7MP/zwQxUVFWnr1q3q16+fJkyYoL1792rZsmX685//rLlz5+rWW2+1/Pzx/Fg1NDRoxPhJ2rZjl/JO66NLikYqIz1dO//5sZ58/s8a2P90DR/y5fY3YnAFCAAAQMIFsqWSeVLxbGn9Qmn762aCVJccM/XzgjLeI05RzJq8gWE3fGnJmjoFQ7F1JARDYS1ZW6ebigc5tCu4ArE0qcfSG+dBad0Cad9m80zOQHbCtgcAAA576TZr36NJZrz5m/8tFf3oi/tcGP/81ltv6aKLLtK2bdvUrVs3SdLatWs1cuRI3X///Zo1a5ZycnI0evRojR49WpWVlTrllFOO6qw+0ne+8x397W9/0y233KKKiorWwe/u3bt12WWX6b//+7/1zW9+U+PGjTtqXV1dnTIzM/XBBx/o9NNPt7T3Bx54QC+++KIGDx6s5cuXq3fv3pKkjz76SMXFxXr22Wf10EMP6Qc/+EGbtQsXLtSKFSt00UUXWf2j6lBtba22bt0qSTrvvPMkSTfccIO2bt2qa665Rr///e9be7xff/11ff3rX9ePf/xjFRcX6/zzz7f0GvH8WFVVVWnbjl26/NKL9Ozvfn3UCQF76z/R7r310TeSmWNpvwAAAHBATi+paKb5CxCzJq8gxhy+ZDVS4lhvb+3gTQf4A7E0qSeWN853vC69PMvZ/QAAgLYadpsJLLH4x0tmfHmEC+Of09LS9Mgjj7QOTyVp6NChGj9+vD7//HOtXbvW8nO98847evHFFzVs2DDNnTu3ddAtSb1799Zvf/tbSdLDDz/c7vq77rrL8qBbkn7zm99IkubOnds66JakU089Vffee68kad68ee2u/e53vxuXQfdnn32m5cuX68orr1QoFNLFF1+sQYMGaevWrfrTn/6knJwcPfjgg62DbkkaPXq0brjhBoVCIf3P//yP5deK58dq7969kqSxo4a3ufK9Z4+T9eVzor3pZUgndHzFPQAASBCq8ACIWZNXcGU3fKnxYHNC18FjiKVJHXbeON/wuPm5wecAAACJs2Fh26qR42lplj54URpyrfn/Lox/7t+/v84+++w290f6pz/66CPLzxXpoZ4wYUK70eGRDu+ampo2jxmGoZKSEsuvtXPnTu3cuVM9e/bUpZde2ubxyy67TCeddJI2b96sjz/+WH36HB0ff/nll1t+rWNVVla22z8+dOhQ/eEPf5BkXr0tSePGjVP37t3bHHvddddp7ty5eu211yy/bjw/VoWFhZKkex/5g3r37K5vfm20cnO6Hn/hCd2l9Cgn5AIAgMSgCg/AEZg1eQPDbvhSTqa9T2276+BRxNL4n603zoPmSRB8XgAAkDjb37C37p/vfDHsdmH8c9++fdu9PzfXzFs/ePCg5efavn27JGn27NmaPXt21OOampra3NerV6+jrgQ/nn/+85+SzAFwewzDUP/+/fXpp5/qww8/bDPs7tevn+XXOtYZZ5yh0aNHS5ICgYB69+6tCy+8UJdccknrkD+yv/z8/HafI3L/hx9+aPl14/mx+trXvqZbb71VDzzwgK6+8afKyMjQBeeeo0suHKFp375CA/u381pdcqRu7e8BAAAkCFV4AI7BrMkb+NOGL40Y0F2vbdoX87qRA4mMA3zF7hvn219n2A0AQCIdarS3Lvj54f9wZ/xze1dg29XS0iLJjOk+44wzYlqblRX/q44Mw3Dk9UaPHh21s9yqjvYWTTw/VpIZ//69731Pzy1dqmV/fkFvvL1GNRve0z0PV2rx/9ylid/8WmS35hXd3fpKcd4DAMCDGvdI6yvN9zNIIUw8O1V4Je3XugDwB2ZN3sCwG740aVie5i3fpGAobHlNIN3QpKF5Du4KQMLZfePc7joAAGBPF5tXZQdOMG9TIP45cuXxhAkT9KMf/cjR1zrttNMkSTt27Ih6TOSxWHrA4+V4+4tcBZ+MvR3p7LPP1k9uu00/ue02NX3WoP9+4D79+D9/qe//7C5N/NYEM43ghB6+/9wFAFhAdHbyUYUHoB3MmryB04bhS71ys1RaGFsEXGlhnnrmWo/2A+ABdt84t7sOAADYkz/K3rrTzvdV/HMgEFBzc/vdbpdccokk6dlnn3V8H/369VO/fv20d+9eLV++vM3jL7zwgj755BMNGjSoTYR5IkRizl9++WV9+umnbR5ftGiRJOnCCy90bA8dfazak9U1VzNnl+vUU0/V3n37taelm5Tbh0E3AOCL6Oz1ldGr2CLR2Ysmmscj/jpThQfAt5g1eQPDbvjWnJLBGjGgu6VjRwzorjklBQ7vCEDC2X3jPH90fPeBthr3SKvulRZOkB672LxddZ95PwAg9Qwpk9JiHPqlZUjnT5a6n+Gb+OfTTjtNu3fvbneAO2LECF1yySV64403dNNNN+lf//pXm2P++te/6uWXX47LXn74wx9KkmbMmKG9e/e23v/xxx/rxz/+sSTplltuictrxWrgwIH65je/qYaGBt1yyy0KBr94Y/qtt97Sww8/rPT0dN10002O7aGjj9XSpUv19ttvt7l/3bp12r17t3JycnTSSSc5tjcAgMfYic5G/HWmCg+ArzFrcj9/vCMAtCMrkK7KacN19fB+yojymZ6RJl09vJ8qpw1XViA9sRsE4Dxbb5wHzC4sOCN4QHr+ZmlugbTiTjOObdca83bFHeb91bdIwaZk7xQAkEi5vaXzr4ltzfnXSKdf4JtBtyRdfvnlam5u1gUXXKBrr71W06dP17333tv6+KJFizRkyBA99NBD6t+/v4qLizV58mRddtll6tevn84///y4DbtvvfVWjR8/Xn/729905pln6sorr9S3vvUtnXXWWXr//fc1YcIE3XjjjXF5LTseeeQRDRgwQAsXLtSZZ56pq6++WhdffLEuvPBCffbZZ7rnnnt0/vnnO/b6HX2sVq5cqa9+9avq27evSkpKNHnyZBUXF2vEiBFqaWlReXm5unTp4tjeAAAeYjc6mxPF448qPABRMGtyPzq7kQLCkozDt8cyErwXAAkVeeN8faX1NUMm07XklEg0W0dnrEei2fZtlq6tkgLZCdseACDJxldI9VusXdnUf7Q0/t7jH+cxd911l8LhsJ577jn98Y9/VHNzsy666KLWK6l79eqlN998U48++qiefPJJbdiwQW+++aZ69+6tgQMH6uabb9a3v/3tuOwlPT1dzz//vB566CEtWLBAf/7znyVJBQUF+s53vqPvfe97SkviiQann3661qxZo7vuuktLly7VM888oxNOOEFf+9rX9KMf/UiXXnqpo6/f0cdq6tSpysjI0KpVq1RTU6P/+7//U58+ffSNb3xDt9xyi772ta85ujcAgId0Jjq7aKYze0pVVOEBOC5mTW5lhMPWS9WRWIZhbCwoKCjYuHFjsrfiSU3BkKbMr9HqbfuPe+yIAd054wbwKysD1oj+o6Vrn5YCWc7vKxU9f3NsJx4UTpVK5jm2HQDoUOMe82vW9jfMqzW65Jg1FxeUpeRJUS0tLfrggw8kSWeffbZzQ87gATOac8Pj7b/xmxYwT0wbV8G/10AnJOzvNACgYwsnmElnsRpYLJUtjfduUtuqe80EuliNvZ0TDwCfY9bkvMGDB6u2trY2HA4PtrOen2bgW+XVGy198ZGk1dv2q7y61uEdAUiKQLZ5hXDh1OiR5mkB83EG3c4hmg2AV1C3kFyBbPNEpxm15huHA4ulvsPM27G3m/eXzOPfawAA4A9EZ7sHVXgAomDW5H7EmMOX9jQ0qWrdrpjWVK2r04xLzlLP3EyHdgUgaSJvnBfPNqO+tr/OVXqJRjQbAC+gbsE9cnqZX//5NwAAAPgZ0dnuQRUegHYwa/IGruyGLy1ZU6dgKLaI/mAorCVr6xzaEQBXiLxxXrZUmr7MvC2ayQ8mibD9DZvrLMTPA0C8vHSbtdoLyTzu5VnO7gcAAAD+lj/K5rrR8d0HTOMrzIo7K/qPNqt1APgasyZvYNgNX7IaKXGst7fWx3knAABJRLMBcD/qFgAgNTTuMXtZF06QHrvYvF11H1/PASQH0dnuQhUegGMwa/IGYszhS40HmxO6DgBwHESzAXA76hYAwN+CB8wEj3eeaPv1fusr0sq7zTjacRUMLwAkDtHZ7kMVHoAjMGvyBobd8KWcTHuf2nbXAQCOI3+U+SZizOuIZgOQIJ2pW2DYDQDuFjwgLSrtuKqiJSitWyDt22xe1RfITtj2AKS48RVS/RZrdTpEZydOpAqP7/WBlMasyRuIMYcvjRjQ3da6kQN7xHkn7SAyDUAqIpoNgNtRtwAA/vXSbdaGSJJ53MuznN0PAByJ6GwAcC1Xz5rQilML4EuThuVp3vJNCobCltcE0g1NGprn3KaITAOQyohmA+B21C0AgD817DZ/Do/FhsfN+Fq+FwWQKERnA4AruXLWhDa4shu+1Cs3S6WFfWNaU1qYp565mc5sKBKZtr4yehdkJDJt0UTzeADwm/EVZuSaFUSzAUi0/FE211G3AACutmFh9J/Do2kJmsMmAEi0SHR22VJp+jLztmgmg24ASBLXzZrQLobd8K05JYMtR0yMGNBdc0oKnNsMkWkAQDQbAHejbgEA/Gn7GzbXWfwZHgAAAPHnojpYV82a0C5izOFbWYF0VU4brvLqWj21tk7NLW1jJjLSDF01NE9zSgqUFUh3ZiNEpgHAF4hmA+BW1C0AgD8dakzsOgAAANjnwjpY18yaEBXDbqSA8OFf0R5zWGci04pmOrMnAEi2SDQbX+cAuMn4Cql+i7VEHuoWAMAbuuQkdh0AAADsidTBdvQzeaQOdt9mM0EykJ2w7SV91oSoiDGHbzUFQ5oyv0aLa+rU3NL+Mc0t0uKanZoyv0ZNwZAzGyEyDQAAwBuoWwAA/8kfZXPd6PjuA8nloihUAAAQhUvrYF0za0JUDLvhW+XVG7V6235Lx67etl/l1bXObITINAAAAO+I1C3MqJXG3i4NLJb6DjNvx95u3l8yj0E3AHjFkLLoJzBFkxYw63XgfcED0vM3S3MLpBV3mvGnu9aYtyvuMO+vvkUKNiV7pwAApDa7dbAJOHHNNbMmRMWwG760p6FJVet2xbSmal2d9jYcjP9miEwDAADwnkjdQtlSafoy87ZoJh3daMMwDBmGEZfnys/Pt/Vcdtcda+XKlTIMQ1OnTrW8ZsyYMa1/BpFfOTk5Ou+883T77bfrX//6V8L3BBwlt7d0/jWxrRkyma/3fhCJQl1fGb1eLhKFumiieTwAAEiOztTBOshVsyZExbAbvrRkTZ2Codg6EoKhsJasrYv/ZohMAwAAAGDT9u3bZRiGxowZk+ytdOjrX/+6pkyZoilTpuirX/2qtmzZojvvvFMjRozQJ598kuztSZIWLFggwzD0i1/8ItlbQaKNr5D6W/wZu/9oaVyFs/tBYrg0ChUAALTDpXWwrpo1IaqMZG8AcILVSIljvb21XjcVD4rvZoaUSSsrYjsricg0AADco3GPeUXQ9jfMmpEuOeZJaReUcdUX4JB9B/bpmU3PaO3Ha/VZ82fqmtFVw/oM07fO/JZOyT4l2dtzzPLlyxUMxng1QyfWxdOsWbOOGshv27ZNY8eO1d///nf913/9l+677z5bzzt8+HC9//77OvHEE+O0U6SkQLZ0bZU5zNzwePs/n6cFzCu6x1VQVeEHdqNQi2fz/R0AAMng0jpYV82aEBXDbvhS48HmhK7rUCQybX2l9TVEpgEAkHzBA+YVQe880fZN8a2vSCvv5k1xIM6ampt0d83dem7Lc2puOfp787c+eksP/fUhTRg0QbOGz1JmemaSdumcM844I6HrnDRgwACVl5drypQpWrp0qe1h9wknnKBzzjknzrtDSgpkSyXzzGHm+oXmVUCcxOZfnYlCLZrpzJ4AAEB0Lq2DddWsCVERYw5fysm0dx6H3XXHRWQaAADeQscjkHBNzU36/rLv6+lNT7cZdEc0tzSr6h9VuuEvN6ipuSnBO7TuyOjxAwcOaNasWerfv78yMzM1aNAgVVRUKBxuG4V3bPf2L37xCw0YMECS9Oqrrx7Vi31kh3W0zu4XXnhB06ZN05e+9CV169ZNXbt21Ve+8hX96le/0sGDznfIDRkyRJJUV3d0hN9bb72lK664Qj179lRmZqby8/N144036p///Geb54jW2f2LX/xChmFowYIFevfdd3X55Zfr5JNPVteuXXXRRRfpzTffPOr4MWPG6Dvf+Y4kqby8/Kg/ywULFrQe9+abb2rChAmtH68+ffpo+PDhmjVrlhobnb1qBAmS08scZpYtlaYvM2+LZjLo9huXRqECAIAoXFoH67pZE9rFsBu+NGJAd1vrRg7sEeedHBaJTCucakajtSctYD5+7dNcHQYAQLLR8Qgk3N01d2vt7rWWjl27e60q1rj/BNFDhw7p0ksv1aOPPqqhQ4equLhYH374oWbNmqXbb7/9uOvPP/98TZw4UZLUu3fv1k7sKVOmaPTo47+p893vfldPP/20unfvrvHjx+vCCy9UXV2dZs+erW984xsKhUKd/j12pKGhQZKUmfnFVfiLFi3ShRdeqOeff15nn322rrzySmVmZurhhx/WBRdcoL///e8xvcbatWs1cuRIbd++XV//+td15plnatWqVfra176m9957r/W4cePGadQo8w20r3zlK0f9WQ4aZMYLVldXt+7t1FNP1ZVXXqkhQ4Zo//79qqio0L59+zr7RwIgUeIRhdq4R1p1r7RwgvTYxebtqvvM+wEAQHwNKYs+O4kmAXWwrps1oV2cWgBfmjQsT/OWb1Iw1PZqiWgC6YYmDc1zblNEpgEA4A10PAIJt+/APj235bmY1izdvFQ3nX+Tqzu833rrLV100UXatm2bunXrJumL4ez999+vWbNmKScneuzehAkTdP755+vpp5/WOeecc9QVyFY88sgjuvTSS5Wdnd16X0NDg6655hr96U9/0uOPP66yMufeHKqurpYknXfeeZLMK7yvv/56SdJzzz2nyy+/XJLU0tKiH/3oR3rggQd03XXXac2aNZZf43/+5380b9483Xzzza333XrrrXrggQd0zz33aOHChZLMTvE+ffrojTfe0IQJE/SLX/yizXPdd999amlpUVVVVetJBhFr1qxRjx68YQV4RmeiUKmyAQAg8VxaB+vKWRPa4Mpu+FKv3CyVFvaNaU1pYZ565iag94/INAAA3K0zHY8AbHlm0zNRo8ujaW5p1rObnnVoR/GRlpamRx55pHXQLUlDhw7V+PHj9fnnn2vtWmtXstt1xRVXHDXolqTc3Fzdf//9ksyBsxP++c9/6te//rXmzp0rSfr+978vSXrsscd04MABTZo0qXXQLZl/TnfffbdOO+00rV27Vm+8YT1+eNSoUUcNuiXpP//zPyVJq1atimnfe/fulSRdfPHFbR4bNmyYcnNzY3o+AElkNwq130iqbAAASBYX1sG6etaEVgy74VtzSgZbjpgYMaC75pQUOLwjAACQdFbiKOl4BBJu7cf2hr5rPrZ+BXAy9O/fX2effXab+8866yxJ0kcffeT4HjZt2qR58+bphz/8oaZNm6apU6fqjjvuaH0sXoqLi1s7sE8//XTNnDlTwWBQP/vZzzR58mRJ0muvvSZJrf9/pMzMTF111VVHHWfFpZde2ua+Hj16qHv37jH/+RYWFkpS69XlLS0tMa0H4CJ2o1Drt1BlAwBAsri0DpZZk/sRYw7fygqkq3LacJVX1+qptTvV3M77FBlp0lVD+2lOSYGyAumJ3yQAAEiMWOIo49HxCCAmnzV/ltB1idK3b/tXAESuED548KBjrx0OhzVz5kzdf//9Cofbj9yLdGrHw9e//nX16dNHhmEoOztbgwYN0uWXX97ahy2ZV3xLUn5+frvPEbn/ww8/tPy6Hf0Z79+/3/LzSNKvfvUrvfvuu6qurlZ1dbVOPvlkjR49WpdffrmuvfZaZWURVwx4hp0o1C9fKb33TGyvQ5UNAADx5cI6WGZN7sewGykgLMk4fHssI8F7AQAACRc8YMZRdnSVTiSOct9mKSM7+nEdsdsNCUBdM7omdF2ipKUlL0ztj3/8o+bOnau8vDzdf//9+upXv6qePXsqEAjo0KFDyszMjDoEt2PWrFkaM2ZMp57DMGL/+Syef8Z5eXlau3atVqxYoT/96U969dVXWwff99xzj9566y16uwEvGV9h/Urt/qOlkwfYr7IpmmlvjwAAoH2ROlhX/RvLrMmtiDGHbzUFQ5oyv0aLa+rU3NL+mzjNLWEtrtmpKfNr1BQMJXiHgE1WIngBAF946bbY4igP2bzSMd9irxSANob2GWpr3bA+w+K8E/949lmzz/zhhx/WxIkTddpppykQMKMAt27dmpQ9nXbaaZKkHTt2tPv49u3bJUmnn356orbURkZGhi699FL95je/0V//+ldt375dY8eO1aZNm1RR4XwnIIA4ijUKtW61vdehygYAAF9j1uR+DLvhW+XVG7V6m7XYutXb9qu8utbhHQGdFDwgPX+zNLdAWnGnGbu7a415u+IO8/7qW6RgU7J3CgDu0bDbjC6PxcfvSkaMAUhpATNKC4AtV555pTLSYvt7l5GWoW+d+S2HduQeXbp0kSQ1NzfHtO6TTz6R1H7M95IlSzq/MRsuvPBCSdLixYvbPHbo0CE99dRTRx0Xb3b+LPv376/bbrtNkvTee+85si8ADopEoc6olcbeLg0slvoOM2/H3m7eXzLP7PykygYAALSDWZP7MeyGL+1paFLVul0xralaV6e9Dc515gGdEongXV8ZPVYtEsG7aKJ5PABA2rDQRhxls3TqubGtGTKZrkagE07JPkVXnHFFTGsmDJqgU7JPcWhH7nHKKacoEAhoy5YtCoWsXyFw1llnSZJ++9vfHhVX/tprr+nee++N+z6t+O53v6vs7Gw9+eSTeuGFF1rvb2lp0c9+9jN9+OGHKiws1KhRoxx5/ciV5R988EG7j99///36+OOP29z/4osvSjJjzgF4VCQKtWypNH2ZeVs08+jv3+xW0lBlAwCAbzFr8gaG3fClJWvqFAzF1j8XDIW1ZG2dQzsCOinWCN6XZzm7HwDwiu1v2FuX2c3sbrSi/2hpHNG2QGfNGj5LQ3tbizMf2nuoZg1Pje93unTponHjxunjjz/WV77yFZWVlWn69On6/e9/3+G6m2++WV27dtVDDz2kL3/5y7r66qtVVFSkiy66SDfccEOCdn+0fv366ZFHHlFLS4tKSkp04YUX6pprrlFBQYF+/etfq3fv3lq0aJFjrz9y5Ej16tVLVVVVGjNmjKZNm6bp06frzTfflCSVl5fr9NNP1wUXXKB///d/16RJk3T22Wdr3rx56t69u2bOdFNfIIC4y7d5og1VNgDQFjWM8AlmTd7AsBu+ZDVS4lhvb62P806AOLATwbvhcb55BADJfqxk8PPYOh4DWXZ3COCwrIwsPXzxwyo9qzRqpHlGWoZKzyrV/3fJ/6fM9MwE7zB5HnvsMV133XWqr6/XE088od/97nd69dVXO1xz1llnae3atSopKdG+ffv0/PPPq7GxUY888kjSruyWpOuuu06vvfaaLrvsMr3//vuqqqrSgQMH9P3vf1/r1q3TOeec49hrZ2Vl6YUXXtAll1yid955RwsWLNDvfvc7/eMf/5AkPfjgg/r2t7+tzz//XC+99JJefvllZWRkaMaMGfrb3/6mM88807G9AXCBIWXRv++LhiobADgaNYzwGWZN3mAcGWcGdzEMY2NBQUHBxo0bk70Vz/nWQ29ow85PY143pN9JevZGZyLzANtW3Wt+cxirsbebsWwAkMoWTjB/qI7VwGIz3lIyTx5av1Da/ro5PO+SY17Bc0EZ0eVIGS0tLa3Rz2effbbS0pw9b3rfgX16dtOzWvPxGn3W/Jm6ZnTVsD7D9K0zv5US0eWA0xL9dxrwjOdvNuvDrCqcanZ+AwC+qGG0kk7Zf7R5gnkg2/l9AZ3ArCkxBg8erNra2tpwODzYzvr2T5cHPC4n096ntt11gKPsRvBuf51hNwDkj7I37D4yjjLS8cjXVCBhTsk+Rf9x3n/oP877j2RvBQCQSsZXSPVbrA9qqLIBgC/YqWHkhCG4HLMmb+DUXfjSiAHdba0bObBHnHcCxIHdCF676wDAT4ijBOB3oaDU8LG0b7O09wPztuFj834AQGwC2VTZAIAd1DDCp5g1eQPDbvjSpGF5CqQbMa0JpBuaNDTPoR0BndAlJ7HrAMBPcntL518T25ohk4knB+B+LS3Spzul3Rulho+kQw1S8HPztuEj8/5Pd5rHAQCsC2SbVxrOqDXrwQYWS32HmbdjbzfvL5nHoBsAjrRhodQS48mWLUGzMgxwMWZN3sCwG77UKzdLpYV9Y1pTWpinnrmZDu0I6IR8m90eR0bwAkAqG19hxkxaQRwlAC9oaZH2b5E+r5cUjnJQ2Hx8/xYG3gBgR6TKpmypNH2ZeVs0k5MiAaA9nalhBFyMWZM3MOyGb80pGWw5YmLEgO6aU1Lg8I4Am4jgBYDOIY4SgN/8a5f1yppDjebxTiJKHQAAILVRwwgfY9bkfgy74VtZgXRVThuuq4f3U0Za+zETGWmGrh7eT5XThisrkJ7gHQIWEcELAJ1HHCUAvwgFpc/3x7bm8/3ODJ6JUgcAAIBEDSN8jVmT+2UkewOA88LqMNoP8ILxFVL9FmmHhWgfIngBILpIHGXRzGTvBPAUw/jiB/qWlhalpXHedNJ0GF0ezeFI89w+8dtHJEq9w6txDr9u80Gp+xkSnzeuEQqFWv/7yL/fAAAAtuSPkra+YmMdNYzwEmZNbsVPmvCtpmBIU+bXaHFNnZqjXEjQ3CItrtmpKfNr1BQMtX8Q4AZE8AIAgCQyDENdunSRJH322WdJ3k2KO2gz6tHuumjcFqWOmPzrX/+SJGVmZjLsBgCktsY90qp7pYUTpMcuNm9X3WfeD+uoYYSPMWtyP67shm+VV2/U6m3W4v1Wb9uv8upa3XXluQ7vCuiESARv8Wxp/UJp++vmG4ddcsyzIC8oI7ocAAA4Jjc3V/X19dq9e7ckqWvXrlzhnQyhZils46qBUHP84sRDQemzGK8w/6xe6tpbSo/xTVDETTgc1sGDB9XQ0KD9+82flU8++eQk7woAgCQJHpBeuk165wmp5Zi6l62vSCvvNmsCx1VwUYkVkRrG9ZXW11DDCI9g1uR+RtjOD8lICMMwNhYUFBRs3Lgx2VvxnD0NTRp19woFQ9Y/vwPpht6c9TX1zM10cGcAAACAN4VCIe3cuVNNTU3J3kpqaz4ohW1cKWCkSxlx+lknFGz7prAVaQGG3S5y0kknqXfv3py0AgBIPcED0qJS63WB11aZF6GgYzH/uZJOCfdj1pQYgwcPVm1tbW04HB5sZz1XdsOXlqypi+mLjyQFQ2EtWVunm4oHObQrAK7WuMc8+3T7G1wxDwBAO9LT09WvXz/V19eroaFBhw4dSvaWUtOBT6SGj2Jfl3tq/Dq7P90hHWyIfV1mrtSDn7eSKT09XV27dlVubq5yc3OJMAcApKaXbrM2kJXM416eZaYtomORGsaXZ0kbHm//5Mi0AFfMw1OYNXkDw274ktVIiWO9vbWeL0BAqiG2CgAAy9LT09WrVy/16tVL4XBYJIUlQcPJ0oOTY7uyOi0g3bw+fifw/f5W6cN1sa87vVD6zovx2QNiZhgGw20AABp2m+8BxWLD42atIBdDHB81jPAZZk3ewLAbvtR4sDmh6wB4lJV4pZagtG6BtG8zsVUAAByBwVmSnNhHOq80xj7Ea6RucbqqWzJPAGyxcWV/IEsiMhsAACTThoWx17G0BM3BbdFMZ/bkRzm9zD8v/szgccyavIGfMuFLOZn2zuOwuw6AR9mJrQIAAEi28RVmz6EV/UebCTXxlD/K5jqLewYAAHDK9jdsrrP4/hEAX2HW5A0Mu+FLIwZ0t7Vu5MAecd4JANeyG1vVuMeZ/aBzGvdIq+6VFk6QHrvYvF11Hx8vAIA/RfoQC6eaEeXtSQuYj1/7dPyrWIaURX/daNICZmwlAABAMh1qTOw6AJ7GrMkbOLUAvjRpWJ7mLd+kYMh6h2Ag3dCkoXkO7gqAqxBb5Q90rgMAUlUy+xBze0vnXxNjlPpk+hkBAEDydclJ7DoAnsasyRu4shu+1Cs3S6WFfWNaU1qYp565mQ7tCIDrEFvlfZHO9fWV0U9ciHSuL5poHg8AgN9E+hDLlkrTl5m3RTOdHywnO0odAADADupYAMSAWZM3MOyGb80pGWw5YmLEgO6aU1Lg8I4AuAqxVd5H5zoAAMmT7Ch1AADcgEot76GOBUCMmDW5HzHm8K2sQLoqpw1XeXWtnlq7U80tbY/JSJOuGtpPc0oKlBVIT/wmASQPsVXeZrdzvXg2EaoAAMRLMqPUAQBIJiq1vIs6FgAxYtbkfgy7kQLCkozDt8cyErwXAK6RP8r8ATTmdcRWuQKd6wAAuEckSp1/YwEAqSBSqdVR0likUmvfZjMJJZCdsO3BgvEVUv0Wa2lx1LEAaMWsya2IMYdvNQVDmjK/Rotr6tTc0t4XH6m5JazFNTs1ZX6NmoKhBO8QQFIRW+VtdK4DAADEDzG8AGAdlVreRx0LgBgwa3I/ruyGb5VXb9TqbfstHbt6236VV9fqrivPdXhXAFyD2Cpvo3MdAACg84jhBYDYUKnlH9SxALCIWZP7cWU3fGlPQ5Oq1u2KaU3VujrtbTjo0I4AuNL4CjOOygpiq9yFznUAAIDOicTwrq+MXg8TieFdNNE8HgBSXWcqteBOkTqWsqXS9GXmbdFMBt0AJDFr8gqG3fClJWvqFAy1HycRTTAU1pK1dQ7tCIArEVvlXfmjbK6jcx0A2iC+GEhNxPACQOyo1AKAlMKsyRuIMYcvWY2UONbbW+t1U/GgOO8GgKsRW+VNQ8qklRWxnVFP5zoAHI34YiB1EcMLAPZQqQUAKYVZkzcw7IYvNR5sTug6AD4Qia0qmpnsncAKOtcBoHMi8cUdXdUZiS/et9lMQglkJ2x7ABzWmRhevl8GkMqo1AKAlMKsyRuIMYcv5WTaO4/D7joAQBLQuQ4A9hFfDKQ2YngBwB4qtQCkAqquWjFr8gaG3fClEQO621o3cmCPOO8EAOAYOtcBwB678cUp+MYG4FvE8AKAPUPKov/8GQ2VWgC8InhAev5maW6BtOJOs95q1xrzdsUd5v3Vt0jBpmTvNGGYNXkDw2740qRheQqkGzGtCaQbmjQ0z6EdAQAcEelcn1Erjb1dGlgs9R1m3o693by/ZB6DbgA4UmfiiwH4AzG8AGBPpFIrFlRqAfCCSNXV+sroPy9Gqq4WTTSPTwHMmryBYTd8qVdulkoL+8a0prQwTz1zMx3aEQDAUZHO9bKl0vRl5m3RTN5QAID2EF8MgBheALCPSi0AfkTVVbuYNXkDw2741pySwZYjJkYM6K45JQUO78hF6NwAAABIXcQXAyCGFwDso1ILgN9QddUhZk3uR0M6fCsrkK5HrivUxIff1Ja9n0U97oyeOfrtdYXKCqQncHdJEjxgnqH1zhNto0i2viKtvNuMVhpXwTfiAAAAfkV8MYBIDO/6SutriOEFgC9EKrWKZ5tVL9tfN08M7JJjpmBcUMbXTADe0Zmqq6KZzuzJRZg1uR9XdsO3moIhfe8P6zr84iNJW/Y26vo/rFNTMJSgnSUJnRsAAACQiC8GYCKGFwA6j0otAH5A1VWHmDW5H8Nu+FZ59Uat3rbf0rGrt+1XeXWtwztKMjo3AACA11HFEh/EFwOQiOEFAACAiaqrDjFrcj9izOFLexqaVLVuV0xrqtbVacYlZ6lnbqZDu0oiu50bxbM5ExUAACQfVSzxRXwxgAhieAEAAEDVVVTMmryBK7vhS0vW1CkYCse0JhgKa8naOod2lGSd6dwAAABIJqpYnEF8MYAjEcMLAACQuqi6iopZkzcw7IYvWY2UONbbW+vjvBOXoHMDAAB4FVUsziC+GACcRfUGAADwCqquomLW5A3EmMOXGg82J3Sd69G5AQAAvIgqFmcRXwwA8Uf1BgAA8BqqrqJi1uQNDLvhSzmZ9j617a5zPTo3AACAF3WmiqVopjN78qNIfDF/ZgDQOZHqjY4SSSLVG/s2mwkbgeyEbQ8AACCq8RVS/RZryWopVHXFrMkbiDGHL40Y0N3WupEDe8R5Jy5B5wYAAPAiqlgAAF5C9QYAwKuo3wBVV+1i1uQNnFoAX5o0LE/zlm9SMBS2vCaQbmjS0DwHd5VEQ8qklRWxXRmVIp0bAADAxahiAQB4BdUbAAAvon4DR6Lqqg1mTd7Ald3wpV65WSot7BvTmtLCPPXMzXRoR0kW6dyIRYp0bgAAABejigUA4BWdqd4AACAZIvUb6yuj/xsWqd9YNNE8HqkhUnVVtlSavsy8LZqZkvMCZk3ewLAbvjWnZLDliIkRA7prTkmBwztKsvEVZpeGFSnUuQEAAFyMKhYAgFdQvQEA8BrqNwBLmDW5H8Nu+FZWIF2V04br6uH9lBHlMz0jTbp6eD9VThuurEB6YjeYaHRuIBo6eQAAbjWkLPr3LdFQxQIASAaqNwAAXmK3foP3C5GCmDW5H53dSAFhScbh22MZCd5LktG5gSPRyQMAcLtIFcv6SutrqGIBACQD1RsAAC/pTP1G0Uxn9gS4HrMmt2LYDd9qCoY0ZX6NVm/bH/WY5pawFtfs1Na9jal1xk2kc4NvTFJXpJOno6iiSCfPvs1mKkAgO2HbAwCg1fgKqX6LtXg9qlgAAMmSP8o8aTjmdVRvAACSoDP1G7ynjBTDrMn9iDGHb5VXb+zwi8+RVm/br/LqWod3BLgInTwAvIKqBVDFAgDwAqo3AABeQv0GYBmzJvfjym740p6GJlWt2xXTmqp1dZpxyVnqmZvp0K4Al7DbyVM8m1hYAIlD1QKORBULAMDtqN4AAHgJ9RuAJcyavIEru+FLS9bUKRhqrzchumAorCVr6xzaEeAinenkAYBEiFQtrK+M/vUqUrWwaKJ5PFJDpIqlbKk0fZl5WzSTQQEAwB3GV5iVGlZQvQEASKb8UTbXUb+B1MKsyRsYdsOXrEZKHOvtrfVx3gngQp3p5AGARKBqAQAAeBHVG+gI9TwA3IT6DcASZk3eQIw5fKnxYHNC1wGeQicPADejagEAAHgZ1Rs4FvU8ANyI+g3AEmZN3sCwG76Uk2nvU9vuOsBT6OQB4GadqVoomunMngAAAGIVqd7g+5PUFqnn6Si1KFLPs2+zmQwQyE7Y9gCkuPEVUv0Wa8lq1G8gRTFr8gZizOFLIwZ0t7Vu5MAecd4J4EJ08rgXsXYAVQsAAADwD+p5ALgZ9RvAcTFr8gZOLYAvTRqWp3nLNykYClteE0g3NGlonoO7AlxiSJm0siK2Kyfp5HEWsXbAF6haAAAAgB9QzwPAC6jfADrErMkbuLIbvtQrN0ulhX1jWlNamKeeuZkO7QhwkUgnTyzo5HFOJNZufWX0ExAisXaLJprHA35G1QIAAAD8oDP1PACQaJH6jbKl0vRl5m3RTN4PRMpj1uQNDLvhW3NKBluOmBgxoLvmlBQ4vCPARcZXmF07VtDJ4yxi7YCjUbUAAAAAP6CeBzg+6twAeACzJvdj2A3fygqkq3LacF09vJ8y0ox2j8lIM3T18H6qnDZcWYH0BO8QSCI6edzBbqwdP/TBz4aURf+6FA1VCwAAAHAb6nmA6IIHpOdvluYWSCvuNCvcdq0xb1fcYd5ffYsUbEr2TgGAWZMH0NmNFBA+/CvaY0CKopMn+ToTa1c005k9AckWqVpYX2l9DVULAAAAcBvqeYD2RercOkq5i9S57dtsXqwRyE7Y9gAgOmZNbsWwG77VFAxpyvward62P+oxzS3S4pqd2rq3kTNukLoinTwMTxOvM7F2fLzgZ+MrpPot1iL+qVoAAACAG+WPMq9SjXkd9TzwOTt1biXznN0TAHSAWZP7EWMO3yqv3tjhF58jrd62X+XVtQ7vCACOQawd0D6qFgAAsaLzE4DbUM8DtEWdGwAPYtbkflzZDV/a09CkqnW7YlpTta5OMy45Sz1zMx3aFQAcg1g7IDqqFgAAVgQPmFeIvfNE23qYra9IK+826y7GVXByFIDEop4HaIs6NwAew6zJG7iyG760ZE2dgqHYOhKCobCWrK1zaEcA0I78UTbXEWuHFBKpWihbKk1fZt4WzeRNQADAF52f6yujv3Ee6fxcNNE8HgASaXyFWbtjBfU8SAWdqXMDgCRg1uQNDLvhS1YjJY719tb6OO8EADpArB0AAN5GdHZy2en8BIBEop4HOBp1bgA8hlmTNxBjDl9qPNic0HUAYAuxdgAAeBPR2clnt/OzeDbfSwFILOp5gC9Q5wbAY5g1eQPDbvhSTqa9T2276wDAtvEVUv0Wa1clEWsHAEDyRaKzO/q3OxKdvW+zeUVfIDth20sZdH4C8JpIPQ9fg5DK8keZJwbGvI46NwDJwazJG4gxhy+NGNDd1rqRA3vEeScAcBzE2gEAYkV0dnIRne0OdH4CAOA91LkB8BhmTd7AqQXwpUnD8jRv+SYFQ2HLawLphiYNzXNwVwAQBbF2AAAriM5OPqKz3YPOTwAAvIc6NwAew6zJG7iyG77UKzdLpYV9Y1pTWpinnrmZDu0IACyIxNqVLZWmLzNvi2byQx0A4Ivo7PWV0aObI9HZiyaaxyP+OhOdjfii8xMAAG8aX2HWtFlBnRuAJGPW5A0Mu+Fbc0oGW46YGDGgu+aUFDi8IwAAAMAmorPdgehs98gfZXMdnZ+Oo2oBANAR6twAeAyzJvczwmHrl94jsQzD2FhQUFCwcePGZG/Fs5qCIZVX1+qptTvV3NL28Yw06aqh/TSnpEBZgfTEbxAAAAA4nobd0v2DY7uiOC0gzaglHSTeHrtY2rUm9nV9h5mpLYgf/l64T0dVC5L550/VAgDgSI17qHMD4AnMmpw1ePBg1dbW1obD4cF21tPZjRQQlmQcvj2WkeC9AAAAADHqTHR20Uxn9pSqiM52Dzo/3SVStdBRAkWkamHfZvOKvkB2wrYHAHCpSJ0b37MC8ARmTW5FjDl8qykY0pT5NVpcU6fmlvYTDJpbwlpcs1NT5teoKRhK8A4BAAAAC4jOdg+is92Fzk/3oGoBAAAAPsWsyf0YdsO3yqs3avW2/ZaOXb1tv8qrax3eEQAAAGDDocbErkN0Q8qid0tGkxYwozgRf3R+ukPDbjO6PBYbHqfDG0DyNO6RVt0rLZxgVpQsnCCtuo+vSwCAdjFrcj9izOFLexqaVLVuV0xrqtbVacYlZ6lnbqZDuwIAAABsIDrbPYjOdp9AtlQyTyqeTednslC1AMArggfMJIp3nmj7dWvrK9LKu81/t8dVcIIUAEASsyav4Mpu+NKSNXUKhtqPk4gmGAprydo6h3YEAAAA2ER0trsQne1Okc7PsqXS9GXmbdFMBt2JQNUCAC8IHpAWlZonrEU7QaclKK1bIC2aaB4PAEh5zJq8gWE3fMlqpMSx3t5aH+edAAA8iVg7AG5CdLa7EJ0NHI2qBQBe8NJt0g6LJ9nseF16eZaz+wEAeAKzJm8gxhy+1HiwOaHrAAA+QawdADciOtt9iM4GvkDVAgC3a9ht/owXiw2Pm//O8+85AKQ0Zk3ewLAbvpSTae9T2+46AIAPRGLtOjrbPxJrt2+zeVVfIDth2wOQ4sZXSPVbrF2RRHR24kSis+kdRirLH2WeFBjzOqoWACTIhoXRo8ujaQmaJ7TxbzwApDRmTd5AjDl8acSA7rbWjRzYI847AQB4BrF2ANyM6GwAbkXVgntRzQOYtr9hc53Fnw8BAL7FrMkbOLUAvjRpWJ7mLd+kYChseU0g3dCkoXkO7goA4FrE2gHwAqKzAbgRVQvuQzUPcLRDjYldBwDwDWZN3sCV3fClXrlZKi3sG9Oa0sI89czNdGhHAABX60ysHQAkWiQ6u2ypNH2ZeVs0k8ERgOQZX2FWKFhB1YKzItU86yujf38bqeZZNNE8HvC7LjmJXQcA8A1mTd7AsBu+NadksOWIiREDumtOSYHDOwIAuBaxdsDxEYUKAIiGqgX3oJoHaCt/lM11Fk/iAQD4GrMm9zPCYeuX3iOxDMPYWFBQULBx48Zkb8WzmoIhlVfX6qm1dWpuafu5npFm6KqheZpTUqCsQHoSdggAcIXHLpZ2rYl9Xd9h5lWVgJ91FIUqmcMLolABABGNe6haSJaG3dL9g2NLLEoLSDNq+djA3/i7AQDoJGZNzho8eLBqa2trw+HwYDvr6exGCggf/hXtMQBAyiPWDmhfJAq1oyvEIlGo+zabV/UFshO2PQCAC0WqFopmJnsnqacz1Tx8vOBnub2l868x4/2tGjKZQTcA4BjMmtyKGHP4VlMwpCnza7S4pk7NLe0f09wiLa7ZqSnza9QUDCV2g6mOKFQAbkKsHdA+olABAPAOqnmA6MZXSP0t/vzWf7SZWgQAgJg1eQHDbvhWefVGrd6239Kxq7ftV3l1rcM7giTzCrHnb5bmFkgr7pS2vmJGB299RVpxh3l/9S1SsCnZOwWQSoaURe+XjCYtYMZxAn7VsNuMLo/Fhsc5cQ0AgGQ51JjYdYCXBLLNFKLCqdF/9ksLmI9f+zT1PACAVsya3I9hN3xpT0OTqtbtimlN1bo67W046NCOIOmLKNT1ldGj1SJRqIsmmscDQCJEYu1iQawd/K4zUagAACDxqOYBOhbIlkrmmV3cY2+XBhZLfYeZt2NvN+8vmcegGwDQilmTNzDshi8tWVOnYCi2joRgKKwla+sc2hEkEYUKwN2ItQOORhQqAADeQjUPYE1OL7OnvmypNH2ZeVs0k5OZAQBtMGvyBobd8CWrkRLHentrfZx3glZEoQJwO2LtgKMRhQoAgLdQzQMAgPc17pFW3SstnCA9drF5u+o+3idPEmZN3pCR7A0ATmg82JzQdbCgM1GoRTOd2RMAHCsSa1c82/z6s/11c3DXJce84uWCMs72R+ogChUAAG+JVPOsr7S+hmoeAADcIXjATEZ954m276NvfUVaebf57/a4Ci7ASCBmTd7AsBu+lJNp71Pb7jpY0JkoVIbdABItEmvH1x+ksvxR5g/UMa8jChUAgKQZXyHVb7FWIUY1DwAA7hA8IC0q7fjf75agtG6BtG+zmUwYyE7Y9lIZsyZvIMYcvjRiQHdb60YO7BHnnaBVPKJQiXABACBxiEIFAMB7qOYBAMB7XrrN2olqknncy7Oc3Q9aMWvyBk4tgC9NGpanecs3KRgKW14TSDc0aWieg7tKcZ2JQiXCBQCAxCMKFQAAb6KaBwAA72jYbb7vHYsNj5v/zvPvueOYNXkDV3bDl3rlZqm0sG9Ma0oL89QzN9OhHUH5o+yt6zfSjHBZXxm98zsS4bJoojkYBwAA8TG+wow4tYIoVAAA3CVSzVO2VJq+zLwtmskb4wAAuMmGhdHf946mJWie0AbHMWvyBobd8K05JYMtR0yMGNBdc0oKHN5RirMbhWq1a0wiwgUAgHgjChUAAAAAAHus1HJuf8Pec2+3+J45Oo1Zk/sZ4bD1S++RWIZhbCwoKCjYuHFjsrfiWU3BkMqra/XU2p1qbmn7eEaadNXQfppTUqCsQHriN5hqnr85tijU8/5deu+Z2M5sSwtIM2o5Ux0AgHhr3EMUKgAAAAAAx9NRLadkvocdqeWsvEzatSb21+g7zExuQUIwa3LW4MGDVVtbWxsOhwfbWU9nN1JAWJJx+PZYRoL3kuLGV1i/Urv/aOnkAfYjXIpm2tsjAABoXyQKlX9jAQAAAABoX/CAWcvZ0XvgkVrOfZuljGx7r9Mlx946dAKzJrcixhy+1RQMacr8Gi2uqVNzS/sJBs0tYS2u2akp82vUFAwleIcpKNYo1LrV9l6HCBcAAAAAAIDOsxLBCwD4wku3xVbLeajB3uvkj7a3DjFj1uR+XNkN3yqv3qjV2/ZbOnb1tv0qr67VXVee6/CuoEC2VDJPKp59/CjUQ432XsPuOgAAAAAAAHQcwbv1FWnl3V9E8AaykrNHAHCbht3m181YfPyuZGRI4Wbra9IC5vvoSAhmTe7HsBu+tKehSVXrdsW0pmpdnWZccpZ65mY6tCscxUoUqt0oFiJcAAAAAAAA7Ik1gvfaKvPiBgBIdRsW2qjlbJZOGyL9c4P1NUMmf3HBGBzFrMkbPB1jbhhGtmEYvzQM4x+GYTQZhvFPwzDmG4Zxuo3nOtkwjHmGYewwDOPg4dsHDMM4qYM1ZxmG8fvDxx4yDKPBMIw1hmHcahhGl0795tApS9bUKRhqP04immAorCVr6xzaEWzJH2VzHREuAAAAAAAAtsQawfvyLGf3AwBesf0Ne+syu0n9Lb6n3X+0maqBhGDW5A2eHXYbhpElaYWk2yXlSHpOUp2k70jaYBjGwBie6xRJNZJultQsaamkBkm3SFptGEb3dtb8m6QNkqZK+uzwmjclDZY0V9L/GobBlfNJYjVS4lhvb62P807QKUPKond7R0OECwC0j649AAAAAMdjJ4J3w+P8XAEAkv16zeDnZkpG4dTo74enBczHr32a+ogEYtbkDV4exv6npJGS3pJ0aTgcbpQkwzBmSPq1pPmSxlh8rgckDZL0jKR/D4fNcgTDMH4j6Ycyh9dTj1nz35JOkPTTcDh8d+ROwzBOk/SapIskXSfp9zH/ztBpjQdj6LeIwzo4JLe3dP410vpK62uIcAGAo9G1BwAAAMAqWxG8QWn9wo6r6gAgFXSmljOQLZXMk4pnm19Tt79uDs+75JhJpheU8b53EjBr8gZPXtl9OCL8B4f/96bIoFuSwuHwXEl/k3SRYRiFFp7rVElXSzok6cbIoPuwH0vaK+lawzB6HbEmR9IQSZ9LuufI5wuHw/+UOQiXpGEx/tYQJzmZ9s7jsLsODhpfQYQLANgV6dpbXxn9DatI196iiebxAAAAAFKX3Qje7RZjzwHAz+JRy5nTyzx5qGypNH2ZeVs0k0F3kjBr8gZPDrsljZJ0oqQt4XB4QzuPVx2+LbHwXONk/jm8Fg6Hdx/5QDgcPiipWlK6pG8c8VBQUouF5yanIElGDGiTPG/JyIE94rwTdFogmwgXALCLrj0AAAAAsbAbwWt3HYDoqCPzHmo5fYdZkzd4ddj9lcO366M8Hrn/PCee6/AQfJXMGPOfHHnw4Rjzm2QOxP9g4fXhgEnD8hRIN2JaE0g3NGlonkM7QqdEIlxm1Epjb5cGFkt9h5m3Y2837y+Zx6AbAI5E1x4AAACAWHUmghdAfAQPSM/fLM0tkFbcaVaQ7Vpj3q64w7y/+hYp2JTsneJYkVrOWFDL6WrMmrzBq9fR9zt8uyvK45H7+zv4XDdI+oukuwzDKJP0nqRukookfSTpm+Fw+B8WXl+GYWyM8tAZVtajrV65WSot7KvFNXWW15QW5qlnbqaDu0KnRSJc6IACgOOjaw8AAABArPJHmQO1mNdZrKAD0LFIHVlHKW2ROrJ9m81EzEB2wrYHC8ZXSPVbrCXtUcvpesyavMGrV3ZHThX8PMrjnx2+zXXqucLh8AeSRsu88vtLkq6S9HVJWZJekRRtgI0EmVMy2HLExIgB3TWnpMDhHQEpjuglILHo2gMAAAAQKyJ4geSijsz7qOX0HWZN7ufVK7uTzjCMsZKellQnaayktZJ6SPqupJ9J+pphGMPD4fDe4z1XOBweHOU1Nkrib4VNWYF0VU4brvLqWj21tk7NLeE2x2SkGbpqaJ7mlBQoK5CehF0CKSB4wPxG/Z0n2l5luvUVaeXdZlzPuAq+uQPiia49AAAAALGKRPCur7S+hgheID7s1pEVz+bvoNtEajmLZ5sJettfN99v6ZJjJmFcUMbHzEOYNbmfV4fdkXdhT4jyeNfDtw1OPJdhGN0lPSUpIGl8OBz+8IhjbjcM40RJP5Q0U9JtFvYAR4UP/4r2GADHEL0EJA9dewAAAADsIIIXSA7qyPyHWk6fYdbkVl6NMd95+LZvlMcj9+9w6Lm+Kam7pLePGHQf6anDt0UWXh8OaQqGNGV+jRbX1Km5pf1jmlukxTU7NWV+jZqCocRuEEgFRC8ByZM/yuY6uvYAoA3qWAAAqYQIXiA5qCMDXIlZk/t5ddj918O3F0R5PHL/3xx6rsgA/P+irIncf7KF14dDyqs3avW2/ZaOXb1tv8qrax3eEZBi7EYv8aYxEB907QFA5wUPSM/fLM0tkFbcaVaw7Fpj3q64w7y/+hYp2JTsnQIAEF+RCN4ZtdLY26WBxVLfYebt2NvN+0vmMegG4ok6MsCVmDW5n1eH3W/IHCifYRjG+e08Xnr4ttrCc70sqUXShYZhHFWSYBhGpqQSSSFJLx7x0MeHb4cYhtFe+P6ww7fbLbw+HLCnoUlV63bFtKZqXZ32Nhx0aEdACupM9BKAzot07cWCrj0A+EKkjmV9ZfTvaSJ1LIsmmscDAOA3kQjesqXS9GXmbdFMfm4AnEAdGeA6zJq8wZPD7nA4fEjSfx/+3/8xDCPSqy3DMGZIOk/Sq+FweN0R9//AMIy/G4Zx1zHP9ZGkxZK6SHrIMIwje8zvkdRT0qJwOHzkpYYvSzooaYCkOwzDaP1zNAzjbEm/PPy/VZ37ncKuJWvqFAzF1pEQDIW1ZG2dQzsCUhDRS0Dyja8wO/SsoGsPAI5GHYt/EEMPAAC8gDoywHWYNXmDJ4fdh90pabWkf5O0yTCMPxqG8bakX0vaK2naMcefIulsSae281z/T9IWSRMl/d0wjCcNw3hX0s2SNkmaceTBhwfkM2U2zv/08OtXGYbxisxY9NNkXgm+oPO/TdhhNVLiWG9vrY/zToAURvQSkHx07QGAPdSx+AMx9AAAwEuoIwNch1mTN3h22B0Oh5skFUu6Q9LnkiZI6i9zwHxBOBzeGsNz7ZM0XNKDMq/w/pakEyX9RtLwcDjc5rM5HA7/t6SxkpZKOkHSFTL7vTdIuknS5eFwuNnWbw6d1njQ3h+93XUA2kH0EuAOdO0BQOyoY/E+YugBAIDXUEcGuA6zJm/IOP4h7hUOhw9I+vnhX8c79heSftHB4/tlXsl9cwyvv1LSSqvHI3FyMu19attdB6Ad+aPMq2ZiXkf0EuCISNde0cxk7wQA3K8zdSx8nXUHOzH0JfOc3RMAAMDxjK+Q6rdY+z6GOjLAccyavMGzV3YDHRkxoLutdSMH9ojzToAURvQSAADwKupYvI0Yen+hcx0AkEqoIwNchVmTN3BqAXxp0rA8zVu+ScFQ2PKaQLqhSUPzHNwVkGIi0UvrK62vIXoJAAC4AXUs3taZGHquzHeP4AHzCv13nmj78dz6irTybvPnh3EVvNEPAPCXSB1Z8Wzz+5Ptr5snVXbJMRMRLyjj/TMgQZg1eQNXdsOXeuVmqbSwb0xrSgvz1DM306EdASlqfIUZqWQF0UsAAMAt8kfZXEcdiyt0JoYe7kDnOgAAX9SRlS2Vpi8zb4tmMugGEohZkzcw7IZvzSkZbDliYsSA7ppTUuDwjoAURPQSAABE8HoRdSzeRgy999npXAcAAAAcwKzJ/Ygxh29lBdJVOW24yqtr9dTanWpuaXtMRpp01dB+mlNSoKxAeuI3CaQCopcAAKmKCF7voo7F24ih9za7nevFs/k7CAAAgLhj1uR+DLuRAsKSjMO3xzISvBcghUWil+hBBACkgkgEb0dXJkYiePdtNpNQAtkJ2x4sGF8h1W+xdnUpdSzukj/KPKEk5nXE0LsCnesAAABwJWZNbkWMOXyrKRjSlPk1WlxTp+aW9r74SM0tYS2u2akp82vUFAwleIcA4CFE8AJAbIjg9T7qWLyLGHpvo3MdAAAALsKsyf24shu+VV69Uau37bd07Opt+1VeXau7rjzX4V0BgMcQwQsAsSOC1z+oY/EmYui9jc51AAAAuAizJvfjym740p6GJlWt2xXTmqp1ddrbcNChHQGAB0UieNdXRo+SjETwLppoHg8A6FwEL9wpUsdStlSavsy8LZrJcNTNxleY8fJWEEPvLnSuAwAAwCWYNXkDw2740pI1dQqG2o+TiCYYCmvJ2jqHdgQAHkQELwDYQwQvkHzE0HtX/iib6+hcB4A2qCQDgE5h1uQNxJjDl6xGShzr7a31uql4UJx3AwAeRAQvANhHBC/gDsTQe9OQMmllRWwJGXSuA8DRqCQDgLhg1uQNDLvhS40HmxO6DgB8pzMRvEUzndkTAHgFEbyAu0Ri6PkexRvoXAeAzolUknWU1BapJNu32UxCCWQnbHsA4CXMmryBGHP4Uk6mvfM47K4DAN8hghdwF+IHvYUIXgDoHDrXAcA+KskAIG6YNXkDw2740ogB3W2tGzmwR5x3AgAeRQQv4A7BA9LzN0tzC6QVd5qRg7vWmLcr7jDvr75FCjYle6c40pCy6B3B0RDBCwBfoHMdAOyxW0nGSbQA0C5mTd7AsBu+NGlYngLpRkxrAumGJg3Nc2hHAOAxRPACyReJH1xfGb1WIBI/uGiieTzcIRLBGwsieAHgaJHO9Rm10tjbpYHFUt9h5u3Y2837S+Yx6AaAI3WmkgwA0AazJm9g2A1f6pWbpdLCvjGtKS3MU8/cTId2BAAeQwQvkHzED3obEbwAEB+RzvWypdL0ZeZt0UxOEAKA9lBJBgBxxazJGxh2w7fmlAy2HDExYkB3zSkpcHhHAOAhRPACyUX8oPcRwQsAgPm9yap7pYUTpMcuNm9X3cf3LIBTqCQDgLhj1uR+NKTDt7IC6aqcNlzl1bV6am2dmlvCbY7JSDN01dA8zSkpUFYgPQm7BACXikTwrq+0voYIXiB+OhM/WDTTmT0hdpEI3uLZ5sdm++vmG4ldcswkjAvK+LoJAPCn4AEzpeadJ9p+T7P1FWnl3ebPD+MqOOELiCcqyQAg7pg1uR/DbqSA8OFf0R4DALRrfIVUv8VajDIRvEB8dSZ+kGG3+0QiePnYAABSQfCAtKi0458jWoLSugXSvs1mEkogO2HbA3wtf5R5QknM66gkA4DjY9bkVsSYw7eagiFNmV+jxTV1am5p/5jmFmlxzU5NmV+jpmAosRsEALcjghdIHuIHAQCAV710m7UTZiXzuJdnObsfIJVQSQYA8XO4jiVUeYV23vNvGr/hRl1vLNUp+r82hzJrSi6G3fCt8uqNWr1tv6VjV2/br/LqWod3BAAeFIngnVErjb1dGlgs9R1m3o693by/ZB6DbiDeiB8EAABe1LDbjC6PxYbH6fAG4iVSSRYLKskA4GjBA9LzN0tzC6QVdyp920qdFfy7itLf1U8CS/Rm5g/0q4zHlKlDbZYya0oOht3wpT0NTapatyumNVXr6rS34aBDOwIAj4tE8JYtlaYvM2+LZvIDMeCU/FE21xE/CAAAkmjDwrYd3cfTEpTWL3RmP0AqGl9hVo1ZQSUZABwtUseyvjLq9zRdjJCuyVihyi4V7Q68mTUlHsNu+NKSNXUKhtp2JJyi/9NN6Uu1MHCXnunycy0M3KUb083YiWAorCVr65KwWwAAgGMQPwgAALxo+xs211mMPQdwfFSSAYB9FutYwmFpZNr7mpPR9oQ9Zk2Jl5HsDQBOODa+PFOHNCejUqXpq9TFOLovoSj9Xf2/jKdVFbpIy7bMkIoHJXKrAAAAbUXiB9dXWl9D/CAAAEi2Q42JXQegfZFKsuLZZnLC9tfNv2ddcsw0qAvK+NkBAI4VQx2LYZi3pemvam7zVdqnE496/O2t9bqJWVPCMOyGLzUebG7970wdUmWXCo1Mez/q8ZHYifN275WCfzG/IQQAAEim8RVS/RZLZxQTPwgAAFyhS05i1wHoWKSSrGhmsncCAO5no46lixHSpPRX9FBowlH3HzmjgvOIMYcv5WR+cR7HnIxKjUx7X+G2qeZHCYelLwfflV6e5fDuAAAALCB+EIDbNO6RVt0rLZwgPXaxebvqPvN+AJCk/FE211nsFwYAAHCKzTqW9i60PHJGBefxpw1fGjGgu17btE899alK01dJ+iJWIprWxzc8bkb8EOUDAACSjfhBAG4QPGB2173zRNsrHba+Iq2826xSGFfBiTdAqhtSJq2siO2qqLSA+T0NAABAMtmsVckxDrS5b+TAHp3dDWLAsBu+NGlYnuYt36RJWtmmo/u4WoLmm8nE+wAAALcgfhBAsgQPSItKO65UaAlK6xZI+zabiRTUQgGpK7e3dP410vpK62uGTObkPQAAkHw2a1Uaw0f//BNINzRpaF48dgSLiDGHL/XKzVJpYV+N6KCnu0PbLXRjAgAAAIDfvXRbx4PuI+14nVooANL4Cqm/xVjy/qPNVAgAAIBks1nH8nbLl476/9LCPPXMzYzHjmARw2741pySweqTFUNs1pFsxlUAAAAAgGt0tmO7YbcZXR6LDY/T4Q2kukC2mfJQONWMKG9PWsB8/NqnqT8AAADuMKQs+vcuURwKp2tJqLj1/0cM6K45JQXx3hmOgxhz+FZWIF0DTu8jbf977IttxlUAAAAAQNLFq2N7w8LYenclaqEAmALZUsk8qXi2+TVh++vmhQVdcqT80WZHN9HlAADATWKoYwmHJcOQqkIXaZ9OlCSd0TNHv72uUFmBdKd3imNwZTd8qykY0tP7+ttbnG8xbgsAAAAA3CTSsb2+MvqgOtKxvWiieXw029+wtwdqoQBE5PQyT34pWypNX2beFs1k0A0AANzJYh2LYZjx5eXNZa33bdnbqOv/sE5NwZCTO0Q7GHbDt8qrN+rX+0boUDjGs2jSAuYZxgDQGZ2NDQUAALAjnh3bduudqIUCAAAA4EUW6lgOhdP1RPNYTTl0mw6qy1GPrd62X+XVtQnYKI5EjDl8aU9Dk6rW7VJQJ6kqVKRrMl5pjZWIpvXxIZM5wxiAffGKDQUAAIiV3Y7t4tnt/wxkt96JWigAAAAAXnVEHUvj2/P1zqo/6QQdUGM4W2+3fElLQsWt0eXtqVpXpxmXnKWeuZkJ3HRqY9gNX1qypk7BUFiSVN48RQPTPtbItPc7XGMY0ocnFur0cRWJ2CIAP4rEhnZ0NVUkNnTfZvMswUB2wrYHAAB8Lt4d2/mjzJP1YkUtFAAAAACvy+mlBWkTdd+hc2NaFgyFtWRtnW4qHuTQxnAsYszhS6u37W/974PqoimHbtMTzWOjRppHYiduzy3nSksA9sUzNhQAACBW8e7YHlIWNbovKmqhAACAk6iNA5BAR86aYvH21vo47wQd4cpu+FLjweaj/v+guuhnzdM1t/kqTUp/RSPT3leO0TZ2Ysghzv8AYFO8Y0MBAABiFe+O7dze0vnXSOsrrT8XtVAAAMAJ1MYBSIJjZ01Or4M9DLvhSzmZ7X9q79OJeig0QQ+FJsS0DgCOK96xoQAAALFyomN7fIVUv8Vaek3/0eYbzAAAAPFEbRyAJLE7M2LWlFhcxgpfGjGgu611Iwf2iPNOAKSMeMeGArCPWDsAqSp/lM11HXRsB7LNN4wLp0aPNE8LmI9f+zRXUgEAgPijNg5AkjBr8gZOLYAvTRqWp3nLNykYClteE0g3NGlonoO7AuBr8Y4NBRA7Yu0ApLohZdLKitjSZqx0bAeypZJ5Zv3K+oXmyXqHGs0rwvNHm+uJLgcAAE6gNg5AEjFr8gau7IYv9crNUmlh35jWlBbmqWdupkM7AuB7TsSGArAuEmu3vjL6kCcSa7doonk8APhNpGM7FrF0bOf0MutXypZK05eZt0UzeSMZAAA4pzO1cQDQScyavIFhN3xrTslgyxETIwZ015ySAod3BMDXnIgNBWAdsXYAYBpfYXZnW0HHNgDEjsocILGojQOQZMya3I9hN3wrK5CuymnDdfXwfspIM9o9JiPN0NXD+6ly2nBlBdITvEMAvjKkLHqPZTRWYkMBHJ/dWDvekATgR3RsA4Azggek52+W5hZIK+40a3J2rTFvV9xh3l99ixRsSvZOAX+hNg5AkjFrcj86u5ECwod/RXsMAOIgEhu6vtL6mlhiQwFE15lYu6KZzuwJAJKJjm0AiK9IZU5HSUKRypx9m82TjgLZCdse4GvUxgFwDWZNbsWwG77VFAxpyvward62P+oxzS3S4pqd2rq3kTNuAHTe+Aqpfou1KGViQ4H46UysHcNuAH4W6djmax0AdI6dypySec7uCUgV+aPMBIWY11EbByA+mDW5HzHm8K3y6o0dfvE50upt+1VeXevwjgD4HrGhQHIQawcAAACnUJkDJBe1cWjcI626V1o4QXrsYvN21X18nUXCMGtyP67shi/taWhS1bpdMa2pWlenGZecpZ65mQ7tCkBKIDYUSDxi7QAAAOAUKnOA5KI2LnUFD5jJGu880fbr8NZXpJV3mx/rcRVcUALHMGvyBq7shi8tWVOnYCi2joRgKKwla+sc2hGAlBOJDS1bKk1fZt4WzeSHLcAJ+aNsriPWDgAAAMfRmcocAPExvsKsg7OC2jh/CB6QFpWaJzlEO+GoJSitWyAtmmgeDziAWZM3MOyGL1mNlDjW21vr47wTQETtAIDTiLUDAACAU6jMAZKP2rjU89Jt0g6LJw3teF16eZaz+0HKYtbkDcSYw5caDzYndB3QLqJ2ACAxiLUDAACAU6jMAdyB2rjU0bDbfD81FhseNz83+BxAnDFr8gaG3fClnEx7n9p21wFtRKJ2OjoDMRK1s2+zeXZqIDth2wMA3xlfIdVvsXbmN7F2AAAAsCp/lHnCeszrqMwBHBGpjSuameydwCkbFkaPLo+mJWieBMHnBeKMWZM3EGMOXxoxoLutdSMH9ojzTpKI6OzkImoHABKLWDsAAAA4gcocAEis7W/YXGfxvVggBsyavIFTC+BLk4blad7yTQqGwpbXBNINTRqa5+CuEoTo7OQjagcAkoNYOwAAAMQblTkAkFiHGhO7DuhASs+aPIQru+FLvXKzVFrYN6Y1pYV56pmb6dCOEiQSnb2+MnrUSyQ6e9FE83jEX2eidgAAnReJtStbKk1fZt4WzeQNRwAAANgzvsKswrGCyhwA6JwuOYldB3QgZWdNHsOwG741p2Sw5YiJEQO6a05JgcM7SgCis92BqB0AAAAAAPyDyhwASJz8UTbXWTwpCfalaHVqSs6aPMYIh61feo/EMgxjY0FBQcHGjRuTvRXPagqGVF5dq6fW7lRzS9vHM9Kkq4b205ySAmUF0hO/wXhq2C3dPzi2K4rTAtKMWq50i7fHLpZ2rYl9Xd9h5hWIAAAAAADAnRr3UJkDAE7ifW736ag6VTL//H1enZpSs6YkGDx4sGpra2vD4fBgO+vp7EYKCEsyDt8ey0jwXhzUmejsopnO7ClVEbUDAAAAAIA/RSpzeC8FAJyR21s6/xqzqtOqIZMZdDslUp3aUaJspDp132YzCSWQnbDtJVaKzJo8iBhz+FZTMKQp82u0uKZOzS3tJxg0t4S1uGanpsyvUVMwlOAdxhnR2e5B1A4AAAAAAAAA2DO+Qupv8b3S/qPNK4rhDKpTU2/W5EEMu+Fb5dUbtXrbfkvHrt62X+XVtQ7vyGGHGhO7DtENKYve4RVNWsCMPAMAAAAA4Fgp2pEJAEhRgWzzCuHCqdHfZ00LmI9f+7Rvo7OTrmG3GV0eiw2P++77k5SbNXkQMebwpT0NTapatyumNVXr6jTjkrPUMzfToV05jOhs9yBqBwAAAAAQDx11ZG59RVp5t+87MgEAKSqQLZXMk4pnm1Wc2183L9zqkmMmZF5QxvupTqM6NTVnTR7Eld3wpSVr6hQMtR8nEU0wFNaStXUO7SgBiM52F6J2AAAAAACdEenIXF8Z/Y3mSEfmoonm8QAA+E1OL3NwWrZUmr7MvC2ayaA7EahOTc1Zkwcx7IYvWY2UONbbW+vjvJMEIjrbXYjaAQCAyFUAADqDjkwAAJBMVKem5qzJg4gxhy81HmxO6DpXIDrbfYjaAQCkKiJXAQDoHLsdmcWz+TkTAADEB9WpqTlr8iCG3fClnEx7n9p217nG+Aqpfou1M7+Jzk6cSNSOT3pKAADoUCRytaPvRyKRq/s2m0kogeyEbQ8AAE+gIxMAACRb/ijzhPWY1/mnOjVlZ00eQ4w5fGnEgO621o0c2CPOO0kworMBAECyEbkKAEDn0ZEJuAv1PABSEdWpqTtr8hhOLYAvTRqWp3nLNykYClteE0g3NGlonoO7ShCiswEAQLIQuQoAQHzQkQm4A/U8AFIZ1ampPWvyEK7shi/1ys1SaWHfmNaUFuapZ26mQztKgkh0dtlSafoy87Zopq/+oQEAAC7TmchVAADwBToygeSL1POsr4z+PW6knmfRRPN4APCb8RVmJaoVPqxOZdbkDQy74VtzSgZbjpgYMaC75pQUOLwjAEBSEDcHJA6RqwAAxEf+KJvr/NORCSQd9TwAQHWqmDV5gREOW7/0HollGMbGgoKCgo0bNyZ7K57VFAypvLpWT62tU3NL28/1jDRDVw3N05ySAmUF0pOwQwCAYzqKm5PMb8SJmwPi67GLpV1rYl/Xd5iZRAMAAEwNu6X7B8eWmJIWkGbUkugGxAN/BwGgrcY9KVudyqzJWYMHD1ZtbW1tOBwebGc9nd1IAeHDv6I9BgDwnUjcXEdn4Ufi5vZtNs9QDWQnbHuAbxG5CgBAfNCRCSRXZ+p5imY6sycASLZIdWrKfp1j1uRWxJjDt5qCIU2ZX6PFNXVqbmn/mOYWaXHNTk2ZX6OmYCixGwQAOIe4OSA5iFyFRH0EAMRLindkAklFPQ8A4DBmTe7HsBu+VV69Uau37bd07Opt+1VeXevwjgAACdGw24wuj8WGxxnCAPEwpCx6h1c0aQEz8gzeFzwgPX+zNLdAWnGntPUVM9Z+6yvSijvM+6tvkYJNyd4pAHgDHZlA8hxqTOw6AIBrMWtyP4bd8KU9DU2qWrcrpjVV6+q0t+GgQzsCACRMZ+LmAHROJHI1FkSu+kOkPmJ9ZfSvwZH6iEUTzeMBAMcXyJZK5pk9wGNvlwYWS32HmbdjbzfvL5nHoBuIN+p5AABi1uQVDLvhS0vW1CkYiq0jIRgKa8naOod2BABIGOLmgOQicjU1UR8BAM6KdGSWLZWmLzNvi2ZywhjgFOp5AABi1uQVDLvhS1YjJY719tb6OO8EAJBwxM0ByUXkauqhPgJIvMY90qp7pYUTpMcuNm9X3cffKwCIF+p5AABi1uQVGcneAOCExoPNCV0HAHAR4uaA5ItErhbPNisCtr9unlDSJce82uWCMq5E85PO1EcUzXRmT4BfBQ+YSQrvPNH2793WV6SVd5v1EOMqOJkIADojUs+zvtL6Gup5AMB3mDV5A8Nu+FJOpr1PbbvrAAAukj/KfLM35nXEzQFxF4lcZaDpb52pj+BzA7AueEBaVNpxZUBLUFq3QNq32UzZCGQnbHsA4DvjK6T6LdaqWqjnAQBfYtbkDcSYw5dGDOhua93IgT3ivBMAQMIRNwcAiRWP+ggimYHje+k2awMXyTzu5VnO7gcA/I56HgBIecyavIFTC+BLk4blad7yTQqGwpbXBNINTRqa5+CuAAAJQdwcACRWZ+ojiGQGrGnYbf49icWGx806Cb7HAQD7qOcBgJTGrMkbuLIbvtQrN0ulhX1jWlNamKeeuZkO7QgAkFDjK8wYOSuImwOAzskfZW9dv5FmJPP6yuid35FI5kUTzcE4kKo2LIz+9ySalqA5mAEAdF6knqdsqTR9mXlbNJNBNwD4HLMmb2DYDd+aUzLYcsTEiAHdNaekwOEdAQAShrg5AEgcu/URVjswJSKZ4W9WYvy3v2Hvubdb/DsGAAAAoF3MmtzPCIetX3qPxDIMY2NBQUHBxo0bk70Vz2oKhlReXaun1u5Uc0vbxzPSpKuG9tOckgJlBdITv0EAgPMa9xA3BwBOe/7m2Oojzvt36b1nYrtSNS0gzajlazf8o6MYf8n8nI/E+FdeJu1aE/tr9B1mXoEIAAAAwDZmTc4aPHiwamtra8Ph8GA76+nsRgoISzIO3x7LSPBeAAAJF4mbK5qZ7J0AgH+Nr7B+pXb/0dLJA+xHMvP1HH4QPGDG+Hf0dyYS479vs5SRbe91uuTYWwcAAADgGMya3IoYc/hWUzCkKfNrtLimTs0t7ScYNLeEtbhmp6bMr1FTMJTgHQIAAAA+EWt9RN1qe69DJDP84qXbYovxP9Rg73XyR9tbBwAA4stKbQkAV2LW5H5c2Q3fKq/eqNXb9ls6dvW2/SqvrtVdV57r8K4AAAAAnwpkSyXzpOLZx6+PONRo7zXsrgPcpGG3GV0ei4/flYwMKdxsfU1awPx7BwAAkqej2pKtr0gr7/6itiSQlZw9AugQsyb3Y9gNX9rT0KSqdbtiWlO1rk4zLjlLPXMzHdoVAAAAkAKs1EfYjVYmkhl+sGGhjRj/Zum0IdI/N1hfM2QyHfcAACRTrLUl11aZJ5ACcA1mTd5AjDl8acmaOgVD7cdJRBMMhbVkbZ1DOwIAAADQKn+UzXVEMsMHtr9hb11mN7Pz3or+o80rxAAAQPLEWlvy8ixn9wMgZsyavIFhN3zJaqTEsd7eWh/nnQDoFPqMAADwpyFl0bu9oyGSGX5hN44/+Ll5xVfh1Oh/f9IC5uPXPk0UKgAAyWSntmTD47znBbgMsyZvIMYcvtR4MIYeszisAxBn9BkBAOBvub2l86+R1ldaX0MkM/yiMzH+gWypZJ5UPFtav1Da/ro5PO+SYyYfXFDG3xMAANzAVm1J0Pz3vaM6IAAJxazJGxh2w5dyMu19attdByCO6DMCACA1jK+Q6rdYi3Ykkhl+kj/KPIEz5nVHRJjn9DLfCOfNcAAA3Mlubcn21/n3HXARZk3eQIw5fGnEgO621o0c2CPOOwEQM/qMAABIDYFsIpmRmojxB+B3VJIB9mtL7K4D4AhmTd7AqQXwpUnD8jRv+SYFQ2HLawLphiYNzXNwVwCOy26fUfFs4hoBAPAiIpmRiojxB+BXVJIBX+hMbQkA12DW5A1c2Q1f6pWbpdLCvjGtKS3MU8/cTId2BMCSzvQZAQAA74pEMpctlaYvM2+LZjLcg3+NrzDj+a0gxh+AF0QqydZXRv+5PlJJtmiieTzgZ/mjbK6z+P0BgIRg1uQNDLvhW3NKBluOmBgxoLvmlBQ4vCMAx9WZPiMglRALCACAtxHjD8BvqCQDjkZtCeAbzJrcjxhz+FZWIF2V04arvLpWT62tU3NL25iJjDRDVw3N05ySAmUF0pOwSwBHoc8I6BixgAAA+Acx/gD8gkoyoC1qSwDfYNbkfgy7kQLCh39FewyAa9BnBEQXiQXs6GqJSCzgvs3m1WKB7IRtDwAA2BSJ8S+ameydAIA9nakk42sf/Gx8hVS/xVrqAbUlgAcwa3IrYszhW03BkKbMr9Himjo1t7R/THOLtLhmp6bMr1FTMJTYDcJ/iBXuPPqMgOiIBQQAAADgRlSSAe2jtgTwBWZN7sewG75VXr1Rq7ftt3Ts6m37VV5d6/CO4FvBA9LzN0tzC6QVd5pRwrvWmLcr7jDvr75FCjYle6fuR58R0D67sYCcbAMAAADAaVSSAdFFaktm1Epjb5cGFkt9h5m3Y2837y+Zx6AbcDFmTe7HsBu+tKehSVXrdsW0pmpdnfY2HHRoR/CtSKzw+srokV2RWOFFE83jEV2kzygW9BkhFXQmFhAAAAAAnEQlGXB8kdqSsqXS9GXmbdFM3tMCXI5Zkzcw7IYvLVlTp2Aoto6EYCisJWvrHNoRfItY4fgbX2H2FFlBnxFSBbGAAAAAANyKSjIAyUKtJBzGrMkbGHbDl6xGShzr7a31cd4JfI1YYWfQZwS0RSwgAAAAALeikgxAolEriQRh1uQNGcneAOCExoPNCV2HFNWZWOGimc7syS8ifUbFs80/r+2vm0O7Ljnmmd8XlBHzhNRCLCAAAAAAt4pUkq2vtL6GSjIAdkVqJTtK24zUSu7bbF5UE8hO2PbgL8yavIFhN3wpJ9Pep7bddUhRnYkVZthtTaTPiD8vpLr8UebZyTGvIxYQAAAAQAKMr5Dqt1ireqOSDEBn2KmVLJnn7J7gW8yavIEYc/jSiAHdba0bObBHnHcCXyNWGECiEAsIAAAAwM2oJAOQCNRK+osHOteZNXkDpxbAlyYNy9O85ZsUDIUtrwmkG5o0NM/BXcF3iBUGkCjEAgIAAABwOyrJADiNWkl/CB4wr9B/54m2H8+tr0gr7zbf1xpXkfSTo5g1eQNXdsOXeuVmqbSwb0xrSgvz1DM306EdwZfyR9lcR6wwABvGV5hxf1YQCwgAAAAgWSKVZGVLpenLzNuimQy6AXReZ2ol4Q6RzvX1ldFPXIh0ri+aaB6fRMyavIFhN3xrTslgyxETIwZ015ySAod3dBweiOzAMYgVBpBIxAICAAAAAIBURq2k99npXE8yz82aUhAx5vCtrEC6KqcNV3l1rZ5au1PNLW2PyUiTrhraT3NKCpQVSE/8JiVPRXbgGMQKA0g0YgEBAAAAAECqolbS2+x2rhfPTur7XZ6ZNaUwht1IAWFJxuHbYxkJ3ssxIpEdHZ3JFIns2LfZvKIvkJ2w7cGC8RVS/RZrZ6MRKwwgXiKxgPRNAQAAAACAVJE/yrxALOZ11Eq6guc71108a0pxxJjDt5qCIU2ZX6PFNXVqbmnvi4/U3BLW4pqdmjK/Rk3BUIJ3KE9GduAYxAoDAGJFdQkAAAAAALGjVtLbPNq57olZU4rjym74Vnn1Rq3ett/Ssau37Vd5da3uuvJch3d1BI9GdqAdxAoDAKygugQAAAAAAPuolfQ2j3auu37WBK7shj/taWhS1bpdMa2pWlenvQ0HHdpROzoT2QF3isQKly2Vpi8zb4tm8s0UAOCL6pL1ldH//Y9UlyyaaB4PAAAAAACONr7CrIu0glpJd/Fg57onZk1g2A1/WrKmTsFQ+3ES0QRDYS1ZW+fQjtrh0cgOAABgA9UlAAAA1lH7AgCIhlpJ78ofZXNd8jrXPTFrAjHm8CerkRLHentrvW4qHhTn3UTh0cgOAAAQI6pLAAAArKH2BQBgBbWS3jSkTFpZEVvibZI71z0xawLDbvhT48HmhK6zxYORHQAAwIbOVJcUzXRmTwAAAG4TqX3pKA0nUvuyb7N5VV8gO2HbAwC4UKRWkp+dvcGDneuemDWBGHP4U06mvfM47K6zxYORHQAAwAaqSwAAAI6P2hcAAPzPY53rnpg1gWE3/GnEgO621o0c2CPOO+nAkLLonSLRJDmyAwBiRtceQHUJAADA8ditfeHnCgAAvMVjneuemDWBGHP406RheZq3fJOCobDlNYF0Q5OG5jm4q2N4MLIDACyjaw/4AtUlAAAAHaP2BQCA1OGhznVPzJrAld3wp165WSot7BvTmtLCPPXMzXRoR1F4LLIDACyJdO2tr4z+hlWka2/RRPN4wM+oLgEAAOgYtS8AAKSeSOd62VJp+jLztmimawbdkodmTSmOYTd8a07JYMsREyMGdNeckgKHd9QOj0V2AIAldO0BR6O6BAAAoGPUvgDHR00YACSFJ2ZNKY4Yc/hWViBdldOGq7y6Vk+trVNzS9uYiYw0Q1cNzdOckgJlBdKTsEt5KrIDAI7Lbtde8Wy+1sG/qC4BAADoGLUvQHTUhAFAUnlm1pTCGHYjBYQP/4r2mEtEIjvomgLgZXTtAe0bXyHVb7GWekB1CQAASDX5o8yhXczrqH2Bz0Vqwjr6OSJSE7Zvs5kgGchO2PYAILV4ZNaUgogxh281BUOaMr9Gi2vq1NzS/jHNLdLimp2aMr9GTcFQYjcIAH5E1x7QPqpLAADwJ2KF44PaF6B91IQBQNIxa3I/ruyGb5VXb9TqbfstHbt6236VV9fqrivPdXhXAOBzdO0B0VFdAgCAfxArHF/UvgBtURMGAK7ArMn9uLIbvrSnoUlV63bFtKZqXZ32Nhx0aEcAkCLo2gOOL1JdUrZUmr7MvC2ayRtSAAB4RSRWeH1l9AqfSKzwoonm8Ti+8RVmnYsV1L4gFXSmJgwAEBfMmryBYTd8acmaOgVDsXUkBENhLVlb59COACBF5I+yuY6uPQCdRIwsACBRiBV2BrUvwNGoCQOApGPW5A3EmMOXrEZKHOvtrfW6qXhQnHcDAClkSJm0siK2s8/p2gPQGcTIAgASiVhhZ1H7AnyBmjAASDpmTd7AsBu+1HiwOaHrAACH0bUHIJEiMbIdXV0XiZHdt9m8WiyQnbDtAQB8qDOxwkUzndmTH0VqX/gzQyqjJgwAko5ZkzcQYw5fysm0dx6H3XUAjkCMLOjaA5AoxMgCABKNWGEAiUJNGAAkHbMmb2DYDV8aMaC7rXUjB/aI806AFBI8ID1/szS3QFpxpxkdu2uNebviDvP+6lukYFOydwqn0bUHIBHsxshy8hUAoDOIFQaQKEPKov9MHQ01YQAQV8yavIFhN3xp0rA8BdKNmNYE0g1NGprn0I4An4vEyK6vjB7pF4mRXTTRPB7+Funam1Erjb1dGlgs9R1m3o693by/ZB6DbgD2dSZGFgAAu4gVBpAokZqwWFATBgBxxazJGxh2w5d65WaptLBvTGtKC/PUMzfToR0BPkeMLKKJdO2VLZWmLzNvi2bywzeAziNGFgCQDMQKA0gkasIAIKmYNXkDw2741pySwZYjJkYM6K45JQUO7wjwKWJkAQDJQIwsACAZiBUGkEjUhCGaxj3SqnulhROkxy42b1fdx/ttgAOYNbkfDenwraxAuh65rlATH35TW/Z+FvW4M3rm6LfXFSorkJ7A3QE+0pkY2aKZzuwJAOB/xMgCAJIhEiu8vtL6GmKFAXRGpCaseLb5Xsr2180TOLvkmKkRF5TxNSaVBA+YCYvvPNH2/bitr0gr7zb/3RlXwckPQJwwa3I/ruyGbzUFQ/reH9Z1+MVHkrbs/f/Z+//oKu78zv98lcRFUiJNEtzgdAbZgu7jfEdKJ8bi13fwKJGP+3us+Y4y/W1k5tjtiA6HTb4nna89SzTrzjCMorF320r3uptJMtnM+jAtt2zOYnWWsb479uxiYBycMQIJT2ak5MQgMOJ0YkB8J5EShK+uav/4qNogdEVV3Vt1qz71fJzDqUa3PlcfjPoi3XfV6zWrX/neqObyhZh2BliGGFkAQCUQIwsAqBRihQFUAjVhyN+UBrvMBVfFbjxZyEuj35UGd5rzAZSMWVPyMeyGtfqGx3X64g1f556+eEN9wxMR7wiwFDGyAIBKIEYWQKUQGwpihQEAlfDW89JHPm8e+eiU9PbXo90PkBHMmpKPGHNY6erMnIZGrwRaMzQ6pX1ffEhrG2oi2hVgKWJkAQCVQIwsgLgRG4rbESsMAIjTzMfme5Agzr1m/p3i3yMgNGZN6cCd3bDSkTNTyhfcQGvyBVdHzk5FtCPAYsTIAgAqhRhZAHEhNhTFECsMAIjDuVeLfw9SzELeXJAFIDRmTenAsBtW8hspsdT7k9Nl3gmQAcTIAgAqhRhZFEPMNMqN2FAAAFBJl94Luc7n9y8AlsWsKR2IMYeVZm/Nx7oOyDRiZAEAlUSMLG5HzDSiQGwoAACotE9m410HQBKzprRg2A0r1deE+9IOuw7IvI5+afqCv7tdiJEFAETBi5Ft66n0TlApXsz0St+PeDHT18+bVIBcXWzbQ4qVEhvKaxIAACiH1fXxrgMgiVlTWhBjDitt27Am1LrtG+8r806AjCBGFgAAVBox04gKsaEAAKDSmnaEXPdoefeBu1GhZDVmTenApQWw0q4tjTr4zofKF1zfa3LVjnZtboxwV4DliJEFAACVQsw0okRsKAAAqLRN3dLJ/mBpM1U5834cokGFUiYwa0oH7uyGldY11KqrdX2gNV2tjVrbUBPRjoAM8WJku49Ke4+ZY1sPbyQDAIDolBIzDdwLsaEAAKDSGu6XHn462JpNX+H9uKh4FUpjA8V/DvEqlAZ3mvORSsya0oFhN6zV29niO2Ji24Y16u1sjnhHAAAAACJBzDSiRGwoAABIgo5+6UGf3188+Ki5oxjRoEIpU5g1JR/DblirNletgT1b9dTWB7Sqyln2nFVVjp7a+oAG9mxVba465h2irOhGAQAAyC5iphGlTd0mBjQIYkMBAEC55eqkZ4ak1q8W/96kKmcef+b7RGdHJWyFEu9TpxazpuSjsxsZ4C7+KvYYUo1uFAAAABAzjSh5saFjA/7XEBsKAACikKuTOg9K7ftNJc+lU+YCztX1JlXmkW6+B4laKRVKbT3R7AkxYdaUVAy7Ya25fEG7D43o9MUbRc+ZX5AOj1zW5LVZrrhJI68bZaXIGK8b5fp5c+Vjri627QEAACAmTTvMhY6B1xEzDZ86+qXpC/7iKokNBQAAUatfZwanDE/jV0qFEn9fqcSsKflSHWPuOE6d4zj/ynGcP3ccZ85xnB84jnPIcZy/G+K5fsJxnIOO43zkOM6txeN3HMf58Xusq3ccp9dxnD9xHGfWcZy/chznvzmO83uO43CbQAX1DY+v+OJzu9MXb6hveCLiHaHs6EYBgMqhPgJAkhAzjagRGwoAAACJCqUMYtaUfKkddjuOUyvpuKQDkuol/XtJU5J+WdI5x3E2Bniuz0gakfSspHlJRyXNSHpO0mnHcZZtnnccZ4OkP5H0W5J+VNJbkv6TpJykX5P044H/YCiLqzNzGhq9EmjN0OiUrs3cimhHKDu6UQCgMvI3pTeflV5ulo6/aO6kvHLGHI+/YD4+/JyUn6v0TgFkiRczHQQx0wjKiw3dNyE9dkDa2C6t32KOjx0wH+88yKAbAADAZlQoZQqzpnRI7bBb0r+QtF3Sf5b0kOu6/8R13W2SfkPSWkmHAjzXdyR9XtIfSvrpxef6GUm/I+khSS8vXeA4To3McPsBSf+r67qfc133Sdd1f9F13Z+W9AVJ/i71QNkdOTOlfCFYR0K+4OrI2amIdoSyK6UbBQAQjlcfMTZQ/DXYq48Y3GnOB4C4dPSb+Gg/iJlGKbzY0O6j0t5j5tjWw8UTAAAAWdC0I+Q6KpTSiFlTOqRy2O04zmpJv77426+5rvvD/AfXdV+Wudv65x3HafXxXJ+V9JSkTyT9muu687c9/M8kXZP0jOM4S39qfU7ST0t62XXdP1j6vK7r/jfXdf82wB8LZeQ3UmKp9yeny7wTRKaUbhQAQDjURwBIMmKmAQCgbggAokaFUqYwa0qHVZXeQEg7JP2YpAuu655b5vEhST8rqVPS6D2e6wmZof8fua778e0PuK57y3GcYUl7JP1DSd+97eH/0+LxdwLvHpGbvTV/75PKuA4VQDcKAMQrbH1E+37udAMQHy9mun2/SfS5dMp8/7e63txJ8Ug3r0kAADvlb5qLUz94/e4UpskT0smXTIXHE/1c8AUApfAqlMYG/K+hQim1mDWlQ1qH3T+3eBwr8rj38Z8t03Ptuf25HMdplIk9v+K67pTjODsk/aLMAP6ipO+7rnvex+dGROprwn1ph12HCqAbBQDiVUp9RFtPNHsCgGK8mGlefwAAWeDVDa2UwuTVDV0/b5JQcnWxbQ8ArNPRL01f8Jd+R4VSqjFrSodUxpjL9GRLUrFWeO/jD0b0XM2Lxx84jvN7kk5J+r9I+lVJL0n6U8dxfsPH55YkOY4zvtwvSZ/z+xy407YNa0Kt277xvjLvBJGhGwUA4kV9BAAAAIohOruyqBsCgHhRoZQZzJrSIa3Dbu/WzGKd2H+zeGyI6Ll+YvH4iKT/VdJvSWqU9FlJzy8+9i3Hcf5nH58fEdi1pVG5aifQmly1o12bGyPaEcqObhQAiBf1EQAAAFgqf1N681np5Wbp+IsmLvvKGXM8/oL5+PBzUn6u0ju1V9i6IS5EAIDSeBVK+yakxw5IG9ul9VvM8bED5uOdBxl0pxyzpnTgPvpwvIsEVkn6fdd1+2577Lcdx/mMpH8m6Z9L+v/c68lc121Z7uOLd3c3L/cYVrauoVZdret1eGTK95qu1katbaiJcFcoK7pRACBe1EcAAADgdkRnJwN1QwBQWVQoWY1ZUzqk9c5u7xahHyny+I8uHmcieq7bb1H6d8us8T62zXEcLtupkN7OFt8RE9s2rFFvJ9cVpE5Hv+k88YNuFAAoDfURyUVsKAAAqASis5OBuiEAACLFrCn50jrsvrx4XF/kce/jH0X0XLf/70vLrPE+Vi0pXKA/Slabq9bAnq16ausDWlXkK31VlfTU1gc0sGeranPV8W4QpaMbBQDiQ31E8hAbCgAAKoXo7OSgbggAgEgxa0q+tMaY/5fF4yNFHvc+/icRPdefSZqTVCvT331tyZrbB9x851hxriRn8bhUsK4FJJDXjdK+30RwXTplfmBbXW/uJnykm+hyACgH6iOShdhQAABQSURnJwd1QwAAxIRZU1Kl9c7u9yT9laTPOY7z8DKPdy0eh30819uSFiT9A8dx7ng31nGcGkmdkgqS/oP3cdd1b0n6j4u//YVlnvPnF4+Truv+tY89IAJz+YJ2HxrR4ZEpzS8s9+IjzS+4OjxyWbsPjWguX4h5hygrrxul+6i095g5tvUwZAGAcqI+IjmIDQUAAJVEdHZyUDcEAECkmDUlXyqH3a7rfiLpdxd/+3uO43i92nIcZ5+kn5X0n1zXHb3t47/uOM6fOY7zjSXP9ReSDktaLenfOI5z+93uvy1praRB13WX5iz99uLxgOM4D932eTZIemHxt/+PsH9GlK5veFynL97wde7pizfUNzwR7BPQjwkAyBrqI5KB2FAAAFBpRGcnB3VDAABEKvJZE0qW1hhzSXpR0uOS/r6kDx3H+SNJD0raJhMrvmfJ+Z+R9NOSPrvMc/1TSdsl7ZT0Z47jnJXUIulnJH0oad/SBa7r/rHjOP9K0r+UdM5xnPdk7gDfIalB0luSXi7tj4iwrs7MaWj0SqA1Q6NT2vfFh7S2oWblE/M3zd1UH7x+d2TX5Anp5EsmtvWJft7kBwDYh/qIyiM2FAAAVBrR2clB3RAAAJGJdNaEsknlnd2S5LrunKR2mbuo/1bSl2SG3d+V9IjrupMBnuu6pK2SfkfmDu//RdKPSfrXkra6rrvsJRuu6/bKDMhHZYblPy/pgqT/s6RfdF2XrIIKOXJmSvnC8nESxeQLro6cnbrHSYv9mGMDxd9k9voxB3ea8wEAsBH1EZVDbCgAAKg0orOThbohAAAiEdmsCWWV2mG3JLmue9N13X/puu7nXdetcV33s67r/rLrunddZuG67m+5ruu4rvvVIs91w3XdZ13XfWDxuR5wXfc513X/+z328Ieu67a5rvt3XNf9Edd1N7mu+x3XdefL86dEGH4jJZZ6f3J65RPoxwQAAJVGbCgAAKg0orOThbohAAAiqZ6NbNaEskpzjDlQ1OytcNcarLgubD9m+37ucgMAAOVDbCgAAKg0orOTh7ohAEBWRVg9G8msCWXHsBtWqq8J96W94jr6MQEAQBI07TA/rAVeR2woAAAoo45+afqCvwQ8orPj49UN8V4UACALvOrZlb4f8apnr583SSi5Ot9PH8msCWWX6hhzoJhtG9aEWrd9433FH6QfEwAAJAGxockVQWQaAACJRXQ2AACotIirZyOZNaHsuLQAVtq1pVEH3/lQ+YLre02u2tGuzY3FT6AfEwAAJAGxockTYWQaAACJRnQ2AAColBiqZyOZNaHsuLMbVlrXUKuu1vWB1nS1NmptQ03xE+jHBAAASdHRb+JA/SA2NFpeZNrYQPHKGy8ybXCnOR8AANt40dndR6W9x8yxrYdBNwAAiE4p1bM+RTJrQtkx7Ia1ejtbfEdMbNuwRr2dzSuf1LQj3EboxwQAAOVGbGhyRByZBgBYAfURAAAA2RVT9WzZZ00oO8d1/d96j3g5jjPe3NzcPD4+XumtpNZcvqC+4Qm9cXZK8wt3f62vqnL05OZG9XY2qzZXvfKTzXwsfbsl2JVCVTlp3wRXMgMAgOjMXiU2tFL4/hAAKmOl+gjJvNZSHwEAAGC3Vx6XrpwJvm79FpNEE0BZZ024S0tLiyYmJiZc120Js57ObmSAu/ir2GM+0Y8JAACSyIsNbeup9E6yp5TINP6+ACAcrz5ipVQNrz7i+nmThJKri217AAAAiEns1bNlmjWh7Igxh7Xm8gXtPjSiwyNTml9Y/pz5BenwyGXtPjSiuXzh3k9KPyYAAAA8MUWmAQBuQ30EAAAApNiqZyOZNaGsGHbDWn3D4zp98Yavc09fvKG+4Yl7n0g/JgAAADyfzMa7DgCybuZjE10exLnX6PAGgHKZvSq9+03p1S+Z+OBXvyS9+y1eZwFUxqbu4nOaYqpypvYtgEhmTSgrYsxhpaszcxoavRJozdDolPZ98SGtbahZ+cRcndR5UGrfTz8mAABAlsUemQYAGUd9BABURv6mSdb44PW7X4cnT0gnXzJ1jk/0c/MPgPjEUD0b6awJZcOd3bDSkTNTyheCdSTkC66OnJ3yv8Drx+w+Ku09Zo5tPQy6AQAAsiKmyDQAwCLqIwAgfvmb0mCXGSYVu+BoIS+Nflca3GnOB4C4RFw9G8usCSVj2A0r+Y2UWOr9yeky7wQAKoh4MQCIVkyRaQCARdRHAED83npe+sjnRUMfnZLe/nq0+wGA20VcPcusKR2IMYeVZm/Nx7oOABKFeDEAiEcMkWkAgNtQHwEA8Zr52Ly3EMS510z9I9/zAohLhNWzzJrSgWE3rFRfE+5LO+w6AEgML15spauuvXix6+fNlY+5uti2BwDW6eiXpi/4u9slRGQaAOA2TTvMxZuB11EfAQChnHu1eHR5MQt5M2xq64lmTwBQjFc9W8bXH2ZN6UCMOay0bcOaUOu2b7yvzDsBgJgRLwYA8Yo4Mg0AcBvqIwAgXpfeC7nutvclqFgDkGLMmtKBSwtgpV1bGnXwnQ+VL7i+1+SqHe3a3BjhrgAgYsSLAUBlRBiZBgC4DfURABCvT2bDr6NiDYAFmDWlA3d2w0rrGmrV1bo+0Jqu1katbaiJaEcAEINS4sUAAKXzItO6j0p7j5ljWw9DFgAop45+UwvhB/URAFCa1fXh1uV+xFSsjQ0Uf5/Cq1gb3GkG4wCQQMya0oFhN6zV29niO2Ji24Y16u1sjnhHABCS38ivcsSLAQAAAElGfQQAxKdpR7h1t/6aijUA1mDWlHyO6/q/9R7xchxnvLm5uXl8fLzSW0mtuXxBfcMTeuPsZc0v3P34qirpyc0PqLezWbW56vg3CAArWSnySzJv4t0e+fXK49KVM8E/z/ot5g5EAAAAIE1mr1IfAQBRmvlY+nZLsBS5qlWSK8mdD7AmJ+2b4LUbQGIxa4pWS0uLJiYmJlzXbQmzns5uZIAryVk8LuXEvBcA8Cl/00R+rXQltBf5df28ubslbLxY2HUAAABAJXn1EW09ld4JANip4X7p4adNHLlfP/kF6Qfngn0er2KN13MAicasKakYdsNac/mCdh8a0emLN4qeM7/g6vDIZU1em9XAnq1ccQMgOd56PnjkV9MOafJE8M/V5LPzEAAARGv2qnkz+dJ73KUKAACSoaNfmr7g7z2KBx+VnJDNqZdOMewGkEjMmpKPzm5Yq294fMUXn9udvnhDfcMTEe8IAHya+dhElwdx7jXpoX9YvLewmKqceQMdAABUTv6m9Oaz0svN0vEXzcVrV86Y4/EXzMeHn5Pyc5XeKQAAyJpcnUmTa/1q8fccqnLm8We+L83fDPd5PpkNu0MAiBSzpuRj2A0rXZ2Z09DolUBrhkandG3mVkQ7AoAAzr0arA9LMuf/+VsmXiyITV/hTjEAACrJqy4ZGyj+779XXTK405wPAAAQp1yd1HnQ9Go/dkDa2C6t32KOjx0wH+88KOVqqVgDYBVmTenAsBtWOnJmSvnCcr0JxeULro6cnYpoRwAQwKX3Qq47ZeLFHvQZS/7go9IT/eE+FwAAKI8w1SUAAACVUL/ORI13H5X2HjPHtp47L6Jv2hHuualYA5BAzJrSgWE3rOQ3UmKp9yeny7wTAAghbHTXJ7PB48VytWF3CQAAShW2umT2ajT7idPsVendb0qvfkl65XFzfPdbdvzZAADIsk3dVKwBsAazpnRYVekNAFGYvTUf6zoAKKtSI7+8eLH2/dLYq+aO709mzeNNj5ofIIkuBwCg8sJWl4y9au6iSqP8TXM3+wev3/1nnzwhnXzJ1Kw80c9FeQAApFHD/aZibWzA/xoq1gAkFLOmdGDYDSvV14T70g67DgDKqmmHebM38LolkV9evFha3wwHAMB2pVSXpPHfd6+ffKXYdq+f/Pp5k1aTq4ttewAAoEw6+qXpC/6qWqhYA5BgzJrSgRhzWGnbhjWh1m3feF+ZdwIkBDGR6ULkFwAA2VBKdUka0U8OAEA2ULEGwBLMmtKBSwtgpV1bGnXwnQ+VL7i+1+SqHe3a3BjhroAKICYynYj8AgAgG0qtLkmTsP3k7fv5HgcAgDSiYg2ABZg1pQN3dsNK6xpq1dW6PtCartZGrW2oiWhHQAV4MZFjA8W7IL2YyMGd5nwkR0e/ifLyg8gvAADSqWlHyHU+v0dIklL6yQEAQHp5FWvdR6W9x8yxrYdBN4BUYNaUDgy7Ya3ezhbfERPbNqxRb2dzxDsCYkZMZLoR+QUAgP2yVF1SSj85AAAAKoNqRIBZUwoQYw5r1eaqNbBnq/qGJ/TG2SnNL9wdM7GqytGTmxvV29ms2lx1BXYJRISYSDsQ+QUAgN2yVF2StX5yAACANKMaEfghZk3Jx7AbGeAu/ir2GGChUmIi23qi2RPC8yK/+LsBAMA+Hf3S9AV/iTxpri7JUj85AABAmnnViCt9f+pVI14/b5IJc3WxbQ+oHGZNSUWMOaw1ly9o96ERHR6Z0vzC8ufML0iHRy5r96ERzeUL8W4QiBIxkQAAAOmQleqSLPWTA0DUiBUGECWqEYE7MGtKPobdsFbf8LhOX7zh69zTF2+ob3gi4h0BMSImEgAAID286pJ9E9JjB6SN7dL6Leb42AHz8c6D6R10S9nqJweAqORvSm8+K73cLB1/0UQJXzljjsdfMB8ffk7Kz1V6pwDSKmw1IhfbwGLMmpKPYTesdHVmTkOjVwKtGRqd0rWZWxHtCIgZMZEAAADp41WXdB+V9h4zx7aedHZ0L+X1kweR1n5yAIiCFys8NlC8tsyLFR7cac4HgKBKqUYELMSsKR0YdsNKR85MKV8I1pGQL7g6cnYqoh0BMSMmEgAAAEnT0W96x/1Icz85AESBWGEAcaAaEbgDs6Z0YNgNK/mNlFjq/cnpMu8EqBBiIgFUCv2BAIBistJPDgDlRqwwgLhQjQjcgVlTOqyq9AaAKMzemo91HZA4Xkzk2ID/NcREAihF/qa52+SD1++OPJs8IZ18ybzOPNHP8AIAsszrJ2/fb+IuL50yb46urjcpQ4908z0pACxVSqxwW080ewJgJ6oRgTswa0oHht2wUn1NuC/tsOuAROrol6Yv+Is5IyYSQCm8/sCVXm+8/sDr581dfbm62LYHAEggr5+cIQwA3FspscK8zgIIommHuWA98DqqEWEnZk3pQIw5rLRtw5pQ67ZvvK/MOwEqiJhIAHGhP9AexNADAAAkD7HCAOJCNSJwB2ZN6cClBbDSri2NOvjOh8oXXN9rctWOdm1ujHBXQAUQEwkgamH7A9v38/qTJMTQAwAAJBexwgDiQjUicAdmTenAnd2w0rqGWnW1rg+0pqu1UWsbaiLaEVBhXkxk91Fp7zFzbOvhG1EApSulPxDJ4MXQjw0U/7v0YugHd5rzAQAAEJ+mHSHXESsMIISOflN56AfViLAcs6Z0YNgNa/V2tviOmNi2YY16O5sj3hEAABYqpT8QyUAMPQAA2UN1SboQKwwgTlQjAndg1pR8xJjDWrW5ag3s2aq+4Qm9cfay5hfuPmdVlfTk5gfU29ms2lx1/JsEACDt6A9MN2LoAQDIFqpL0olYYQBxoxoR+CFmTcnHsBsZ4EpyFo9LOTHvBQAAy9AfmG6lxNC39USzJwAAEA2vumSlRBevuuT6eXNXX64utu3hHjr6pekL/hJ5iBUGUC5eNSI//wFi1pRcxJjDWnP5gnYfGtHhkSnNLyz34iPNL7g6PHJZuw+NaC5fiHmHAABYgP7AdCOGHgCA7KC6JN2IFQYAhEF1ScmYNSUfw25Yq294XKcv3vB17umLN9Q3PBHxjgAAsBD9gelGDD0AANkQtrqEN8KTxYsV3jchPXZA2tgurd9ijo8dMB/vPMigGwBgEl3efFZ6uVk6/qKpK7lyxhyPv2A+PvyclJ+r9E4Tj1lT8jHshpWuzsxpaPRKoDVDo1O6NnMroh0BAGAprz8wCPoDk4MYegAAsqGU6hIkjxcr3H1U2nvMHNt6+B4bAGB41SVjA8X//feqSwZ3mvOxLGZN6cCwG1Y6cmZK+cLycRLF5AuujpydimhHFiDuBABQTEe/6QX0g/7AZCGGHgCAbKC6BACA7KC6pGyYNaUDw25YyW+kxFLvT06XeScWIO4EAHAv9AemFzH0AABkA9UlAABkA9UlZcWsKR1WVXoDQBRmb83Hus5aXtzJSleBeXEn18+bQUeuLrbtAQASxOsPbN9v4i4vnTJvjq6uN3cBP9JNrGISeTH0YwP+1xBDDwBA+lBdAgBANpRSXdLWE82eUoxZUzow7IaV6mvCfWmHXWetMHEnnQej3RMAINm8/kB+QEqPjn5p+oK/f/OJoQcAIJ2adpiEtsDrqC4BACBVSqku4b2cuzBrSgdizGGlbRvWhFq3feN9Zd5JihF3AgBANhBDDwAIY/aq9O43pVe/JL3yuDm++y1+JkwqqksAAMgGqkvKillTOnBpAay0a0ujDr7zofIF1/eaXLWjXZsbI9xVyhB3AgBAdhBDDwDwK3/TpIB98PrdPzNOnpBOvmQqL57o5wKpJKG6BACAbKC6pKyYNaUDd3bDSusaatXVuj7Qmq7WRq1tqIloRylUStwJAABIJy+GvvuotPeYObb18EY3AMDI35QGu8zAtNjF0Qt5afS70uBOcz6So6PfVJL4QXUJAADp1LQj5DqqS5bDrCkdGHbDWr2dLb4jJrZtWKPezuaId5QyxJ0AAACkD7HCAKL01vPSRz4vcP7olPT216PdD4KhugQAAPtRXVJ2zJqSjxhzWKs2V62BPVvVNzyhN85OaX7h7piJVVWOntzcqN7OZtXmqiuwywQj7gQAACA9iBUGELWZj81rTBDnXjMVGSSEJAfVJQAA2I3qkrJj1pR8DLuRAe7ir2KPYVlNO8wbo4HXEXcCAAAQKy9WeKW7Lb1Y4evnzV19ubrYtgfAEudeLR5dXsxC3gxU23qi2RPC86pL+LsBAMA+Hf3S9AV/iTxUlwTArCmpiDGHtebyBe0+NKLDI1OaX1j+nPkF6fDIZe0+NKK5fCHeDSYdcScAUD7ECgOIErHCAOJw6b2Q63y+PgEAAKA8qC4pK2ZNyced3bBW3/C4Tl+84evc0xdvqG94Qt/48hci3lWKEHcCAKUjVhhA1IgVBhCXT2bjXQcAAIDwqC4pG2ZNyced3bDS1Zk5DY1eCbRmaHRK12ZuRbSjlOroNzEmfhB3AgB38mKFxwaKR356scKDO835ABBUKbHCABDE6vp41wEAAKB0XnVJ91Fp7zFzbOth0O0Ts6Z0YNgNKx05M6V8IVhHQr7g6sjZqYh2lFLEnQBAeMQKA4gDscIA4tK0I+Q6nxdQA0Ax1EIBACqEWVM6EGMOK/mNlFjq/clpfa3982XeTcoRdwIAwRErDCAuxAoDiMumbulkf7A0iaqc+ZkRAMKgFgoAUGHMmtKBYTesNHtrPtZ1meDFnbT1VHonAJB8pcQK8zoLIAhihQHEpeF+6eGnTUWLX5u+woV8AMLxaqFWSsvyaqGunzfJhLm62LYHAMgGZk3pQIw5rFRfE+46jrDrAAC4A7HCAOJCrDCAOHX0Sw/6fP148FFztyUAhBG0Fuo7XyDeHABQdsya0oFhN6y0bcOaUOu2b7yvzDsBAGQSscIA4rKp28QEB0GsMICwcnXm7snWrxZ/7anKmcef+T6xwgDCCVML9TfXTLT58Rekl5ul4eek/Fw0+wMAZAazpnRg2A0r7drSqFy1E2hNrtrRrs2NEe0IAJApxAoDiIsXKxwEscIASpGrkzoPSvsmpMcOSBvbpfVbzPGxA+bjnQcZdAMIL0wt1O28ePPBnSYOHQCAkJg1pQPDblhpXUOtulrXB1rT1dqotQ01Ee0IAJApxAoDiBOxwgAqoX6d1NYjdR+V9h4zx7YeLqYBULqwtVBLfXRKevvr5XkuAEAmMWtKB4bdsFZvZ4vviIltG9aot7M54h0BAKw2e1V695umJ+5P/3dJwa76JFYYQGjECgMAAJuUs97p3Gt0eAMASsKsKfnK1pDuOM4hSadc1z10j/O+KqnNdd095frcwHJqc9Ua2LNVfcMTeuPsZc0v3H3Oqirpyc0PqLezWbW56vg3CQBIv/xN6a3nTadcKVF7xAoDKIUXK9y+Xxp7Vbp0yrxRvLrepEY80s1rDAAASIdy1jst5M33Rm095XtOAECmMGtKvrINuyV9dfG44rBb0g5JuyUx7EZMXJm769xlHgt41x0AALfL35QGu0w8XimIFQZQLl6sMG/oAgCAtGraIU2eKN/zXTrF90YAgDJg1pRU5Rx2+7VaUqECnxcZM5cvaPehEZ2+eKPoOfMLrg6PXNbktVkN7NnKFTcAgGDeer60QXdVztzR/UQ/scIAojV7VRobMB2Y3PENAACSbFO3dLK/tOSs25UzFh0AkDnMmpIv1mG34ziOpEckXYvz8yKb+obHV3zxud3pizfUNzyhb3z5CxHvCgBgjZmPTXR5II702Z+T6n6CIROAeKxUtTB5Qjr5EhfdAACAZGm4X3r4aXOhXjmUMxYdAJA5zJqSr6Rht+M4x5d86IllPnb75/qcpJ+U9L1SPi9wL1dn5jQ0eiXQmqHRKe374kNa21AT0a4AAFY592qIOw1c6e91EqEHIB5+qhYW8tLod6Xr56Vnhkz3NwAAQKV19EvTF0qvjJLMhcYAAITArCkdqkpc/wu3/XJlBtm/UOTXo5I+I+l/l8Q7vIjUkTNTyheW600oLl9wdeTsVEQ7AgBY59J7IdeV4c0aAPAjSNXCR6ekt78e7X4ApM/sVendb0qvfkl65XFzfPdb5uMAEKVcnbkQr/Wrpv4prKqcSdQCACAEZk3pUOqwe8Pir40y7etDt31s6a+/K6nedd1/7Lru9RI/L7Aiv5ESS70/OV3mnQAArBW2942+OABxCFO1cO41BlgAjPxN6c1npZebpeMvmtqDK2fM8fgL5uPDz0n5uUrvFIDNcnVS50Fp34T02AFpY7v0o2uDPcemr1AdBQAIjVlTOpQUY+667kfe/3Ycp0/Suds/BlTK7K35WNcBADIobO8bfXEA4hCmamEhL429StUCkHVUIABImvp15vuTth5/r1GeBx+VnuiPfn8AAGsxa0qHUu/s/iHXdftc132zXM8HlKK+Jtx1HGHXZRqxdgCyqmlHyHX0xQGIAVULAMKiAgFAkvmJN6/Kmcef+b6Uq41zdwAAyzBrSgf+a8NK2zas0R99GDwtf/vG+yLYjaXyN82bIB+8fvddQ5MnpJMvmaioJ/r5wQKAnTZ1Syf7g905SV8cgLhQtQAgjLAVCO37iQkGEB8v3rx9v0mluXTKfA+zut5cXPxIN69JAICyYNaUDmW7sxtIkl1bGpWrdgKtyVU72rW5MaIdWcaLjBobKD7k8WLtBnea8wHANg33Sw8/HWwNfXEA4kLVAoAwSqlAAIC4efHm3UelvcfMsa2Hn7kAAGXDrCkdGHbDSusaatXVuj7Qmq7WRq1tqIloR5Yh1g4AjI5+0wPnB31xAOJE1QKAMKhAAAAAAH6IWVM6MOyGtXo7W7Rtwxpf527bsEa9nc0R78gSYWPt6PAGYCP64gAk1abu4q9LxVC1AIAKBAAAgPSZvSq9+03p1S9Jrzxuju9+i/fky4RZU/LR2Q1r1eaq9Qe/1Kqdv//HunDtb4qe97m19fq3v9Sq2lx1jLtLsVJi7dp6otkTAFQSfXEAksirWhgb8L+GqgUAVCAAAACkR/6mSWH94PW737OfPCGdfMn8nPdEPzdglIBZU/JxZzesNZcv6Fe/N7rii48kXbg2q1/53qjm8oWYdpZyxNoBwPLoiwOQNFQtAAiKCgQAAIB0yN+UBrvMBc7Fbk5byEuj35UGd5rzEQqzpuRj2A1r9Q2P6/TFG77OPX3xhvqGJyLekSWItQMAAEgHqhYABEUFAiSiUAEASIO3npc+8nmD2UenpLe/Hu1+LMasKfmIMYeVrs7MaWj0SqA1Q6NT2vfFh7S2oSaiXVmCWDsAAID0oGoBQBBUIGQbUagAAKTDzMfm3+sgzr1mfi7k+7ZAmDWlA3d2w0pHzkwpX3ADrckXXB05OxXRjixCrB0AAED6ULUAwC8qELKJKFQAANLj3KvF/70uZiFvLoBGIMya0oFhN6zkN1Jiqfcnp8u8EwsRawcAQPoRTwoAKIYKhGwiChUAgPS49F7IdT7/rccPMWtKB2LMYaXZW/OxrssUYu0AAEgv4kkBAH5QgZAtRKECAJAun8zGuy7DmDWlA8NuWKm+JtyXdth1mdPRL01f8HfVN7F2AAAkgxdPutK/31486fXz5q6+XF1s2wMAJJBXgdDWU+mdIEqlRKHytQEAQPxW18e7LsOYNaUDMeaw0rYNa0Kt277xvjLvxFLE2gEAwiA6u7KIJwUAAMshChUAgHRp2hFy3aPl3UcGMGtKBy4tgJV2bWnUwXc+VL7g+l6Tq3a0a3NjhLuyDLF2AAC/iM6uPOJJAQBAMUShAgCQLpu6pZP9wZJZqnLmPXsEwqwpHbizG1Za11Crrtb1gdZ0tTZqbUNNRDuymBdr131U2nvMHNt6eGMcAGB40dljA8V/CPOiswd3mvNRfqXEkwIAALsRhQoAQLo03C89/HSwNZu+wnv2ITBrSgeG3bBWb2eL74iJbRvWqLezOeIdAQCQQURnJwPxpAAAoBiiUJOLGiAAQDEd/dKDPv8tfvBRk6aHUJg1JR/DblirNletgT1b9dTWB7SqyFf6qirpqa0PaGDPVtXmquPdIAAAtgsbnc2bd+VHPCkAAChmU7eJNg2CKNRo5W9Kbz4rvdwsHX/RVP9cOWOOx18wHx9+TsrPVXqnAIBKydVJzwxJrV8t/u94Vc48/sz3qY0rAbOm5KOzGxngSnIWj0s5Me8FAIAMKSU6u60nmj1lFfGkAACgGC8KdWzA/xqiUKPj1QCtlI7k1QBdP28GHbm62LYHAEiQXJ3UeVBq32/eS7l0yly0vrreJLA80s2/12XFrCmpGHbDWnP5gnYfGtHpizeKnjO/4OrwyGVNXpvlihsAAMqtlOhsht3l1bTD3AkUeB3xpAAAZEJHvzR9wV/9DFGo0QpTA9R5MNo9AQCSrX6deR+F91Iiwawp+Ygxh7X6hsdXfPG53emLN9Q3PBHxjgAAyBiis5ODeFIAALASolCTgRogAGkye1V695vSq1+SXnncHN/9Fq9JsA6zpuTjzm5Y6erMnIZGrwRaMzQ6pX1ffEhrG2oi2hUAABlDdHZyEE8KAADuhSjUyqMGCEAa5G+aFIoPXr/7NWvyhHTyJfPz5BP9XByF1GPWlA7c2Q0rHTkzpXxhud6E4vIFV0fOTkW0IwAAMqhpR8h1RGdHoqPfxI76QTwpAADZ5UWhdh+V9h4zx7YeBt1xKKUGCADikL8pDXaZC6mLXZyzkJdGvysN7jTnAynGrCkdGHbDSn4jJZZ6f3K6zDsBYkZ8EIAkITo7WYgnBQAASDZqgAAk3VvPSx/5vMDmo1PS21+Pdj9AxJg1pQMx5rDS7K35WNcBFUd8EIAkIjo7eYgnBQAASC5qgAAk2czH5r3HIM69Zn7+5OdMpBSzpnRg2A0r1deE+9IOuw6oKC8+aKWrKr34oOvnzV19ubrYtgcg4zr6pekL/q78Jjo7Pl48Kd2OAAAAydG0w1ywHngdNUAAYnDu1eLR5cUs5M2F1vzsiZRi1pQOxJjDSts2rAm1bvvG+8q8EyAGxAcBSDKiswEAQVHNAyCrqAECkGSX3gu5zuf7lkACMWtKBy4tgJV2bWnUwXc+VL7g+l6Tq3a0a3NjhLsCIkB8EIA0IDobAOAH1TwAso4aIABJ9slsvOuABGDWlA7c2Q0rrWuoVVfr+kBrulobtbahJqIdAREpJT4IAOLmRWd3H5X2HjPHth7enAMAfFrNMzZQ/Ptbr5pncKc5HwBs1NFv6n38oAYIQJxW18e7DkgAZk3pwLAb1urtbPEdMbFtwxr1djZHvCMgAsQHAQAApAsR3cujmgcADGqAACRV046Q63xewAMkFLOm5HNc1/+t94iX4zjjzc3NzePj45XeSmrN5QvqG57QG2enNL9w99f6qipHT25uVG9ns2pz1RXYIVCiVx6XrpwJvm79FnNXJQAAAOKxUkS3ZAYXWY3onvlY+nZLsMSiqpy0b4J0EAB2m71KDRCA5OB7NmQYs6ZotbS0aGJiYsJ13ZYw6+nsRga4i7+KPQakGPFBAAAAyedFdK9057IX0X39vLmjL1cX2/YqrpRqnraeaPYEAEng1QDxWgcgCRrulx5+2tTO+LXpKwy6YRFmTUlFjDmsNZcvaPehER0emdL8wvLnzC9Ih0cua/ehEc3lC/FuECgH4oMAAACSj4julVHNAwAAkA4d/dKDPt9XfPBRk1oEpByzpuRj2A1r9Q2P6/TFG77OPX3xhvqGJyLeERCBTd3FO7yKqcqZyDPYgd5PAACSbeZjE10exLnXsvVv+Sez8a4DAABAOLk6k0LU+tXi70lW5czjz3w/e/U8sBKzpuQjxhxWujozp6HRK4HWDI1Oad8XH9LahpqIdgVEgPig7Fqp93PyhHTypez2fgIAkCREdN8b1TwAAADpkauTOg9K7fvN96yXTpmLEFfXmzTJR7p57xHWYNaUDtzZDSsdOTOlfCFYR0K+4OrI2amIdgREiPig7PF6P8cGir957vV+Du405wMAgMogovveqOYBAABIn/p15uLM7qPS3mPm2NbDoBtWYdaUDgy7YSW/kRJLvT85XeadADEgPih76P0EACA9iOi+N6p5AABINyrWAFiKWVM6EGMOK83emo91HVBxxAdlR9jez/b9fA0AAFAJRHTfG9U8AACkExVrACzHrCkdGHbDSvU14b60w64DEsOLD8pKv2MW0fsJAEC6NO0wb/YGXpexiO6Ofmn6gr/0Gqp5AACoPK9ibaV/u72KtevnTSphri627QFAOTBrSgdizGGlbRvWhFq3feN9Zd4JAJRZOXo/iRcDACA+RHT7QzUPAADpQsUagAxg1pQOXFoAK+3a0qiD73yofMH1vSZX7WjX5sYIdwUAZVBK7yfxYgAAxI+Ibv+o5gEAIB2oWAOQEcya0oE7u2GldQ216mpdH2hNV2uj1jbURLQjACiTsP2duR8x8WJjA8Vj0L14scGdZjAOAADKo6PfRG/7QUT3p9U83UelvcfMsa2HN8cBAEiKUirWACBFmDWlA8NuWKu3s8V3xMS2DWvU29kc8Y4AoAyadoRbd+uviRcDAKBSiOgGAABp4af6rBwVawCQEsyaks9xXf+33iNejuOMNzc3N4+Pj1d6K6k1ly+ob3hCb5y9rPmFux9fVSU9ufkB9XY2qzZXHf8GASComY+lb7cEu4K6apXkSnLnA6zJSfsmuIMKAIBym71KRDcAAEielarPJPM+gVd9NvCPpCtngn+O9VtMagsApAyzpmi1tLRoYmJiwnXdljDr6exGBriSnMXjUk7MewGAEoXp/fzJL0g/OBfs83jxYm09wdYBAICVeRHd/BsLAACSIn/TVJ+tlAjnVZ9dPy+tqgv3ecJWswFAIjBrSiqG3bDWXL6g3YdGdPrijaLnzC+4OjxyWZPXZjWwZytX3ABIh45+afqCv1jyBx+VnJCtJZdO8UY8AAAA0mf2qrk49NJ7JCgAgB9vPR+s+uynNoX7PE2PhlsHABXErCn56OyGtfqGx1d88bnd6Ys31Dc8EfGOAKBMgvZ+zt8M93k+mQ27QwAAACB++ZvSm89KLzdLx1+UJk+YmN3JE9LxF8zHh5+T8nOV3ikAJMfMxya6PIi//K+SE/A+uqqcuegIAFKGWVPyMeyGla7OzGlo9EqgNUOjU7o2cyuiHQFAmeXqpM6Dplf7sQPSxnbTfbWx3fx+34R5PFcbPiaMeDEAAACkhRfBOzawfNes9GkE7+BOcz4AQDr3avHXzWIW5qXPfiHYmk1fIV0DQOowa0oHht2w0pEzU8oXlutNKC5fcHXk7FREOwKAiHi9n91Hpb3HzLGt584fIJt2hHtu4sUAAACQFkEjeN/+erT7AYC0uPReuHU1f8dUp/nx4KPSE/3hPg8AVBCzpnRg2A0r+Y2UWOr9yeky7wQAEmBTd/G482KIFwOA5c1eld79pvTql6RXHjfHd79lPg4AqIwwEbznXuO1GwCk8BVm+b8NVrGWqw27QwCoGGZN6RCwWANIh9lb87GuA4BEa7hfevhpE+noF/FiAHCn/E1z1+AHr98d8zh5Qjr5knntfKKfN/IAIG6hInjz0tirJhUJALKslOozr2Ktfb95Tb10ygzPV9ebtLhHunlvAUCqMWtKB4bdsFJ9Tbgv7bDrACDxOvql6Qv+oh2JFwOAO3k9sCu9hno9sNfPmztccnWxbQ8AMi9sBO+lUwy7AaBph7l4M/C62yLMvYo1XlMBWIZZUzoQYw4rbduwJtS67RvvK/NOACAhcnXEiwFAWPTAAkCyhY3gDbsOAGxC9RmALAhZScasKR24tABW2rWlUQff+VD5gut7Ta7a0a7NjRHuCgAqjHgxAAgubA9s+35eUwEgLqVE8AJA1lF9BsBmJVaSMWtKB+7shpXWNdSqq3V9oDVdrY1a21AT0Y4AIEG8eLHuo9LeY+bY1sMPqgCwnFJ6YAEA8WjaEXLdo/c+BwCyoKPfVJr5QfUZgLTwKsnGBor/XO9Vkg3uNOcvwawpHRh2w1q9nS2+Iya2bVij3s7m5R8MGW8BAAAAC5TSAwsAiAcRvABQGqrPANioTJVkZZs1ITLEmMNatblqDezZqr7hCb1xdkrzC3fHTKyqcvTk5kb1djarNld954MlxlsAAADAAvTAAkDyEcELAKWj+gyATcpYSVbyrAmRY9iNDHAXfxV7bBlevMVKV/148RbXz5srH3N1Je4TAAAAiUMPLACkQ0e/NH3B3907RPACQHFe9VlbT6V3AgDhlVJJVvT1L8SsCbEgxhzWmssXtPvQiA6PTGl+Yflz5hekwyOXtfvQiObyhU8fKFO8BQAAQMVQxVIe9MACQDoQwQsAAABPGSvJSpo1IRYMu2GtvuFxnb54w9e5py/eUN/whPlN2HgL3jgGAABJkL8pvfms9HKzdPxFU79y5Yw5Hn/BfHz4OSk/V+mdpgM9sACQHl4E774J6bED0sZ2af0Wc3zsgPl450EG3QAAALYrYyVZ6FkTYsOwG1a6OjOnodErgdYMjU7p2syt0uItAAAAKsmrYhkbKP79jFfFMrjTnI+VeT2wQdADCwCV5UXwdh+V9h4zx7YeXpsBAACyokyVZCXNmhAbht2w0pEzU8oXgnUk5AuujpydKmu8BQAAQKyoYolGR7/pd/WDHlgAAAAAACqrTJVkJc2aEBuG3bCS30iJpd6fnC5rvAUAAEBsqGKJDj2wAACY7xne/ab06pekVx43x3e/xfcSAAAgecpUSVbSrAmxWVXpDQBRmL01H35dfXniLQAAAGJVShVLW080e7KJ1wPbvt/8N7t0ylzsuLreXPn9SDfxuAAAO+VvmvSYD16/+3uNyRPSyZdMhccT/VzwBQAAksGrJBsb8L9mmUqykmZNiA3Dblipvibcl3Z9zSoTbzF5IvjiJp/RlgAAAFEopYqFYbd/Xg8s/80AAFmQvykNdq1ck7KQl0a/K10/b5JQcnWxbQ8AAKCojn5p+oK/urcilWQlzZoQG2LMYaVtG9aEWrd9431li7cAAACIFVUsAACg3N563t8bxJI57+2vR7sflIYoegBAlpShkqykWRNiw6UFsNKuLY06+M6Hyhdc32ty1Y52bW6UGmrKEm8BAAAQq7CVKlSxAACA5cx8bKLLgzj3mqn84D2SZCGKHgCQVSVWkpU0a0JsuLMbVlrXUKuu1vWB1nS1NmptQ435TUe/ia3wo0i8BQAAQKyadoRcRxULAABYxrlX7x6M3stC3ryRjOTwoujHBor/fXpR9IM7zfkAANjGqyTrPirtPWaObT33vECv5FkTYsGwG9bq7WzxHTGxbcMa9XY2f/qBMsRbAACQesQcpgtVLAAAoJwuvRdync/Yc8SDKHoAAEpS0qwJsUj1sNtxnDrHcf6V4zh/7jjOnOM4P3Ac55DjOH83xHP9hOM4Bx3H+chxnFuLx+84jvPjPtevdhxnwnEc13Gc+cB/GJRdba5aA3u26qmtD2hVka/0VVXSU1sf0MCerarNVd/5oBdvsW9CeuyAtLFdWr/FHB87YD7eeZBBNwDAPvmb0pvPSi83S8dfNNGGV86Y4/EXzMeHn5Pyc5XeKW7XcL+pYgmCKhYAAFDMJ7PxrkP5hY2i5+JWAAB+qORZEyKX2s5ux3FqJR2XtF3SX0j695KaJP2ypH/kOM5213UnfT7XZyT9Z0mflzQp6aikFknPSepwHOd/dF33xj2e5p9L+h+C/0kQPVeSs3hcyrn3ci/eoq2nzPsCACCBvJjDle7+8GIOr583SSi5uti2h3vo6JemL/i7e4cqFgAAsJLV9fGuQ/mVEkXP+2AAACxR4qwJkUnznd3/QmbQ/Z8lPeS67j9xXXebpN+QtFbSoQDP9R2ZQfcfSvrpxef6GUm/I+khSS+vtNhxnL8n6Tcl/T+D/iEQnbl8QbsPjejwyJTmF5Z78ZHmF1wdHrms3YdGNJcvxLxDxIIIXgAIhpjDdKOKBQAAlEvTjpDrHi3vPhAeUfQAAJSMWVPyOa67/F9MkjmOs1rSVUk/JukR13XPLXn8v0j6WUmbXdcdvcdzfVbSFUnzkh5wXffj2x6rkTQlaY2kn3Jd967pmOM4jqR3ZYbi/4OkG5IKruuWfNe84zjjzc3NzePj46U+VSb95h/+iQ6PTPk+/6mtD+gbX/5ChDtCrPI3zcDmg9eXv4q5KmeiW5/o541+APDMfCx9uyXY3R9VOVPtQRR28sxeNXflXDpl4kRX15s3nx/p5u8LAADcG98bpt8rj5s6oqDWb5H2Hiv/fgAASCFmTdFraWnRxMTEhOu6LWHWp/XO7h0yg+4LSwfdi4YWj50+nusJmf8Of3T7oFuSXNe9JWlYUrWkf1hk/a9KelTSb7iu+3/4+HyIwdWZOQ2NXgm0Zmh0StdmbkW0I8TKi+AdGyj+Q7kXwTu405wPACgt5hDJ41WxdB81b1Z2HzW/581nAADgR8P90sNPB1uz6St8r5EkRNEDAFASZk3pkNZh988tHseKPO59/GejfK7Fu8JfkvSO67qDPj4XYnLkzJTyhWCpBfmCqyNn/V+dgwQjghcAwiHmEAAAALfr6Jce9BlL/uCjJj0NyUEUPQCUB1WZmcWsKR3SOux+YPFY7HIK7+MPRvxcvyupVtKv+fg8RTmOM77cL0mfK+V5s+z0xRuh1r0/OV3mnSB2Mx+b6PIgzr3GNyYAIJmo6zjXAQAAINlyddIzQ1LrV01E+XKqcubxZ75PTVjSbOou/vdWTFXO1N4AAEwi6JvPSi83S8dflCZPmHqIyRPS8RfMx4efk/Jzld4pIsKsKR1K7pWuEC9L52+LPP43i8eGqJ7LcZx/LOnLkvpc1/1zH58HMZq9NR/rOiRIKRG8bT3R7AkA0oKYQwAAACyVq5M6D0rt+83PzpdOmYsdV9ebO4Af6Sa6PKm8KPqxAf9riKIHAMOrylwpQdSryrx+3lwclquLbXuIB7OmdEjrsLuiHMdpkLmr+88lfaPU5ytWuL54d3dzqc+fRfU14b60w65DgpQSwcuwG0DWNe0wVycHXkfMIQAAgPXq15mfm/nZOV06+qXpC/7q3oiiB4BPhanK7DwY7Z4QO2ZN6ZDWGHMvK/NHijz+o4vHmYie6/8mab2kX3Ndl5b5BNq2YU2odds33lfmnSB2RPACQHjEHAKwHV17AICsIYoeAIKjKhOLmDWlQ1ovLbi8eFxf5HHv4x9F9FydkuYkHXAc58Aya6odxzm5+L//qeu6H/jYB8po15ZGHXznQ+ULru81uWpHuzY3RrgrxIIIXgAIj5hDALbK3zR3Znzw+t2VN5MnpJMvmdezJ/p5kx8AYB+i6AEgGKoysYhZUzqkddj9XxaPjxR53Pv4n0T4XLWSfn6F5/Ue+3Efe0CZrWuoVVfreh0emfK9pqu1UWsbaiLcFWJBBC8AlIaYQwC2oWsPAACDKHoA8IeqTCxi1pQOaY0xf0/SX0n6nOM4Dy/zeNficdjHc70taUHSP3Ac545LGB3HqZG5i7sg6T94H3ddt8l1XWe5X4unFG772MlAfzKUTW9ni++IiW0b1qi3k3p0KxDBCwClIeYQgG3CdO0BRN4DAABkF1WZuA2zpuRL5bDbdd1PJP3u4m9/z3Ecr1dbjuPsk/Szkv6T67qjt3381x3H+TPHcb6x5Ln+QtJhSasl/RvHcW6/2/23Ja2VNOi6Lj/RpkxtrloDe7bqqa0PaFWVs+w5q6ocPbX1AQ3s2araXHXMO0QkvAjeIIjgBYA7eTGH+yakxw5IG9ul9VvM8bED5uOdBxl0A0g+uvYQVP6m9Oaz0svN0vEXTWrUlTPmePwF8/Hh56T8XKV3CgAAgKhQlYnbMGtKvrTGmEvSi5Iel/T3JX3oOM4fSXpQ0jZJ1yTtWXL+ZyT9tKTPLvNc/1TSdkk7Jf2Z4zhnJbVI+hlJH0raF8H+ERt38Vexx2AdIngBoDyIOQSQdnTtIQgi7wEAACBRlYkimDUlVSrv7JYk13XnJLVLekHS30r6ksyw+7uSHnFddzLAc12XtFXS78jc4f2/SPoxSf9a0lbXdW+Uc++Ix1y+oN2HRnR4ZErzC8ufM78gHR65rN2HRjSXL8S7QUSHCF4AAABIpXXtIXuIvAcAADagjqV0VGXiNsyaks9xXa42SCrHccabm5ubx8fHK72VVPrNP/wTHR6Z8n3+U1sf0De+/IUId4SKmL1q7sy5dMp0pqyuN1fYPdJNdDkAAIDtXnncRFAHtX6LtPdY+feD5Jr5WPp2S7AkgKqcqfbg5woAAJAE+Zvm4r0PXl/+e5qqnKlzfKKfm3/8ePNZaWzA//mtXzWVb7AOs6botbS0aGJiYsJ13ZYw61N7ZzewkqszcxoavRJozdDolK7N3IpoR6gYL4K3+6h5w7L7qPk9b0gBAADYj649+FVK5D0AAECleXUsYwPFv6fx6lgGd5rzsbKOflOB6QdVmdZi1pQODLthpSNnppQvBEstyBdcHTnr/+ocINOIQwIAAGnQtCPkOrr2MofIewAAkGbUsZQfVZkQs6a0WFXpDQBROH0xXM36+5PT+lr758u8G8AiK8UhTZ6QTr5EHBIAAEiOTd3Syf7g0dR07WXPJ7PxrgMAACiXmY/Ne3VBnHtNat9P+uW95OpMNHn7fqoyM4pZUzow7IaVZm/Nx7oOyAQvDmmlq0S9OKTr582Vj7m62LYHAABwl4b7pYefDta1t+krvGGVRUTeAwCAtCqljqWtJ5o92caryuS/V+Ywa0oHYsxhpfqacNdxhF0HZAJxSAAAII3o2oMfRN4DAIC0oo4FiAyzpnRg2A0rbduwJtS67RvvK/NOAEuEjUOiwxsAUGmzV6V3vym9+iXplcfN8d1v8W9UltC1Bz82dRf/+iiGyHsAAJAE1LEAkWHWlA5cWgAr7drSqIPvfKh8wfW9JlftaNfmxgh3BaQYcUgAgLTJ3zSpJB+8fve/YZMnpJMvmbjqJ/oZbmYBXXu4FyLvAQBAWlHHAkSGWVM6cGc3rLSuoVZdresDrelqbdTahpqIdgSkHHFIAIA0yd+UBrvM0KrYxVoLeWn0u9LgTnM+ssHr2us+Ku09Zo5tPQwsYRB5DwAA0og6FiAyzJrSgWE3rNXb2eI7YmLbhjXq7WyOeEdAihGHBABIk7eelz7yecHVR6ekt78e7X4ApAOR9yiGSgwAQJJRxwJEillT8hFjDmvV5qo1sGer+oYn9MbZy5pfuPucVVXSk5sfUG9ns2pz1fFvEkgL4pAAAGkx87GJLg/i3Gsm3pq7ewEQeY/bUYkBAEgD6liASDFrSj6G3cgAV5KzeFzKiXkvQEo17TBv5gReRxwSACBm514tHl1ezELeDLXaeqLZE4D08SLveV3ILq8SY6WkEK8S4/p5kwqQq4ttewAA3KGjX5q+4C/hijoWICRmTUlFjDmsNZcvaPehER0emdL8wnIvPtL8gqvDI5e1+9CI5vKFmHcIpAhxSACAtLj0Xsh1PmPPAQDZQCUGgLSgagESdSxAhJg1JR93dsNafcPjOn3xhq9zT1+8ob7hCX3jy1+IeFdAShGHBABIi09m410HALAPlRgA0oCqBSxFHQsQCWZNyced3bDS1Zk5DY1eCbRmaHRK12ZuRbQjwAId/SbmyA/ikAAAlbK6Pt51AAD7lFKJAQBx8KoWxgaKv155VQuDO835yA6vjqX7qLT3mDm29TDoBkJg1pQODLthpSNnppQvLB8nUUy+4OrI2amIdgRYgDgkFENkGoAkadoRcp3PC7oAAPajEgNA0lG1AACxYNaUDsSYw0p+IyWWen9yWl9r/3yZdwNYhDgk3I7INABJtKlbOtkf7I68qpz5NwwAAIlKDADJRtUCAMSGWVM6MOyGlWZvzce6DsgcLw6prafSO0GleJFpK11J7kWmXT9vUgFydbFtD0CGNdwvPfy0iXT0a9NXeOMPAPApKjEAJFkpVQu8jwMAgTBrSgdizGGl+ppw13GEXQcAmUNkGoAk6+iXHvQZS/7goyaBAgAAD5UYyUWFEkDVAgDEiFlTOjDshpW2bVgTat32jfeVeScAYKGwkWm8AQUgLrk6kyjR+lUTUb6cqpx5/JnvU7UAALjTpu7i/34UQyVGtPI3pTeflV5ulo6/aGqTrpwxx+MvmI8PPyfl5yq9UyB6VC0AQGyYNaUDw25YadeWRuWqnUBrctWOdm1ujGhHAGCRUiLTACAuuTqp86C0b0J67IC0sV1av8UcHztgPt55kEE3AOBuXiVGEFRiRMerUBobKP5ziFehNLjTnA/YjKoFAIgNs6Z0YNgNK61rqFVX6/pAa7paG7W2oSaiHQGARYhMA5Am9etMN2H3UWnvMXNs62EgAQBYGZUYyUGFEnAnqhYAIDbMmtKBYTes1dvZ4jtiYtuGNertbI54RwBgCSLTgHujTxIAgHSjEiMZqFAC7kbVAgDEillT8tGQDmvV5qr1B7/Uqp2//8e6cO1vip73ubX1+re/1KraXHWMuwOAFCMyDSguf9PcffTB63fHbE6ekE6+ZGJOn+jnTXEAAJLOq8Ro328qeS6dMhdwrq43d0g+0k1SSNRKqVBq64lmT0CleVULYwP+11C1AAChMWtKPu7shrXm8gX96vdGV3zxkaQL12b1K98b1Vy+ENPOACDliEwDlkefJAAAdqISo3KoUAKWR9UCAMSGWVPyMeyGtfqGx3X64g1f556+eEN9wxMR76gERKECSBIi04Dl0ScJAABQXlQoAcujagEAYmPVrMlSxJjDSldn5jQ0eiXQmqHRKe374kNa21AT0a5CIAoVQBIRmQbcLWyfZPt+/r8BAABQDBVKQHFULQBA5KyZNVmOO7thpSNnppQvuIHW5AuujpydimhHIRCFCiDJiEwD7lRKnyQAAACWR4UScG9ULQBAZKyYNWUAw25YyW+kxFLvT06XeSclIAoVQJIRmQbciT5JAACA8qNCCQCA9EtxTasVs6YMIMYcVpq9NR/rurIjChVAGhCZBnyKPkkAAIDyo0IJAID0sqCmNfWzpoxg2A0r1deE+9IOu67sSolCbeuJZk8AUIwXmcbrD7KMPkkAAIBodPRL0xf8pd9RoQQAQDJ4Na0r/fvt1bReP28SJHN1sW3Pr9TPmjKCGHNYaduGNaHWbd94X5l3EhJRqAAApAt9kgAAANGgQgkAEEaKo7OtYElNa+pnTRnBpQWw0q4tjTr4zofKF1zfa3LVjnZtboxwVwEQhQoAQLps6pZO9gdLZqFPEgAAwB8qlAAAflkQnZ16FtW0pn7WlBHc2Q0rrWuoVVfr+kBrulobtbahJqIdBUQUKgAA6eL1SQZBnyQAAEAwXoVS91Fp7zFzbOvheyoAgOFFZ48NFL8Y3YvOHtxpzkf5lVLTmjCpnzVlBMNuWKu3s8V3xMS2DWvU29kc8Y4CIAoVAID06eg3PZF+0CcJAAAAAEB5WRKdnXqW1bSmetaUEQy7Ya3aXLUG9mzVU1sf0KoiX+mrqqSntj6ggT1bVZurjneDK9nUXbyHqhiiUONB1wsAoBj6JAEAAAAAqIyw0dm8r1t+ltW0pnrWlBF0diMDXEnO4nEpJ+a9+ORFoY4N+F9DFGq06HoBAPhBnyQAAAAAAPErJTq7rSeaPWWVtTWtKZw1ZQTDblhrLl/Q7kMjOn3xRtFz5hdcHR65rMlrs8m74qajX5q+4C92hSjUaHldLyv9XXhdL9fPm7v6cnWxbQ8AkEBenyQ/MAMAAAAAEL1SorP52b28mnaYG8QCr0tmTWvqZ00ZQIw5rNU3PL7ii8/tTl+8ob7hiYh3FBBRqMlB1wuAtKBqAQAAAAAAZJFl0dmpZllNa+pnTRnAnd2w0tWZOQ2NXgm0Zmh0Svu++JDWNtREtKsQiEKtvLBdL+37+bsBEB+qFgAAAAAAQJZZG52dQhbVtFoza7Icd3bDSkfOTClfWK43obh8wdWRs1MR7ahEXhRq91Fp7zFzbOtJ5Iu/dUrpegGAOHhVC2MDxV+vvKqFwZ3mfAAAAAAAAJs07Qi5LpnR2anX0W/qV/1IcE2rdbMmSzHshpX8Rkos9f7kdJl3gtQrpesFAOJA1QIAAACAuFGhBCBpLIvOTj1LalqZNaUDMeaw0uyt+VjXwWJ0vQBIMqoWAAAAAMSJCiUASWVRdLY1LKhpZdaUDgy7YaX6mnBf2mHXwWJ0vQBIslKqFtp6otkTAAAAADt5FUorJUt5FUrXz5s7+nJ1sW0PANTRL01f8JeAl+DobOt4Na0pfC+KWVM6EGMOK23bsCbUuu0b7yvzTpB6dL0kF5FpAFULAAAAAOJDhRKApLMkOhvJwawpHbi0AFbataVRB9/5UPmC63tNrtrRrs2NEe4KqbSpWzrZH+zOSbpeokVkGvApqhYAAAAAxIEKJQBpYUF0NpKDWVM6cGc3rLSuoVZdresDrelqbdTahpqIdoTU8rpegqDrJTpeZNrYQPELELzItMGd5nzAZlQtAAAAAIhDKRVKAFAJXnR291Fp7zFzbOvhfVsEwqwpHRh2w1q9nS2+Iya2bVij3s7miHeE1OroNx0uftD1Ei0i04A7UbUAAAAAIA5UKAH+ULsHWIdZU/Ix7Ia1anPVGtizVU9tfUCrqpxlz1lV5eiprQ9oYM9W1eaqY94hUoOul2QIG5nGDxOw2abu4q9LxVC1AAAAACAoKpSAleVvSm8+K73cLB1/0VTtXTljjsdfMB8ffk7Kz1V6pwACYtaUfHR2IwPcxV/FHgN8oOul8kqJTGvriWZPQKV5VQtjA/7XULUAAAAAICgqlIDivNq9ldIIvdq96+fNTTW5uti2B6BcmDUlFcNuWGsuX9DuQyM6ffFG0XPmF6TDI5c1eW2WK27gj9f1wvA0fqVEpvH3BZt19EvTF/xF/FO1AAAAACCMph3mDtXA66hQQgaEqd3rPBjtngCUDbOm5CPGHNbqGx5f8cXndqcv3lDf8ETEOwJQEiLTgOVRtQAAgJ3o/ASQJFQoAcujdg+wHrOm5OPObljp6sychkavBFozNDqlfV98SGsbaiLaFYCSEJkGFEfVAgAA9sjfNHeIffD63TU+kyekky+ZWpIn+rmIDUB8qFAClkftHmA1Zk3pwJ3dsNKRM1PKF4J1JOQLro6cnYpoRwBK1rQj5Doi05AhXtVC91Fp7zFzbOvhDSYAANLC6/wcGyj+xrnX+Tm405wPAHHp6DfVSH5QoYSsKKV2D0DiMWtKB4bdsJLfSIml3p+cLvNOAJQNkWkAAKQbkczAvYXp/ASAuFChBNyN2j3Aasya0oEYc1hp9tZ8rOsAxIDINAAA0olIZsCfsJ2f7fv5nhdAfKhQAu5E7R5gNWZN6cCwG1aqrwn3pR12HYCYdPRL0xf83e1CZBoAAJXnRTKv9G+3F8l8/by5WyxXF9v2gESh8xNAmngVSrz+IOuadpgLOAOvo3YPSANmTelAjDmstG3DmlDrtm+8r8w7AVBWRKYBAJAuRDID/pWj85O6AAAA4kXtHmA1Zk3pwKUFsNKuLY06+M6Hyhdc32ty1Y52bW6McFcAyoLINAAA0oFIZiCYUjo/qQsAAKAyqN0DrMasKR24sxtWWtdQq67W9YHWdLU2am1DTUQ7AlB2XmRa91Fp7zFzbOvhhwUAAJKilEhmIIvCdnfmfsTUBYwNFP//nFcXMLjTDMYBAED5dPSbOj0/qN0DUoVZUzow7Ia1ejtbfEdMbNuwRr2dzRHvCAAAALCEn6jkckQyA1nStCPcult/TV0AAACVRO0eYDVmTcnnuK7/W+8RL8dxxpubm5vHx8crvZXUmssX1Dc8oTfOXtb8wt2Pr6qSntz8gHo7m1Wbq45/gwAAAECarBSVLJk38byo5IF/JF05E/xzrN9iUluArJn5WPp2S7BEhKpVkivJnQ+wJiftmyARCQCAKMxepXYPsBCzpmi1tLRoYmJiwnXdljDr6exGBriSnMXjUk7MewEAAABSKn/TRCWvdAepF5V8/by0qi7c5wkb5QykXZjOz5/8gvSDc8E+j1cX0NYTbB0AALg3r3aPf2cBCzFrSipizGGtuXxBuw+N6PDIlOYXlk8wmF9wdXjksnYfGtFcvhDzDgEAAIAUeev5YFHJn8yE+zxNPvsOARsF7fxc3RDu81AXAAAAAPjCrCn5GHbDWn3D4zp98Yavc09fvKG+4YmIdwQASBQ/fbMAAGPmYxNdHsRf/lfJCRgmVpUzEY9AVgXt/Jy/Ge7zfDIbdocAAABApjBrSj5izGGlqzNzGhq9EmjN0OiU9n3xIa1tqIloVwCARFipb3byhHTypU/7ZnO1ldkjACTNuVeD9QhL0sK89FObgkUsb/oKXYZArk7qPCi1779352fY2H/qAgAAAIB7YtaUDtzZDSsdOTOlfGH5OIli8gVXR85ORbQjAEAieH2zYwPFhzZe3+zgTnM+AEC69F64dTV/J1gk8xP94T4PYCOv87P7qLT3mDm29dx5QUjTjnDPTV0AAAAAcE/MmtKBYTes5DdSYqn3J6fLvBMAQKIE7Zt9++vR7gcA0iJs5HH+b4NFMpOoAQSzqbv4/7eKoS4AAJZH1RUAYAlmTelAjDmsNHtrPtZ1AIAUCNM3e+41EyFKpC6ArCslKjlIJDOAYBrulx5+2qTW+EVdAADciaorAEARzJrSgWE3rFRfE+5LO+w6AEAKhOqbzZvBTFtPNHsCgLRo2mHe7A287raoZC+SmddUoLw6+qXpC/7Sa6gLAIA7eVVXK72GelVX18+bxJpcXWzbAwBUFrOmdCDGHFbatmFNqHXbN95X5p0AABIjbN/sJZ+x5wCCISYyXYhKBpIrV0ddAACERdUVAGAFzJrSgUsLYKVdWxp18J0PlS+4vtfkqh3t2twY4a4AABUVtm827DoAyyMmMp2ISgaSjboAAAiOqisAwD0wa0oH7uyGldY11KqrdX2gNV2tjVrbUBPRjgAAFVdK3yyA8vBiIscGitcKeDGRgzvN+UiOjn4TgewHUclAZXh1Ad1Hpb3HzLGth6EMACynlKorAEAmMGtKB4bdsFZvZ4vviIltG9aot7M54h0BACqqaUfIdT4HOwDujZjIdCMqGQCiR80HEB+qrgAAPjBrSj7Hdf3feo94OY4z3tzc3Dw+Pl7praTWXL6gvuEJvXF2SvMLd3+tr6py9OTmRvV2Nqs2V12BHQIAYjPzsfTtlmBX7lflpH0T3A0FlAP/H7TL7FWikgGgnFaq+ZDMv4nUfADl9crj0pUzwdet32LSMwAAmcGsKVotLS2amJiYcF23Jcx6OruRAe7ir2KPAQAygb5ZoLJKiYls64lmTwjPi0rm7wYASufVfKyUfuLVfFw/b1I2cnWxbQ+wFlVXAIBAmDUlFTHmsNZcvqDdh0Z0eGRK8wvLnzO/IB0euazdh0Y0ly/Eu0EAQPzomwUqh5hIAACWR80HUBlUXQFA+VhcxcKsKfkYdsNafcPjOn3xhq9zT1+8ob7hiYh3BACoOPpmgcr5ZDbedQAApMHMxya6PIhzr1nxxjFQcZu6i/9cWExVztS2AACM/E3pzWell5ul4y9KkydMRcTkCen4C+bjw89J+blK7zQ0Zk3Jx7AbVro6M6eh0SuB1gyNTunazK2IdgQASIxcndR50PQAP3ZA2thuOtc2tpvf75swjzPoBsqLmEgAAO5WSs0HgNJ4VVdBUHUFAJ/yqljGBop/P+NVsQzuNOenDLOmdGDYDSsdOTOlfCFYR0K+4OrI2amIdgQASByvb7b7qLT3mDm29fDGBRAVYiIBALgbNR9AZVF1BQDhZaCKhVlTOjDshpX8Rkos9f7kdJl3EjGLezAAAIBliIkEAOBu1HwAlUXVFQCEk5EqlszMmlJuVaU3AERh9tZ8rOtil79prpr64PW740EmT0gnXzKxSk/08004AABIBi8mcmzA/xpiIgEAtqPmA6g8r+qqfb+pCLh0ylxQsrrepAw90s33pACwVClVLG090ewpAtbPmizBsBtWqq8J96Uddl2svB6MleJBvB6M6+fN1am5uti2BwAAUFRHvzR9wV/MGTGRAIAsaNphLloPvI6aD6DsvKqrFA1hAKBiSqliSdHrrNWzJosQYw4rbduwJtS67RvvK/NOIpCBHoxMIYoeAJAlxEQCAHAnaj4AAEAaZaSKxepZk0W4tABW2rWlUQff+VD5gut7Ta7a0a7NjRHuqgzC9mC07yduKWmIogcAZBUxkQAAfIqaDwAAkEYZqWKxdtZkGe7shpXWNdSqq3V9oDVdrY1a21AT0Y7KpJQeDCSHF0U/NlD879OLoh/cac4HAMA2Xkxk91Fp7zFzbOvhzXsAQPZ09Jv6Dj+o+QAAAEnQtCPkunRVsVg7a7IMw25Yq7ezxXfExLYNa9Tb2RzxjsqglB4MJAdR9AAAAAAADzUfAABQ95g2GapisXLWZBlizGGt2ly1BvZsVd/whN44e1nzC3efs6pKenLzA+rtbFZtrjr+TQaVkR4MqxFFDwAAAABYipoPAEBWUfeYThmqYrFy1mQZht3IAFeSs3hcyol5LyXKSA+G1UqJom/riWZPAAAAAIBk8Go++PkPAJAFXt3jSimYXt3j9fMmCSVXF9v2cA8d/dL0BX8pplZUsVg0a7IMMeaw1ly+oN2HRnR4ZErzC8u9+EjzC64Oj1zW7kMjmssXYt5hCBnpwbAaUfQAAAAAANiJCF4ACIa6x3TLSBWLlbMmyzDshrX6hsd1+uINX+eevnhDfcMTEe+oDDLUg2EtougBAAAAALBL/qb05rPSy83S8RdN7O6VM+Z4/AXz8eHnpPxcpXcKAMkRtu6RC4iSxati2TchPXZA2tgurd9ijo8dMB/vPJjaQbdk6azJMgy7YaWrM3MaGr0SaM3Q6JSuzdyKaEdl4vVgBJHSHgxrEUUPAAAAAIA9vAjesYHitWVeBO/gTnM+AKC0ukckj1fF0n1U2nvMHNt6Uj+bsHbWZBmG3bDSkTNTyheWj5MoJl9wdeTsVEQ7KqOOftNv4YcVPRiWIYoeAMqHmEgAAABUGhG8ABAOdY9IAatnTRZh2A0r+Y2UWOr9yeky7yQCGenBsBZR9ABQOmIiAQAAkARE8AJAeNQ9IgWsnjVZZFWlNwBEYfbWfKzrYuf1YLTvN7Etl06Zf+RX15s7gB/pTn08iLW8KPqxAf9riKIHgE95MZEr3T3jxUReP28uEMvVxbY9AAAAZEgpEbxtPdHsCQDSgrpHpID1syZLMOyGleprwn1ph11XMV4PBj8gpUtHvzR9wV/MGVH0AHCnMDGRnQej3RMAAACyqZQIXt7LAZB1TTtMQlvgddQ9Ij6ZmTWlHDHmsNK2DWtCrdu+8b4y7wRYBlH0ABAOMZEAAABIEiJ4gWSZvSq9+03p1S9Jrzxuju9+i58Jk4q6R6QAs6Z04NICWGnXlkYdfOdD5Quu7zW5ake7NjdGuCvgNkTRA0BwxEQCAAAgSYjgBZIhf9OkgH3w+t0/M06ekE6+ZGoCn+jnppIkoe4RKcCsKR24sxtWWtdQq67W9YHWdLU2am1DTUQ7Aorwoui7j0p7j5ljWw/ftAHAckqJiQQAAADKrWlHyHVE8AJlk78pDXaZgWmxi6MX8tLod6XBneZ8JEdHv6lx9IO6R1QAs6Z0YNgNa/V2tviOmNi2YY16O5sj3hEA6xCPBcSLmEgAAAAkCRG8QOW99bz0kc8LnD86Jb399Wj3g2Coe0QKMGtKPmLMYa3aXLUG9mxV3/CE3jg7pfmFu2MmVlU5enJzo3o7m1Wbq67ALgGkEvFYQGUQEwkAAIAkIYIXqKyZj817M0Gce83UCvL/w+Sg7hEJx6wp+Rh2IwPcxV/FHgOAALx4rJWuGvbisa6fN1en5upi2x5gtaYd5oKSwOuIiQQAAEBEOvql6Qv+7iwlghcor3OvFo8uL2YhbwaqbT3R7AnheXWP/N0gsZg1JRUx5rDWXL6g3YdGdHhkSvMLy58zvyAdHrms3YdGNJcvxLtBAOlEPBZQOcREAkB5UMUCAOVDBC9QOZfeC7nO5/s6ACBmTWnAnd2wVt/wuE5fvOHr3NMXb6hveELf+PIXIt4VgFQjHguoLGIiAaA0VLEAQDSI4AUq45PZeNcByCRmTcnHnd2w0tWZOQ2NXgm0Zmh0StdmbkW0IwBWKCUeC0B5dPSb+Ec/iIkEgE95VSxjA8W/n/GqWAZ3mvMBAMF4EbzdR6W9x8yxrYdBNxCV1fXxrgOQOcya0oFhN6x05MyU8oVgHQn5gqsjZ6ci2hEAKxCPBVQeMZEAEE7QKpZ//QgR5wAAINmadoRc5/MCagCZx6wpHRh2w0p+IyWWen9yusw7AWAV4rGAZPBiIvdNSI8dkDa2S+u3mONjB8zHOw8y6AYAT5gqlpkfSFfOmHjz4y9ILzdLw89J+blo9ggAABDUpu7iF0EXU5Uz1QIA4AOzpnSgsxtWmr01H+s6ABlBPBaQLF5MZFtPpXcCAMkWpoplKS/i/Pp5k7CRqyvL1gAAAEJruF96+GlT0+LXpq9QLQDAN2ZN6cCd3bBSfU246zjCrgOQEcRjAQCANApbxbKcj05Jb3+9fM8HAABQio5+6UGf77s8+Kj0RH+0+wFgFWZN6cCwG1batmFNoPM/o7/S16qP6v86e4BeOgDFEY8FAADSqNyVKude42clAACQDLk6kzrT+tXi79lU5czjz3yfuisAgQSdNXm2b7yvzDvBSri0AFbataVRB9/5UPmCu+J5NfpEvasG1FX9rlY7Ben/kPklmW66ky+ZaJsn+vlGCADxWAAAIJ3KXamykJfGXqVGAgAAJEOuTuo8KLXvN9+jXDplLvZbXW/S9h7p5r0ZAKH4nTXdLlftaNfmxgh3haW4sxtWWtdQq67W9SueU6NPNLC6X0+vOmEG3cvxeukGd0r5m+XfKID0IR4LAACkTdgqlpVcOlX+5wQAAChF/TpzMV73UWnvMXNs62HQDSA0P7OmpbpaG7W2oSaiHWE5DLthrd7OlhUjJnpXDWh71Z/K9XNBDr10ADzEYwEAgLQJU8VyL+WORgcAAACAuM1eld79pqm2LVJxe69Z0+22bVij3s7maPaKohzX16QPleA4znhzc3Pz+Ph4pbeSWnP5gvqGJ/TG2cuaX/j042v13/Vezf9W/I7u5VTlpH0TXAkI4FOzV4nHAgAA6fDms8GqWO5lY7u5WwoAAAAA0iZ/U3rreemD103C71JVuTsqbovNmjyrqqQnNz+g3s5m1eaqo9+/ZVpaWjQxMTHhum5LmPV0diMDXEnO4tHYVX0y2KBbopcOwN28eCxeFwAAQNJ19EvTF0xqVTk0+ax1AQAAAIAkyd+UBrtW/tnIq7i9ft6kfGq1lps1fcqJYqfwiWE3rDWXL2j3oRGdvnjjrse2Vf1puCe9dIqhFgAAAID08apY3v66dO615e9e8KsqZ5JsAKAUs1dN4sSl90jKAgAA8Xnref8XAX90SvP/4Xnt/sunlp01eeYXXB0euazJa7Ma2LOVu7tjxrAb1uobHi/64lPv3Az3pPTSAQAAAEirXJ3UeVBq339nFctfXZFm/sL/82z6CoMoAOGtFBs6eUI6+dIdsaEAAABlM/Ox+R4kiA9e04Wb2yX92D1PPX3xhvqGJ/SNL38h3P4QSlWlNwBE4erMnIZGrxR9fNatC/fEq+tD7ggAAAAAEsKrYuk+Ku09Jj17TnrQZyz5g4+aARQAhOHFho4NFE+Y8GJDB3ea8wEAAMrl3KuBU65WufPaVX3C9/lDo1O6NnMr6M5QAobdsNKRM1PKF5brTTBOL/y9cE9MLx0AAIjK7FXp3W9Kr35JeuVxc3z3W+bjABAlL+K89asmonw5VTnz+DPf505LAOEFjA3V21+Pdj8AACBbLr0Xatn2ANW4+YKrI2enQn0ehEOMOay0UneCJB0p/IKeW/V9rXYK/p+UXjoAABAFojwBJEGxiHM6dAGUS5jY0HOvmdclXn8AAEA5hKyqDVqN+/7ktL7W/vlQnwvBMeyGlWZvza/4+DX9uIYKbXp61Qm5ruQ4Pp6UXjoAAFBuXpTnSnc4eVGe18+bOy9zIetYAMAPL+K8rafSOwFgmxCxoVrImwtweE0CAADlELKqNmg17r1mVCgvYsxhpfqae1/H0Te/W+8v/D1/g2566QAAQBSI8gQAAFkRMjZUl3x+rwQgGGqUAGRR045Qy94PWI3rZ0aF8mHYDStt27Dmnufc0mrt/uR5vT7/mD5xq5c/iV46AAAQlbBRnrz5BAAA0ihkbGjodQCWl78pvfms9HKzdPxFU5105Yw5Hn/BfHz4OSk/V+mdAkD5beo2c58APnGrdaTQHmjN9o33BTofpWHYDSvt2tKoXPW9b9m+pdX65/N79fdv/a7+74V/ok8e/Hlp/RZpY7v02AFp34TprWPQDQAAyq2UKE8AAIC0CRkbGnodgLt5NUpjA8V/FvFqlAZ3mvMBwCYN90sPPx1oyR8u/IKu68d8n5+rdrRrc2PQnaEEDLthpXUNtepqXe/7/Ov6MV3f9L9p9S+/Ke09JnUfNX1QdHQDAICoEOUJAACyJGRsqJoeLe8+gCyjRgkApI5+U13rx4OPavznfjPQ03e1NmptQ02IjSEsht2wVm9ni684c8nEnvd2Nke8IwBIATq7gPgQ5QkAALIkRGyoqnLSI93R7AfIGmqUAMDI1UnPDJkK22Lfm9xWcbv/Hz/CrCnhaEiHtWpz1RrYs1V9wxN64+yU5hfcu85ZVeXoyc2N6u1sVm2uSG83AGRB/qa5wvuD1++OMps8IZ18Sdr0FemJfqodgHIhyhMAAGSJFxs6NuB/zaavkLoHlEspNUptPdHsCQAqJVdnKmzb95vXuUunzM0Fq+tNqswj3T/8HqRWYtaUcAy7kQHu4q9ijwFAxnmdXStFmXmdXdfPmysfc3WxbQ+wVtMOczFJ4HVEeQIAgJTq6JemL/iLUX7wUXOxLYDyKKVGiWE3AFvVrzOvcb5e55g1JRUx5rDWXL6g3YdGdHhkSvMLy58zvyAdHrms3YdGNJcvxLtBAEgKOruAyiDKExL1EQCAbAkYG0qqFFBG1CgBQCjMmpKPO7thrb7hcZ2+eMPXuacv3lDf8IS+8eUvRLwrAEiYsJ1d7fuJEwRKRZRntlEfAQDIqgCxoQDKiBolAAiFWVPycWc3rHR1Zk5Do1cCrRkandK1mVsR7QgAEqqUzi4ApevoNxGdfhDlaQ+vPmJsoPhrsFcfMbjTnA8AgG282NDuo9LeY+bY1sOgG4hK046Q66hRApBdzJrSgWE3rHTkzJTyhWAdCfmCqyNnpyLaEQAkVCmdXQBKR5RnNlEfAQB3o9YBAKJFjRIABMasKR2IMYeV/EZKLPX+5LS+1v75Mu8GABKMzi6g8ojyzBbqIwDgTtQ6AEA8qFECgMCYNaUDw25YafbWfKzrACC16OwCksOL8mzrqfROEKVS6iP42gBgG6/WYaW0C6/W4fp5k4aSq4ttewBgnY5+afqCv5QhapQAgFlTShBjDivV14S7jiPsOgBILTq7ACBe1EcAyUJ0dmVR6wAA8aJGCQACYdaUDvzXhpW2bVijP/rweuB12zfeF8FuACDBNnVLJ/uD3WVIZxcAhEd9BJAMRGdXHrUOAFAZ1CgBgG/MmtKBO7thpV1bGpWrdgKtyVU72rW5MaIdAUBCeZ1dQdDZBQDhUR8BVJ4XnT02UPyCPy86e3CnOR/lV0qtAwCgdF6NUvdRae8xc2zr4ed9ALgNs6Z0YNgNK61rqFVX6/pAa7paG7W2oSaiHQFAgnX0my4uP+jsAoDSUB8BVB7R2clArQMAAAASjllTOjDshrV6O1u0bcMaX+du27BGvZ3NEe8IABKKzi4AiM+m7uKvtcVQHxEPupuzIWx0Nl8H5UetAwAAAFKAWVPy0dkNa9XmqvUHv9Sqnb//x7pw7W+Knve5tfX6t7/UqtpcdYy7A4CEobMLAOLh1UeMDfhfQ31EtOhuzpZSorPbeqLZU1ZR6wAAAIAUYNaUfNzZDWvN5Qv61e+NrvjiI0kXrs3qV743qrl8IaadAUCC0dkFANGjPiI56G7OHqKzk4NaBwAAAKQAs6bkY9gNa/UNj+v0xRu+zj198Yb6hici3hGAoogNBQBkCfURyUF3c/YQnZ0c1DoAAAAgBZg1JR8x5rDS1Zk5DY1eCbRmaHRK+774kNY21ES0KwB3ITYUAJBV1EdUXtju5vb9/N2kGdHZyUGtAwAAABKOWVM6cGc3rHTkzJTyBTfQmnzB1ZGzUxHtCMBdiA0FAID6iEoqpbsZ6UV0drJQ6wAAAIAEY9aUDgy7YSW/kRJLvT85XeadACiK2FAAAFBJdDdnE9HZyUKtAwAA1PsBCcasKR2IMYeVZm/Nx7oOQEDEhgIAgEqjuzmbiM5OHmodAABZRb0fkHjMmtKBYTesVF8T7ks77DoAAZUSG9rWE82eAABAttDdnF0d/dL0BX8pQ0Rnx8erdeD7fQBAFnj1fit9P+LV+10/b5JQcnWxbQ+AwawpHYgxh5W2bVgTat32jfeVeScAlkVsKJAcxKUByCq6m7OL6GwAAFBp1PsBqcCsKR24tABW2rWlUQff+VD5gut7Ta7a0a7NjRHuCsAPERsKVB5xaQCyblO3dLI/WNoM3c32IDobAABUCvV+QGowa0qHVN/Z7ThOneM4/8pxnD93HGfOcZwfOI5zyHGcvxviuX7CcZyDjuN85DjOrcXjdxzH+fFlzs05jvM/OY7zu47j/DfHcf7WcZybjuP8qeM433IcZ21Z/oAIbV1Drbpa1wda09XaqLUNNRHtCMAdiA0FKsuLSxsbKD7k8eLSBnea8wHANl53cxB0N9vHi87uPirtPWaObT38PQMAgOiUUu8HIFbMmtIhtcNux3FqJR2XdEBSvaR/L2lK0i9LOuc4zsYAz/UZSSOSnpU0L+mopBlJz0k67TjO0pyCn5f0HyV9TdKPSnpL0v9P0mck/YakP3Ec56fD/tlQHr2dLb4jJrZtWKPezuaIdwTgh4gNBSqLuDQAMDr6TSezH3Q3AwBsRbUREC/q/YBUYdaUfKkddkv6F5K2S/rPkh5yXfefuK67TWbYvFbSoQDP9R1Jn5f0h5J+evG5fkbS70h6SNLLS85fkHRE0jbXdTe4rrvTdd1fXHyO/yjpJyX9u9B/MpRFba5aA3u26qmtD2hVlbPsOauqHD219QEN7Nmq2lx1zDsEMmxTd/F+xGKIDQXKI2xcGm90AbAR3c0AgCzL35TefFZ6uVk6/qKpM7pyxhyPv2A+PvyclJ+r9E4Bu1DvB6QKs6bkS+Ww23Gc1ZJ+ffG3X3Nd94ev8q7rvizpTyT9vOM4rT6e67OSnpL0iaRfc113/raH/5mka5KecRznhxlmruseXxyIj9z+XK7r/pWkPYu//R8dx3kw+J8O5ecu/ir2GIDYERsKVA5xaQBwJ6+7ed+E9NgBaWO7tH6LOT52wHy88yCDbgCAXag2AiqHej8gpZg1JVUqh92Sdkj6MUkXXNc9t8zjQ4vHTh/P9YTMf4c/cl3349sfcF33lqRhSdWS/qGfjbmu+wOZAbkk/ZSfNYjGXL6g3YdGdHhkSvMLy58zvyAdHrms3YdGNJcvxLtBIOuIDQUqg7g0AFge3c0AgCyh2gioHOr9gFRh1pR8aR12/9zicazI497Hfzbm55LjOD8u6ScWf/uXftYgGn3D4zp98Yavc09fvKG+4YmIdwTgDsSGApVBXBoAAACQbVQbAZVFvR9mr0rvflN69UvSK4+b47vf4nU2oZg1Jd+qSm8gpAcWj1eKPO593E+MeDmfS5K+JvPf9b+6rnvRzwLHccaLPPQ5n58TS1ydmdPQaLG/0uUNjU5p3xcf0tqGmoh2BeAuXmxo+34TkXzplBmora43V6s+0s3dVEC5EZcGAAAAZFsp1UZtPdHsCcgSr95vbMD/Gur97JC/aZI1Pnj97tfhyRPSyZfM3/UT/dz4kxDMmtIhrXd2e++2/m2Rx/9m8dgQ53M5jrNJ0r9Y/O3zPj43InLkzJTyhWAdCfmCqyNnpyLaEYAVERsKxIe4NAAAACDbqDYCKo96v+zJ35QGu8xFDsUuOFrIS6PflQZ3mvNRccya0iGtw+7EcRznfkl/KKlW0ndc133L71rXdVuW+yXpQlT7tZ3fSIml3p+cLvNOEBgRLgAQLeLSAAAAgGyj2gioPOr9suet56WPfF409NEp6e2vR7sf+MKsKR3SGmPufWf1I0Ue/9HF40wcz+U4ToOk/yCpSdIbkn7Dx+dFhGZvzce6DmVAhAsAxIO4NAAAACDbqDYCkoF6v+yY+di87x3EudfM1wZfAxXFrCkd0jrsvrx4XF/kce/jH0X9XI7j1Ep6U9Ijkv6/kp5xXXfBx+dFhOprwn1ph12HEnkRLitd2eZFuFw/b656zNXFtj0AsE5HvzR9wd8VxcSlAQAAAHZp2mFuLAi8jmojIBJevV9bT6V3gqice7V4dHkxC3lzEQRfFxXFrCkd0hpj/l8Wj48Uedz7+J9E+VyO46yS9P+S9AuS/ljSl13X/cTH50TEtm1YE2rd9o33lXkn8IUIFwCIF3FpAAAAQHZRbQQA8br0Xsh1t71nTv1nRTBrSoe0XlrwnqS/kvQ5x3Eedl33gyWPdy0eh30819uSFiT9A8dx1rmu+8NXBsdxaiR1SirIxJTrtsccSf9O0i9K+kDS/+y67t8E/6MgCru2NOrgOx8qX3B9r8lVO9q1uTHCXWFZRLgAQGUQlwYAAABkE9VGABCvT2bvfU6xddR/VhSzpnRI5Z3di3dP/+7ib3/PcRyvV1uO4+yT9LOS/pPruqO3ffzXHcf5M8dxvrHkuf5C0mFJqyX9m8W7tT2/LWmtpMHbh+CLviPpGUl/Jul/cl33v5fjz4byWNdQq67WYsn0y+tqbdTahpqIdoSiSolwAQCUzotL6z4q7T1mjm09vJEFAAAA2Kyj31QW+UG1EQCUZnV9uHW5HzH1n2MDxd9D9+o/B3eawTjKillTOqT1zm5JelHS45L+vqQPHcf5I0kPStom6ZqkPUvO/4ykn5b02WWe659K2i5pp6Q/cxznrKQWST8j6UNJ+24/2XGcfyzp2cXfTkn6prnR+y4vua77Z0H/YCiP3s4WTV77G52+eOOe527bsEa9nc0x7CpjZq+af4gvvVf8bsFSIlzoKwEAAAAAAAjOqzZ6++smQW+5IUpVjrsFAaAcmnaYu7CDuvXX0g/O+TvXq//sPBj882BFzJqSz3Fd/7feJ43jOHWSflPS05IaJd2QiSU/4LrulSXn/pakXkkDrut+dZnnWiPptyR9SdL9kj6W9P+W1Lv0rm3Hcb4qE2F+L+2u6570/Qe6e0/jzc3NzePj42GfIvPm8gX1DU/ojbOXNb9w9+OrqqQnNz+g3s5m1eaq49+grVaKVpHu/GFp4B9JV84E/xzrt5g7EAEAAAAAABDe7FWqjQAgSjMfS99uCZZwWrVKciW58wHW5KR9E7x2R4BZU7RaWlo0MTEx4bpuS5j1ab6zW67r3pT0Lxd/3evc35IZZhd7/IbM3drPFjvntnO/K+m7/naJynMlOYvHpZa9Ix+lyN800SofnSp+jhetcv28tKou3OcJG/0CAAAAAACAT3nVRiToAUA0Gu6XHn7apKD69ZNf8H9Xt8er/+T1PCLMmpIqlZ3dgB9z+YJ2HxrR4ZEpHE7QxgAATntJREFUzS8sn2Awv+Dq8Mhl7T40orl8IeYdWuqt51cedN/uo1PSJzPhPk+Tz14pAAAAAAAAAAAqqaNfetDne9oPPiqtbgj3eS75fG8evjFrSj6G3bBW3/C4rw4FSTp98Yb6hici3lEGzHxsosuD+Mv/KjkBQyaqciZKCwAAJMPsVendb0qvfkl65XFzfPdb5uMAAAAAAGRdrk56Zkhq/ap5f3s5VTnz+DPfl+Zvhvs8n8yG3SGKYNaUfKmOMQeKuTozp6HRK/c+8TZDo1Pa98WHtLahJqJdZcC5V4P1jkjSwrz0U5uCRbJs+gq9IwAAJEH+pkl1+eD1u78HmDwhnXzJ/Lv9RL+Uq63MHgEAAAAASIJcndR5UGrfb+LGL50yw+nV9SbJ9JHuT9/3DlvjSf1nWTFrSgfu7IaVjpyZUr6wfJxEMfmCqyNnpyLaUUZcei/cupq/EyzC5Yn+cJ8HAACUT/6mNNhlOseKXey2kJdGvysN7jTnAwAAAACQdfXrTK9291Fp7zFzbOu58wavph3hnpv6z7Ji1pQODLthJb+REku9Pzld5p1kTNiIlPzfBotw4c4wAAAq763npY98doF9dEp6++vR7gcAgKyiTgQAAPts6i7+Xnkx1H+WHbOmdCDGHFaavTUf6zosKiVaJUiECwAAqKyZj010eRDnXjP/zvPvOQAA5UGdCAAA9mq4X3r4aZOm5hf1n2XHrCkdGHbDSvU14b60w67DoqYd5gfqwOtui1bxIlzaesq3LwAAUF7nXi0eXV7MQt5c0Ma/8QAAlM6rE1kpZcWrE7l+3qSp5epi2x4AACiDjn5p+oK/VDXqPyPBrCkdiDGHlbZtWBNq3faN95V5JxlDtAqALCAmEpAuvRdync/YcwAAsDLqRAAAsF+ujvrPCmPWlA5cWgAr7drSqIPvfKh8wfW9JlftaNfmxgh3lQFEqwCwGTGRwKc+mY13HQAA+BR1IgAAZAf1nxXFrCkduLMbVlrXUKuu1vWB1nS1NmptQ01EO8qQjn4TmeIH0SoA0sKLiRwbKB7d7MVEDu405wM2W10f7zoAAPCpUupEAABAOnn1n91Hpb3HzLGth0F3xJg1pQPDblirt7PFd8TEtg1r1NvZHPGOMoJoFQA2IiYSuFPTjpDrfF4QBwAAiqNOBLg36qcAAGXCrCn5HNf1f+s94uU4znhzc3Pz+Ph4pbeSWnP5gvqGJ/TG2SnNL9z9tb6qytGTmxvV29ms2lx1BXZoudmrRKsASL+Zj6VvtwS7e6YqJ+2b4LUO9uL/FwAAVM4rj0tXzgRft36LuRMMsNlK9VOS+Z6U+ikAQEDMmqLV0tKiiYmJCdd1W8Ksp7MbGeAu/ir2GCLjRau09VR6JwAQXikxkbz+wVYN90sPP22i/f3a9BUG3QAAlAN1IsDyvPqplVK5vPqp6+dNMmGuLrbtAQDSjllTUhFjDmvN5QvafWhEh0emNL+w/DnzC9LhkcvafWhEc/lCvBsEAKQDMZHA8jr6pQd9xpI/+Ki5ewYAkG3ECpcHdSLA8qifAgBEgFlT8jHshrX6hsd1+uINX+eevnhDfcMTEe8IAJBKn8zGuw5Ii1yduRum9asmDnI5VTnz+DPfJyYSALIsf1N681np5Wbp+IvS5AkTwz15Qjr+gvn48HNSfq7SO02HTd3F/+0tpipnKsUAW818bKLLgzj3GhfbAADuiVlT8jHshpWuzsxpaPRKoDVDo1O6NnMroh0BAFKLmEiguFyd1HnQdHE/dkDa2G76QDe2m9/vmzCPM+gGgOzyYoXHBopXw3ixwoM7zflYmVcnEgR1IrBdKfVTAAAUwawpHRh2w0pHzkwpXwjWkZAvuDpydiqiHQEAUouYSODe6teZjvruo9LeY+bY1sOb6gAAYoWjQp0IcCfqpwAAEWDWlA4Mu2Elv5ESS70/OV3mnQAAUo+YSACVQrctgLQjVjg61IkAd6J+CgAQAWZN6bCq0hsAojB7az7WdQAAi3kxkWMD/tcQEwmgFPmb5k7ID16/O45z8oR08iXzOvNEP8MLAMlWSqxwW080e7KJVyfSvt/8N7t0ygzuVteblKFHuvmeFNlB/RQAIALMmtKBYTesVF8T7ks77DoAgOU6+qXpC/4iOImJBFAKr9t2pdcbr9v2+nlzV1+uLrbtAUAgpcQKM+z2z6sT4b8Zsqxph7koMPA66qcAAMUxa0oHYsxhpW0b1oRat33jfWXeCQDACsREAogL3bb2IIYeIFYYQHyonwIARIBZUzpwaQGstGtLow6+86HyBdf3mly1o12bGyPcFQAg1YiJBBC1sN227ft5/UkSYuiBTxErDCAu1E8BACLArCkduLMbVlrXUKuu1vWB1nS1NmptQ01EOwIAWMOLiew+Ku09Zo5tPbxJAqB0pXTbIhm8GPqxgeJ/l14M/eBOcz5gs6YdIdcRKwwghI5+UyvlB/VTAAAfmDWlA8NuWKu3s8V3xMS2DWvU29kc8Y4AAACAFZTSbYtkIIY+esTDpwuxwgDiRP0UACACzJqSjxhzWKs2V62BPVvVNzyhN85e1vzC3eesqpKe3PyAejubVZurjn+TAAAAgIdu23Qjhj5axMOnE7HCAOJG/RQAoMyYNSUfw25kgCvJWTwu5cS8FwAAAKAIum3TrZQY+raeaPZkCy8efqW75r14+OvnzV19ubrYtod76OiXpi/4Sz0gVhhAuXj1U/wbCwAoG2ZNSUWMOaw1ly9o96ERHR6Z0vzCci8+0vyCq8Mjl7X70Ijm8oWYdwgAAADchm7bdCOGPjrEw6cbscIAgKCoLQGQIMyako9hN6zVNzyu0xdv+Dr39MUb6hueiHhHAAAAwArotk03YuijETYenjfDk8WLFd43IT12QNrYLq3fYo6PHTAf7zzIoBsAsi5/U3rzWenlZun4i6aq5MoZczz+gvn48HNSfq7SOwWQIcyako9hN6x0dWZOQ6NXAq0ZGp3StZlbEe0IAAAAuAev2zYIum2Tgxj6aJQSD4/k8WKFu49Ke4+ZY1sPr2MAgE9rS8YGiv/b79WWDO405wNAxJg1pQPDbljpyJkp5QvLx0kUky+4OnJ2KqIdAQAAAD509JvOWj/otk0WYuijQTw8AADZQG0JgARi1pQODLthJb+REku9Pzld5p0AwBL0TgEAVkK3bXoRQx8N4uEBALAftSUAEopZUzqsqvQGgCjM3pqPdR0A3FP+prlK+YPX747jmjwhnXzJRNE+0c/gAgCyzuu2bd9vopgvnTKDu9X15i7gR7qJ/E0iL4Z+bMD/GmLo7414eAAA7FdKbUlbTzR7AgAxa0oLht2wUn1NuC/tsOsAYEVe79RKcVxe79T18+aOvlxdbNsDACSU123LG3jp0dEvTV/wF8FJDL0/TTvMhYGB1xEPDwBAapRSW8L3ygAixKwpHYgxh5W2bVgTat32jfeVeScAIHqnAADICmLoy494eAC2o+oKoLYEQGIxa0oHLi2AlXZtadTBdz5UvuD6XpOrdrRrc2OEuwKQSWF7p9r3E2sKAEAaEUNfXsTDA7AVVVfAp6gtAZBQzJrSgTu7YaV1DbXqal0faE1Xa6PWNtREtCMAmVVK7xQAAEgvL4a++6i095g5tvUwhA2jo9/EvvtBPDyANPCqrsYGiv+86FVdDe405wM2a9oRch21JQCixawpHRh2w1q9nS2+Iya2bVij3s7miHcEIJNK6Z0CsoLoRgDASoiHB2Abqq6AO1FbAiDBmDUlHzHmsFZtrloDe7aqb3hCb5yd0vzC3TETq6ocPbm5Ub2dzarNVVdglwCsR+8UUBzRjQAAv4iHB2ALqq6Au1FbAiDBmDUlH8NuZIC7+KvYYwAQIXqngOV50Y0r3dHiRTdeP2/u6MvVxbY9AEBCefHwbT2V3gkAhFNK1RWvfbBZR780fcFf6gG1JQAqgllTUhFjDmvN5QvafWhEh0emNL+w/DnzC9LhkcvafWhEc/lCvBsEko5Y4fKgdwpYHtGNAAAAyCKqroDlUVsCIKGYNSUfw25Yq294XKcv3vB17umLN9Q3PBHxjoCUyN+U3nxWerlZOv6iiRK+csYcj79gPj78nJSfq/RO04HeKeBuYaMbudgGAAAAaUfVFVCcV1uyb0J67IC0sV1av8UcHztgPt55kEE3gFgxa0o+ht2w0tWZOQ2NXgm0Zmh0StdmbkW0IyAlvFjhsYHisWperPDgTnM+Vub1TgVB7xRsV0p0IwAAAJBmVF0B9+bVlnQflfYeM8e2Ht4rARA7Zk3pwLAbVjpyZkr5QrCOhHzB1ZGzUxHtCEgJYoWj0dFv+qT8oHcKWUB0IwAAALKKqisAlUJlIRAYs6Z0YNgNK/mNlFjq/cnpMu8ESBFihaND7xRwJ6IbAQAAkFVUXQGIG5WFQGjMmtJhVaU3AERh9tZ8rOsAK5QSK9zWE82ebOL1TrXvN//NLp0yg7vV9eYK/Ue6ieNCdhDdCAAAgKzyqq7GBvyvoeoKQFheZeFKSY5eZeH18+ZmjVxdbNsDko5ZUzow7IaV6mvCfWmHXQdYoZRYYYbd/nm9U/w3Q5Y17TBXkAdeR3QjAAAALNDRL01f8FcjRtUVgFKEqSzsPBjtnoAUYdaUDsSYw0rbNqwJtW77xvvKvBMgRYgVBhAXohsBAECW0ZkKqq4AxIHKQqBkzJrSgUsLYKVdWxp18J0PlS+4vtfkqh3t2twY4a6AhCNWGEBciG4EAABZlL9p7rD74PW7K6QmT0gnXzLf8zzRz3AzC6i6AhA1KguBkjFrSgfu7IaV1jXUqqt1faA1Xa2NWttQE9GOgBRo2hFyHbHCAELo6DeRjH4Q3QgAANLO60wdGyg+ePA6Uwd3mvORDV7VVfdRae8xc2zrYdANoHSlVBYCkMSsKS0YdsNavZ0tviMmtm1Yo97O5oh3BCQcscIA4kR0I4oh2hUAYKMwnakAAJSCykKgLJg1JR8x5rBWba5aA3u2qm94Qm+cvaz5hbvPWVUlPbn5AfV2Nqs2Vx3/JoEkIVYYQNyIbsTtiHYFANgqbGdq+36+FwIAhEdlIVAWzJqSj2E3MsCV5Cwel3Ji3guQcB390vQFf3ccECsMoFy86EY6wbLLi3Zd6d8fL9r1+nmTCpCri217AACUhM5UAEAlNO0wFw4HXkdlIbA8Zk1JRYw5rDWXL2j3oREdHpnS/MJyLz7S/IKrwyOXtfvQiObyhZh3mEDEhoJYYQBAJRDtCgCwGZ2pAIBKoLIQKAtmTcnHnd2wVt/wuE5fvOHr3NMXb6hveELf+PIXIt5VQhEbitsRKwwAiBPRrgAA29GZCgCoBCoLgbJg1pR83NkNK12dmdPQ6JVAa4ZGp3Rt5lZEO0owLzZ0bKB4rJoXGzq405yPbPBihbuPSnuPmWNbD9/wAgDKq5RoVwAA0oDOVABApXT0mypCP6gsBO7CrCkdGHbDSkfOTClfWD5Ooph8wdWRs1MR7SjBiA0FAACVRLQrAMB2TTtCrqMzFQBQIioLUQyVpr4wa0oHYsxhJb+REku9Pzmtr7V/vsy7STBiQwEAQKUR7QoAsN2mbulkf7AkEzpTAQDlQmUhbkelaSDMmtKBYTesNHtrPtZ1qVVKbGhbTzR7AgAA2UK0KwDAdnSmAgCSwKss5H3d7PIqTVdKevUqTa+fN6kAubrYtpdEzJrSgRhzWKm+Jtx1HGHXpRaxoQAAoNKIdgUAZAGdqQAAoNKoNA2MWVM6MOyGlbZtWBNq3faN95V5JwlHbCgAAKi0Td3Fu+OKIdo1PvS4AUB50JkKAAAqKWylacZ/9mPWlA5cWgAr7drSqIPvfKh8wfW9JlftaNfmxgh3lUDEhgIAgEoj2jWZ6HEDgPKjMxUAAFQKlaahMGtKB+7shpXWNdSqq3V9oDVdrY1a21AT0Y4SithQAACQBES7JovX4zY2UPzNEK/HbXCnOR8A4J/Xmdp9VNp7zBzbehh0AwCA6FBpGgqzpnRg2A1r9Xa2+I6Y2LZhjXo7myPeUQIRGwoAAJKAaNdkoccNsBO1BAAAANlFpWlozJqSjxhzWKs2V62BPVvVNzyhN85OaX7h7piJVVWOntzcqN7OZtXmqiuwywojNhQAACQF0a7JELbHrX0/fz9AUlFLAAAAACpNQ2PWlHwMu5EB7uKvYo9lXEe/NH3B3907xIYCAICoedGuGe4Eqyh63AC7eLUEK/2859USXD9vUjZydbFtDwAAADFp2mEudAy8jkrTTzFrSipizGGtuXxBuw+N6PDIlOYXlj9nfkE6PHJZuw+NaC5fiHeDSUFsKAAAADz0uAF2oZYAACqH+ggASUKlaWjMmpKPO7thrb7hcZ2+eMPXuacv3lDf8IS+8eUvRLyrhCI2FAAAABI9boBNqCUAgMqgPgJAElFpGhqzpuTjzm5Y6erMnIZGrwRaMzQ6pWsztyLaUUp4saHdR6W9x8yxrYd/0AAAALKCHjfAHqXUEgAAwvHqI8YGir8Ge/URgzvN+QAQl45+U1XqB5Wmkpg1pQXDbljpyJkp5QvBOhLyBVdHzk5FtCMAQMmIgAOA6DXtCLmOHjcgcaglAID4UR8BIMmoNA2MWVM6EGMOK/mNlFjq/clpfa3982XeDQCgJETAAUB8NnVLJ/uD3Q1KjxuQTNQSAEC8qI8AkAZUmgbCrCkdGHbDSrO35mNdBwCIiBcBt9KV8V4E3PXz5urUXF1s2wMA69DjBtiDWgIAiFcp9RFtPdHsCQCK8SpNef1ZEbOmdCDGHFaqrwl3HUfYdQAsRnR2ZREBBwDxo8cNsAO1BAAQL+ojAMA6zJrSgWE3rLRtw5pQ67ZvvK/MOwGQWvmb0pvPSi83S8dfNHHZV86Y4/EXzMeHn5Pyc5Xeqb3CRsBxIQIAlIYeN8AOm7qL/3+4GGoJACA86iMAwDrMmtKBYTestGtLo3LVTqA1uWpHuzY3RrQjAKniRWePDRSPIPOiswd3mvNRfqVEwAEASuP1uO2bkB47IG1sl9ZvMcfHDpiPdx5k0A0kmVdLEAS1BAAQHvURAGAdZk3pwLAbVlrXUKuu1vWB1nS1NmptQ01EOwKQKkRnJwMRcABQeV6PW/dRae8xc2zrYRgGpAW1BAAQH+ojAMA6zJrSgWE3rNXb2eI7YmLbhjXq7WyOeEcAUoHo7OQgAg4AAKA01BIAQHyoj0iu2avSu9+UXv2S9Mrj5vjut3gvB4AvzJqSj4Z0WKs2V60/+KVW7fz9P9aFa39T9LzPra3Xv/2lVtXmqmPcHYDEKiU6u60nmj1lFRFwAAAApfNqCdr3m+9ZL50yFweurjd3Ez7STVoDAJSDVx8xNuB/DfUR0crfNOl9H7x+93s9kyekky+Zv4Mn+rngC0BRzJqSjzu7Ya25fEG/+r3RFV98JOnCtVn9yvdGNZcvxLQzAIlGdHZyEAEHAABQPtQSAED0qI9IjvxNabDLXHxQ7KaGhbw0+l1pcKc5HwCWwawp+Rh2w1p9w+M6ffGGr3NPX7yhvuGJiHcEIBWIzk4OIuAAAEg/YkMBAFlCfURyvPW89JHPGxM+OiW9/fVo9wMgtZg1JR8x5rDS1Zk5DY1eCbRmaHRK+774kNY21ES0KwCpQHR2chABBwBAehEbCgDIKuojKm/mY/M9SBDnXjN/Z/zdALgNs6Z04M5uWOnImSnlC26gNfmCqyNnpyLaEYDUIDo7WYiAAwAgfYgNBQCA+ohKOvdq8e9BilnIm4sTAOA2zJrSgWE3rOQ3UmKp9yeny7wTAKlDdHayEAEHAICRpjhwYkMBAEAlXXov5Dqf378AyAxmTelAjDmsNHtrPtZ1ACxCdHbyEAEHAMiytMWBExsKAAAq7ZPZeNcBsBazpnRg2A0r1deE+9IOuw6AZTr6pekL/u5IIjo7Pl4EXFtPpXcCAEA8vDjwlb4n8eLAr583aSi5uti2t6xSYkP5Nx4AAJTD6vp41wGwFrOmdCDGHFbatmFNqHXbN95X5p0ASCWiswEAQBKkMQ6c2FAAAFBpTTtCrnu0vPvA3dJUzQOIWVNacGkBrLRrS6MOvvOh8gXX95pctaNdmxsj3BWAVCE6GwAAVFJa48CJDQUAAJW2qVs62R8sbaYqZ97rQTTSVs0DLGLWlA7c2Q0rrWuoVVfr+kBrulobtbahJqIdAUgtLzq7+6i095g5tvUw6AYAANEqJQ68kogNBQAAldZwv/Tw08HWbPoK7/VExavmGRso/v2tV80zuNOcDyQEs6Z0YNgNa/V2tviOmNi2YY16O5sj3hEAAAAA+JTWOHBiQwEAQBJ09EsP+vz+4sFHzR3FiEYaq3mA2zBrSj6G3bBWba5aA3u26qmtD2hVlbPsOauqHD219QEN7Nmq2lx1zDsEVkB/DQAAQLalNQ58U7eJAQ2C2FAAAFBuuTrpmSGp9avFvzepypnHn/k+0dlRCVvNw3ugSBBmTclHZzcywF38VewxIEHorwEAAICU3jhwLzZ0bMD/GmJDAQBAFHJ1UudBqX2/qXq5dMpcGLi63qTKPNLN9yBRK6Wap60nmj0BoTFrSiqG3bDWXL6g3YdGdPrijaLnzC9Ih0cua/LaLFfcoPK8/pqVYn28/prr583Vqbm62LYHAACAGDXtMBc7Bl6XgDjwjn5p+oK/uEpiQwEAQNTq15nBKcPT+JVSzcPfFxKCWVPyEWMOa/UNj6/44nO70xdvqG94IuIdAfdAfw0AVA71EQCSJs1x4MSGAvj/t3fv4ZLdZZ3ov7/u3nQ3SSPEhKAmkABB7UYk5AZGguEyGJkMuYEDaODwxGdUFMZM0Hg4TJLRGdM6AxMHxTnDYQwTJmMMJBB1YCbcFBlyRdH0KLkBnRECTUDSIZ10d37nj1UF2529d+9du/aqtWp/Ps9TT/VeVb/1rl91rVpV9dZ6XwBI+tuaB2aRa+o+Z3Yzlb5y/55cfcs9yxpz9S07c/5LnpHDtmxcpa2CRYzav+bUtyi3BLAS2kcAXdX3cuDKhgIA0NfWPDAg19QPzuxmKl11087s3b+8Hgl799dcdfPOVdoiOICV9K8BYDTD9hG3Xr7wa/CwfcQVZzf3B2jTadubMt9L0dVy4MOyoedem5x3fXN9ygUS3QAAa8FRJ484rgOteSByTX0h2c1UWmpJibk+fdfXxrwlsEQr6V8DwGi0jwC6TjlwgNWllQ3A6upzax6IXFNfKGPOVNr90L5Wx8GK6V8D0C7tI4C+UA4cYPy0sgFoR99b87DmyTX1g2Q3U+ngjaM9tUcdByumfw1Au1bSPuKUC1ZnmwAWMywH7jUIYGWGrWwWq/AzbGWz646mwsbM5tY2D2DqnLY9+dqdS6us1tXWPKxZck39oIw5U+mkow8Zadxzn/rdY94SWCL9awDaNa72EUpfAgD0i1Y2AO3Smocek2vqBz8tYCq98oQjc9lHbs/e/XXJY2bWl7zy+CNXcatgEceem3x8+/LOMtS/BmB0K20fofQlAED/aGUDMBla89BTck394MxuptITt2zKOccdsawx5xx3ZA7bsnGVtggOYNi/Zjn0rwEY3UraRwxLX956+cI/UhqWvrzi7Ob+AABM3kpa2QCwcsPWPOdem5x3fXN9ygW+46Sz5Jr6QbKbqXXR6duWXGLipKMPyUWnb13lLYIDOG1705dmKfSvAViZlbSPUPoSAKB7ltJeZlytbACANUOuqfsku5lam2bW5/LXn5hXnfjkbFjgmb5hXfKqE5+cy19/YjbNrG93A2Eu/WsA2nPsuQu/1i5k3UzyjNNGK32phzcAwOrY+2DywTcmb9uafPTXm5Yy99zUXH/015rl170p2btn5a1sAIA1R66p+/TsZg2oScrgeq7S8rbAAehfA9COYfuIWy9f+phjX5N87k9GL315ygXLGwcAwOKG7WUWq7ozbC+z645kw+bR4ozaAgcAmCJyTV0l2c3U2rN3f1777htzw933LXiffY/UXHnjF3PXV3f7xQ3dMuxfIzECsHpO25587c6llSQfto+48p+OFuvzn/SaDgAwbsttL/O9x44W56glthwDAKaOXFP3KWPO1LrkutsWffGZ7Ya778sl1+1Y5S0CADpllPYRSl8CAHTD/fcuv73Ml/8qKcs892fdTFNlDQCYvN1fSf70t5L3nJG868XN9Z/+21VtHyfX1H3O7GYqfeX+Pbn6lnuWNebqW3bm/Jc8I4dt2bhKWwUAdM5y20eMWsJS6UsAgPH6zHtGaC+zrzm7++8+s/Qxx75GOzEAmLS9DzYVXf7ivz76+H/Xx5KPX9ocs398e3OywpjINfWDM7uZSlfdtDN798/XN2Fhe/fXXHXzzlXaIgCg04btI869Njnv+ub6lAse/cXmUSePtn6lLwEAxuvzfz7auI2Pa1rULMWwlQ0AMDl7H0yuOCe59fKFf+j2yN7klt9Prji7uf+YyDX1g2Q3U2mpJSXm+vRdXxvPBkyglAYA0IJjz1245PlClL4EABi/UdvE7P3W8lvZAACT899/JfnCJ5d23y98MvnQhWMLPfFcE0uijDlTafdD+1od920TKqUBALRky+HJs1/d/Jp4qZS+BAAYv5W0l1luKxsAYDLuv7fJtyzHZ97bHOPHcCyfWK6JZZHsZiodvHG0p/ao45J8p5TGYr8wGpbS2HVH8yvimc2jxwMAJuO07cnX7lzar4qVvgQAWB1HndycWLDscbNKmA9b2Zxywfi2CwAYn8+8Z+HS5Qt5ZG/zY7YxHN8nkmti2ZQxZyqddPQhI4177lO/e/SgEyylAQC0aGaz0pcAMI20JOsX7WUAYPp9/s9HHLfEXM0BTCTXxLL5aQFT6ZUnHJnLPnJ79u6vSx4zs77klccfOVrACZfSAABapvQlAEwPLcn6SXsZAJh+D+9ud9wcreeaGIkzu5lKT9yyKeccd8Syxpxz3JE5bMvG0QKupJQGANBfw9KX516bnHd9c33KBb5EBYC+GLYku/XyhT/XD1uSXXF2c3+647TtTduYpdBeBgD65zEHtztujtZzTYxEspupddHp25ZcYuKkow/JRadvHT3YhEtpAAAwAuVqAdCSrN+0lwGA6XbUySOOW+KP4Zag1VwTIym1Lv3Ue9pVSrlt69atW2+77bZJb0pv7dm7P5dctyN/ePPO7Hvk0c/1DetKXnH8kbno9K3ZNLN+9EDvenFyz03LH3fECc1ZYAAAtGexcrVJ86W4crUA0+/+e5O3b1tepbZ1M8n5O1Rx6aLdX9FeBgCmTUfer7WWa1qjtm3blh07duyotW4bZbye3awBdXBZ6LYxmHApDQAAlmhYrnaxs/iG5Wp33dGcLTazubXNA6BFK2lJdsoFq7NNjG7YXsb/DQBMjy2HJ89+ddNyZqmOfc0q/dCthVwTI1HGnKm1Z+/+vPbdN+bKG3dm3yPz32ffI8mVN34xr333jdmzd//owTpQSgMAgCVQrhaAIS3JAAC677TtyVOWmEt5yo82VdrGqNVcEyOR7GZqXXLdbbnh7vuWdN8b7r4vl1y3Y/Rgx567cG+ohaybaUppAfAP6aELrJb7721Kly/HZ97r9QdgWj28u91xAAAs38zmpuraca9bOA+zbqa5/afeN/Z2ZK3mmhiJMuZMpa/cvydX33LPssZcfcvOnP+SZ+SwLRuXH7BTpTQAemqxHrp3fSz5+KV66AIro1wtALNpSQYA0A8zm5PTL0tOfUvzGf3zn2x+gPiYg5sKus85d1XyLa3nmhiJM7uZSlfdtDN79y+vR8Le/TVX3bxz9KATLqUB0GvDHrq3Xr5wImrYQ/eKs5v7AyyXcrUAzKYlGQBAvxz8xObH6Odem5x3fXN9ygWrdmLhRHJNLJtkN1NpqSUl5vr0XV8bPeiES2kA9JoeukAblKsFYDYtyYBJ0b4LoBcmkmti2ZQxZyrtfmhfq+O+bUKlNAB6bdQeuqe+xWsqsDzK1QIwm5ZkQNu07wLolYnlmlgWyW6m0sEbR3tqjzru0SsalNLQ2xHgwPTQBdpy1MnNl4jLHqdcLcDUOm178rU7l1ZlSEsyYCWG7bsWe70Ztu/adUdTQXJmc2ubB8CjTTzXxJIoY85UOunoQ0Ya99ynfveYtwSAA9JDF2iLcrUAzKUlGdAW7bumhzL0sGbINfWDnxYwlV55wpG57CO3Z+/+uuQxM+tLXnn8kau4VQDMSw9doC3K1QIwHy3JgNWmfdd0UIYe1hy5pn5wZjdT6YlbNuWc445Y1phzjjsyh23ZuEpbBMCC9NAF2nTa9qYM7VIoVwuwtgxbkp17bXLe9c31KRdINAErt5L2XXTDsAz9rZcv/H85LEN/xdnN/YHek2vqB8luptZFp29bcomJk44+JBedvnWVtwhojXJS/XLUySOO00MXGIFytQAAtE37rv5Thh7WLLmm7iu1Lv3Ue9pVSrlt69atW2+77bZJb0pv7dm7P5dctyN/ePMXs++RR9++YV3yiuOfnItO35pNM+vb30BgvBYrJ5U0yQvlpLrn/nuTt29b3q/c180k5+9wlg2wMru/olwtAACr710vTu65afnjjjihqTTBZPneAtY8uabVtW3btuzYsWNHrXXbKOP17GYNqEnK4Hqu0vK2AKtmWE5qsV/ZDstJ7bqjOatvZnNrm8ci9NAFJmVYrvaUCya9JQAATDPtu/ptJWXofdaAKSLX1FXKmDO19uzdn9e++8ZceePO7Htk/goG+x6pufLGL+a1774xe/bub3kLgbFSTqrf9NAFYLm0LQEA+kL7rn5Thh7WNLmm7pPsZmpdct1tueHu+5Z03xvuvi+XXLdjlbcIWDX339uULl+Oz7zXl+FdoocuAEu198Hkg29M3rY1+eivJ3d9rCkLetfHko/+WrP8ujcle/dMeksBABrHnrvwZ92FrJtp2usweQ/vbncc0ClyTd0n2c1U+sr9e3L1Lfcsa8zVt+zMV+9/aJW2CFhVKyknRXfMbE5Ov6zpafXCtyZPPbXpT/bUU5u/z9/R3C7RDbB2DduW3Hr5wsf+YduSK85u7g8AMGnD9l3LoX1XdyhDD2uWXFM/SHYzla66aWf27p+/nMRC9u6vuermnau0RcCqUk5qugx76J57bXLe9c31KRf4kA+AtiUAQH9p39VfytDDmiXX1A+S3UylpZaUmOvTd31tzFsCtEI5KQCYftqW0HX6yAOwGO27+ksZeliz5Jr6YcOkNwBWw+6H9rU6Dpgw5aQAYPqtpG3JKReszjZB0pTL/++/0vwYY+5z9K6PJR+/tClF++PbJS4A1rph+65T39K8R/n8J5sf4j/m4OYs4Oecq6pZFw3L0N96+dLHKEMPU0GuqR8ku5lKB28c7ak96jhgwo46ufkicdnjlJMCgN5YSdsSyW5Wy7CP/GLl9Yd95Hfd0ZzRN7O5tc0DoKOG7bu8R+mP07YnX7tzaS11lKGHqSHX1A/KmDOVTjr6kJHGPfep3z3mLaGXlB/sH+WkAGD6aVtCF+kjDwBrgzL0sCbJNfWDnxYwlV55wpG57CO3Z+/+uuQxM+tLXnn8kau4VXSe8oP9pZwUAEw/bUvomlH7yJ/6Fu9DAaCPlKGHNUeuqR+c2c1UeuKWTTnnuCOWNeac447MYVs2rtIW0XnD8oO3Xr5wL8hh+cErzm7uT7ectr0pE7UUykkBQP8cdfKI47QtYZWspI88ANBfwzL0516bnHd9c33KBRLdMIXkmvpBspupddHp25ZcYuKkow/JRadvXeUtotOUH+w/5aQAYLppW0LXrKSPPAAAk6GFJcsk19R9ypgztTbNrM/lrz8xl1y3I394887se+TRZSY2rCt5xfFH5qLTt2bTzPoJbCWdoPzg9FBOCgCml7YldI0+8gAA/aGFJSOSa+o+yW7WgDq4LHQba95Kyg+ecsHqbBMrMywn5f8HAKbLaduTr925tIo82paw2vSRBwDoh2ELy8U+RwxbWO66o6keObO5tc2jL+SaukoZc6bWnr3789p335grb9yZfY/Mf599jyRX3vjFvPbdN2bP3v3tbiDdofwgAEA/aFtCl+gjDzA+ygoDq0kLS1ZArqn7JLuZWpdcd1tuuPu+Jd33hrvvyyXX7VjlLaKzlB8EAOiPYduS83ckL3xr8tRTkyNOaK5f+NZm+emXSXSz+vSRB1i5vQ8mH3xj8ratyUd/vSklfM9NzfVHf61Zft2bkr17Jr2lQF+N2sLSj20YkGvqPsluptJX7t+Tq2+5Z1ljrr5lZ756/0OrtEV0mvKDAAD9M2xbcu61yXnXN9enXKBHN+0Z9pFfDn3kAb5jWFb41ssXbi83LCt8xdnN/QGWayUtLFnz5Jr6QbKbqXTVTTuzd//yeiTs3V9z1c07V2mL6DTlB4FJUaoPAPrttO1Nf/il0Ece4B9SVhhogxaWrIBcUz9IdjOVllpSYq5P3/W1MW8JvaD8INA2pfoAYDroIw8wGmWFgbZoYckKyDX1w4ZJbwCsht0P7Wt1HD03LD946+VLH6P8IDCqYam+xc5gGJbq23VH8wX6zObWNg8AWKZhH/lT39KUu/z8J5svRx9zcFMN6jnn+uwAMNdKygqfcsHqbBMwnbSwZAXkmvqh18nuUsrmJL+a5J8meXKS+5J8KMlba63/Z5nrekKSi5OckeRJSb6c5JokF9dav7HAmPVJ3pjk9UmenmR3ko8luajW+r+XPSHG5uCNCz+1y/r7M/P4m7L+sXenrHso9ZGN2f+tp2bvN47PwRsPHet27HpwV95/+/tz85dvzgP7HshBGw7KCU86IWcec2YO3Ty+WG3FaTNW63E2fisPHPX0HLTn73PCgw/lzPt359BHHpl/0IjlB6ftsWsz1rTFaTOWOXUw1jyl+natW5f3bzk4N2/emAfKuhxUH2lei3Z+Kod+6MLmC/Qx6P1jN8E4bcYyp+7HaTOWOXU/TpuxzKnjsQZ95Hed8LrvxNn9mRz0qc957DoWp81Y5tT9OG3GMqdZlllW+Nufme6+qnltXcuPXYdjmVP347QZqzNzOurkppLecs3TwnLNPXbmtGiuaTXGMZpS6/JqzXdFKWVTmsTyc5N8KcmfJTkqyYlJvprkubXWu5a4rkOT/K80Ceu7ktycZNvg8rkkz6u13jdnzLokVyc5M8k3knwkyaFJTknyYJJTa603rnCOt23dunXrbbfdtpLVrEnv+Ojt+bf/43P/cGHZm42HX5eZx9+SUvY/akyt67N1y4vyX874N9m4fuOK4u/ZtyeX3nhpPnDnB7LvkUf/gmfDug054+ln5MITL1xRrLbitBmrM3FqzRn3786F9309G4cvk+tmmjO6f3z7ssoPdmZOng8Tj9NmLHPq6Jzuvzd5+7Zvn8Gwp5RcesgT8oEtB2VfKY+OU2vO2P2tXPjTf5qN33VE9+YzwVjmZE6TiNNmLHPqfpw2Y5mTOU0iTpuxzMmcJhGnzVjmNE+cd724aeV0oDgH+sy0Fh+7DsYyp+7HaTNW5+b05Jfmwk+8KxuXU01i3Uxy/o5vV+dZs4+dOc2fa1qCN7/0+/OGU5++7HFr1bZt27Jjx44dtdZto4zvc7L715O8JU2S+h/VWncPlp+f5N8l+USt9ceWuK4rkrwmyfuT/GStdd9g+W8n+cUkl9daXzdnzHlJ/lOS25M8v9Z672D52WmS4Hck+cHhukaco2T3iL5y/56cfOlHs3f/4Pld9mbzke/OhoPuPuDY4w8/Pu988TuzacNovdT27NuTn7v+53LzvTevaqy24rQZq5NxHpnJO9cdkU1HnzJS+cFOzsnzYSJx2oxlTh2e05/+VtOjO82XNj93+GG5efOBxx6/6fC88+w/WtuP3QTitBnLnLofp81Y5tT9OG3GMidzmkScNmOZkzlNIk6bscxpgTjvOeOAZ1ou6zPTWnrsOhbLnLofp81YnZ3ThsfnnXf8VTYtNR923Ou+XWVvzT92a3xOj8o1LcHM+pJPXfiiHLZlZcn7tWSlye51496gNpRSHpPkFwZ/vmGY6E6SWuvbknw2yQtKKcctYV3fk+RVSR5O8vNzktNvTnOW+E+VUuZmuM4fXP/yMNE9iP++JB9Mc5b4y5c1McbmiVs25ZzjvnMG3MbDr8uGg+7OUo5lN997c7bftPwS1UOX3njpkl5QVxqrrThtxupknHV7s/0ZxzX9oEbos9fJOXk+TCROm7HMqcNzmlWq79JDntB8aXOgg1OtuXnPvR67CcRpM5Y5dT9Om7HMqftx2oxlTuY0iThtxjInc5pEnDZjmdMCcY46+cBxlvqZabE4S9Srx65jscyp+3HajNXZOe37RrY/5QeXtuI5LSzX/GO3xuc0N9e0FOccd6REd8t6mexOcnKS70pyZ631M/PcfvXg+vQlrOvH0zwOfzY7aZ0ktdaHklyXZH2SnxguL6UcneQH05Qr/+MVxmeVXHT6tpx09CGDHt23JEnmqXY0r2vvuDa7Hty17Ji7HtyVD9z5gWWNGSVWW3HajDVtcdqMZU7dj9NmLHMaPU4rsR5ufp+3a/26fGDLQc2yAx2cBrev+ceu5ThtxjKn7sdpM5Y5dT9Om7HMafQ4bcaatjhtxjKn0eO0GWva4rQZy5wWiXPsuU2Z4IXiLOcz02JxlqB3j12HYplT9+O0Gavzc1q/J7uOffXCrz3rZpozun/qfd9uYemxGz3WNM1pmGtaipOOPiQXnb51WdvCyvU12f3Dg+tbF7h9uPxZq7Su4Zi/rrXO1+hhOfFZJZtm1ufy15+Y4555+7w9uhez75F9ueb2a5Yd8/23v3/eXhDjjtVWnDZjTVucNmOZU/fjtBnLnEaP00qsxxzcxDn44Hn7zY0tzsBUPXYtx2kzljl1P06bscyp+3HajGVOo8dpM9a0xWkzljmNHqfNWNMWp81Y5rRInC2HJ89+9cJxWvrMlPTwsetQLHPqfpw2Y/ViTkc/p+nF/cK3Jk89NTnihOb6hW9tlp9+2bcT3SuKM42P3Rqe0zDX9KoTn5yZ9fMfm2bWl7zqxCfn8tefmE0z65e1LaxcX5PdTx5c37PA7cPlT1mldY0zfkopt813SfK0pYxnYZtm1ueQ79450tibvnzTssfc/OWbW4nVVpw2Y01bnDZjmVP347QZy5xGj9NKrEGpvps3j1bKaE0/di3HaTOWOXU/TpuxzKn7cdqMZU6jx2kz1rTFaTOWOY0ep81Y0xanzVjmdIA4p21vygXPF6elz0xJTx+7jsQyp+7HaTNWb+Z08BOblpXnXpucd31zvUALS4/d6LGmbU6bZtbnN876oXzqwhflzS/9/jz/mENz7JMfn+cfc2je/NLvz6cufFF+46wfkuiekA2T3oARHTy4/tYCtz8wuN6ySusaZ3xW2QP7HjjwncY0rq1Y5tT9OG3GMqfux2kzljmtbNyqxzr23OTj2/NAGe33hmv6sWs5TpuxzKn7cdqMZU7dj9NmLHNa2bhpm5PHbmXjzGn0cdMWp81Y5nSAcTObk5+6OvnQhcln3ps88p0Cmm19Zhp1zCjjPB9WNm7a5uSxW9m4aZuTx25l49qMddiWjXnDqU/PG059+kgxWR19TXZPlVrrtvmWD87uVtx/hQ7acFBr49qKZU7dj9NmLHPqfpw2Y5nTysateqxBqb6D/u5PVjfOiPdfyTjPh9HHmVP347QZy5y6H6fNWOa0snHTNieP3crGmdPo46YtTpuxzGkJ42Y2N2WDT31Lcut7ks9/Mnl4dw6a+WaSB8cXZ8xjRhnn+bCycdM2J4/dysZN25w8disb12YsuqmvZcx3D64fu8Dtw2fo/au0rnHGZ5Ud/6TjRxp3wpNO6Gwsc+p+nDZjmVP347QZy5xGj9NarNO25/iNT1r9OJnCx67FOG3GMqfux2kzljl1P06bscxp9Dhtxpq2OG3GMqfR47QZa9ritBnLnJYRZ05Z4eOPPW914syj94/dBGOZU/fjtBnLnLofp81Y0zgnuquvye4vDq6PWOD24fIvrNK6xhmfVXbWMWdlw7rlFTHYsG5DzjzmzM7GMqfux2kzljl1P06bscxp9DitxZrZnLPOvjIbUlY3TqbwsWsxTpuxzKn7cdqMZU7dj9NmLHMaPU6bsaYtTpuxzGn0OG3GmrY4bcYyp+7HaTOWOY0ep81Y0xanzVjm1P04bcaaxjnRXX1Ndv/l4Po5C9w+XP7ZVVrXcMwzSykzK4zPKjt086F5+dNevqwxZzz9jBy6+dDOxjKn7sdpM5Y5dT9Om7HMafQ4bcY69HFH5uXHnLX6cabxsTOnkeO0GWva4rQZy5y6H6fNWOY0epw2Y01bnDZjmdPocdqMNW1x2oxlTt2P02Yscxo9Tpuxpi1Om7HMqftx2ow1jXOiu/qa7P7zJH+f5GmllGfPc/s5g+vrlrCuDyV5JMnzSylPnH1DKWVjktOT7E/y7eaatda7k/zvJJuTvGyF8WnBhSdemOMPP35J9z3+8ONz4YkXdj6WOXU/TpuxzKn7cdqMZU7mNIk4bcYyJ3OaRJw2Y5lT9+O0GcuczGkScdqMZU7mNIk4bcYyp+7HaTOWOZnTJOK0Gcucuh+nzVjTOCe6qZfJ7lrrw0neMfjzd0op3+4iX0o5P8mzknyi1nrLrOW/UEr5m1LKb8xZ15eSXJnkMUl+t5SyYdbNv5nksCRX1Fq/Mmcz3ja8z+wkeSnlrCT/JMkdST6wgmkyRps2bMo7X/zOnPOMcxYsZ7Fh3Yac84xz8nsv+b1sXL+x87HMqftx2oxlTt2P02YsczKnScRpM5Y5mdMk4rQZy5y6H6fNWOZkTpOI02YsczKnScRpM5Y5dT9Om7HMyZwmEafNWObU/ThtxprGOdFNpdY66W0YSSllU5KPJzkpyZeS/FmSpwz+/mqS59Za75p1/4uTXJTk8lrr6+as69Akn07ytCR3Jrk5ybYkz0xy+2Bd980Zsy7J1UnOTPL1JB9JcmiSFyTZk+TUWusNK5zjbVu3bt162223rWQ1zLHrwV255vZrctOXb8oD+x7IQRsOyglPOiFnHnPm2MtWtBXLnLofp81Y5tT9OG3GMqd+xJq2OG3GMqd+xJq2OG3GMqfux2kzljn1I9a0xWkzljn1I9a0xWkzljl1P06bscypH7GmLU6bscyp+3HajDWNc2J8tm3blh07duyotW4bZXxvk91JUkrZnORXk7w6yZFJ7ktTlvyttdZ75tz34iyQ7B7cfkiSi5OckeTwJPcmuSbJRbXWbywQf32SNyV5fZpE+QNJPjYYs2OF05PsBgAAAAAAAKbWmk52TzvJbgAAAAAAAGBarTTZ3cue3QAAAAAAAACsbZLdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0jmQ3AAAAAAAAAL0j2Q0AAAAAAABA70h2AwAAAAAAANA7kt0AAAAAAAAA9I5kNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0jmQ3AAAAAAAAAL0j2Q0AAAAAAABA70h2AwAAAAAAANA7kt0AAAAAAAAA9I5kNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0Tqm1TnobWEAp5ZsbN27c8rSnPW3SmwIAAAAAAAAwVnfeeWceeuih+2utjxtlvGR3h5VSvpzksUl2TnpbpsjwlwN3TnQroP/sSzA+9icYD/sSjId9CcbH/gTjYV+C8bE/wXjYl8bryCTfqrU+aZTBkt2sKaWU25Kk1rpt0tsCfWZfgvGxP8F42JdgPOxLMD72JxgP+xKMj/0JxsO+1C16dgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0Dul1jrpbQAAAAAAAACAZXFmNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0jmQ3vVVKOaiU8tOllP9QSrmhlPJQKaWWUi5e4XpPL6V8opTyzcHl46WUlx1gzLZSyh+WUr5aSnmwlPJXpZR/Xkqxj9ErpZSTSyl/Ukq5r5Syu5RyYynl3BHW8/nB/rjY5a45Y446wP2/PL6Zwuoa4770ugPsF/9tkbGOTfTeGPel40opF5dSPlVK+UYp5eFSys5SyhWllGctMMZxiV4ppWwupfyrUsrnSil7Sil/V0p5dynl+0ZY1xNKKZeVUr4w+Jz1hVLKvy+lPH6RMetLKb80ON48ODj+XFVK+cEVTQxaNo59qZTy+FLKq0spV5ZS7h4cd+4ffHfxplLKzALjfv8Ax56fHd9MYXWN67i0hO8XfmCBcY5LTI0xHZsO9P3C8HLunHGOTUyFwfcCF5ZS3l9KuWf4HF7B+nxm6pANk94AWIFjkrxnnCsspfzzJG9Psi/J9UkeSvKPkvxRKeUXa63vmGfM85J8JMnmJDcm+XySUwbr+ZFSyk/WWkd+0YS2lFLOTvIHaX4I9adJdiV5UZLLSynPqrVesIzVXZ3k0AVue0GSo5L82QK335vkQ/Ms//tlxIeJGfO+NPSXSf5inuU3LLANjk303rj2pVLKhiQ3D/68L8mnkjyQ5Ngkr0nyilLKa2qtVy+wCsclOq+UsinJR5M8N8mXknwgzfut/yvJPy6lPLfWetfCa/gH6zo0yf9K8vQkdyW5Nsm2JG9Kclop5Xm11vvmjFmX5A+TnJnkG0n+OM17wXOSvKyUcmqt9caVzRJW3xj3pQuSvCVJTfMe7oYkhyU5OcmJSc4ppby01vqtBcZ/OMl8P6r62yVPBiZonMelWS5fYPmj3pM5LjFNxrg/3ZGF96PvSnLG4N+fXOA+jk303VuTvHwcK/KZqYNqrS4uvbwkeVqSdyX5Z0mek+bFqia5eMT1fX+aJPeeJM+btfwZab5c3Zvk6XPGzKR5MatJfmnW8oPTfJFak7xu0o+Vi8uBLkkOSfMBsSY5a9byw5PcPlj+Y2OIsy7J3w3W9+I5tx01WP7xST8eLi6jXsa9LyV53XKPbY5NLtNwGee+lOYHvjem+VC7ftbydUl+fbCubyY5dM44xyWX3lxmPZc/leTgWcvPX+7zOMkVgzHvS7Jh1vLfHiz//XnGnDe47XNJDp+1/OzB8ttnr8vFpauXce1LSX41yfYkT56z/JgkXxis69/MM+73x/XZy8VlkpcxH5c+n6QuM77jksvUXMa5Py0S4+cG6/rkPLc5NrlMxSXJryT5V0lOT/KkNHmgOuK6fGbq2EUZS3qr1npnrfW8Wut/rLXemiYZvRJvSrI+ye/VWv/XrDifS/Kv03xR+qY5Y85McnSSv6y1vn3WmN1JfmHw579Y4XZBG85L8rgkH6i1vn+4sNZ6b5JfHvw5jufyi5J8T5L/k+ZXqTBt2tqXFuPYxDQY275Ua91Xaz2x1vqBWuv+WcsfSfNjyb9NsiXJom1roKtKKY/Jd17f3zB4vU+S1FrfluSzSV5QSjluCev6niSvSvJwkp+vte6bdfObk3w1yU+VUp44Z+j5g+tfHuynw/jvS/LBNGc8jOUsClgt49yXaq2/UWv9lVrrF+csvz3JhYM/XzWeLYduGee+tAKOS0yFFvennxpc/5cVrgc6q9a6vdb6L2ut19VaR25L5jNTN0l2w3cMv+Ccr4TlcNnpSx0zSMDfleSZpZSjxrGBsIoWe/7/cZpfur14UDppJYZvnv/rIMkA06atfWmkbXBsokda2Zdq8zPqzw7+/N6VrAsm6OQ0pSfvrLV+Zp7bF/osM58fT/M9wZ/N/gImSWqtDyW5Ls0PhH9iuLyUcnSSH0zyYJr9cyXxYZLGuS8t5i8H1447TKu29qV5OS4xZVZ9fxrsMz+SJnF31ajrgTXEZ6YO0rMbkpRSHp/kyYM/H/XGoda6s5SyK8lTSimPq7V+c3DTDw+ub11g1bcmeWqSZ6UpuwRdteBzudb6cCnlr5Mcn6as/2fn3mcpSimb05xxmjSlXhZyeCnlkjRngP99mv52H6y1PjxKXGjZau1Lx5VSfivNma5fTvLRWusnlrsNs5Y7NtF1q35cmuWpg+uFftntuETXLeV1P2le98exrtfPWddwzF/XWuertrWc+DBJ49yXFnOg406SnFVKOTvNF6V3J7mu1vo3K4wLbVmVfamU8uY0LQ0fSnJbkmtqrV9dJL7jEtOgjWPT8MSUP661fn2R+zk2QcNnpg6S7IbGMNH99VrrAwvc554khyZ5SpK/mjPunkXGZDAGOqmU8rg0vxJNFn8uH5/muTxqUuGMNGViP1trXWwdP5DkX85Z9sVSyitqrTeOGBtW3SrvS/94cBn6l6WUTyT5ybm/Io1jEz3X4nEppZQfTXJcmrMYPrTA3RyX6Lpxvu6Psi7HHaZFW8/lYXu0Dyxyn1+c8/f2Uso7k7xpTqlM6KLV2pd+c87fby+l/GKt9d0txYdJaOP5vNQS5o5N0PCZqYOUMYfGwYPrby1yn2ESfMsyxs03Brrm4Fn/Xs3n8k8Prhd68/xQkncm+bEkh6c5g/V5Sf4kzRuCD5dSHPDpstXYl76U5OIkx6ZJ/j0pyT9J8jdJXpDkj0op6xfYDscm+qqV49IgqT78cvTttdYvzbmL4xJ9Mc7X/VHW5bjDtFj153Ip5WeTvDjJN5JcOs9dPpPkZ9NULnlsmrPA3zC4/88n+a1RY0OLxr0vfTDJWWkSAI9N8swkb0uyMcm7Silz+5s6LjFNVvX5XEo5Mc0x577MX1o5cWyCuXxm6iBndjMxpZRr0vQpWI5znUEDj9b1/amU8sQkL0nySJL/Ot99BkmGn5+z+NNJXlZKeW+SVyf5v5P8s1XcVNa4ru1LtdYPJ/nwrEXfTHJdKeVjSW5Jc2brK5NcuRrxYVRd25fmGvxI5L1JjklyYx595rbjEgBjVUp5fpLLktQkr6+1/t3c+9RaL5uz6O4kvzuo6HNrkl8opbyt1rpz1TcYOqLW+sY5i25L8i9KKX+T5P9Nsj2LV0oAFjY8q/uqhdo0OTYBfSDZzSQdneT7lznmsauxIUl2L2H9Bw2u758z7gmLjJtvDKyGlexPu+cs++Y8913pc/mfpjnm/M/5vtRZgn+TJqnw0hHjw1J1fV9KktRad5dSfjvJO9LsF7OT3Y5NdEHX96V3pmkN8LdJXjZC/23HJbrkQJ9llrO/jLKuccaHSVq153Ip5ZlpknGPSfLGWus1yxlfa72tlPLBJOckeVGS31/uNkCL2jou/H9Jfj3J95dSjqq1fr7l+NCG1Tw2bUjyk4M/D1TC/FEcm1jDfGbqIMluJqbW+uxJb8MsXxxcP6GUctACfbuPGFx/Yc64Jwxum69f5HxjYOxWsj/VWr9ZSvn7NCWSj0iyY567rfS5PPyl6BUjjr99cP09I46HJenBvjTbQvuFYxMT1+V9qZRyaZKfSbIzyUtqrbtG2EzHJbpk+FnmiAVuX87+Msq6xhkfJmlVnsullKOT/I80788urrX+h9E2z7GH3mjluFBrfaSUcmeSJ6bZLz7fZnxoyWo+n/9Rmv3nrlrrp0YYnzg2sTb5zNRBenZDklrrN/KdF5xj595eSjkyyaFJvlBrnX120V8Orp+zwKqHy+dLNkCXLPhcLqXMpOmJtSfJ55a74lLKM5KckKYnyftH3L4nDK7n+yEKdMmq7UvzWGi/cGxiGqzKvlRK+eUkv5LkK2kS3aOW2nNcokvG+bo/yrqGY5452D9XEh8maezvoUop35Pkf6ZJAlxWa71k9M1z7KE32vw8Mt9+4bjENFnN/WmlJ6Ykjk2sTT4zdZBkN3zHHw+uz5nntuGy65Y6ppRybJKnJvnrWaWUoKsWe/7/4ySbklxfa90zwrqHb56vqbXuXvSeCzt7cH3riOOhLau5L8210H7h2MQ0GPu+VEr5mTQ9Hb+R5KW11r9dwfY5LtElf57k75M8rZTy7HluX+izzHw+lOSRJM8vpTxx9g2llI1JTk+yP8mfDJfXWu9O8r+TbE7yshXGh0ka576UUsoTknw4ydOS/OckvzTqhg32v+H+5dhD1411X1pIKWVbmrY530ryN8PljktMmVXZn0opByd5+eDPkZLdjk2sYT4zdZBkN2tOKeVvBpfvm3PTZWlehH62lPLcWfc/Jslbkuwb3Ge2a5LcneSHSym/NGvMQUl+Z/DnvxvzFGA1vCtNT9SXl1LOGi4cHLB/c/Dno57Li+xPs71mcL1o/59Sys+UUn5gnuVnJbl08OfvzL0dOmas+1Ip5VdLKYfOWTZTSrkoySuSPJjmy9PZHJuYBuPel85J8ntp+mT9RK31Lw60AY5L9MWg5/w7Bn/+zuD1PklSSjk/ybOSfKLWesus5b8w2Fd+Y866vpTkyjR9hX930Mtx6DeTHJbkilrrV+ZsxtuG95n9hc9gf/knSe5I068YOmuc+1Ip5bFpfrj1Q0muSvIztda6WPxSyg+UUn568CXp7OWHJflvSY5Mc1bQn486R2jDmPelnyilvHBujFLKs5L8YZKS5F2DmLM5LjEVxrk/zXFWmt7Bn6613r7QnRybWMt8ZuqXcoD32tBppZRr8p2eIN+b5gD7f5LcM1j2pVrrmXPGDJ/0R889q22QFHhbmsT2/0zycJr+JZuTvHG+3lqllB9Jcv3gPjek6avw/MF2XZ3klQf6UAtdUEo5O80XMSXJx5N8LcmLkzw+ydtqrf9injEL7k+D238kzRveLyc5ota6f5H4H0/ygjTlWj6X5gdZW5MMEw2/VWv95eXPDNo1zn1psPyhJDen6S/8uCTPTnPM25PkNbXWR7UHcGxiGoxrXxp8iNyZ5oPoX2Xhsw6urbVeO2tdH4/jEj1RStmUZj85KcmXkvxZkqcM/v5qkufWWu+adf+Lk1yU5PJa6+vmrOvQJJ9OczbqnWmOQdvStA+4fbCu++aMWZfm+HJmkq8n+UiaNlAvSHO8OrXWesMYpwyrYlz7Uinl7Un+eZof1P9Bkr3zxZsz5seSfCzNPnTzIN73JjkuyZY033O8qNY6jnY4sKrGuC8Nl38hTULtW2kqVT0nyYZBjJ+otT44J77jElNjnO/zZt3nfyR5SZI31Fp/d5HYPxbHJqZEKeVlSd46a9GJab5vmH08+LVa6x8P7n9xfGbqjQ0Hvgt02rFpDu6zfd/gkjRvhpes1vr2UsodSd6cJimQNC9Uv1lr/aMFxnyqlHJCkkuS/FiSH07zAvdbaXpySSbQC7XW95VSTkny/yR5bpqkwI4k76i1Xj7iaoclzK9cLNE98J/SvGl+dr7zI5Ovpunz/c5a6/UjbgO0asz70r9K8rw05fmek+ZN+D1J/mOSty9UhtmxiWkwxn3psYOxSXOG3Q8tcL/PJ7l21t+OS/RGrXVPKeXUJL+a5NVJzkhyX5LfT/LWWus9C49+1Lp2lVJOTHLxYD1nJrk3yW8nuajW+o15xjxSSnlFkjcleX2adgMPJHnfYMyOEacGrRrjvjTsYbp+sJ6FvG7Wvz+X5N+nOeb9UJLvTvOjx8+lKWl5Wa3160uMDxM1xn3pw2lObDkhyclJvitN9Z9PJnlvkv8833cNjktMk3G+z0uSUsr3JHlhmh9i/cEB7u7YxDQ5LM2PROY6ac59Dshnpu5xZjcAAAAAAAAAvaNnNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0jmQ3AAAAAAAAAL0j2Q0AAAAAAABA70h2AwAAAAAAANA7kt0AAAAAAAAA9I5kNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAsIaVUv6glFJLKb85z23PKKXsHlyOmcT2AQAAwEJKrXXS2wAAAABMSCnlCUk+m+R7k7y41vqxwfKZJJ9KcnySn6m1vmtyWwkAAACP5sxuAAAAWMNqrV9Pcu7gz/cMkt9JcnGaRPe1Et0AAAB0kTO7AQAAgAzKmL85yVVJ3pHk40nuTfKsWuuuCW4aAAAAzEuyGwAAAEgp5TFJbkjy7CTfTLIlyWm11g9PcrsAAABgIcqYAwAAAKm1PpzktYM/H5fk9yS6AQAA6DLJbgAAAGDoJ2f9+9mllPUT2xIAAAA4AMluAAAAIKWUH03yK0m+nOT6JM9L8paJbhQAAAAsQs9uAAAAWONKKY9L8pdJjkpyWpLPJPmrJE9I8qO11hsmt3UAAAAwP2d2AwAAAO9Ik+h+R631Q7XWe5Ocl2RDkitKKQdNcuMAAABgPpLdAAAAsIaVUl6R5KeT7Ejyy8PltdYPJvlPSZ6e5LLJbB0AAAAsTBlzAAAAWKNKKd+Xplz5QUlOqrX+xZzbD0pT0vyYJGfVWq9pfSMBAABgAZLdAAAAAAAAAPSOMuYAAAAAAAAA9I5kNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPSOZDcAAAAAAAAAvSPZDQAAAAAAAEDvSHYDAAAAAAAA0DuS3QAAAAAAAAD0jmQ3AAAAAAAAAL0j2Q0AAAAAAABA70h2AwAAAAAAANA7kt0AAAAAAAAA9I5kNwAAAAAAAAC9I9kNAAAAAAAAQO9IdgMAAAAAAADQO5LdAAAAAAAAAPTO/w+m5niVIMM76gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the input training points\n",
        "input_sb_, output_sb_ = pinn.add_spatial_boundary_points()\n",
        "input_tb_, output_tb_ = pinn.add_temporal_boundary_points()\n",
        "input_int_, output_int_ = pinn.add_interior_points()\n",
        "\n",
        "plt.figure(figsize=(16, 8), dpi=150)\n",
        "plt.scatter(input_sb_[:, 1].detach().numpy(), input_sb_[:, 0].detach().numpy(), label=\"Boundary Points\")\n",
        "plt.scatter(input_int_[:, 1].detach().numpy(), input_int_[:, 0].detach().numpy(), label=\"Interior Points\")\n",
        "plt.scatter(input_tb_[:, 1].detach().numpy(), input_tb_[:, 0].detach().numpy(), label=\"Initial Points\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"t\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0CPnHdKtfQxN"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1\n",
        "optimizer_LBFGS = optim.LBFGS(pinn.approximate_solution.parameters(),\n",
        "                              lr=float(0.5),\n",
        "                              max_iter=50000,\n",
        "                              max_eval=50000,\n",
        "                              history_size=150,\n",
        "                              line_search_fn=\"strong_wolfe\",\n",
        "                              tolerance_change=1.0 * np.finfo(float).eps)\n",
        "optimizer_ADAM = optim.Adam(pinn.approximate_solution.parameters(),\n",
        "                            lr=float(0.001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qub-M5jqfQxN",
        "outputId": "6cf2b62f-f8f2-4e80-b0c4-c3a736fa93eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################  0  ################################\n",
            "Total loss:  1.4502 | PDE Loss:  0.3077 | Function Loss:  0.8971\n",
            "Total loss:  1.374 | PDE Loss:  0.226 | Function Loss:  0.8345\n",
            "Total loss:  1.1674 | PDE Loss:  0.0886 | Function Loss:  0.3875\n",
            "Total loss:  1.0596 | PDE Loss:  -0.0211 | Function Loss:  0.2891\n",
            "Total loss:  1.0808 | PDE Loss:  -0.0025 | Function Loss:  0.3225\n",
            "Total loss:  0.8375 | PDE Loss:  -0.2269 | Function Loss:  -0.0234\n",
            "Total loss:  0.7851 | PDE Loss:  -0.281 | Function Loss:  -0.065\n",
            "Total loss:  0.6995 | PDE Loss:  -0.3646 | Function Loss:  -0.1628\n",
            "Total loss:  0.6099 | PDE Loss:  -0.4577 | Function Loss:  -0.2315\n",
            "Total loss:  0.5505 | PDE Loss:  -0.5338 | Function Loss:  -0.2029\n",
            "Total loss:  0.4674 | PDE Loss:  -0.6645 | Function Loss:  -0.1144\n",
            "Total loss:  0.4199 | PDE Loss:  -0.7541 | Function Loss:  -0.0615\n",
            "Total loss:  0.3914 | PDE Loss:  -0.7738 | Function Loss:  -0.1086\n",
            "Total loss:  0.3652 | PDE Loss:  -0.7847 | Function Loss:  -0.1696\n",
            "Total loss:  0.2875 | PDE Loss:  -0.7849 | Function Loss:  -0.526\n",
            "Total loss:  0.2535 | PDE Loss:  -0.8056 | Function Loss:  -0.6417\n",
            "Total loss:  0.2143 | PDE Loss:  -0.8541 | Function Loss:  -0.6217\n",
            "Total loss:  0.1053 | PDE Loss:  -1.0276 | Function Loss:  -0.4738\n",
            "Total loss:  0.033 | PDE Loss:  -1.2013 | Function Loss:  -0.3468\n",
            "Total loss:  -0.0438 | PDE Loss:  -1.368 | Function Loss:  -0.3229\n",
            "Total loss:  -0.0868 | PDE Loss:  -1.4678 | Function Loss:  -0.3203\n",
            "Total loss:  -0.0965 | PDE Loss:  -1.4707 | Function Loss:  -0.335\n",
            "Total loss:  -0.1017 | PDE Loss:  -1.4834 | Function Loss:  -0.3347\n",
            "Total loss:  -0.1131 | PDE Loss:  -1.5108 | Function Loss:  -0.3352\n",
            "Total loss:  -0.1397 | PDE Loss:  -1.573 | Function Loss:  -0.3396\n",
            "Total loss:  -0.1689 | PDE Loss:  -1.6635 | Function Loss:  -0.3365\n",
            "Total loss:  -0.1883 | PDE Loss:  -1.6829 | Function Loss:  -0.3558\n",
            "Total loss:  -0.2152 | PDE Loss:  -1.7027 | Function Loss:  -0.3861\n",
            "Total loss:  -0.2391 | PDE Loss:  -1.6683 | Function Loss:  -0.4413\n",
            "Total loss:  -0.2583 | PDE Loss:  -1.6707 | Function Loss:  -0.4708\n",
            "Total loss:  -0.2768 | PDE Loss:  -1.6631 | Function Loss:  -0.5065\n",
            "Total loss:  -0.2907 | PDE Loss:  -1.6665 | Function Loss:  -0.528\n",
            "Total loss:  -0.3018 | PDE Loss:  -1.7058 | Function Loss:  -0.5196\n",
            "Total loss:  -0.3101 | PDE Loss:  -1.7058 | Function Loss:  -0.5335\n",
            "Total loss:  -0.318 | PDE Loss:  -1.7176 | Function Loss:  -0.5387\n",
            "Total loss:  -0.3258 | PDE Loss:  -1.7373 | Function Loss:  -0.5389\n",
            "Total loss:  -0.3311 | PDE Loss:  -1.7412 | Function Loss:  -0.545\n",
            "Total loss:  -0.3362 | PDE Loss:  -1.756 | Function Loss:  -0.5441\n",
            "Total loss:  -0.3436 | PDE Loss:  -1.7738 | Function Loss:  -0.5452\n",
            "Total loss:  -0.3536 | PDE Loss:  -1.8132 | Function Loss:  -0.5388\n",
            "Total loss:  -0.3664 | PDE Loss:  -1.8555 | Function Loss:  -0.5366\n",
            "Total loss:  -0.3799 | PDE Loss:  -1.9139 | Function Loss:  -0.5301\n",
            "Total loss:  -0.3894 | PDE Loss:  -1.9311 | Function Loss:  -0.5364\n",
            "Total loss:  -0.3954 | PDE Loss:  -1.9662 | Function Loss:  -0.5313\n",
            "Total loss:  -0.4001 | PDE Loss:  -1.9796 | Function Loss:  -0.5328\n",
            "Total loss:  -0.4062 | PDE Loss:  -2.0005 | Function Loss:  -0.5337\n",
            "Total loss:  -0.4144 | PDE Loss:  -2.0123 | Function Loss:  -0.5407\n",
            "Total loss:  -0.4249 | PDE Loss:  -2.0313 | Function Loss:  -0.5484\n",
            "Total loss:  -0.4339 | PDE Loss:  -2.0447 | Function Loss:  -0.556\n",
            "Total loss:  -0.4421 | PDE Loss:  -2.0327 | Function Loss:  -0.5709\n",
            "Total loss:  -0.4507 | PDE Loss:  -2.0619 | Function Loss:  -0.5727\n",
            "Total loss:  -0.4563 | PDE Loss:  -2.0383 | Function Loss:  -0.5882\n",
            "Total loss:  -0.4621 | PDE Loss:  -2.0484 | Function Loss:  -0.5924\n",
            "Total loss:  -0.4673 | PDE Loss:  -2.0454 | Function Loss:  -0.6005\n",
            "Total loss:  -0.4765 | PDE Loss:  -2.0344 | Function Loss:  -0.6173\n",
            "Total loss:  -0.4875 | PDE Loss:  -2.0083 | Function Loss:  -0.6433\n",
            "Total loss:  -0.4935 | PDE Loss:  -2.0312 | Function Loss:  -0.6423\n",
            "Total loss:  -0.497 | PDE Loss:  -2.0253 | Function Loss:  -0.6495\n",
            "Total loss:  -0.5004 | PDE Loss:  -2.0379 | Function Loss:  -0.6491\n",
            "Total loss:  -0.5037 | PDE Loss:  -2.0448 | Function Loss:  -0.651\n",
            "Total loss:  -0.5087 | PDE Loss:  -2.0552 | Function Loss:  -0.6539\n",
            "Total loss:  -0.516 | PDE Loss:  -2.0556 | Function Loss:  -0.6639\n",
            "Total loss:  -0.5228 | PDE Loss:  -2.0729 | Function Loss:  -0.6665\n",
            "Total loss:  -0.5287 | PDE Loss:  -2.0743 | Function Loss:  -0.6743\n",
            "Total loss:  -0.5355 | PDE Loss:  -2.0714 | Function Loss:  -0.6849\n",
            "Total loss:  -0.543 | PDE Loss:  -2.07 | Function Loss:  -0.6962\n",
            "Total loss:  -0.5512 | PDE Loss:  -2.0671 | Function Loss:  -0.7091\n",
            "Total loss:  -0.5619 | PDE Loss:  -2.0809 | Function Loss:  -0.7184\n",
            "Total loss:  -0.5706 | PDE Loss:  -2.0924 | Function Loss:  -0.726\n",
            "Total loss:  -0.5778 | PDE Loss:  -2.1156 | Function Loss:  -0.7265\n",
            "Total loss:  -0.5811 | PDE Loss:  -2.1258 | Function Loss:  -0.727\n",
            "Total loss:  -0.5837 | PDE Loss:  -2.1427 | Function Loss:  -0.724\n",
            "Total loss:  -0.5865 | PDE Loss:  -2.1481 | Function Loss:  -0.7258\n",
            "Total loss:  -0.5894 | PDE Loss:  -2.1662 | Function Loss:  -0.7231\n",
            "Total loss:  -0.5937 | PDE Loss:  -2.1738 | Function Loss:  -0.7262\n",
            "Total loss:  -0.6004 | PDE Loss:  -2.2001 | Function Loss:  -0.7262\n",
            "Total loss:  -0.6067 | PDE Loss:  -2.1998 | Function Loss:  -0.7347\n",
            "Total loss:  -0.6114 | PDE Loss:  -2.2077 | Function Loss:  -0.7383\n",
            "Total loss:  -0.6159 | PDE Loss:  -2.2005 | Function Loss:  -0.7468\n",
            "Total loss:  -0.6199 | PDE Loss:  -2.1916 | Function Loss:  -0.7554\n",
            "Total loss:  -0.6227 | PDE Loss:  -2.1847 | Function Loss:  -0.7618\n",
            "Total loss:  -0.6243 | PDE Loss:  -2.1728 | Function Loss:  -0.7687\n",
            "Total loss:  -0.6257 | PDE Loss:  -2.1711 | Function Loss:  -0.7713\n",
            "Total loss:  -0.6267 | PDE Loss:  -2.1663 | Function Loss:  -0.7746\n",
            "Total loss:  -0.6286 | PDE Loss:  -2.1661 | Function Loss:  -0.7775\n",
            "Total loss:  -0.6339 | PDE Loss:  -2.1704 | Function Loss:  -0.7831\n",
            "Total loss:  -0.6404 | PDE Loss:  -2.1802 | Function Loss:  -0.7883\n",
            "Total loss:  -0.6456 | PDE Loss:  -2.1949 | Function Loss:  -0.7897\n",
            "Total loss:  -0.6498 | PDE Loss:  -2.2086 | Function Loss:  -0.7902\n",
            "Total loss:  -0.6528 | PDE Loss:  -2.2196 | Function Loss:  -0.7902\n",
            "Total loss:  -0.6555 | PDE Loss:  -2.2295 | Function Loss:  -0.7902\n",
            "Total loss:  -0.6577 | PDE Loss:  -2.2356 | Function Loss:  -0.791\n",
            "Total loss:  -0.6608 | PDE Loss:  -2.2369 | Function Loss:  -0.7947\n",
            "Total loss:  -0.6645 | PDE Loss:  -2.2335 | Function Loss:  -0.8011\n",
            "Total loss:  -0.6676 | PDE Loss:  -2.2285 | Function Loss:  -0.8072\n",
            "Total loss:  -0.6696 | PDE Loss:  -2.2226 | Function Loss:  -0.8123\n",
            "Total loss:  -0.6712 | PDE Loss:  -2.2178 | Function Loss:  -0.8163\n",
            "Total loss:  -0.6727 | PDE Loss:  -2.211 | Function Loss:  -0.8212\n",
            "Total loss:  -0.6743 | PDE Loss:  -2.2113 | Function Loss:  -0.8233\n",
            "Total loss:  -0.6761 | PDE Loss:  -2.2051 | Function Loss:  -0.8285\n",
            "Total loss:  -0.6784 | PDE Loss:  -2.2037 | Function Loss:  -0.8323\n",
            "Total loss:  -0.6809 | PDE Loss:  -2.2086 | Function Loss:  -0.8337\n",
            "Total loss:  -0.6831 | PDE Loss:  -2.2095 | Function Loss:  -0.8366\n",
            "Total loss:  -0.6865 | PDE Loss:  -2.2273 | Function Loss:  -0.8339\n",
            "Total loss:  -0.6902 | PDE Loss:  -2.2256 | Function Loss:  -0.8398\n",
            "Total loss:  -0.6941 | PDE Loss:  -2.279 | Function Loss:  -0.825\n",
            "Total loss:  -0.6979 | PDE Loss:  -2.275 | Function Loss:  -0.8315\n",
            "Total loss:  -0.7028 | PDE Loss:  -2.2673 | Function Loss:  -0.841\n",
            "Total loss:  -0.7077 | PDE Loss:  -2.2683 | Function Loss:  -0.8473\n",
            "Total loss:  -0.7113 | PDE Loss:  -2.2547 | Function Loss:  -0.8576\n",
            "Total loss:  -0.7129 | PDE Loss:  -2.2559 | Function Loss:  -0.8595\n",
            "Total loss:  -0.7154 | PDE Loss:  -2.2512 | Function Loss:  -0.8649\n",
            "Total loss:  -0.7175 | PDE Loss:  -2.2612 | Function Loss:  -0.8638\n",
            "Total loss:  -0.7198 | PDE Loss:  -2.2653 | Function Loss:  -0.8654\n",
            "Total loss:  -0.7217 | PDE Loss:  -2.2731 | Function Loss:  -0.8649\n",
            "Total loss:  -0.7252 | PDE Loss:  -2.2835 | Function Loss:  -0.8658\n",
            "Total loss:  -0.7315 | PDE Loss:  -2.2984 | Function Loss:  -0.8688\n",
            "Total loss:  -0.7396 | PDE Loss:  -2.3101 | Function Loss:  -0.8756\n",
            "Total loss:  -0.7486 | PDE Loss:  -2.3331 | Function Loss:  -0.8796\n",
            "Total loss:  -0.7581 | PDE Loss:  -2.3213 | Function Loss:  -0.8967\n",
            "Total loss:  -0.7656 | PDE Loss:  -2.3499 | Function Loss:  -0.8965\n",
            "Total loss:  -0.7714 | PDE Loss:  -2.3369 | Function Loss:  -0.9093\n",
            "Total loss:  -0.7771 | PDE Loss:  -2.313 | Function Loss:  -0.9266\n",
            "Total loss:  -0.7812 | PDE Loss:  -2.3148 | Function Loss:  -0.9316\n",
            "Total loss:  -0.7847 | PDE Loss:  -2.301 | Function Loss:  -0.9424\n",
            "Total loss:  -0.7888 | PDE Loss:  -2.3074 | Function Loss:  -0.9455\n",
            "Total loss:  -0.7935 | PDE Loss:  -2.2967 | Function Loss:  -0.9571\n",
            "Total loss:  -0.7972 | PDE Loss:  -2.319 | Function Loss:  -0.9526\n",
            "Total loss:  -0.7997 | PDE Loss:  -2.3264 | Function Loss:  -0.953\n",
            "Total loss:  -0.803 | PDE Loss:  -2.3475 | Function Loss:  -0.9489\n",
            "Total loss:  -0.8072 | PDE Loss:  -2.3708 | Function Loss:  -0.9457\n",
            "Total loss:  -0.8112 | PDE Loss:  -2.3967 | Function Loss:  -0.9418\n",
            "Total loss:  -0.8191 | PDE Loss:  -2.4384 | Function Loss:  -0.9384\n",
            "Total loss:  -0.8287 | PDE Loss:  -2.4684 | Function Loss:  -0.9418\n",
            "Total loss:  -0.8371 | PDE Loss:  -2.47 | Function Loss:  -0.9522\n",
            "Total loss:  -0.8419 | PDE Loss:  -2.4704 | Function Loss:  -0.9583\n",
            "Total loss:  -0.8493 | PDE Loss:  -2.4234 | Function Loss:  -0.984\n",
            "Total loss:  -0.8522 | PDE Loss:  -2.4061 | Function Loss:  -0.9945\n",
            "Total loss:  -0.8538 | PDE Loss:  -2.404 | Function Loss:  -0.9975\n",
            "Total loss:  -0.8604 | PDE Loss:  -2.4021 | Function Loss:  -1.0074\n",
            "Total loss:  -0.8787 | PDE Loss:  -2.399 | Function Loss:  -1.0347\n",
            "Total loss:  -0.8967 | PDE Loss:  -2.3992 | Function Loss:  -1.0607\n",
            "Total loss:  -0.9096 | PDE Loss:  -2.4202 | Function Loss:  -1.0699\n",
            "Total loss:  -0.9187 | PDE Loss:  -2.4014 | Function Loss:  -1.092\n",
            "Total loss:  -0.9233 | PDE Loss:  -2.4502 | Function Loss:  -1.0765\n",
            "Total loss:  -0.9281 | PDE Loss:  -2.4833 | Function Loss:  -1.0698\n",
            "Total loss:  -0.933 | PDE Loss:  -2.5064 | Function Loss:  -1.0679\n",
            "Total loss:  -0.9405 | PDE Loss:  -2.553 | Function Loss:  -1.062\n",
            "Total loss:  -0.9519 | PDE Loss:  -2.5927 | Function Loss:  -1.0647\n",
            "Total loss:  -0.9636 | PDE Loss:  -2.6486 | Function Loss:  -1.0641\n",
            "Total loss:  -0.9736 | PDE Loss:  -2.66 | Function Loss:  -1.0737\n",
            "Total loss:  -0.9815 | PDE Loss:  -2.6665 | Function Loss:  -1.082\n",
            "Total loss:  -0.9918 | PDE Loss:  -2.6496 | Function Loss:  -1.0997\n",
            "Total loss:  -1.0 | PDE Loss:  -2.6402 | Function Loss:  -1.1129\n",
            "Total loss:  -1.0055 | PDE Loss:  -2.6104 | Function Loss:  -1.1295\n",
            "Total loss:  -1.0092 | PDE Loss:  -2.6121 | Function Loss:  -1.1339\n",
            "Total loss:  -1.0132 | PDE Loss:  -2.611 | Function Loss:  -1.1396\n",
            "Total loss:  -1.0158 | PDE Loss:  -2.618 | Function Loss:  -1.1407\n",
            "Total loss:  -1.0188 | PDE Loss:  -2.6341 | Function Loss:  -1.1394\n",
            "Total loss:  -1.0211 | PDE Loss:  -2.6413 | Function Loss:  -1.1402\n",
            "Total loss:  -1.0251 | PDE Loss:  -2.6725 | Function Loss:  -1.1359\n",
            "Total loss:  -1.0275 | PDE Loss:  -2.6685 | Function Loss:  -1.1402\n",
            "Total loss:  -1.0298 | PDE Loss:  -2.6681 | Function Loss:  -1.1433\n",
            "Total loss:  -1.0324 | PDE Loss:  -2.6572 | Function Loss:  -1.15\n",
            "Total loss:  -1.0359 | PDE Loss:  -2.6502 | Function Loss:  -1.1569\n",
            "Total loss:  -1.0411 | PDE Loss:  -2.6445 | Function Loss:  -1.1656\n",
            "Total loss:  -1.0498 | PDE Loss:  -2.6302 | Function Loss:  -1.1823\n",
            "Total loss:  -1.0604 | PDE Loss:  -2.6211 | Function Loss:  -1.2\n",
            "Total loss:  -1.0682 | PDE Loss:  -2.6124 | Function Loss:  -1.2142\n",
            "Total loss:  -1.0735 | PDE Loss:  -2.6023 | Function Loss:  -1.2259\n",
            "Total loss:  -1.0765 | PDE Loss:  -2.6111 | Function Loss:  -1.2265\n",
            "Total loss:  -1.0784 | PDE Loss:  -2.6196 | Function Loss:  -1.2257\n",
            "Total loss:  -1.0791 | PDE Loss:  -2.6288 | Function Loss:  -1.223\n",
            "Total loss:  -1.0799 | PDE Loss:  -2.6333 | Function Loss:  -1.2224\n",
            "Total loss:  -1.081 | PDE Loss:  -2.642 | Function Loss:  -1.2205\n",
            "Total loss:  -1.0828 | PDE Loss:  -2.6512 | Function Loss:  -1.2196\n",
            "Total loss:  -1.0865 | PDE Loss:  -2.6539 | Function Loss:  -1.2236\n",
            "Total loss:  -1.0927 | PDE Loss:  -2.6801 | Function Loss:  -1.2227\n",
            "Total loss:  -1.1025 | PDE Loss:  -2.6849 | Function Loss:  -1.2342\n",
            "Total loss:  -1.1131 | PDE Loss:  -2.7037 | Function Loss:  -1.242\n",
            "Total loss:  -1.1255 | PDE Loss:  -2.7023 | Function Loss:  -1.2592\n",
            "Total loss:  -1.1301 | PDE Loss:  -2.6877 | Function Loss:  -1.271\n",
            "Total loss:  -1.1383 | PDE Loss:  -2.6777 | Function Loss:  -1.2863\n",
            "Total loss:  -1.1413 | PDE Loss:  -2.6643 | Function Loss:  -1.2961\n",
            "Total loss:  -1.1438 | PDE Loss:  -2.651 | Function Loss:  -1.3056\n",
            "Total loss:  -1.1459 | PDE Loss:  -2.6516 | Function Loss:  -1.3084\n",
            "Total loss:  -1.1496 | PDE Loss:  -2.6385 | Function Loss:  -1.3199\n",
            "Total loss:  -1.1533 | PDE Loss:  -2.6356 | Function Loss:  -1.3268\n",
            "Total loss:  -1.1571 | PDE Loss:  -2.6298 | Function Loss:  -1.3355\n",
            "Total loss:  -1.1605 | PDE Loss:  -2.6462 | Function Loss:  -1.3323\n",
            "Total loss:  -1.1629 | PDE Loss:  -2.6488 | Function Loss:  -1.3346\n",
            "Total loss:  -1.1647 | PDE Loss:  -2.6495 | Function Loss:  -1.3369\n",
            "Total loss:  -1.1664 | PDE Loss:  -2.6575 | Function Loss:  -1.3357\n",
            "Total loss:  -1.1692 | PDE Loss:  -2.6704 | Function Loss:  -1.3336\n",
            "Total loss:  -1.1731 | PDE Loss:  -2.6867 | Function Loss:  -1.3321\n",
            "Total loss:  -1.1786 | PDE Loss:  -2.6976 | Function Loss:  -1.3352\n",
            "Total loss:  -1.1847 | PDE Loss:  -2.7089 | Function Loss:  -1.339\n",
            "Total loss:  -1.189 | PDE Loss:  -2.7077 | Function Loss:  -1.3457\n",
            "Total loss:  -1.1933 | PDE Loss:  -2.7023 | Function Loss:  -1.3543\n",
            "Total loss:  -1.198 | PDE Loss:  -2.693 | Function Loss:  -1.3654\n",
            "Total loss:  -1.2008 | PDE Loss:  -2.686 | Function Loss:  -1.3729\n",
            "Total loss:  -1.2027 | PDE Loss:  -2.6812 | Function Loss:  -1.3781\n",
            "Total loss:  -1.2034 | PDE Loss:  -2.6791 | Function Loss:  -1.3803\n",
            "Total loss:  -1.2047 | PDE Loss:  -2.6798 | Function Loss:  -1.3818\n",
            "Total loss:  -1.2059 | PDE Loss:  -2.6831 | Function Loss:  -1.382\n",
            "Total loss:  -1.207 | PDE Loss:  -2.6873 | Function Loss:  -1.3815\n",
            "Total loss:  -1.2082 | PDE Loss:  -2.6933 | Function Loss:  -1.3804\n",
            "Total loss:  -1.2098 | PDE Loss:  -2.7016 | Function Loss:  -1.3787\n",
            "Total loss:  -1.212 | PDE Loss:  -2.713 | Function Loss:  -1.3766\n",
            "Total loss:  -1.217 | PDE Loss:  -2.7212 | Function Loss:  -1.3801\n",
            "Total loss:  -1.2287 | PDE Loss:  -2.7373 | Function Loss:  -1.3899\n",
            "Total loss:  -1.2415 | PDE Loss:  -2.75 | Function Loss:  -1.4027\n",
            "Total loss:  -1.2489 | PDE Loss:  -2.7451 | Function Loss:  -1.4157\n",
            "Total loss:  -1.2568 | PDE Loss:  -2.742 | Function Loss:  -1.4289\n",
            "Total loss:  -1.2647 | PDE Loss:  -2.7193 | Function Loss:  -1.4526\n",
            "Total loss:  -1.2707 | PDE Loss:  -2.7107 | Function Loss:  -1.4666\n",
            "Total loss:  -1.2747 | PDE Loss:  -2.7 | Function Loss:  -1.4792\n",
            "Total loss:  -1.2776 | PDE Loss:  -2.6844 | Function Loss:  -1.4936\n",
            "Total loss:  -1.2795 | PDE Loss:  -2.6853 | Function Loss:  -1.4963\n",
            "Total loss:  -1.2813 | PDE Loss:  -2.6895 | Function Loss:  -1.4964\n",
            "Total loss:  -1.2844 | PDE Loss:  -2.6961 | Function Loss:  -1.4973\n",
            "Total loss:  -1.2882 | PDE Loss:  -2.7043 | Function Loss:  -1.4983\n",
            "Total loss:  -1.2926 | PDE Loss:  -2.71 | Function Loss:  -1.5019\n",
            "Total loss:  -1.297 | PDE Loss:  -2.7161 | Function Loss:  -1.5053\n",
            "Total loss:  -1.3009 | PDE Loss:  -2.7185 | Function Loss:  -1.5101\n",
            "Total loss:  -1.304 | PDE Loss:  -2.7172 | Function Loss:  -1.516\n",
            "Total loss:  -1.307 | PDE Loss:  -2.718 | Function Loss:  -1.5204\n",
            "Total loss:  -1.3106 | PDE Loss:  -2.7151 | Function Loss:  -1.5281\n",
            "Total loss:  -1.314 | PDE Loss:  -2.7155 | Function Loss:  -1.5334\n",
            "Total loss:  -1.3168 | PDE Loss:  -2.7141 | Function Loss:  -1.5391\n",
            "Total loss:  -1.3202 | PDE Loss:  -2.7097 | Function Loss:  -1.5478\n",
            "Total loss:  -1.3236 | PDE Loss:  -2.7128 | Function Loss:  -1.5513\n",
            "Total loss:  -1.3263 | PDE Loss:  -2.7052 | Function Loss:  -1.5614\n",
            "Total loss:  -1.3283 | PDE Loss:  -2.7082 | Function Loss:  -1.5627\n",
            "Total loss:  -1.3305 | PDE Loss:  -2.7067 | Function Loss:  -1.5675\n",
            "Total loss:  -1.3334 | PDE Loss:  -2.7118 | Function Loss:  -1.5688\n",
            "Total loss:  -1.3373 | PDE Loss:  -2.715 | Function Loss:  -1.5732\n",
            "Total loss:  -1.3418 | PDE Loss:  -2.725 | Function Loss:  -1.5737\n",
            "Total loss:  -1.3486 | PDE Loss:  -2.7359 | Function Loss:  -1.5778\n",
            "Total loss:  -1.3563 | PDE Loss:  -2.7598 | Function Loss:  -1.5746\n",
            "Total loss:  -1.3624 | PDE Loss:  -2.7694 | Function Loss:  -1.5783\n",
            "Total loss:  -1.3672 | PDE Loss:  -2.7769 | Function Loss:  -1.5814\n",
            "Total loss:  -1.373 | PDE Loss:  -2.7763 | Function Loss:  -1.5913\n",
            "Total loss:  -1.3782 | PDE Loss:  -2.7773 | Function Loss:  -1.5994\n",
            "Total loss:  -1.3809 | PDE Loss:  -2.7638 | Function Loss:  -1.613\n",
            "Total loss:  -1.3825 | PDE Loss:  -2.7576 | Function Loss:  -1.6202\n",
            "Total loss:  -1.3838 | PDE Loss:  -2.7532 | Function Loss:  -1.6257\n",
            "Total loss:  -1.3851 | PDE Loss:  -2.752 | Function Loss:  -1.6289\n",
            "Total loss:  -1.3864 | PDE Loss:  -2.7537 | Function Loss:  -1.63\n",
            "Total loss:  -1.3873 | PDE Loss:  -2.7568 | Function Loss:  -1.6292\n",
            "Total loss:  -1.3882 | PDE Loss:  -2.7633 | Function Loss:  -1.6259\n",
            "Total loss:  -1.3892 | PDE Loss:  -2.767 | Function Loss:  -1.6249\n",
            "Total loss:  -1.3907 | PDE Loss:  -2.771 | Function Loss:  -1.6247\n",
            "Total loss:  -1.3935 | PDE Loss:  -2.7774 | Function Loss:  -1.6251\n",
            "Total loss:  -1.4002 | PDE Loss:  -2.7786 | Function Loss:  -1.6356\n",
            "Total loss:  -1.4092 | PDE Loss:  -2.783 | Function Loss:  -1.648\n",
            "Total loss:  -1.4168 | PDE Loss:  -2.7774 | Function Loss:  -1.6655\n",
            "Total loss:  -1.4148 | PDE Loss:  -2.7775 | Function Loss:  -1.6619\n",
            "Total loss:  -1.4208 | PDE Loss:  -2.7784 | Function Loss:  -1.6718\n",
            "Total loss:  -1.4238 | PDE Loss:  -2.7765 | Function Loss:  -1.6787\n",
            "Total loss:  -1.4258 | PDE Loss:  -2.7738 | Function Loss:  -1.6845\n",
            "Total loss:  -1.4276 | PDE Loss:  -2.7715 | Function Loss:  -1.6897\n",
            "Total loss:  -1.4292 | PDE Loss:  -2.7735 | Function Loss:  -1.6909\n",
            "Total loss:  -1.43 | PDE Loss:  -2.7731 | Function Loss:  -1.6927\n",
            "Total loss:  -1.4306 | PDE Loss:  -2.7729 | Function Loss:  -1.6939\n",
            "Total loss:  -1.4314 | PDE Loss:  -2.7752 | Function Loss:  -1.6935\n",
            "Total loss:  -1.4329 | PDE Loss:  -2.7794 | Function Loss:  -1.6928\n",
            "Total loss:  -1.4351 | PDE Loss:  -2.7855 | Function Loss:  -1.6917\n",
            "Total loss:  -1.4379 | PDE Loss:  -2.7953 | Function Loss:  -1.6889\n",
            "Total loss:  -1.4422 | PDE Loss:  -2.8015 | Function Loss:  -1.6918\n",
            "Total loss:  -1.4483 | PDE Loss:  -2.8132 | Function Loss:  -1.6937\n",
            "Total loss:  -1.4541 | PDE Loss:  -2.8202 | Function Loss:  -1.6985\n",
            "Total loss:  -1.4593 | PDE Loss:  -2.8196 | Function Loss:  -1.7082\n",
            "Total loss:  -1.4637 | PDE Loss:  -2.8186 | Function Loss:  -1.7167\n",
            "Total loss:  -1.4668 | PDE Loss:  -2.816 | Function Loss:  -1.7245\n",
            "Total loss:  -1.4686 | PDE Loss:  -2.8058 | Function Loss:  -1.7362\n",
            "Total loss:  -1.4697 | PDE Loss:  -2.8071 | Function Loss:  -1.7372\n",
            "Total loss:  -1.4704 | PDE Loss:  -2.8079 | Function Loss:  -1.7377\n",
            "Total loss:  -1.4709 | PDE Loss:  -2.8079 | Function Loss:  -1.7387\n",
            "Total loss:  -1.4713 | PDE Loss:  -2.8096 | Function Loss:  -1.7379\n",
            "Total loss:  -1.4717 | PDE Loss:  -2.8115 | Function Loss:  -1.7371\n",
            "Total loss:  -1.4727 | PDE Loss:  -2.815 | Function Loss:  -1.736\n",
            "Total loss:  -1.4753 | PDE Loss:  -2.8224 | Function Loss:  -1.7347\n",
            "Total loss:  -1.479 | PDE Loss:  -2.8325 | Function Loss:  -1.7332\n",
            "Total loss:  -1.4842 | PDE Loss:  -2.8438 | Function Loss:  -1.7337\n",
            "Total loss:  -1.4914 | PDE Loss:  -2.8594 | Function Loss:  -1.7344\n",
            "Total loss:  -1.4997 | PDE Loss:  -2.8661 | Function Loss:  -1.744\n",
            "Total loss:  -1.5065 | PDE Loss:  -2.879 | Function Loss:  -1.7463\n",
            "Total loss:  -1.5124 | PDE Loss:  -2.8739 | Function Loss:  -1.7603\n",
            "Total loss:  -1.5171 | PDE Loss:  -2.8676 | Function Loss:  -1.7737\n",
            "Total loss:  -1.5225 | PDE Loss:  -2.8598 | Function Loss:  -1.7901\n",
            "Total loss:  -1.5272 | PDE Loss:  -2.8534 | Function Loss:  -1.8045\n",
            "Total loss:  -1.5313 | PDE Loss:  -2.8571 | Function Loss:  -1.8088\n",
            "Total loss:  -1.5342 | PDE Loss:  -2.8525 | Function Loss:  -1.8187\n",
            "Total loss:  -1.5362 | PDE Loss:  -2.857 | Function Loss:  -1.8183\n",
            "Total loss:  -1.5383 | PDE Loss:  -2.8667 | Function Loss:  -1.8136\n",
            "Total loss:  -1.5402 | PDE Loss:  -2.8749 | Function Loss:  -1.81\n",
            "Total loss:  -1.5418 | PDE Loss:  -2.8836 | Function Loss:  -1.8056\n",
            "Total loss:  -1.5442 | PDE Loss:  -2.8919 | Function Loss:  -1.8031\n",
            "Total loss:  -1.5477 | PDE Loss:  -2.9071 | Function Loss:  -1.7972\n",
            "Total loss:  -1.551 | PDE Loss:  -2.9095 | Function Loss:  -1.8013\n",
            "Total loss:  -1.5537 | PDE Loss:  -2.9256 | Function Loss:  -1.7938\n",
            "Total loss:  -1.5553 | PDE Loss:  -2.9266 | Function Loss:  -1.7958\n",
            "Total loss:  -1.5566 | PDE Loss:  -2.9244 | Function Loss:  -1.7998\n",
            "Total loss:  -1.5574 | PDE Loss:  -2.929 | Function Loss:  -1.7977\n",
            "Total loss:  -1.5578 | PDE Loss:  -2.9326 | Function Loss:  -1.7958\n",
            "Total loss:  -1.5583 | PDE Loss:  -2.9343 | Function Loss:  -1.7954\n",
            "Total loss:  -1.5588 | PDE Loss:  -2.9368 | Function Loss:  -1.7944\n",
            "Total loss:  -1.5593 | PDE Loss:  -2.9404 | Function Loss:  -1.7928\n",
            "Total loss:  -1.5602 | PDE Loss:  -2.945 | Function Loss:  -1.7911\n",
            "Total loss:  -1.5616 | PDE Loss:  -2.9506 | Function Loss:  -1.7896\n",
            "Total loss:  -1.5637 | PDE Loss:  -2.959 | Function Loss:  -1.7873\n",
            "Total loss:  -1.5663 | PDE Loss:  -2.9644 | Function Loss:  -1.7881\n",
            "Total loss:  -1.5693 | PDE Loss:  -2.972 | Function Loss:  -1.7879\n",
            "Total loss:  -1.5727 | PDE Loss:  -2.978 | Function Loss:  -1.7897\n",
            "Total loss:  -1.577 | PDE Loss:  -2.9759 | Function Loss:  -1.7982\n",
            "Total loss:  -1.5813 | PDE Loss:  -2.9756 | Function Loss:  -1.8055\n",
            "Total loss:  -1.5862 | PDE Loss:  -2.9661 | Function Loss:  -1.8205\n",
            "Total loss:  -1.5899 | PDE Loss:  -2.9646 | Function Loss:  -1.8279\n",
            "Total loss:  -1.5923 | PDE Loss:  -2.9611 | Function Loss:  -1.8348\n",
            "Total loss:  -1.5947 | PDE Loss:  -2.9611 | Function Loss:  -1.8388\n",
            "Total loss:  -1.5971 | PDE Loss:  -2.9659 | Function Loss:  -1.8395\n",
            "Total loss:  -1.5989 | PDE Loss:  -2.9718 | Function Loss:  -1.8382\n",
            "Total loss:  -1.6002 | PDE Loss:  -2.9748 | Function Loss:  -1.8383\n",
            "Total loss:  -1.6018 | PDE Loss:  -2.9807 | Function Loss:  -1.8369\n",
            "Total loss:  -1.6035 | PDE Loss:  -2.9862 | Function Loss:  -1.8359\n",
            "Total loss:  -1.6057 | PDE Loss:  -2.9908 | Function Loss:  -1.8364\n",
            "Total loss:  -1.6088 | PDE Loss:  -2.9996 | Function Loss:  -1.8355\n",
            "Total loss:  -1.6126 | PDE Loss:  -3.0023 | Function Loss:  -1.84\n",
            "Total loss:  -1.6164 | PDE Loss:  -3.0098 | Function Loss:  -1.8413\n",
            "Total loss:  -1.6196 | PDE Loss:  -3.0101 | Function Loss:  -1.8465\n",
            "Total loss:  -1.6228 | PDE Loss:  -3.0085 | Function Loss:  -1.8531\n",
            "Total loss:  -1.6253 | PDE Loss:  -3.0163 | Function Loss:  -1.8518\n",
            "Total loss:  -1.6272 | PDE Loss:  -3.0147 | Function Loss:  -1.8562\n",
            "Total loss:  -1.629 | PDE Loss:  -3.0178 | Function Loss:  -1.8571\n",
            "Total loss:  -1.6308 | PDE Loss:  -3.0235 | Function Loss:  -1.8562\n",
            "Total loss:  -1.6322 | PDE Loss:  -3.0287 | Function Loss:  -1.8551\n",
            "Total loss:  -1.6337 | PDE Loss:  -3.0315 | Function Loss:  -1.8556\n",
            "Total loss:  -1.6351 | PDE Loss:  -3.0378 | Function Loss:  -1.8538\n",
            "Total loss:  -1.6378 | PDE Loss:  -3.0411 | Function Loss:  -1.856\n",
            "Total loss:  -1.6429 | PDE Loss:  -3.05 | Function Loss:  -1.8587\n",
            "Total loss:  -1.6461 | PDE Loss:  -3.0517 | Function Loss:  -1.863\n",
            "Total loss:  -1.6507 | PDE Loss:  -3.0504 | Function Loss:  -1.8714\n",
            "Total loss:  -1.6544 | PDE Loss:  -3.0581 | Function Loss:  -1.8724\n",
            "Total loss:  -1.6595 | PDE Loss:  -3.0599 | Function Loss:  -1.8797\n",
            "Total loss:  -1.6631 | PDE Loss:  -3.0613 | Function Loss:  -1.8849\n",
            "Total loss:  -1.6661 | PDE Loss:  -3.0674 | Function Loss:  -1.8858\n",
            "Total loss:  -1.6689 | PDE Loss:  -3.0703 | Function Loss:  -1.8885\n",
            "Total loss:  -1.6723 | PDE Loss:  -3.0703 | Function Loss:  -1.8942\n",
            "Total loss:  -1.677 | PDE Loss:  -3.0777 | Function Loss:  -1.897\n",
            "Total loss:  -1.6814 | PDE Loss:  -3.0747 | Function Loss:  -1.9064\n",
            "Total loss:  -1.6849 | PDE Loss:  -3.0733 | Function Loss:  -1.9132\n",
            "Total loss:  -1.6874 | PDE Loss:  -3.0757 | Function Loss:  -1.9157\n",
            "Total loss:  -1.6896 | PDE Loss:  -3.0693 | Function Loss:  -1.9241\n",
            "Total loss:  -1.692 | PDE Loss:  -3.0753 | Function Loss:  -1.9239\n",
            "Total loss:  -1.6948 | PDE Loss:  -3.0736 | Function Loss:  -1.9299\n",
            "Total loss:  -1.697 | PDE Loss:  -3.0723 | Function Loss:  -1.9346\n",
            "Total loss:  -1.7017 | PDE Loss:  -3.0694 | Function Loss:  -1.945\n",
            "Total loss:  -1.7072 | PDE Loss:  -3.0819 | Function Loss:  -1.9453\n",
            "Total loss:  -1.713 | PDE Loss:  -3.0844 | Function Loss:  -1.9535\n",
            "Total loss:  -1.7166 | PDE Loss:  -3.0996 | Function Loss:  -1.9487\n",
            "Total loss:  -1.7185 | PDE Loss:  -3.1231 | Function Loss:  -1.936\n",
            "Total loss:  -1.7203 | PDE Loss:  -3.1167 | Function Loss:  -1.9432\n",
            "Total loss:  -1.7216 | PDE Loss:  -3.1161 | Function Loss:  -1.9458\n",
            "Total loss:  -1.7227 | PDE Loss:  -3.1163 | Function Loss:  -1.9475\n",
            "Total loss:  -1.7235 | PDE Loss:  -3.1177 | Function Loss:  -1.9479\n",
            "Total loss:  -1.7242 | PDE Loss:  -3.1188 | Function Loss:  -1.9484\n",
            "Total loss:  -1.7252 | PDE Loss:  -3.1205 | Function Loss:  -1.9488\n",
            "Total loss:  -1.7269 | PDE Loss:  -3.1243 | Function Loss:  -1.9491\n",
            "Total loss:  -1.7298 | PDE Loss:  -3.128 | Function Loss:  -1.9515\n",
            "Total loss:  -1.734 | PDE Loss:  -3.1366 | Function Loss:  -1.9527\n",
            "Total loss:  -1.7385 | PDE Loss:  -3.1424 | Function Loss:  -1.9565\n",
            "Total loss:  -1.743 | PDE Loss:  -3.148 | Function Loss:  -1.9602\n",
            "Total loss:  -1.7472 | PDE Loss:  -3.1516 | Function Loss:  -1.9648\n",
            "Total loss:  -1.7511 | PDE Loss:  -3.1567 | Function Loss:  -1.9679\n",
            "Total loss:  -1.7528 | PDE Loss:  -3.1577 | Function Loss:  -1.97\n",
            "Total loss:  -1.7545 | PDE Loss:  -3.1613 | Function Loss:  -1.9705\n",
            "Total loss:  -1.756 | PDE Loss:  -3.1633 | Function Loss:  -1.9718\n",
            "Total loss:  -1.7573 | PDE Loss:  -3.1671 | Function Loss:  -1.9715\n",
            "Total loss:  -1.7587 | PDE Loss:  -3.1701 | Function Loss:  -1.9718\n",
            "Total loss:  -1.7606 | PDE Loss:  -3.1733 | Function Loss:  -1.9729\n",
            "Total loss:  -1.763 | PDE Loss:  -3.1767 | Function Loss:  -1.9746\n",
            "Total loss:  -1.7657 | PDE Loss:  -3.1789 | Function Loss:  -1.9776\n",
            "Total loss:  -1.7683 | PDE Loss:  -3.1827 | Function Loss:  -1.9795\n",
            "Total loss:  -1.77 | PDE Loss:  -3.1819 | Function Loss:  -1.9828\n",
            "Total loss:  -1.7719 | PDE Loss:  -3.1811 | Function Loss:  -1.9864\n",
            "Total loss:  -1.7735 | PDE Loss:  -3.1819 | Function Loss:  -1.9884\n",
            "Total loss:  -1.7747 | PDE Loss:  -3.1791 | Function Loss:  -1.9924\n",
            "Total loss:  -1.776 | PDE Loss:  -3.1815 | Function Loss:  -1.9929\n",
            "Total loss:  -1.7772 | PDE Loss:  -3.1814 | Function Loss:  -1.995\n",
            "Total loss:  -1.7783 | PDE Loss:  -3.1845 | Function Loss:  -1.9947\n",
            "Total loss:  -1.7791 | PDE Loss:  -3.1862 | Function Loss:  -1.995\n",
            "Total loss:  -1.78 | PDE Loss:  -3.1891 | Function Loss:  -1.9945\n",
            "Total loss:  -1.7809 | PDE Loss:  -3.1913 | Function Loss:  -1.9947\n",
            "Total loss:  -1.7821 | PDE Loss:  -3.1952 | Function Loss:  -1.9941\n",
            "Total loss:  -1.784 | PDE Loss:  -3.1961 | Function Loss:  -1.9966\n",
            "Total loss:  -1.7874 | PDE Loss:  -3.2025 | Function Loss:  -1.9982\n",
            "Total loss:  -1.7925 | PDE Loss:  -3.2068 | Function Loss:  -2.0038\n",
            "Total loss:  -1.7978 | PDE Loss:  -3.2166 | Function Loss:  -2.0062\n",
            "Total loss:  -1.803 | PDE Loss:  -3.2227 | Function Loss:  -2.011\n",
            "Total loss:  -1.8062 | PDE Loss:  -3.2269 | Function Loss:  -2.0135\n",
            "Total loss:  -1.8096 | PDE Loss:  -3.2329 | Function Loss:  -2.0153\n",
            "Total loss:  -1.8118 | PDE Loss:  -3.232 | Function Loss:  -2.0194\n",
            "Total loss:  -1.8133 | PDE Loss:  -3.2378 | Function Loss:  -2.0183\n",
            "Total loss:  -1.8143 | PDE Loss:  -3.2371 | Function Loss:  -2.0203\n",
            "Total loss:  -1.8151 | PDE Loss:  -3.2409 | Function Loss:  -2.0193\n",
            "Total loss:  -1.8156 | PDE Loss:  -3.2405 | Function Loss:  -2.0203\n",
            "Total loss:  -1.816 | PDE Loss:  -3.242 | Function Loss:  -2.0201\n",
            "Total loss:  -1.8165 | PDE Loss:  -3.2429 | Function Loss:  -2.0203\n",
            "Total loss:  -1.8171 | PDE Loss:  -3.2413 | Function Loss:  -2.0223\n",
            "Total loss:  -1.8178 | PDE Loss:  -3.2432 | Function Loss:  -2.0222\n",
            "Total loss:  -1.8192 | PDE Loss:  -3.2436 | Function Loss:  -2.0243\n",
            "Total loss:  -1.8212 | PDE Loss:  -3.2442 | Function Loss:  -2.0271\n",
            "Total loss:  -1.8234 | PDE Loss:  -3.2426 | Function Loss:  -2.0317\n",
            "Total loss:  -1.8259 | PDE Loss:  -3.242 | Function Loss:  -2.0361\n",
            "Total loss:  -1.8291 | PDE Loss:  -3.2405 | Function Loss:  -2.0421\n",
            "Total loss:  -1.8327 | PDE Loss:  -3.2404 | Function Loss:  -2.0481\n",
            "Total loss:  -1.8359 | PDE Loss:  -3.2394 | Function Loss:  -2.0541\n",
            "Total loss:  -1.8386 | PDE Loss:  -3.2428 | Function Loss:  -2.0563\n",
            "Total loss:  -1.8405 | PDE Loss:  -3.2453 | Function Loss:  -2.0579\n",
            "Total loss:  -1.8422 | PDE Loss:  -3.2515 | Function Loss:  -2.0567\n",
            "Total loss:  -1.8434 | PDE Loss:  -3.2554 | Function Loss:  -2.0562\n",
            "Total loss:  -1.8445 | PDE Loss:  -3.2585 | Function Loss:  -2.0559\n",
            "Total loss:  -1.8454 | PDE Loss:  -3.2609 | Function Loss:  -2.0558\n",
            "Total loss:  -1.8463 | PDE Loss:  -3.262 | Function Loss:  -2.0566\n",
            "Total loss:  -1.8476 | PDE Loss:  -3.2616 | Function Loss:  -2.0591\n",
            "Total loss:  -1.8495 | PDE Loss:  -3.2609 | Function Loss:  -2.0626\n",
            "Total loss:  -1.8509 | PDE Loss:  -3.2471 | Function Loss:  -2.0738\n",
            "Total loss:  -1.8551 | PDE Loss:  -3.2492 | Function Loss:  -2.0796\n",
            "Total loss:  -1.859 | PDE Loss:  -3.2526 | Function Loss:  -2.0838\n",
            "Total loss:  -1.8592 | PDE Loss:  -3.2539 | Function Loss:  -2.0833\n",
            "Total loss:  -1.8621 | PDE Loss:  -3.2535 | Function Loss:  -2.0884\n",
            "Total loss:  -1.8666 | PDE Loss:  -3.252 | Function Loss:  -2.097\n",
            "Total loss:  -1.8707 | PDE Loss:  -3.2502 | Function Loss:  -2.1053\n",
            "Total loss:  -1.874 | PDE Loss:  -3.2406 | Function Loss:  -2.1182\n",
            "Total loss:  -1.8766 | PDE Loss:  -3.238 | Function Loss:  -2.1246\n",
            "Total loss:  -1.8788 | PDE Loss:  -3.2334 | Function Loss:  -2.1322\n",
            "Total loss:  -1.8821 | PDE Loss:  -3.2307 | Function Loss:  -2.1404\n",
            "Total loss:  -1.8855 | PDE Loss:  -3.2293 | Function Loss:  -2.1476\n",
            "Total loss:  -1.8872 | PDE Loss:  -3.2337 | Function Loss:  -2.1472\n",
            "Total loss:  -1.8887 | PDE Loss:  -3.2382 | Function Loss:  -2.1461\n",
            "Total loss:  -1.8899 | PDE Loss:  -3.2418 | Function Loss:  -2.1454\n",
            "Total loss:  -1.8905 | PDE Loss:  -3.2461 | Function Loss:  -2.143\n",
            "Total loss:  -1.8908 | PDE Loss:  -3.2479 | Function Loss:  -2.1422\n",
            "Total loss:  -1.8911 | PDE Loss:  -3.2481 | Function Loss:  -2.1425\n",
            "Total loss:  -1.8915 | PDE Loss:  -3.2497 | Function Loss:  -2.1421\n",
            "Total loss:  -1.8927 | PDE Loss:  -3.2508 | Function Loss:  -2.1433\n",
            "Total loss:  -1.8944 | PDE Loss:  -3.2517 | Function Loss:  -2.1456\n",
            "Total loss:  -1.8966 | PDE Loss:  -3.252 | Function Loss:  -2.1494\n",
            "Total loss:  -1.8999 | PDE Loss:  -3.2513 | Function Loss:  -2.1557\n",
            "Total loss:  -1.9042 | PDE Loss:  -3.2516 | Function Loss:  -2.1634\n",
            "Total loss:  -1.9097 | PDE Loss:  -3.2499 | Function Loss:  -2.1748\n",
            "Total loss:  -1.9151 | PDE Loss:  -3.2504 | Function Loss:  -2.1844\n",
            "Total loss:  -1.9198 | PDE Loss:  -3.2519 | Function Loss:  -2.1918\n",
            "Total loss:  -1.924 | PDE Loss:  -3.2481 | Function Loss:  -2.2032\n",
            "Total loss:  -1.9285 | PDE Loss:  -3.2472 | Function Loss:  -2.2125\n",
            "Total loss:  -1.9328 | PDE Loss:  -3.2483 | Function Loss:  -2.2198\n",
            "Total loss:  -1.9346 | PDE Loss:  -3.2486 | Function Loss:  -2.2229\n",
            "Total loss:  -1.9353 | PDE Loss:  -3.2486 | Function Loss:  -2.2244\n",
            "Total loss:  -1.9358 | PDE Loss:  -3.2481 | Function Loss:  -2.2259\n",
            "Total loss:  -1.9365 | PDE Loss:  -3.2471 | Function Loss:  -2.2283\n",
            "Total loss:  -1.9372 | PDE Loss:  -3.246 | Function Loss:  -2.2305\n",
            "Total loss:  -1.9376 | PDE Loss:  -3.2455 | Function Loss:  -2.232\n",
            "Total loss:  -1.938 | PDE Loss:  -3.2453 | Function Loss:  -2.2327\n",
            "Total loss:  -1.9383 | PDE Loss:  -3.245 | Function Loss:  -2.2337\n",
            "Total loss:  -1.9386 | PDE Loss:  -3.246 | Function Loss:  -2.2334\n",
            "Total loss:  -1.9391 | PDE Loss:  -3.2474 | Function Loss:  -2.2329\n",
            "Total loss:  -1.9399 | PDE Loss:  -3.2497 | Function Loss:  -2.2323\n",
            "Total loss:  -1.9411 | PDE Loss:  -3.2524 | Function Loss:  -2.2322\n",
            "Total loss:  -1.9433 | PDE Loss:  -3.2566 | Function Loss:  -2.2324\n",
            "Total loss:  -1.9467 | PDE Loss:  -3.2638 | Function Loss:  -2.2323\n",
            "Total loss:  -1.9515 | PDE Loss:  -3.2731 | Function Loss:  -2.2329\n",
            "Total loss:  -1.9578 | PDE Loss:  -3.2862 | Function Loss:  -2.233\n",
            "Total loss:  -1.9627 | PDE Loss:  -3.3011 | Function Loss:  -2.2293\n",
            "Total loss:  -1.9666 | PDE Loss:  -3.3179 | Function Loss:  -2.2225\n",
            "Total loss:  -1.9724 | PDE Loss:  -3.3164 | Function Loss:  -2.2343\n",
            "Total loss:  -1.9816 | PDE Loss:  -3.3184 | Function Loss:  -2.2496\n",
            "Total loss:  -1.9899 | PDE Loss:  -3.327 | Function Loss:  -2.2577\n",
            "Total loss:  -1.9949 | PDE Loss:  -3.3327 | Function Loss:  -2.2621\n",
            "Total loss:  -1.9985 | PDE Loss:  -3.3396 | Function Loss:  -2.263\n",
            "Total loss:  -2.0012 | PDE Loss:  -3.3543 | Function Loss:  -2.2557\n",
            "Total loss:  -2.003 | PDE Loss:  -3.3643 | Function Loss:  -2.2512\n",
            "Total loss:  -2.0039 | PDE Loss:  -3.371 | Function Loss:  -2.2477\n",
            "Total loss:  -2.0051 | PDE Loss:  -3.3751 | Function Loss:  -2.2466\n",
            "Total loss:  -2.0064 | PDE Loss:  -3.3781 | Function Loss:  -2.2467\n",
            "Total loss:  -2.0076 | PDE Loss:  -3.3797 | Function Loss:  -2.2475\n",
            "Total loss:  -2.0086 | PDE Loss:  -3.3782 | Function Loss:  -2.2505\n",
            "Total loss:  -2.0097 | PDE Loss:  -3.377 | Function Loss:  -2.2533\n",
            "Total loss:  -2.0109 | PDE Loss:  -3.3729 | Function Loss:  -2.2584\n",
            "Total loss:  -2.0116 | PDE Loss:  -3.3691 | Function Loss:  -2.2626\n",
            "Total loss:  -2.0121 | PDE Loss:  -3.3672 | Function Loss:  -2.265\n",
            "Total loss:  -2.0124 | PDE Loss:  -3.3652 | Function Loss:  -2.2671\n",
            "Total loss:  -2.0126 | PDE Loss:  -3.3653 | Function Loss:  -2.2674\n",
            "Total loss:  -2.0127 | PDE Loss:  -3.3647 | Function Loss:  -2.2681\n",
            "Total loss:  -2.0129 | PDE Loss:  -3.3652 | Function Loss:  -2.2681\n",
            "Total loss:  -2.0131 | PDE Loss:  -3.3656 | Function Loss:  -2.2682\n",
            "Total loss:  -2.0135 | PDE Loss:  -3.367 | Function Loss:  -2.2676\n",
            "Total loss:  -2.0139 | PDE Loss:  -3.3684 | Function Loss:  -2.2673\n",
            "Total loss:  -2.0144 | PDE Loss:  -3.3711 | Function Loss:  -2.2661\n",
            "Total loss:  -2.0152 | PDE Loss:  -3.3722 | Function Loss:  -2.2667\n",
            "Total loss:  -1.9999 | PDE Loss:  -3.3741 | Function Loss:  -2.2383\n",
            "Total loss:  -2.0159 | PDE Loss:  -3.3743 | Function Loss:  -2.2664\n",
            "Total loss:  -2.0173 | PDE Loss:  -3.379 | Function Loss:  -2.2651\n",
            "Total loss:  -2.0203 | PDE Loss:  -3.3847 | Function Loss:  -2.266\n",
            "Total loss:  -2.0241 | PDE Loss:  -3.3936 | Function Loss:  -2.2661\n",
            "Total loss:  -2.0283 | PDE Loss:  -3.4012 | Function Loss:  -2.2677\n",
            "Total loss:  -2.0324 | PDE Loss:  -3.4106 | Function Loss:  -2.268\n",
            "Total loss:  -2.0362 | PDE Loss:  -3.4158 | Function Loss:  -2.2708\n",
            "Total loss:  -2.0398 | PDE Loss:  -3.4245 | Function Loss:  -2.2708\n",
            "Total loss:  -2.0424 | PDE Loss:  -3.4287 | Function Loss:  -2.2721\n",
            "Total loss:  -2.0469 | PDE Loss:  -3.4339 | Function Loss:  -2.2762\n",
            "Total loss:  -2.05 | PDE Loss:  -3.4413 | Function Loss:  -2.2763\n",
            "Total loss:  -2.0517 | PDE Loss:  -3.4475 | Function Loss:  -2.275\n",
            "Total loss:  -2.0526 | PDE Loss:  -3.4493 | Function Loss:  -2.2753\n",
            "Total loss:  -2.0534 | PDE Loss:  -3.4545 | Function Loss:  -2.2732\n",
            "Total loss:  -2.054 | PDE Loss:  -3.4648 | Function Loss:  -2.2674\n",
            "Total loss:  -2.0543 | PDE Loss:  -3.4694 | Function Loss:  -2.2651\n",
            "Total loss:  -2.0548 | PDE Loss:  -3.4675 | Function Loss:  -2.267\n",
            "Total loss:  -2.0552 | PDE Loss:  -3.4655 | Function Loss:  -2.2689\n",
            "Total loss:  -2.0555 | PDE Loss:  -3.4639 | Function Loss:  -2.2705\n",
            "Total loss:  -2.0558 | PDE Loss:  -3.4628 | Function Loss:  -2.2717\n",
            "Total loss:  -2.0563 | PDE Loss:  -3.4626 | Function Loss:  -2.2726\n",
            "Total loss:  -2.0572 | PDE Loss:  -3.4635 | Function Loss:  -2.2736\n",
            "Total loss:  -2.0587 | PDE Loss:  -3.4661 | Function Loss:  -2.2744\n",
            "Total loss:  -2.0605 | PDE Loss:  -3.4714 | Function Loss:  -2.2739\n",
            "Total loss:  -2.0629 | PDE Loss:  -3.4792 | Function Loss:  -2.273\n",
            "Total loss:  -2.0659 | PDE Loss:  -3.4895 | Function Loss:  -2.2715\n",
            "Total loss:  -2.0703 | PDE Loss:  -3.5068 | Function Loss:  -2.2682\n",
            "Total loss:  -2.0735 | PDE Loss:  -3.5259 | Function Loss:  -2.2626\n",
            "Total loss:  -2.0772 | PDE Loss:  -3.5493 | Function Loss:  -2.2559\n",
            "Total loss:  -2.08 | PDE Loss:  -3.5516 | Function Loss:  -2.2588\n",
            "Total loss:  -2.0847 | PDE Loss:  -3.5574 | Function Loss:  -2.2631\n",
            "Total loss:  -2.0907 | PDE Loss:  -3.5676 | Function Loss:  -2.2668\n",
            "Total loss:  -2.0947 | PDE Loss:  -3.5668 | Function Loss:  -2.2733\n",
            "Total loss:  -2.0976 | PDE Loss:  -3.584 | Function Loss:  -2.2692\n",
            "Total loss:  -2.1004 | PDE Loss:  -3.5886 | Function Loss:  -2.2711\n",
            "Total loss:  -2.1028 | PDE Loss:  -3.5855 | Function Loss:  -2.2761\n",
            "Total loss:  -2.1047 | PDE Loss:  -3.5799 | Function Loss:  -2.2818\n",
            "Total loss:  -2.1059 | PDE Loss:  -3.5804 | Function Loss:  -2.2833\n",
            "Total loss:  -2.1065 | PDE Loss:  -3.5803 | Function Loss:  -2.2842\n",
            "Total loss:  -2.1069 | PDE Loss:  -3.5795 | Function Loss:  -2.2853\n",
            "Total loss:  -2.1075 | PDE Loss:  -3.5779 | Function Loss:  -2.287\n",
            "Total loss:  -2.1082 | PDE Loss:  -3.5761 | Function Loss:  -2.2891\n",
            "Total loss:  -2.109 | PDE Loss:  -3.5735 | Function Loss:  -2.2916\n",
            "Total loss:  -2.1098 | PDE Loss:  -3.5701 | Function Loss:  -2.2946\n",
            "Total loss:  -2.1086 | PDE Loss:  -3.5672 | Function Loss:  -2.2942\n",
            "Total loss:  -2.1103 | PDE Loss:  -3.5696 | Function Loss:  -2.2955\n",
            "Total loss:  -2.1111 | PDE Loss:  -3.5663 | Function Loss:  -2.2986\n",
            "Total loss:  -2.1118 | PDE Loss:  -3.5656 | Function Loss:  -2.3001\n",
            "Total loss:  -2.1126 | PDE Loss:  -3.5625 | Function Loss:  -2.3029\n",
            "Total loss:  -2.1133 | PDE Loss:  -3.563 | Function Loss:  -2.3037\n",
            "Total loss:  -2.1139 | PDE Loss:  -3.5627 | Function Loss:  -2.3049\n",
            "Total loss:  -2.1146 | PDE Loss:  -3.5653 | Function Loss:  -2.3046\n",
            "Total loss:  -2.1155 | PDE Loss:  -3.5667 | Function Loss:  -2.3051\n",
            "Total loss:  -2.1165 | PDE Loss:  -3.5699 | Function Loss:  -2.3049\n",
            "Total loss:  -2.1176 | PDE Loss:  -3.5722 | Function Loss:  -2.3054\n",
            "Total loss:  -2.1188 | PDE Loss:  -3.5743 | Function Loss:  -2.3062\n",
            "Total loss:  -2.12 | PDE Loss:  -3.5751 | Function Loss:  -2.3075\n",
            "Total loss:  -2.1209 | PDE Loss:  -3.5749 | Function Loss:  -2.309\n",
            "Total loss:  -2.1216 | PDE Loss:  -3.5746 | Function Loss:  -2.3103\n",
            "Total loss:  -2.1222 | PDE Loss:  -3.5744 | Function Loss:  -2.3113\n",
            "Total loss:  -2.123 | PDE Loss:  -3.5753 | Function Loss:  -2.3121\n",
            "Total loss:  -2.1245 | PDE Loss:  -3.5777 | Function Loss:  -2.3131\n",
            "Total loss:  -2.1122 | PDE Loss:  -3.5981 | Function Loss:  -2.2839\n",
            "Total loss:  -2.1253 | PDE Loss:  -3.5844 | Function Loss:  -2.3107\n",
            "Total loss:  -2.1278 | PDE Loss:  -3.5886 | Function Loss:  -2.3124\n",
            "Total loss:  -2.1304 | PDE Loss:  -3.5987 | Function Loss:  -2.311\n",
            "Total loss:  -2.1342 | PDE Loss:  -3.615 | Function Loss:  -2.3085\n",
            "Total loss:  -2.1385 | PDE Loss:  -3.6357 | Function Loss:  -2.3048\n",
            "Total loss:  -2.135 | PDE Loss:  -3.6675 | Function Loss:  -2.2859\n",
            "Total loss:  -2.1406 | PDE Loss:  -3.6519 | Function Loss:  -2.3006\n",
            "Total loss:  -2.144 | PDE Loss:  -3.6672 | Function Loss:  -2.2988\n",
            "Total loss:  -2.1483 | PDE Loss:  -3.6872 | Function Loss:  -2.2965\n",
            "Total loss:  -2.1526 | PDE Loss:  -3.7047 | Function Loss:  -2.2955\n",
            "Total loss:  -2.1566 | PDE Loss:  -3.7294 | Function Loss:  -2.2918\n",
            "Total loss:  -2.1585 | PDE Loss:  -3.7355 | Function Loss:  -2.2921\n",
            "Total loss:  -2.1533 | PDE Loss:  -3.7451 | Function Loss:  -2.2818\n",
            "Total loss:  -2.1597 | PDE Loss:  -3.74 | Function Loss:  -2.2921\n",
            "Total loss:  -2.1615 | PDE Loss:  -3.7379 | Function Loss:  -2.2953\n",
            "Total loss:  -2.1649 | PDE Loss:  -3.7345 | Function Loss:  -2.3012\n",
            "Total loss:  -2.1673 | PDE Loss:  -3.7285 | Function Loss:  -2.3068\n",
            "Total loss:  -2.1689 | PDE Loss:  -3.7258 | Function Loss:  -2.31\n",
            "Total loss:  -2.1709 | PDE Loss:  -3.7212 | Function Loss:  -2.3146\n",
            "Total loss:  -2.1726 | PDE Loss:  -3.7242 | Function Loss:  -2.3157\n",
            "Total loss:  -2.1743 | PDE Loss:  -3.7279 | Function Loss:  -2.3166\n",
            "Total loss:  -2.1752 | PDE Loss:  -3.7293 | Function Loss:  -2.3174\n",
            "Total loss:  -2.1759 | PDE Loss:  -3.7331 | Function Loss:  -2.3169\n",
            "Total loss:  -2.1772 | PDE Loss:  -3.7404 | Function Loss:  -2.3159\n",
            "Total loss:  -2.1791 | PDE Loss:  -3.7487 | Function Loss:  -2.3154\n",
            "Total loss:  -2.1809 | PDE Loss:  -3.7541 | Function Loss:  -2.3159\n",
            "Total loss:  -2.1826 | PDE Loss:  -3.7588 | Function Loss:  -2.3165\n",
            "Total loss:  -2.1843 | PDE Loss:  -3.7574 | Function Loss:  -2.3193\n",
            "Total loss:  -2.1857 | PDE Loss:  -3.7532 | Function Loss:  -2.3228\n",
            "Total loss:  -2.1864 | PDE Loss:  -3.7498 | Function Loss:  -2.325\n",
            "Total loss:  -2.1869 | PDE Loss:  -3.7469 | Function Loss:  -2.3269\n",
            "Total loss:  -2.1875 | PDE Loss:  -3.7414 | Function Loss:  -2.3298\n",
            "Total loss:  -2.1881 | PDE Loss:  -3.7418 | Function Loss:  -2.3304\n",
            "Total loss:  -2.189 | PDE Loss:  -3.7409 | Function Loss:  -2.332\n",
            "Total loss:  -2.1904 | PDE Loss:  -3.7417 | Function Loss:  -2.3337\n",
            "Total loss:  -2.192 | PDE Loss:  -3.7434 | Function Loss:  -2.3353\n",
            "Total loss:  -2.194 | PDE Loss:  -3.7441 | Function Loss:  -2.3377\n",
            "Total loss:  -2.1964 | PDE Loss:  -3.7474 | Function Loss:  -2.3398\n",
            "Total loss:  -2.1988 | PDE Loss:  -3.7513 | Function Loss:  -2.3416\n",
            "Total loss:  -2.2011 | PDE Loss:  -3.7552 | Function Loss:  -2.3432\n",
            "Total loss:  -2.2034 | PDE Loss:  -3.7614 | Function Loss:  -2.344\n",
            "Total loss:  -2.2056 | PDE Loss:  -3.7687 | Function Loss:  -2.3443\n",
            "Total loss:  -2.207 | PDE Loss:  -3.7767 | Function Loss:  -2.3433\n",
            "Total loss:  -2.2081 | PDE Loss:  -3.7805 | Function Loss:  -2.3434\n",
            "Total loss:  -2.2088 | PDE Loss:  -3.783 | Function Loss:  -2.3435\n",
            "Total loss:  -2.2095 | PDE Loss:  -3.7845 | Function Loss:  -2.3438\n",
            "Total loss:  -2.2101 | PDE Loss:  -3.7841 | Function Loss:  -2.3448\n",
            "Total loss:  -2.2106 | PDE Loss:  -3.7823 | Function Loss:  -2.3462\n",
            "Total loss:  -2.2111 | PDE Loss:  -3.7816 | Function Loss:  -2.3471\n",
            "Total loss:  -2.212 | PDE Loss:  -3.7795 | Function Loss:  -2.3491\n",
            "Total loss:  -2.2136 | PDE Loss:  -3.7749 | Function Loss:  -2.353\n",
            "Total loss:  -2.2155 | PDE Loss:  -3.7752 | Function Loss:  -2.3555\n",
            "Total loss:  -2.2181 | PDE Loss:  -3.7729 | Function Loss:  -2.3601\n",
            "Total loss:  -2.2211 | PDE Loss:  -3.7761 | Function Loss:  -2.3629\n",
            "Total loss:  -2.2237 | PDE Loss:  -3.7784 | Function Loss:  -2.3657\n",
            "Total loss:  -2.2265 | PDE Loss:  -3.7813 | Function Loss:  -2.3684\n",
            "Total loss:  -2.2287 | PDE Loss:  -3.7819 | Function Loss:  -2.3712\n",
            "Total loss:  -2.2308 | PDE Loss:  -3.7794 | Function Loss:  -2.3751\n",
            "Total loss:  -2.2323 | PDE Loss:  -3.7808 | Function Loss:  -2.3767\n",
            "Total loss:  -2.2337 | PDE Loss:  -3.7803 | Function Loss:  -2.3789\n",
            "Total loss:  -2.2349 | PDE Loss:  -3.7784 | Function Loss:  -2.3813\n",
            "Total loss:  -2.2365 | PDE Loss:  -3.7807 | Function Loss:  -2.3826\n",
            "Total loss:  -2.2379 | PDE Loss:  -3.7788 | Function Loss:  -2.3852\n",
            "Total loss:  -2.239 | PDE Loss:  -3.7788 | Function Loss:  -2.3868\n",
            "Total loss:  -2.2401 | PDE Loss:  -3.7801 | Function Loss:  -2.3878\n",
            "Total loss:  -2.2412 | PDE Loss:  -3.7814 | Function Loss:  -2.3889\n",
            "Total loss:  -2.2425 | PDE Loss:  -3.7826 | Function Loss:  -2.3903\n",
            "Total loss:  -2.244 | PDE Loss:  -3.7853 | Function Loss:  -2.3913\n",
            "Total loss:  -2.2456 | PDE Loss:  -3.7889 | Function Loss:  -2.3921\n",
            "Total loss:  -2.2475 | PDE Loss:  -3.7917 | Function Loss:  -2.3935\n",
            "Total loss:  -2.2491 | PDE Loss:  -3.7982 | Function Loss:  -2.3933\n",
            "Total loss:  -2.2504 | PDE Loss:  -3.8002 | Function Loss:  -2.3943\n",
            "Total loss:  -2.2516 | PDE Loss:  -3.8049 | Function Loss:  -2.3941\n",
            "Total loss:  -2.2529 | PDE Loss:  -3.8068 | Function Loss:  -2.3952\n",
            "Total loss:  -2.2545 | PDE Loss:  -3.8087 | Function Loss:  -2.3966\n",
            "Total loss:  -2.2561 | PDE Loss:  -3.8076 | Function Loss:  -2.3993\n",
            "Total loss:  -2.2581 | PDE Loss:  -3.8081 | Function Loss:  -2.4019\n",
            "Total loss:  -2.2606 | PDE Loss:  -3.8046 | Function Loss:  -2.4068\n",
            "Total loss:  -2.2642 | PDE Loss:  -3.8041 | Function Loss:  -2.4121\n",
            "Total loss:  -2.2688 | PDE Loss:  -3.7984 | Function Loss:  -2.4209\n",
            "Total loss:  -2.2741 | PDE Loss:  -3.7981 | Function Loss:  -2.4285\n",
            "Total loss:  -2.2816 | PDE Loss:  -3.8053 | Function Loss:  -2.4362\n",
            "Total loss:  -2.2904 | PDE Loss:  -3.8173 | Function Loss:  -2.4435\n",
            "Total loss:  -2.298 | PDE Loss:  -3.833 | Function Loss:  -2.4479\n",
            "Total loss:  -2.3039 | PDE Loss:  -3.8418 | Function Loss:  -2.4524\n",
            "Total loss:  -2.3073 | PDE Loss:  -3.8473 | Function Loss:  -2.4551\n",
            "Total loss:  -2.3088 | PDE Loss:  -3.8576 | Function Loss:  -2.453\n",
            "Total loss:  -2.311 | PDE Loss:  -3.8626 | Function Loss:  -2.4541\n",
            "Total loss:  -2.3121 | PDE Loss:  -3.8642 | Function Loss:  -2.4551\n",
            "Total loss:  -2.3139 | PDE Loss:  -3.8679 | Function Loss:  -2.4561\n",
            "Total loss:  -2.3158 | PDE Loss:  -3.8736 | Function Loss:  -2.4566\n",
            "Total loss:  -2.3173 | PDE Loss:  -3.8789 | Function Loss:  -2.4567\n",
            "Total loss:  -2.3187 | PDE Loss:  -3.883 | Function Loss:  -2.457\n",
            "Total loss:  -2.3201 | PDE Loss:  -3.8841 | Function Loss:  -2.4585\n",
            "Total loss:  -2.3212 | PDE Loss:  -3.8874 | Function Loss:  -2.4588\n",
            "Total loss:  -2.3224 | PDE Loss:  -3.8866 | Function Loss:  -2.4607\n",
            "Total loss:  -2.3234 | PDE Loss:  -3.8855 | Function Loss:  -2.4625\n",
            "Total loss:  -2.3242 | PDE Loss:  -3.8831 | Function Loss:  -2.4645\n",
            "Total loss:  -2.3246 | PDE Loss:  -3.8805 | Function Loss:  -2.4661\n",
            "Total loss:  -2.325 | PDE Loss:  -3.879 | Function Loss:  -2.4672\n",
            "Total loss:  -2.3253 | PDE Loss:  -3.8779 | Function Loss:  -2.468\n",
            "Total loss:  -2.3254 | PDE Loss:  -3.8789 | Function Loss:  -2.4679\n",
            "Total loss:  -2.3255 | PDE Loss:  -3.8803 | Function Loss:  -2.4675\n",
            "Total loss:  -2.3256 | PDE Loss:  -3.8813 | Function Loss:  -2.4672\n",
            "Total loss:  -2.3259 | PDE Loss:  -3.8841 | Function Loss:  -2.4664\n",
            "Total loss:  -2.3262 | PDE Loss:  -3.8854 | Function Loss:  -2.4665\n",
            "Total loss:  -2.3269 | PDE Loss:  -3.8926 | Function Loss:  -2.4647\n",
            "Total loss:  -2.3281 | PDE Loss:  -3.8912 | Function Loss:  -2.4669\n",
            "Total loss:  -2.3297 | PDE Loss:  -3.8979 | Function Loss:  -2.4665\n",
            "Total loss:  -2.3319 | PDE Loss:  -3.9037 | Function Loss:  -2.4674\n",
            "Total loss:  -2.3358 | PDE Loss:  -3.9134 | Function Loss:  -2.4692\n",
            "Total loss:  -2.3406 | PDE Loss:  -3.9159 | Function Loss:  -2.4748\n",
            "Total loss:  -2.348 | PDE Loss:  -3.9187 | Function Loss:  -2.4839\n",
            "Total loss:  -2.3547 | PDE Loss:  -3.9194 | Function Loss:  -2.4929\n",
            "Total loss:  -2.3595 | PDE Loss:  -3.9263 | Function Loss:  -2.4968\n",
            "Total loss:  -2.3606 | PDE Loss:  -3.9279 | Function Loss:  -2.4978\n",
            "Total loss:  -2.3632 | PDE Loss:  -3.9277 | Function Loss:  -2.5014\n",
            "Total loss:  -2.3652 | PDE Loss:  -3.9256 | Function Loss:  -2.5049\n",
            "Total loss:  -2.3671 | PDE Loss:  -3.9225 | Function Loss:  -2.5088\n",
            "Total loss:  -2.3692 | PDE Loss:  -3.9267 | Function Loss:  -2.5101\n",
            "Total loss:  -2.3704 | PDE Loss:  -3.9298 | Function Loss:  -2.5105\n",
            "Total loss:  -2.3714 | PDE Loss:  -3.9329 | Function Loss:  -2.5107\n",
            "Total loss:  -2.3722 | PDE Loss:  -3.9345 | Function Loss:  -2.5113\n",
            "Total loss:  -2.373 | PDE Loss:  -3.9316 | Function Loss:  -2.5134\n",
            "Total loss:  -2.3736 | PDE Loss:  -3.9337 | Function Loss:  -2.5135\n",
            "Total loss:  -2.3742 | PDE Loss:  -3.9322 | Function Loss:  -2.5149\n",
            "Total loss:  -2.375 | PDE Loss:  -3.9311 | Function Loss:  -2.5164\n",
            "Total loss:  -2.3762 | PDE Loss:  -3.9257 | Function Loss:  -2.5202\n",
            "Total loss:  -2.3775 | PDE Loss:  -3.9242 | Function Loss:  -2.5226\n",
            "Total loss:  -2.3791 | PDE Loss:  -3.9243 | Function Loss:  -2.5248\n",
            "Total loss:  -2.3806 | PDE Loss:  -3.9258 | Function Loss:  -2.5263\n",
            "Total loss:  -2.3821 | PDE Loss:  -3.9293 | Function Loss:  -2.527\n",
            "Total loss:  -2.3833 | PDE Loss:  -3.9332 | Function Loss:  -2.5271\n",
            "Total loss:  -2.385 | PDE Loss:  -3.9404 | Function Loss:  -2.5267\n",
            "Total loss:  -2.3863 | PDE Loss:  -3.9486 | Function Loss:  -2.5253\n",
            "Total loss:  -2.3872 | PDE Loss:  -3.956 | Function Loss:  -2.5238\n",
            "Total loss:  -2.3878 | PDE Loss:  -3.9597 | Function Loss:  -2.5232\n",
            "Total loss:  -2.3885 | PDE Loss:  -3.9648 | Function Loss:  -2.5224\n",
            "Total loss:  -2.3892 | PDE Loss:  -3.9695 | Function Loss:  -2.5216\n",
            "Total loss:  -2.3898 | PDE Loss:  -3.9709 | Function Loss:  -2.5219\n",
            "Total loss:  -2.3903 | PDE Loss:  -3.9735 | Function Loss:  -2.5217\n",
            "Total loss:  -2.3908 | PDE Loss:  -3.974 | Function Loss:  -2.5222\n",
            "Total loss:  -2.3913 | PDE Loss:  -3.9749 | Function Loss:  -2.5225\n",
            "Total loss:  -2.3919 | PDE Loss:  -3.9753 | Function Loss:  -2.5232\n",
            "Total loss:  -2.3926 | PDE Loss:  -3.9756 | Function Loss:  -2.5242\n",
            "Total loss:  -2.3937 | PDE Loss:  -3.9761 | Function Loss:  -2.5253\n",
            "Total loss:  -2.395 | PDE Loss:  -3.9774 | Function Loss:  -2.5266\n",
            "Total loss:  -2.3963 | PDE Loss:  -3.9785 | Function Loss:  -2.528\n",
            "Total loss:  -2.3976 | PDE Loss:  -3.9783 | Function Loss:  -2.53\n",
            "Total loss:  -2.3985 | PDE Loss:  -3.9804 | Function Loss:  -2.5304\n",
            "Total loss:  -2.3995 | PDE Loss:  -3.978 | Function Loss:  -2.5326\n",
            "Total loss:  -2.4001 | PDE Loss:  -3.9768 | Function Loss:  -2.5339\n",
            "Total loss:  -2.4008 | PDE Loss:  -3.9743 | Function Loss:  -2.5357\n",
            "Total loss:  -2.4018 | PDE Loss:  -3.9686 | Function Loss:  -2.5392\n",
            "Total loss:  -2.4029 | PDE Loss:  -3.964 | Function Loss:  -2.5424\n",
            "Total loss:  -2.404 | PDE Loss:  -3.9596 | Function Loss:  -2.5457\n",
            "Total loss:  -2.4057 | PDE Loss:  -3.9538 | Function Loss:  -2.5503\n",
            "Total loss:  -2.4076 | PDE Loss:  -3.9479 | Function Loss:  -2.5553\n",
            "Total loss:  -2.4094 | PDE Loss:  -3.9463 | Function Loss:  -2.5584\n",
            "Total loss:  -2.4114 | PDE Loss:  -3.9609 | Function Loss:  -2.5554\n",
            "Total loss:  -2.4131 | PDE Loss:  -3.9582 | Function Loss:  -2.5588\n",
            "Total loss:  -2.4147 | PDE Loss:  -3.9559 | Function Loss:  -2.562\n",
            "Total loss:  -2.4162 | PDE Loss:  -3.9549 | Function Loss:  -2.5646\n",
            "Total loss:  -2.4176 | PDE Loss:  -3.9555 | Function Loss:  -2.5662\n",
            "Total loss:  -2.4186 | PDE Loss:  -3.9554 | Function Loss:  -2.5677\n",
            "Total loss:  -2.4192 | PDE Loss:  -3.9542 | Function Loss:  -2.5691\n",
            "Total loss:  -2.4198 | PDE Loss:  -3.9543 | Function Loss:  -2.5698\n",
            "Total loss:  -2.4201 | PDE Loss:  -3.9571 | Function Loss:  -2.569\n",
            "Total loss:  -2.4204 | PDE Loss:  -3.9535 | Function Loss:  -2.5709\n",
            "Total loss:  -2.4206 | PDE Loss:  -3.9501 | Function Loss:  -2.5726\n",
            "Total loss:  -2.4207 | PDE Loss:  -3.9485 | Function Loss:  -2.5736\n",
            "Total loss:  -2.4209 | PDE Loss:  -3.9421 | Function Loss:  -2.5764\n",
            "Total loss:  -2.421 | PDE Loss:  -3.9441 | Function Loss:  -2.5758\n",
            "Total loss:  -2.4212 | PDE Loss:  -3.9438 | Function Loss:  -2.5762\n",
            "Total loss:  -2.4217 | PDE Loss:  -3.9432 | Function Loss:  -2.5772\n",
            "Total loss:  -2.4224 | PDE Loss:  -3.9424 | Function Loss:  -2.5785\n",
            "Total loss:  -2.4231 | PDE Loss:  -3.9429 | Function Loss:  -2.5794\n",
            "Total loss:  -2.4241 | PDE Loss:  -3.9421 | Function Loss:  -2.5811\n",
            "Total loss:  -2.4254 | PDE Loss:  -3.9441 | Function Loss:  -2.5822\n",
            "Total loss:  -2.4276 | PDE Loss:  -3.949 | Function Loss:  -2.5832\n",
            "Total loss:  -2.4309 | PDE Loss:  -3.9529 | Function Loss:  -2.5862\n",
            "Total loss:  -2.4317 | PDE Loss:  -3.9655 | Function Loss:  -2.582\n",
            "Total loss:  -2.4332 | PDE Loss:  -3.9608 | Function Loss:  -2.586\n",
            "Total loss:  -2.4366 | PDE Loss:  -3.9778 | Function Loss:  -2.5839\n",
            "Total loss:  -2.442 | PDE Loss:  -3.9834 | Function Loss:  -2.5892\n",
            "Total loss:  -2.4458 | PDE Loss:  -3.9836 | Function Loss:  -2.5945\n",
            "Total loss:  -2.4498 | PDE Loss:  -3.9819 | Function Loss:  -2.6008\n",
            "Total loss:  -2.4513 | PDE Loss:  -3.9827 | Function Loss:  -2.6026\n",
            "Total loss:  -2.4528 | PDE Loss:  -3.9802 | Function Loss:  -2.6057\n",
            "Total loss:  -2.4539 | PDE Loss:  -3.9775 | Function Loss:  -2.6086\n",
            "Total loss:  -2.4556 | PDE Loss:  -3.9715 | Function Loss:  -2.6136\n",
            "Total loss:  -2.4576 | PDE Loss:  -3.9655 | Function Loss:  -2.6191\n",
            "Total loss:  -2.459 | PDE Loss:  -3.9608 | Function Loss:  -2.6233\n",
            "Total loss:  -2.4602 | PDE Loss:  -3.9594 | Function Loss:  -2.6256\n",
            "Total loss:  -2.4612 | PDE Loss:  -3.9573 | Function Loss:  -2.6281\n",
            "Total loss:  -2.462 | PDE Loss:  -3.9574 | Function Loss:  -2.6292\n",
            "Total loss:  -2.4626 | PDE Loss:  -3.9576 | Function Loss:  -2.6301\n",
            "Total loss:  -2.463 | PDE Loss:  -3.9583 | Function Loss:  -2.6303\n",
            "Total loss:  -2.4633 | PDE Loss:  -3.9591 | Function Loss:  -2.6303\n",
            "Total loss:  -2.4635 | PDE Loss:  -3.9597 | Function Loss:  -2.6304\n",
            "Total loss:  -2.4599 | PDE Loss:  -3.9444 | Function Loss:  -2.6323\n",
            "Total loss:  -2.4636 | PDE Loss:  -3.958 | Function Loss:  -2.6313\n",
            "Total loss:  -2.4641 | PDE Loss:  -3.9592 | Function Loss:  -2.6314\n",
            "Total loss:  -2.4647 | PDE Loss:  -3.9617 | Function Loss:  -2.6311\n",
            "Total loss:  -2.4654 | PDE Loss:  -3.9646 | Function Loss:  -2.6309\n",
            "Total loss:  -2.4662 | PDE Loss:  -3.9677 | Function Loss:  -2.6307\n",
            "Total loss:  -2.4672 | PDE Loss:  -3.9697 | Function Loss:  -2.6311\n",
            "Total loss:  -2.468 | PDE Loss:  -3.9715 | Function Loss:  -2.6314\n",
            "Total loss:  -2.4688 | PDE Loss:  -3.9706 | Function Loss:  -2.633\n",
            "Total loss:  -2.4699 | PDE Loss:  -3.9701 | Function Loss:  -2.6349\n",
            "Total loss:  -2.4711 | PDE Loss:  -3.9671 | Function Loss:  -2.638\n",
            "Total loss:  -2.4722 | PDE Loss:  -3.9667 | Function Loss:  -2.6398\n",
            "Total loss:  -2.4733 | PDE Loss:  -3.9671 | Function Loss:  -2.6413\n",
            "Total loss:  -2.4747 | PDE Loss:  -3.9694 | Function Loss:  -2.6422\n",
            "Total loss:  -2.4763 | PDE Loss:  -3.974 | Function Loss:  -2.6424\n",
            "Total loss:  -2.4776 | PDE Loss:  -3.9786 | Function Loss:  -2.6421\n",
            "Total loss:  -2.4793 | PDE Loss:  -3.9859 | Function Loss:  -2.6413\n",
            "Total loss:  -2.4811 | PDE Loss:  -3.9961 | Function Loss:  -2.6395\n",
            "Total loss:  -2.4833 | PDE Loss:  -4.0023 | Function Loss:  -2.6399\n",
            "Total loss:  -2.4848 | PDE Loss:  -4.0112 | Function Loss:  -2.6382\n",
            "Total loss:  -2.4863 | PDE Loss:  -4.0185 | Function Loss:  -2.6373\n",
            "Total loss:  -2.4878 | PDE Loss:  -4.0221 | Function Loss:  -2.6379\n",
            "Total loss:  -2.4893 | PDE Loss:  -4.0241 | Function Loss:  -2.6392\n",
            "Total loss:  -2.4924 | PDE Loss:  -4.0244 | Function Loss:  -2.6435\n",
            "Total loss:  -2.4952 | PDE Loss:  -4.0244 | Function Loss:  -2.6474\n",
            "Total loss:  -2.4975 | PDE Loss:  -4.0246 | Function Loss:  -2.6507\n",
            "Total loss:  -2.4992 | PDE Loss:  -4.0237 | Function Loss:  -2.6535\n",
            "Total loss:  -2.5002 | PDE Loss:  -4.0166 | Function Loss:  -2.6579\n",
            "Total loss:  -2.5013 | PDE Loss:  -4.0165 | Function Loss:  -2.6595\n",
            "Total loss:  -2.502 | PDE Loss:  -4.0169 | Function Loss:  -2.6603\n",
            "Total loss:  -2.5027 | PDE Loss:  -4.0184 | Function Loss:  -2.6608\n",
            "Total loss:  -2.5035 | PDE Loss:  -4.0224 | Function Loss:  -2.6601\n",
            "Total loss:  -2.5042 | PDE Loss:  -4.0266 | Function Loss:  -2.6593\n",
            "Total loss:  -2.505 | PDE Loss:  -4.0313 | Function Loss:  -2.6584\n",
            "Total loss:  -2.5058 | PDE Loss:  -4.0358 | Function Loss:  -2.6577\n",
            "Total loss:  -2.507 | PDE Loss:  -4.0419 | Function Loss:  -2.6568\n",
            "Total loss:  -2.5024 | PDE Loss:  -4.0433 | Function Loss:  -2.6498\n",
            "Total loss:  -2.5074 | PDE Loss:  -4.0435 | Function Loss:  -2.6567\n",
            "Total loss:  -2.509 | PDE Loss:  -4.0509 | Function Loss:  -2.656\n",
            "Total loss:  -2.5106 | PDE Loss:  -4.0557 | Function Loss:  -2.6563\n",
            "Total loss:  -2.5122 | PDE Loss:  -4.063 | Function Loss:  -2.6556\n",
            "Total loss:  -2.5138 | PDE Loss:  -4.063 | Function Loss:  -2.6578\n",
            "Total loss:  -2.5147 | PDE Loss:  -4.061 | Function Loss:  -2.66\n",
            "Total loss:  -2.5159 | PDE Loss:  -4.0584 | Function Loss:  -2.6627\n",
            "Total loss:  -2.517 | PDE Loss:  -4.0538 | Function Loss:  -2.6661\n",
            "Total loss:  -2.5179 | PDE Loss:  -4.0471 | Function Loss:  -2.6702\n",
            "Total loss:  -2.5188 | PDE Loss:  -4.042 | Function Loss:  -2.6736\n",
            "Total loss:  -2.5196 | PDE Loss:  -4.0404 | Function Loss:  -2.6753\n",
            "Total loss:  -2.5208 | PDE Loss:  -4.0391 | Function Loss:  -2.6777\n",
            "Total loss:  -2.522 | PDE Loss:  -4.0385 | Function Loss:  -2.6797\n",
            "Total loss:  -2.5231 | PDE Loss:  -4.0366 | Function Loss:  -2.6821\n",
            "Total loss:  -2.5241 | PDE Loss:  -4.0351 | Function Loss:  -2.6841\n",
            "Total loss:  -2.5251 | PDE Loss:  -4.0337 | Function Loss:  -2.6863\n",
            "Total loss:  -2.5263 | PDE Loss:  -4.0337 | Function Loss:  -2.688\n",
            "Total loss:  -2.5274 | PDE Loss:  -4.033 | Function Loss:  -2.6899\n",
            "Total loss:  -2.5283 | PDE Loss:  -4.0348 | Function Loss:  -2.6904\n",
            "Total loss:  -2.529 | PDE Loss:  -4.0342 | Function Loss:  -2.6917\n",
            "Total loss:  -2.5296 | PDE Loss:  -4.0346 | Function Loss:  -2.6923\n",
            "Total loss:  -2.5302 | PDE Loss:  -4.0344 | Function Loss:  -2.6933\n",
            "Total loss:  -2.5307 | PDE Loss:  -4.0363 | Function Loss:  -2.6932\n",
            "Total loss:  -2.5311 | PDE Loss:  -4.036 | Function Loss:  -2.694\n",
            "Total loss:  -2.5313 | PDE Loss:  -4.0366 | Function Loss:  -2.694\n",
            "Total loss:  -2.5318 | PDE Loss:  -4.0368 | Function Loss:  -2.6946\n",
            "Total loss:  -2.5321 | PDE Loss:  -4.0375 | Function Loss:  -2.6948\n",
            "Total loss:  -2.5325 | PDE Loss:  -4.0381 | Function Loss:  -2.695\n",
            "Total loss:  -2.5328 | PDE Loss:  -4.039 | Function Loss:  -2.6951\n",
            "Total loss:  -2.5332 | PDE Loss:  -4.0392 | Function Loss:  -2.6956\n",
            "Total loss:  -2.5338 | PDE Loss:  -4.0392 | Function Loss:  -2.6964\n",
            "Total loss:  -2.5343 | PDE Loss:  -4.0383 | Function Loss:  -2.6976\n",
            "Total loss:  -2.5349 | PDE Loss:  -4.0366 | Function Loss:  -2.6993\n",
            "Total loss:  -2.5356 | PDE Loss:  -4.0355 | Function Loss:  -2.7007\n",
            "Total loss:  -2.5365 | PDE Loss:  -4.0335 | Function Loss:  -2.703\n",
            "Total loss:  -2.5379 | PDE Loss:  -4.0339 | Function Loss:  -2.7049\n",
            "Total loss:  -2.5106 | PDE Loss:  -3.9905 | Function Loss:  -2.6854\n",
            "Total loss:  -2.5387 | PDE Loss:  -4.0317 | Function Loss:  -2.7071\n",
            "Total loss:  -2.5401 | PDE Loss:  -4.0325 | Function Loss:  -2.7087\n",
            "Total loss:  -2.542 | PDE Loss:  -4.034 | Function Loss:  -2.7108\n",
            "Total loss:  -2.5434 | PDE Loss:  -4.0369 | Function Loss:  -2.7115\n",
            "Total loss:  -2.5445 | PDE Loss:  -4.0379 | Function Loss:  -2.7126\n",
            "Total loss:  -2.5468 | PDE Loss:  -4.0414 | Function Loss:  -2.7144\n",
            "Total loss:  -2.5485 | PDE Loss:  -4.0463 | Function Loss:  -2.7146\n",
            "Total loss:  -2.5501 | PDE Loss:  -4.0497 | Function Loss:  -2.7153\n",
            "Total loss:  -2.5516 | PDE Loss:  -4.0533 | Function Loss:  -2.7158\n",
            "Total loss:  -2.5524 | PDE Loss:  -4.0615 | Function Loss:  -2.7133\n",
            "Total loss:  -2.5534 | PDE Loss:  -4.0629 | Function Loss:  -2.7142\n",
            "Total loss:  -2.5543 | PDE Loss:  -4.0568 | Function Loss:  -2.7182\n",
            "Total loss:  -2.5546 | PDE Loss:  -4.0582 | Function Loss:  -2.718\n",
            "Total loss:  -2.5552 | PDE Loss:  -4.0577 | Function Loss:  -2.7192\n",
            "Total loss:  -2.5556 | PDE Loss:  -4.0577 | Function Loss:  -2.7197\n",
            "Total loss:  -2.5559 | PDE Loss:  -4.0573 | Function Loss:  -2.7204\n",
            "Total loss:  -2.5562 | PDE Loss:  -4.0581 | Function Loss:  -2.7205\n",
            "Total loss:  -2.5565 | PDE Loss:  -4.0583 | Function Loss:  -2.7208\n",
            "Total loss:  -2.5568 | PDE Loss:  -4.0597 | Function Loss:  -2.7205\n",
            "Total loss:  -2.5571 | PDE Loss:  -4.0613 | Function Loss:  -2.7203\n",
            "Total loss:  -2.5574 | PDE Loss:  -4.0632 | Function Loss:  -2.7199\n",
            "Total loss:  -2.5577 | PDE Loss:  -4.0655 | Function Loss:  -2.7193\n",
            "Total loss:  -2.558 | PDE Loss:  -4.0678 | Function Loss:  -2.7187\n",
            "Total loss:  -2.5583 | PDE Loss:  -4.0683 | Function Loss:  -2.7188\n",
            "Total loss:  -2.5585 | PDE Loss:  -4.0704 | Function Loss:  -2.7182\n",
            "Total loss:  -2.5588 | PDE Loss:  -4.0717 | Function Loss:  -2.718\n",
            "Total loss:  -2.559 | PDE Loss:  -4.0724 | Function Loss:  -2.718\n",
            "Total loss:  -2.5591 | PDE Loss:  -4.0723 | Function Loss:  -2.7183\n",
            "Total loss:  -2.5593 | PDE Loss:  -4.072 | Function Loss:  -2.7186\n",
            "Total loss:  -2.5591 | PDE Loss:  -4.0698 | Function Loss:  -2.7193\n",
            "Total loss:  -2.5593 | PDE Loss:  -4.0714 | Function Loss:  -2.7189\n",
            "Total loss:  -2.5595 | PDE Loss:  -4.071 | Function Loss:  -2.7194\n",
            "Total loss:  -2.5596 | PDE Loss:  -4.0701 | Function Loss:  -2.7199\n",
            "Total loss:  -2.5599 | PDE Loss:  -4.0706 | Function Loss:  -2.7201\n",
            "Total loss:  -2.56 | PDE Loss:  -4.0706 | Function Loss:  -2.7203\n",
            "Total loss:  -2.5606 | PDE Loss:  -4.0721 | Function Loss:  -2.7205\n",
            "Total loss:  -2.561 | PDE Loss:  -4.0737 | Function Loss:  -2.7204\n",
            "Total loss:  -2.5614 | PDE Loss:  -4.0706 | Function Loss:  -2.7223\n",
            "Total loss:  -2.5618 | PDE Loss:  -4.0751 | Function Loss:  -2.7209\n",
            "Total loss:  -2.5608 | PDE Loss:  -4.0541 | Function Loss:  -2.729\n",
            "Total loss:  -2.562 | PDE Loss:  -4.0694 | Function Loss:  -2.7237\n",
            "Total loss:  -2.5625 | PDE Loss:  -4.0701 | Function Loss:  -2.7241\n",
            "Total loss:  -2.5635 | PDE Loss:  -4.0728 | Function Loss:  -2.7243\n",
            "Total loss:  -2.5642 | PDE Loss:  -4.0746 | Function Loss:  -2.7246\n",
            "Total loss:  -2.5647 | PDE Loss:  -4.0761 | Function Loss:  -2.7246\n",
            "Total loss:  -2.565 | PDE Loss:  -4.0776 | Function Loss:  -2.7244\n",
            "Total loss:  -2.5654 | PDE Loss:  -4.0792 | Function Loss:  -2.7242\n",
            "Total loss:  -2.5657 | PDE Loss:  -4.0765 | Function Loss:  -2.7258\n",
            "Total loss:  -2.5661 | PDE Loss:  -4.081 | Function Loss:  -2.7245\n",
            "Total loss:  -2.5664 | PDE Loss:  -4.0811 | Function Loss:  -2.7248\n",
            "Total loss:  -2.567 | PDE Loss:  -4.0819 | Function Loss:  -2.7253\n",
            "Total loss:  -2.5676 | PDE Loss:  -4.0825 | Function Loss:  -2.726\n",
            "Total loss:  -2.5683 | PDE Loss:  -4.0843 | Function Loss:  -2.7263\n",
            "Total loss:  -2.5691 | PDE Loss:  -4.0865 | Function Loss:  -2.7264\n",
            "Total loss:  -2.5698 | PDE Loss:  -4.0897 | Function Loss:  -2.726\n",
            "Total loss:  -2.5706 | PDE Loss:  -4.0925 | Function Loss:  -2.7259\n",
            "Total loss:  -2.5714 | PDE Loss:  -4.0949 | Function Loss:  -2.7261\n",
            "Total loss:  -2.5726 | PDE Loss:  -4.0971 | Function Loss:  -2.7269\n",
            "Total loss:  -2.5738 | PDE Loss:  -4.0983 | Function Loss:  -2.728\n",
            "Total loss:  -2.5754 | PDE Loss:  -4.0991 | Function Loss:  -2.73\n",
            "Total loss:  -2.5765 | PDE Loss:  -4.0998 | Function Loss:  -2.7312\n",
            "Total loss:  -2.578 | PDE Loss:  -4.101 | Function Loss:  -2.7329\n",
            "Total loss:  -2.5798 | PDE Loss:  -4.103 | Function Loss:  -2.7345\n",
            "Total loss:  -2.5816 | PDE Loss:  -4.1066 | Function Loss:  -2.7356\n",
            "Total loss:  -2.5834 | PDE Loss:  -4.1105 | Function Loss:  -2.7365\n",
            "Total loss:  -2.5839 | PDE Loss:  -4.1142 | Function Loss:  -2.7356\n",
            "Total loss:  -2.5843 | PDE Loss:  -4.1131 | Function Loss:  -2.7367\n",
            "Total loss:  -2.5852 | PDE Loss:  -4.1164 | Function Loss:  -2.7366\n",
            "Total loss:  -2.5862 | PDE Loss:  -4.1179 | Function Loss:  -2.7373\n",
            "Total loss:  -2.5869 | PDE Loss:  -4.1181 | Function Loss:  -2.7383\n",
            "Total loss:  -2.5875 | PDE Loss:  -4.1174 | Function Loss:  -2.7395\n",
            "Total loss:  -2.588 | PDE Loss:  -4.1165 | Function Loss:  -2.7405\n",
            "Total loss:  -2.5788 | PDE Loss:  -4.0782 | Function Loss:  -2.7441\n",
            "Total loss:  -2.588 | PDE Loss:  -4.1146 | Function Loss:  -2.7413\n",
            "Total loss:  -2.5884 | PDE Loss:  -4.114 | Function Loss:  -2.7421\n",
            "Total loss:  -2.5887 | PDE Loss:  -4.1137 | Function Loss:  -2.7427\n",
            "Total loss:  -2.589 | PDE Loss:  -4.1129 | Function Loss:  -2.7434\n",
            "Total loss:  -2.5892 | PDE Loss:  -4.1131 | Function Loss:  -2.7436\n",
            "Total loss:  -2.5894 | PDE Loss:  -4.1136 | Function Loss:  -2.7437\n",
            "Total loss:  -2.5895 | PDE Loss:  -4.1136 | Function Loss:  -2.7439\n",
            "Total loss:  -2.5897 | PDE Loss:  -4.1148 | Function Loss:  -2.7436\n",
            "Total loss:  -2.5898 | PDE Loss:  -4.1156 | Function Loss:  -2.7435\n",
            "Total loss:  -2.59 | PDE Loss:  -4.117 | Function Loss:  -2.7432\n",
            "Total loss:  -2.5903 | PDE Loss:  -4.1179 | Function Loss:  -2.7432\n",
            "Total loss:  -2.5906 | PDE Loss:  -4.1192 | Function Loss:  -2.743\n",
            "Total loss:  -2.5911 | PDE Loss:  -4.121 | Function Loss:  -2.743\n",
            "Total loss:  -2.5917 | PDE Loss:  -4.1244 | Function Loss:  -2.7425\n",
            "Total loss:  -2.5924 | PDE Loss:  -4.1258 | Function Loss:  -2.7429\n",
            "Total loss:  -2.5931 | PDE Loss:  -4.1306 | Function Loss:  -2.7419\n",
            "Total loss:  -2.5935 | PDE Loss:  -4.1346 | Function Loss:  -2.7408\n",
            "Total loss:  -2.5948 | PDE Loss:  -4.1392 | Function Loss:  -2.7408\n",
            "Total loss:  -2.5952 | PDE Loss:  -4.1404 | Function Loss:  -2.7409\n",
            "Total loss:  -2.5961 | PDE Loss:  -4.14 | Function Loss:  -2.7423\n",
            "Total loss:  -2.5968 | PDE Loss:  -4.1382 | Function Loss:  -2.7439\n",
            "Total loss:  -2.5972 | PDE Loss:  -4.1372 | Function Loss:  -2.745\n",
            "Total loss:  -2.5974 | PDE Loss:  -4.1365 | Function Loss:  -2.7456\n",
            "Total loss:  -2.5976 | PDE Loss:  -4.1362 | Function Loss:  -2.7459\n",
            "Total loss:  -2.5978 | PDE Loss:  -4.1361 | Function Loss:  -2.7463\n",
            "Total loss:  -2.598 | PDE Loss:  -4.1367 | Function Loss:  -2.7464\n",
            "Total loss:  -2.5982 | PDE Loss:  -4.1371 | Function Loss:  -2.7465\n",
            "Total loss:  -2.5984 | PDE Loss:  -4.1357 | Function Loss:  -2.7473\n",
            "Total loss:  -2.5985 | PDE Loss:  -4.1381 | Function Loss:  -2.7465\n",
            "Total loss:  -2.5988 | PDE Loss:  -4.1339 | Function Loss:  -2.7486\n",
            "Total loss:  -2.5991 | PDE Loss:  -4.1338 | Function Loss:  -2.749\n",
            "Total loss:  -2.5996 | PDE Loss:  -4.1352 | Function Loss:  -2.7492\n",
            "Total loss:  -2.6001 | PDE Loss:  -4.1347 | Function Loss:  -2.7501\n",
            "Total loss:  -2.6007 | PDE Loss:  -4.1359 | Function Loss:  -2.7504\n",
            "Total loss:  -2.6013 | PDE Loss:  -4.1403 | Function Loss:  -2.7495\n",
            "Total loss:  -2.6021 | PDE Loss:  -4.1413 | Function Loss:  -2.7502\n",
            "Total loss:  -2.6034 | PDE Loss:  -4.1429 | Function Loss:  -2.7513\n",
            "Total loss:  -2.5735 | PDE Loss:  -4.1867 | Function Loss:  -2.6948\n",
            "Total loss:  -2.6036 | PDE Loss:  -4.1483 | Function Loss:  -2.7496\n",
            "Total loss:  -2.6055 | PDE Loss:  -4.1504 | Function Loss:  -2.7513\n",
            "Total loss:  -2.6075 | PDE Loss:  -4.1524 | Function Loss:  -2.7533\n",
            "Total loss:  -2.605 | PDE Loss:  -4.1547 | Function Loss:  -2.7489\n",
            "Total loss:  -2.6082 | PDE Loss:  -4.1538 | Function Loss:  -2.7538\n",
            "Total loss:  -2.6101 | PDE Loss:  -4.1542 | Function Loss:  -2.7563\n",
            "Total loss:  -2.6125 | PDE Loss:  -4.1532 | Function Loss:  -2.76\n",
            "Total loss:  -2.6159 | PDE Loss:  -4.1524 | Function Loss:  -2.7651\n",
            "Total loss:  -2.6186 | PDE Loss:  -4.1514 | Function Loss:  -2.7693\n",
            "Total loss:  -2.622 | PDE Loss:  -4.1545 | Function Loss:  -2.7728\n",
            "Total loss:  -2.6246 | PDE Loss:  -4.1541 | Function Loss:  -2.7767\n",
            "Total loss:  -2.6267 | PDE Loss:  -4.1568 | Function Loss:  -2.7785\n",
            "Total loss:  -2.6286 | PDE Loss:  -4.1605 | Function Loss:  -2.7796\n",
            "Total loss:  -2.6302 | PDE Loss:  -4.1693 | Function Loss:  -2.7784\n",
            "Total loss:  -2.6317 | PDE Loss:  -4.1723 | Function Loss:  -2.7792\n",
            "Total loss:  -2.633 | PDE Loss:  -4.1772 | Function Loss:  -2.7791\n",
            "Total loss:  -2.6346 | PDE Loss:  -4.1872 | Function Loss:  -2.7774\n",
            "Total loss:  -2.6356 | PDE Loss:  -4.1899 | Function Loss:  -2.7778\n",
            "Total loss:  -2.6363 | PDE Loss:  -4.1938 | Function Loss:  -2.7772\n",
            "Total loss:  -2.6372 | PDE Loss:  -4.1944 | Function Loss:  -2.7782\n",
            "Total loss:  -2.6379 | PDE Loss:  -4.1919 | Function Loss:  -2.7801\n",
            "Total loss:  -2.6388 | PDE Loss:  -4.1941 | Function Loss:  -2.7805\n",
            "Total loss:  -2.6396 | PDE Loss:  -4.1916 | Function Loss:  -2.7826\n",
            "Total loss:  -2.6402 | PDE Loss:  -4.1883 | Function Loss:  -2.7847\n",
            "Total loss:  -2.6407 | PDE Loss:  -4.1896 | Function Loss:  -2.7849\n",
            "Total loss:  -2.6412 | PDE Loss:  -4.1903 | Function Loss:  -2.7854\n",
            "Total loss:  -2.6417 | PDE Loss:  -4.1931 | Function Loss:  -2.7849\n",
            "Total loss:  -2.642 | PDE Loss:  -4.1943 | Function Loss:  -2.7848\n",
            "Total loss:  -2.6422 | PDE Loss:  -4.1877 | Function Loss:  -2.7878\n",
            "Total loss:  -2.6425 | PDE Loss:  -4.1893 | Function Loss:  -2.7875\n",
            "Total loss:  -2.6427 | PDE Loss:  -4.1902 | Function Loss:  -2.7874\n",
            "Total loss:  -2.6429 | PDE Loss:  -4.1917 | Function Loss:  -2.7871\n",
            "Total loss:  -2.6431 | PDE Loss:  -4.1928 | Function Loss:  -2.7869\n",
            "Total loss:  -2.6432 | PDE Loss:  -4.1939 | Function Loss:  -2.7867\n",
            "Total loss:  -2.6433 | PDE Loss:  -4.1949 | Function Loss:  -2.7865\n",
            "Total loss:  -2.6434 | PDE Loss:  -4.196 | Function Loss:  -2.7862\n",
            "Total loss:  -2.6436 | PDE Loss:  -4.1975 | Function Loss:  -2.7859\n",
            "Total loss:  -2.644 | PDE Loss:  -4.1982 | Function Loss:  -2.7861\n",
            "Total loss:  -2.6444 | PDE Loss:  -4.2018 | Function Loss:  -2.7853\n",
            "Total loss:  -2.6449 | PDE Loss:  -4.2007 | Function Loss:  -2.7864\n",
            "Total loss:  -2.6455 | PDE Loss:  -4.2114 | Function Loss:  -2.7832\n",
            "Total loss:  -2.6461 | PDE Loss:  -4.2108 | Function Loss:  -2.7843\n",
            "Total loss:  -2.649 | PDE Loss:  -4.2066 | Function Loss:  -2.7898\n",
            "Total loss:  -2.651 | PDE Loss:  -4.2068 | Function Loss:  -2.7926\n",
            "Total loss:  -2.6524 | PDE Loss:  -4.2076 | Function Loss:  -2.7941\n",
            "Total loss:  -2.6537 | PDE Loss:  -4.2072 | Function Loss:  -2.796\n",
            "Total loss:  -2.6553 | PDE Loss:  -4.2083 | Function Loss:  -2.7979\n",
            "Total loss:  -2.6572 | PDE Loss:  -4.206 | Function Loss:  -2.8014\n",
            "Total loss:  -2.6588 | PDE Loss:  -4.2043 | Function Loss:  -2.8044\n",
            "Total loss:  -2.6603 | PDE Loss:  -4.2012 | Function Loss:  -2.8077\n",
            "Total loss:  -2.6618 | PDE Loss:  -4.1993 | Function Loss:  -2.8105\n",
            "Total loss:  -2.6634 | PDE Loss:  -4.1947 | Function Loss:  -2.8147\n",
            "Total loss:  -2.6648 | PDE Loss:  -4.1956 | Function Loss:  -2.8163\n",
            "Total loss:  -2.6666 | PDE Loss:  -4.1961 | Function Loss:  -2.8187\n",
            "Total loss:  -2.6687 | PDE Loss:  -4.201 | Function Loss:  -2.8196\n",
            "Total loss:  -2.6708 | PDE Loss:  -4.2053 | Function Loss:  -2.8208\n",
            "Total loss:  -2.6725 | PDE Loss:  -4.2091 | Function Loss:  -2.8217\n",
            "Total loss:  -2.6739 | PDE Loss:  -4.2123 | Function Loss:  -2.8223\n",
            "Total loss:  -2.6756 | PDE Loss:  -4.2139 | Function Loss:  -2.824\n",
            "Total loss:  -2.6767 | PDE Loss:  -4.2023 | Function Loss:  -2.8304\n",
            "Total loss:  -2.6788 | PDE Loss:  -4.2079 | Function Loss:  -2.831\n",
            "Total loss:  -2.6814 | PDE Loss:  -4.2136 | Function Loss:  -2.8324\n",
            "Total loss:  -2.6838 | PDE Loss:  -4.2197 | Function Loss:  -2.8333\n",
            "Total loss:  -2.6856 | PDE Loss:  -4.2218 | Function Loss:  -2.8349\n",
            "Total loss:  -2.6874 | PDE Loss:  -4.2169 | Function Loss:  -2.8395\n",
            "Total loss:  -2.6889 | PDE Loss:  -4.2169 | Function Loss:  -2.8416\n",
            "Total loss:  -2.691 | PDE Loss:  -4.2149 | Function Loss:  -2.8455\n",
            "Total loss:  -2.6931 | PDE Loss:  -4.2229 | Function Loss:  -2.8452\n",
            "Total loss:  -2.6949 | PDE Loss:  -4.2211 | Function Loss:  -2.8485\n",
            "Total loss:  -2.6964 | PDE Loss:  -4.2138 | Function Loss:  -2.8536\n",
            "Total loss:  -2.6974 | PDE Loss:  -4.2132 | Function Loss:  -2.8553\n",
            "Total loss:  -2.6984 | PDE Loss:  -4.214 | Function Loss:  -2.8564\n",
            "Total loss:  -2.6995 | PDE Loss:  -4.2149 | Function Loss:  -2.8577\n",
            "Total loss:  -2.7004 | PDE Loss:  -4.218 | Function Loss:  -2.8576\n",
            "Total loss:  -2.7011 | PDE Loss:  -4.2193 | Function Loss:  -2.858\n",
            "Total loss:  -2.7017 | PDE Loss:  -4.22 | Function Loss:  -2.8585\n",
            "Total loss:  -2.7026 | PDE Loss:  -4.2171 | Function Loss:  -2.8611\n",
            "Total loss:  -2.7034 | PDE Loss:  -4.2163 | Function Loss:  -2.8627\n",
            "Total loss:  -2.7042 | PDE Loss:  -4.2155 | Function Loss:  -2.8642\n",
            "Total loss:  -2.7053 | PDE Loss:  -4.2151 | Function Loss:  -2.866\n",
            "Total loss:  -2.7068 | PDE Loss:  -4.2135 | Function Loss:  -2.8688\n",
            "Total loss:  -2.708 | PDE Loss:  -4.2134 | Function Loss:  -2.8706\n",
            "Total loss:  -2.7089 | PDE Loss:  -4.217 | Function Loss:  -2.8702\n",
            "Total loss:  -2.7097 | PDE Loss:  -4.2205 | Function Loss:  -2.8699\n",
            "Total loss:  -2.7105 | PDE Loss:  -4.2222 | Function Loss:  -2.8702\n",
            "Total loss:  -2.7112 | PDE Loss:  -4.2247 | Function Loss:  -2.8701\n",
            "Total loss:  -2.7117 | PDE Loss:  -4.2249 | Function Loss:  -2.8708\n",
            "Total loss:  -2.7122 | PDE Loss:  -4.2247 | Function Loss:  -2.8716\n",
            "Total loss:  -2.7127 | PDE Loss:  -4.2236 | Function Loss:  -2.8728\n",
            "Total loss:  -2.7131 | PDE Loss:  -4.2219 | Function Loss:  -2.8742\n",
            "Total loss:  -2.7136 | PDE Loss:  -4.2204 | Function Loss:  -2.8756\n",
            "Total loss:  -2.7138 | PDE Loss:  -4.2196 | Function Loss:  -2.8763\n",
            "Total loss:  -2.7141 | PDE Loss:  -4.2195 | Function Loss:  -2.8767\n",
            "Total loss:  -2.7145 | PDE Loss:  -4.2191 | Function Loss:  -2.8774\n",
            "Total loss:  -2.7148 | PDE Loss:  -4.221 | Function Loss:  -2.877\n",
            "Total loss:  -2.715 | PDE Loss:  -4.2221 | Function Loss:  -2.8769\n",
            "Total loss:  -2.7153 | PDE Loss:  -4.2244 | Function Loss:  -2.8763\n",
            "Total loss:  -2.7155 | PDE Loss:  -4.2261 | Function Loss:  -2.8758\n",
            "Total loss:  -2.7159 | PDE Loss:  -4.2281 | Function Loss:  -2.8754\n",
            "Total loss:  -2.7154 | PDE Loss:  -4.2342 | Function Loss:  -2.872\n",
            "Total loss:  -2.716 | PDE Loss:  -4.2303 | Function Loss:  -2.8746\n",
            "Total loss:  -2.7169 | PDE Loss:  -4.2332 | Function Loss:  -2.8746\n",
            "Total loss:  -2.7176 | PDE Loss:  -4.2363 | Function Loss:  -2.8743\n",
            "Total loss:  -2.7195 | PDE Loss:  -4.241 | Function Loss:  -2.875\n",
            "Total loss:  -2.7218 | PDE Loss:  -4.2503 | Function Loss:  -2.8744\n",
            "Total loss:  -2.7239 | PDE Loss:  -4.2553 | Function Loss:  -2.8752\n",
            "Total loss:  -2.7257 | PDE Loss:  -4.2594 | Function Loss:  -2.876\n",
            "Total loss:  -2.7273 | PDE Loss:  -4.2602 | Function Loss:  -2.8781\n",
            "Total loss:  -2.7288 | PDE Loss:  -4.2572 | Function Loss:  -2.8813\n",
            "Total loss:  -2.7298 | PDE Loss:  -4.2524 | Function Loss:  -2.8848\n",
            "Total loss:  -2.7308 | PDE Loss:  -4.2486 | Function Loss:  -2.888\n",
            "Total loss:  -2.7316 | PDE Loss:  -4.247 | Function Loss:  -2.8897\n",
            "Total loss:  -2.7322 | PDE Loss:  -4.2471 | Function Loss:  -2.8906\n",
            "Total loss:  -2.7333 | PDE Loss:  -4.2499 | Function Loss:  -2.8909\n",
            "Total loss:  -2.7344 | PDE Loss:  -4.2503 | Function Loss:  -2.8924\n",
            "Total loss:  -2.7359 | PDE Loss:  -4.2627 | Function Loss:  -2.8891\n",
            "Total loss:  -2.7372 | PDE Loss:  -4.2633 | Function Loss:  -2.8908\n",
            "Total loss:  -2.7385 | PDE Loss:  -4.2615 | Function Loss:  -2.8933\n",
            "Total loss:  -2.74 | PDE Loss:  -4.2517 | Function Loss:  -2.8998\n",
            "Total loss:  -2.7412 | PDE Loss:  -4.2537 | Function Loss:  -2.9006\n",
            "Total loss:  -2.742 | PDE Loss:  -4.2583 | Function Loss:  -2.8998\n",
            "Total loss:  -2.7426 | PDE Loss:  -4.2609 | Function Loss:  -2.8994\n",
            "Total loss:  -2.7429 | PDE Loss:  -4.2613 | Function Loss:  -2.8997\n",
            "Total loss:  -2.7433 | PDE Loss:  -4.2625 | Function Loss:  -2.8998\n",
            "Total loss:  -2.7438 | PDE Loss:  -4.2639 | Function Loss:  -2.8999\n",
            "Total loss:  -2.7443 | PDE Loss:  -4.2626 | Function Loss:  -2.9012\n",
            "Total loss:  -2.7448 | PDE Loss:  -4.2611 | Function Loss:  -2.9026\n",
            "Total loss:  -2.7455 | PDE Loss:  -4.2619 | Function Loss:  -2.9032\n",
            "Total loss:  -2.7465 | PDE Loss:  -4.2519 | Function Loss:  -2.9092\n",
            "Total loss:  -2.747 | PDE Loss:  -4.2498 | Function Loss:  -2.9109\n",
            "Total loss:  -2.748 | PDE Loss:  -4.2489 | Function Loss:  -2.9127\n",
            "Total loss:  -2.749 | PDE Loss:  -4.2466 | Function Loss:  -2.9152\n",
            "Total loss:  -2.7501 | PDE Loss:  -4.2505 | Function Loss:  -2.9149\n",
            "Total loss:  -2.7508 | PDE Loss:  -4.2485 | Function Loss:  -2.917\n",
            "Total loss:  -2.7515 | PDE Loss:  -4.2498 | Function Loss:  -2.9174\n",
            "Total loss:  -2.752 | PDE Loss:  -4.2495 | Function Loss:  -2.9182\n",
            "Total loss:  -2.7524 | PDE Loss:  -4.2498 | Function Loss:  -2.9187\n",
            "Total loss:  -2.7528 | PDE Loss:  -4.2507 | Function Loss:  -2.9188\n",
            "Total loss:  -2.7532 | PDE Loss:  -4.2506 | Function Loss:  -2.9195\n",
            "Total loss:  -2.7535 | PDE Loss:  -4.2512 | Function Loss:  -2.9197\n",
            "Total loss:  -2.7541 | PDE Loss:  -4.2513 | Function Loss:  -2.9206\n",
            "Total loss:  -2.7461 | PDE Loss:  -4.2045 | Function Loss:  -2.9318\n",
            "Total loss:  -2.7542 | PDE Loss:  -4.2477 | Function Loss:  -2.9224\n",
            "Total loss:  -2.7551 | PDE Loss:  -4.2496 | Function Loss:  -2.9227\n",
            "Total loss:  -2.7557 | PDE Loss:  -4.2513 | Function Loss:  -2.9229\n",
            "Total loss:  -2.7565 | PDE Loss:  -4.2534 | Function Loss:  -2.923\n",
            "Total loss:  -2.7572 | PDE Loss:  -4.2553 | Function Loss:  -2.9232\n",
            "Total loss:  -2.7579 | PDE Loss:  -4.2574 | Function Loss:  -2.9232\n",
            "Total loss:  -2.7584 | PDE Loss:  -4.2584 | Function Loss:  -2.9235\n",
            "Total loss:  -2.7589 | PDE Loss:  -4.258 | Function Loss:  -2.9243\n",
            "Total loss:  -2.7594 | PDE Loss:  -4.2578 | Function Loss:  -2.9251\n",
            "Total loss:  -2.7598 | PDE Loss:  -4.2564 | Function Loss:  -2.9265\n",
            "Total loss:  -2.7602 | PDE Loss:  -4.2566 | Function Loss:  -2.9269\n",
            "Total loss:  -2.7605 | PDE Loss:  -4.2534 | Function Loss:  -2.9289\n",
            "Total loss:  -2.7607 | PDE Loss:  -4.2523 | Function Loss:  -2.9297\n",
            "Total loss:  -2.7609 | PDE Loss:  -4.2502 | Function Loss:  -2.931\n",
            "Total loss:  -2.7611 | PDE Loss:  -4.2483 | Function Loss:  -2.9323\n",
            "Total loss:  -2.7614 | PDE Loss:  -4.2465 | Function Loss:  -2.9335\n",
            "Total loss:  -2.7617 | PDE Loss:  -4.2452 | Function Loss:  -2.9346\n",
            "Total loss:  -2.7494 | PDE Loss:  -4.209 | Function Loss:  -2.9345\n",
            "Total loss:  -2.7617 | PDE Loss:  -4.2434 | Function Loss:  -2.9356\n",
            "Total loss:  -2.7621 | PDE Loss:  -4.2421 | Function Loss:  -2.9368\n",
            "Total loss:  -2.7596 | PDE Loss:  -4.247 | Function Loss:  -2.9306\n",
            "Total loss:  -2.7624 | PDE Loss:  -4.2435 | Function Loss:  -2.9364\n",
            "Total loss:  -2.7632 | PDE Loss:  -4.2425 | Function Loss:  -2.9382\n",
            "Total loss:  -2.7642 | PDE Loss:  -4.2435 | Function Loss:  -2.9392\n",
            "Total loss:  -2.766 | PDE Loss:  -4.2462 | Function Loss:  -2.9406\n",
            "Total loss:  -2.7684 | PDE Loss:  -4.2516 | Function Loss:  -2.9415\n",
            "Total loss:  -2.7702 | PDE Loss:  -4.2615 | Function Loss:  -2.9394\n",
            "Total loss:  -2.7726 | PDE Loss:  -4.267 | Function Loss:  -2.9404\n",
            "Total loss:  -2.7744 | PDE Loss:  -4.2721 | Function Loss:  -2.9405\n",
            "Total loss:  -2.7771 | PDE Loss:  -4.2831 | Function Loss:  -2.9395\n",
            "Total loss:  -2.7801 | PDE Loss:  -4.2936 | Function Loss:  -2.9391\n",
            "Total loss:  -2.7828 | PDE Loss:  -4.3027 | Function Loss:  -2.939\n",
            "Total loss:  -2.7859 | PDE Loss:  -4.3077 | Function Loss:  -2.9413\n",
            "Total loss:  -2.7896 | PDE Loss:  -4.3094 | Function Loss:  -2.9458\n",
            "Total loss:  -2.7908 | PDE Loss:  -4.3134 | Function Loss:  -2.9458\n",
            "Total loss:  -2.7926 | PDE Loss:  -4.3116 | Function Loss:  -2.9492\n",
            "Total loss:  -2.7962 | PDE Loss:  -4.3122 | Function Loss:  -2.9541\n",
            "Total loss:  -2.7982 | PDE Loss:  -4.3105 | Function Loss:  -2.9578\n",
            "Total loss:  -2.8005 | PDE Loss:  -4.3089 | Function Loss:  -2.9617\n",
            "Total loss:  -2.8032 | PDE Loss:  -4.3142 | Function Loss:  -2.9633\n",
            "Total loss:  -2.8052 | PDE Loss:  -4.3136 | Function Loss:  -2.9664\n",
            "Total loss:  -2.8062 | PDE Loss:  -4.3178 | Function Loss:  -2.966\n",
            "Total loss:  -2.8072 | PDE Loss:  -4.3235 | Function Loss:  -2.9649\n",
            "Total loss:  -2.8083 | PDE Loss:  -4.3259 | Function Loss:  -2.9656\n",
            "Total loss:  -2.8092 | PDE Loss:  -4.3303 | Function Loss:  -2.9648\n",
            "Total loss:  -2.81 | PDE Loss:  -4.3328 | Function Loss:  -2.9649\n",
            "Total loss:  -2.8106 | PDE Loss:  -4.3315 | Function Loss:  -2.9663\n",
            "Total loss:  -2.8112 | PDE Loss:  -4.3273 | Function Loss:  -2.9691\n",
            "Total loss:  -2.8121 | PDE Loss:  -4.3241 | Function Loss:  -2.9717\n",
            "Total loss:  -2.8128 | PDE Loss:  -4.3239 | Function Loss:  -2.9728\n",
            "Total loss:  -2.8134 | PDE Loss:  -4.3231 | Function Loss:  -2.9741\n",
            "Total loss:  -2.814 | PDE Loss:  -4.3241 | Function Loss:  -2.9744\n",
            "Total loss:  -2.8144 | PDE Loss:  -4.3247 | Function Loss:  -2.9748\n",
            "Total loss:  -2.8149 | PDE Loss:  -4.3258 | Function Loss:  -2.975\n",
            "Total loss:  -2.8151 | PDE Loss:  -4.332 | Function Loss:  -2.9727\n",
            "Total loss:  -2.8156 | PDE Loss:  -4.3311 | Function Loss:  -2.9737\n",
            "Total loss:  -2.8159 | PDE Loss:  -4.3294 | Function Loss:  -2.9749\n",
            "Total loss:  -2.8162 | PDE Loss:  -4.3289 | Function Loss:  -2.9756\n",
            "Total loss:  -2.8164 | PDE Loss:  -4.3284 | Function Loss:  -2.976\n",
            "Total loss:  -2.8166 | PDE Loss:  -4.327 | Function Loss:  -2.977\n",
            "Total loss:  -2.8169 | PDE Loss:  -4.3276 | Function Loss:  -2.9771\n",
            "Total loss:  -2.8172 | PDE Loss:  -4.3264 | Function Loss:  -2.9781\n",
            "Total loss:  -2.8172 | PDE Loss:  -4.3276 | Function Loss:  -2.9775\n",
            "Total loss:  -2.8174 | PDE Loss:  -4.3271 | Function Loss:  -2.978\n",
            "Total loss:  -2.8178 | PDE Loss:  -4.3274 | Function Loss:  -2.9785\n",
            "Total loss:  -2.8181 | PDE Loss:  -4.3273 | Function Loss:  -2.979\n",
            "Total loss:  -2.8185 | PDE Loss:  -4.3277 | Function Loss:  -2.9795\n",
            "Total loss:  -2.819 | PDE Loss:  -4.3281 | Function Loss:  -2.98\n",
            "Total loss:  -2.8194 | PDE Loss:  -4.3284 | Function Loss:  -2.9804\n",
            "Total loss:  -2.8198 | PDE Loss:  -4.3286 | Function Loss:  -2.9809\n",
            "Total loss:  -2.8202 | PDE Loss:  -4.3287 | Function Loss:  -2.9815\n",
            "Total loss:  -2.814 | PDE Loss:  -4.3303 | Function Loss:  -2.9718\n",
            "Total loss:  -2.8204 | PDE Loss:  -4.33 | Function Loss:  -2.9811\n",
            "Total loss:  -2.8213 | PDE Loss:  -4.3293 | Function Loss:  -2.9828\n",
            "Total loss:  -2.8222 | PDE Loss:  -4.3292 | Function Loss:  -2.9841\n",
            "Total loss:  -2.823 | PDE Loss:  -4.3284 | Function Loss:  -2.9856\n",
            "Total loss:  -2.8236 | PDE Loss:  -4.3272 | Function Loss:  -2.987\n",
            "Total loss:  -2.824 | PDE Loss:  -4.3259 | Function Loss:  -2.9883\n",
            "Total loss:  -2.8244 | PDE Loss:  -4.3252 | Function Loss:  -2.9891\n",
            "Total loss:  -2.8249 | PDE Loss:  -4.3239 | Function Loss:  -2.9904\n",
            "Total loss:  -2.8253 | PDE Loss:  -4.3235 | Function Loss:  -2.9913\n",
            "Total loss:  -2.8258 | PDE Loss:  -4.3225 | Function Loss:  -2.9925\n",
            "Total loss:  -2.826 | PDE Loss:  -4.3328 | Function Loss:  -2.9879\n",
            "Total loss:  -2.8266 | PDE Loss:  -4.3305 | Function Loss:  -2.9899\n",
            "Total loss:  -2.8271 | PDE Loss:  -4.3277 | Function Loss:  -2.9919\n",
            "Total loss:  -2.8278 | PDE Loss:  -4.3254 | Function Loss:  -2.9939\n",
            "Total loss:  -2.8285 | PDE Loss:  -4.3231 | Function Loss:  -2.9961\n",
            "Total loss:  -2.829 | PDE Loss:  -4.3246 | Function Loss:  -2.9961\n",
            "Total loss:  -2.8293 | PDE Loss:  -4.3253 | Function Loss:  -2.9963\n",
            "Total loss:  -2.8296 | PDE Loss:  -4.3283 | Function Loss:  -2.9953\n",
            "Total loss:  -2.8298 | PDE Loss:  -4.33 | Function Loss:  -2.9948\n",
            "Total loss:  -2.83 | PDE Loss:  -4.331 | Function Loss:  -2.9946\n",
            "Total loss:  -2.8303 | PDE Loss:  -4.3327 | Function Loss:  -2.9942\n",
            "Total loss:  -2.8306 | PDE Loss:  -4.333 | Function Loss:  -2.9946\n",
            "Total loss:  -2.831 | PDE Loss:  -4.3339 | Function Loss:  -2.9947\n",
            "Total loss:  -2.8314 | PDE Loss:  -4.3365 | Function Loss:  -2.9942\n",
            "Total loss:  -2.8318 | PDE Loss:  -4.3362 | Function Loss:  -2.9949\n",
            "Total loss:  -2.8322 | PDE Loss:  -4.3363 | Function Loss:  -2.9954\n",
            "Total loss:  -2.8326 | PDE Loss:  -4.3367 | Function Loss:  -2.9958\n",
            "Total loss:  -2.8331 | PDE Loss:  -4.3359 | Function Loss:  -2.9969\n",
            "Total loss:  -2.8331 | PDE Loss:  -4.335 | Function Loss:  -2.9973\n",
            "Total loss:  -2.8333 | PDE Loss:  -4.3356 | Function Loss:  -2.9974\n",
            "Total loss:  -2.8337 | PDE Loss:  -4.3359 | Function Loss:  -2.9978\n",
            "Total loss:  -2.8342 | PDE Loss:  -4.3364 | Function Loss:  -2.9982\n",
            "Total loss:  -2.8348 | PDE Loss:  -4.3379 | Function Loss:  -2.9984\n",
            "Total loss:  -2.8354 | PDE Loss:  -4.3403 | Function Loss:  -2.9983\n",
            "Total loss:  -2.8361 | PDE Loss:  -4.3435 | Function Loss:  -2.9978\n",
            "Total loss:  -2.8369 | PDE Loss:  -4.3473 | Function Loss:  -2.9972\n",
            "Total loss:  -2.8377 | PDE Loss:  -4.3503 | Function Loss:  -2.997\n",
            "Total loss:  -2.8383 | PDE Loss:  -4.3516 | Function Loss:  -2.9974\n",
            "Total loss:  -2.8389 | PDE Loss:  -4.3531 | Function Loss:  -2.9976\n",
            "Total loss:  -2.8394 | PDE Loss:  -4.352 | Function Loss:  -2.9988\n",
            "Total loss:  -2.8399 | PDE Loss:  -4.3506 | Function Loss:  -3.0001\n",
            "Total loss:  -2.8403 | PDE Loss:  -4.3479 | Function Loss:  -3.002\n",
            "Total loss:  -2.8409 | PDE Loss:  -4.344 | Function Loss:  -3.0046\n",
            "Total loss:  -2.8416 | PDE Loss:  -4.34 | Function Loss:  -3.0075\n",
            "Total loss:  -2.8422 | PDE Loss:  -4.3378 | Function Loss:  -3.0094\n",
            "Total loss:  -2.8429 | PDE Loss:  -4.3371 | Function Loss:  -3.0107\n",
            "Total loss:  -2.8435 | PDE Loss:  -4.3373 | Function Loss:  -3.0115\n",
            "Total loss:  -2.844 | PDE Loss:  -4.3373 | Function Loss:  -3.0123\n",
            "Total loss:  -2.8445 | PDE Loss:  -4.3399 | Function Loss:  -3.0118\n",
            "Total loss:  -2.8451 | PDE Loss:  -4.3413 | Function Loss:  -3.0119\n",
            "Total loss:  -2.8456 | PDE Loss:  -4.3433 | Function Loss:  -3.0118\n",
            "Total loss:  -2.846 | PDE Loss:  -4.3449 | Function Loss:  -3.0116\n",
            "Total loss:  -2.8464 | PDE Loss:  -4.3443 | Function Loss:  -3.0125\n",
            "Total loss:  -2.8468 | PDE Loss:  -4.344 | Function Loss:  -3.0131\n",
            "Total loss:  -2.8471 | PDE Loss:  -4.3428 | Function Loss:  -3.0142\n",
            "Total loss:  -2.8473 | PDE Loss:  -4.3413 | Function Loss:  -3.0153\n",
            "Total loss:  -2.8475 | PDE Loss:  -4.3409 | Function Loss:  -3.0157\n",
            "Total loss:  -2.8476 | PDE Loss:  -4.3403 | Function Loss:  -3.0162\n",
            "Total loss:  -2.8478 | PDE Loss:  -4.3409 | Function Loss:  -3.0161\n",
            "Total loss:  -2.8479 | PDE Loss:  -4.3419 | Function Loss:  -3.0157\n",
            "Total loss:  -2.848 | PDE Loss:  -4.3434 | Function Loss:  -3.0153\n",
            "Total loss:  -2.8482 | PDE Loss:  -4.3453 | Function Loss:  -3.0146\n",
            "Total loss:  -2.8484 | PDE Loss:  -4.3467 | Function Loss:  -3.0143\n",
            "Total loss:  -2.8484 | PDE Loss:  -4.3552 | Function Loss:  -3.0104\n",
            "Total loss:  -2.8485 | PDE Loss:  -4.3511 | Function Loss:  -3.0124\n",
            "Total loss:  -2.8488 | PDE Loss:  -4.3545 | Function Loss:  -3.0113\n",
            "Total loss:  -2.849 | PDE Loss:  -4.3533 | Function Loss:  -3.0122\n",
            "Total loss:  -2.8494 | PDE Loss:  -4.3528 | Function Loss:  -3.013\n",
            "Total loss:  -2.8499 | PDE Loss:  -4.3531 | Function Loss:  -3.0135\n",
            "Total loss:  -2.8503 | PDE Loss:  -4.3522 | Function Loss:  -3.0144\n",
            "Total loss:  -2.8505 | PDE Loss:  -4.3528 | Function Loss:  -3.0146\n",
            "Total loss:  -2.8507 | PDE Loss:  -4.3528 | Function Loss:  -3.0148\n",
            "Total loss:  -2.8508 | PDE Loss:  -4.3529 | Function Loss:  -3.0149\n",
            "Total loss:  -2.8509 | PDE Loss:  -4.3533 | Function Loss:  -3.0149\n",
            "Total loss:  -2.8511 | PDE Loss:  -4.353 | Function Loss:  -3.0153\n",
            "Total loss:  -2.8476 | PDE Loss:  -4.3572 | Function Loss:  -3.0084\n",
            "Total loss:  -2.8512 | PDE Loss:  -4.3538 | Function Loss:  -3.0151\n",
            "Total loss:  -2.8515 | PDE Loss:  -4.3539 | Function Loss:  -3.0155\n",
            "Total loss:  -2.852 | PDE Loss:  -4.352 | Function Loss:  -3.0171\n",
            "Total loss:  -2.8525 | PDE Loss:  -4.3512 | Function Loss:  -3.0182\n",
            "Total loss:  -2.8532 | PDE Loss:  -4.3508 | Function Loss:  -3.0194\n",
            "Total loss:  -2.8539 | PDE Loss:  -4.3497 | Function Loss:  -3.021\n",
            "Total loss:  -2.8546 | PDE Loss:  -4.35 | Function Loss:  -3.0219\n",
            "Total loss:  -2.8553 | PDE Loss:  -4.3506 | Function Loss:  -3.0226\n",
            "Total loss:  -2.8561 | PDE Loss:  -4.3517 | Function Loss:  -3.0233\n",
            "Total loss:  -2.857 | PDE Loss:  -4.3538 | Function Loss:  -3.0236\n",
            "Total loss:  -2.8581 | PDE Loss:  -4.3562 | Function Loss:  -3.0241\n",
            "Total loss:  -2.8593 | PDE Loss:  -4.3602 | Function Loss:  -3.0239\n",
            "Total loss:  -2.8606 | PDE Loss:  -4.3646 | Function Loss:  -3.0238\n",
            "Total loss:  -2.8619 | PDE Loss:  -4.3695 | Function Loss:  -3.0235\n",
            "Total loss:  -2.864 | PDE Loss:  -4.3762 | Function Loss:  -3.0235\n",
            "Total loss:  -2.8661 | PDE Loss:  -4.3841 | Function Loss:  -3.023\n",
            "Total loss:  -2.8689 | PDE Loss:  -4.3897 | Function Loss:  -3.0247\n",
            "Total loss:  -2.8712 | PDE Loss:  -4.3983 | Function Loss:  -3.0244\n",
            "Total loss:  -2.8729 | PDE Loss:  -4.401 | Function Loss:  -3.0256\n",
            "Total loss:  -2.8767 | PDE Loss:  -4.398 | Function Loss:  -3.0322\n",
            "Total loss:  -2.8786 | PDE Loss:  -4.3939 | Function Loss:  -3.0368\n",
            "Total loss:  -2.8812 | PDE Loss:  -4.3937 | Function Loss:  -3.0406\n",
            "Total loss:  -2.883 | PDE Loss:  -4.3878 | Function Loss:  -3.0459\n",
            "Total loss:  -2.8845 | PDE Loss:  -4.3885 | Function Loss:  -3.0477\n",
            "Total loss:  -2.886 | PDE Loss:  -4.3912 | Function Loss:  -3.0487\n",
            "Total loss:  -2.8873 | PDE Loss:  -4.394 | Function Loss:  -3.0493\n",
            "Total loss:  -2.8884 | PDE Loss:  -4.3939 | Function Loss:  -3.051\n",
            "Total loss:  -2.8895 | PDE Loss:  -4.395 | Function Loss:  -3.0521\n",
            "Total loss:  -2.8889 | PDE Loss:  -4.3905 | Function Loss:  -3.0533\n",
            "Total loss:  -2.8899 | PDE Loss:  -4.3935 | Function Loss:  -3.0534\n",
            "Total loss:  -2.8912 | PDE Loss:  -4.3893 | Function Loss:  -3.0572\n",
            "Total loss:  -2.8921 | PDE Loss:  -4.3873 | Function Loss:  -3.0593\n",
            "Total loss:  -2.8931 | PDE Loss:  -4.386 | Function Loss:  -3.0616\n",
            "Total loss:  -2.894 | PDE Loss:  -4.3871 | Function Loss:  -3.0623\n",
            "Total loss:  -2.8947 | PDE Loss:  -4.3883 | Function Loss:  -3.0628\n",
            "Total loss:  -2.8954 | PDE Loss:  -4.3921 | Function Loss:  -3.0619\n",
            "Total loss:  -2.8963 | PDE Loss:  -4.3984 | Function Loss:  -3.0604\n",
            "Total loss:  -2.8971 | PDE Loss:  -4.4057 | Function Loss:  -3.0583\n",
            "Total loss:  -2.8976 | PDE Loss:  -4.4113 | Function Loss:  -3.0566\n",
            "Total loss:  -2.898 | PDE Loss:  -4.4148 | Function Loss:  -3.0556\n",
            "Total loss:  -2.8985 | PDE Loss:  -4.415 | Function Loss:  -3.0561\n",
            "Total loss:  -2.899 | PDE Loss:  -4.4342 | Function Loss:  -3.0487\n",
            "Total loss:  -2.8995 | PDE Loss:  -4.4307 | Function Loss:  -3.0509\n",
            "Total loss:  -2.9003 | PDE Loss:  -4.4243 | Function Loss:  -3.0548\n",
            "Total loss:  -2.9011 | PDE Loss:  -4.4203 | Function Loss:  -3.0576\n",
            "Total loss:  -2.9017 | PDE Loss:  -4.4172 | Function Loss:  -3.0598\n",
            "Total loss:  -2.9023 | PDE Loss:  -4.4182 | Function Loss:  -3.0601\n",
            "Total loss:  -2.9027 | PDE Loss:  -4.4149 | Function Loss:  -3.0623\n",
            "Total loss:  -2.9033 | PDE Loss:  -4.4152 | Function Loss:  -3.063\n",
            "Total loss:  -2.9039 | PDE Loss:  -4.4189 | Function Loss:  -3.0623\n",
            "Total loss:  -2.9048 | PDE Loss:  -4.4243 | Function Loss:  -3.0611\n",
            "Total loss:  -2.9055 | PDE Loss:  -4.4295 | Function Loss:  -3.06\n",
            "Total loss:  -2.9062 | PDE Loss:  -4.4335 | Function Loss:  -3.0593\n",
            "Total loss:  -2.9071 | PDE Loss:  -4.4374 | Function Loss:  -3.0588\n",
            "Total loss:  -2.908 | PDE Loss:  -4.4389 | Function Loss:  -3.0595\n",
            "Total loss:  -2.9084 | PDE Loss:  -4.4413 | Function Loss:  -3.0592\n",
            "Total loss:  -2.909 | PDE Loss:  -4.4387 | Function Loss:  -3.0611\n",
            "Total loss:  -2.9098 | PDE Loss:  -4.4331 | Function Loss:  -3.0645\n",
            "Total loss:  -2.9105 | PDE Loss:  -4.4257 | Function Loss:  -3.0687\n",
            "Total loss:  -2.9109 | PDE Loss:  -4.4241 | Function Loss:  -3.07\n",
            "Total loss:  -2.9113 | PDE Loss:  -4.4234 | Function Loss:  -3.071\n",
            "Total loss:  -2.9119 | PDE Loss:  -4.4182 | Function Loss:  -3.0741\n",
            "Total loss:  -2.9124 | PDE Loss:  -4.4187 | Function Loss:  -3.0746\n",
            "Total loss:  -2.9129 | PDE Loss:  -4.4235 | Function Loss:  -3.0732\n",
            "Total loss:  -2.9134 | PDE Loss:  -4.4229 | Function Loss:  -3.0741\n",
            "Total loss:  -2.9138 | PDE Loss:  -4.4228 | Function Loss:  -3.0748\n",
            "Total loss:  -2.9143 | PDE Loss:  -4.4239 | Function Loss:  -3.0751\n",
            "Total loss:  -2.9148 | PDE Loss:  -4.4232 | Function Loss:  -3.0761\n",
            "Total loss:  -2.9152 | PDE Loss:  -4.4235 | Function Loss:  -3.0765\n",
            "Total loss:  -2.9159 | PDE Loss:  -4.4252 | Function Loss:  -3.0768\n",
            "Total loss:  -2.7802 | PDE Loss:  -4.3046 | Function Loss:  -2.9345\n",
            "Total loss:  -2.9162 | PDE Loss:  -4.4228 | Function Loss:  -3.0782\n",
            "Total loss:  -2.9168 | PDE Loss:  -4.4251 | Function Loss:  -3.0781\n",
            "Total loss:  -2.9175 | PDE Loss:  -4.4274 | Function Loss:  -3.0781\n",
            "Total loss:  -2.9179 | PDE Loss:  -4.4302 | Function Loss:  -3.0774\n",
            "Total loss:  -2.9184 | PDE Loss:  -4.4313 | Function Loss:  -3.0776\n",
            "Total loss:  -2.9187 | PDE Loss:  -4.4316 | Function Loss:  -3.078\n",
            "Total loss:  -2.919 | PDE Loss:  -4.432 | Function Loss:  -3.0783\n",
            "Total loss:  -2.9193 | PDE Loss:  -4.4322 | Function Loss:  -3.0786\n",
            "Total loss:  -2.9196 | PDE Loss:  -4.4342 | Function Loss:  -3.0782\n",
            "Total loss:  -2.9199 | PDE Loss:  -4.4347 | Function Loss:  -3.0783\n",
            "Total loss:  -2.9202 | PDE Loss:  -4.4356 | Function Loss:  -3.0783\n",
            "Total loss:  -2.9206 | PDE Loss:  -4.4373 | Function Loss:  -3.0782\n",
            "Total loss:  -2.9211 | PDE Loss:  -4.4385 | Function Loss:  -3.0783\n",
            "Total loss:  -2.9215 | PDE Loss:  -4.4393 | Function Loss:  -3.0785\n",
            "Total loss:  -2.9217 | PDE Loss:  -4.44 | Function Loss:  -3.0786\n",
            "Total loss:  -2.9219 | PDE Loss:  -4.4394 | Function Loss:  -3.0792\n",
            "Total loss:  -2.9222 | PDE Loss:  -4.4388 | Function Loss:  -3.0798\n",
            "Total loss:  -2.9226 | PDE Loss:  -4.4416 | Function Loss:  -3.0792\n",
            "Total loss:  -2.9082 | PDE Loss:  -4.416 | Function Loss:  -3.0697\n",
            "Total loss:  -2.9228 | PDE Loss:  -4.4406 | Function Loss:  -3.0799\n",
            "Total loss:  -2.9233 | PDE Loss:  -4.4419 | Function Loss:  -3.0801\n",
            "Total loss:  -2.9241 | PDE Loss:  -4.4426 | Function Loss:  -3.0809\n",
            "Total loss:  -2.924 | PDE Loss:  -4.4659 | Function Loss:  -3.0709\n",
            "Total loss:  -2.9249 | PDE Loss:  -4.4543 | Function Loss:  -3.0771\n",
            "Total loss:  -2.9256 | PDE Loss:  -4.4554 | Function Loss:  -3.0776\n",
            "Total loss:  -2.9269 | PDE Loss:  -4.4592 | Function Loss:  -3.0778\n",
            "Total loss:  -2.928 | PDE Loss:  -4.4653 | Function Loss:  -3.0769\n",
            "Total loss:  -2.929 | PDE Loss:  -4.4715 | Function Loss:  -3.0757\n",
            "Total loss:  -2.9296 | PDE Loss:  -4.4768 | Function Loss:  -3.0745\n",
            "Total loss:  -2.9305 | PDE Loss:  -4.4848 | Function Loss:  -3.0726\n",
            "Total loss:  -2.9315 | PDE Loss:  -4.4935 | Function Loss:  -3.0707\n",
            "Total loss:  -2.9327 | PDE Loss:  -4.5038 | Function Loss:  -3.0684\n",
            "Total loss:  -2.9335 | PDE Loss:  -4.5112 | Function Loss:  -3.0669\n",
            "Total loss:  -2.9347 | PDE Loss:  -4.5179 | Function Loss:  -3.0661\n",
            "Total loss:  -2.9357 | PDE Loss:  -4.5224 | Function Loss:  -3.0659\n",
            "Total loss:  -2.9365 | PDE Loss:  -4.5246 | Function Loss:  -3.0662\n",
            "Total loss:  -2.9373 | PDE Loss:  -4.5232 | Function Loss:  -3.0677\n",
            "Total loss:  -2.938 | PDE Loss:  -4.5237 | Function Loss:  -3.0685\n",
            "Total loss:  -2.9382 | PDE Loss:  -4.5204 | Function Loss:  -3.07\n",
            "Total loss:  -2.939 | PDE Loss:  -4.5219 | Function Loss:  -3.0705\n",
            "Total loss:  -2.9397 | PDE Loss:  -4.5237 | Function Loss:  -3.0708\n",
            "Total loss:  -2.9406 | PDE Loss:  -4.5267 | Function Loss:  -3.071\n",
            "Total loss:  -2.9416 | PDE Loss:  -4.5308 | Function Loss:  -3.0709\n",
            "Total loss:  -2.9427 | PDE Loss:  -4.5325 | Function Loss:  -3.0718\n",
            "Total loss:  -2.9435 | PDE Loss:  -4.5373 | Function Loss:  -3.0712\n",
            "Total loss:  -2.9442 | PDE Loss:  -4.5411 | Function Loss:  -3.0708\n",
            "Total loss:  -2.9449 | PDE Loss:  -4.5438 | Function Loss:  -3.071\n",
            "Total loss:  -2.9456 | PDE Loss:  -4.5459 | Function Loss:  -3.0711\n",
            "Total loss:  -2.9463 | PDE Loss:  -4.5467 | Function Loss:  -3.0718\n",
            "Total loss:  -2.947 | PDE Loss:  -4.5464 | Function Loss:  -3.0729\n",
            "Total loss:  -2.9476 | PDE Loss:  -4.5456 | Function Loss:  -3.0739\n",
            "Total loss:  -2.9481 | PDE Loss:  -4.5421 | Function Loss:  -3.0757\n",
            "Total loss:  -2.9486 | PDE Loss:  -4.5408 | Function Loss:  -3.0769\n",
            "Total loss:  -2.9495 | PDE Loss:  -4.5378 | Function Loss:  -3.0791\n",
            "Total loss:  -2.9506 | PDE Loss:  -4.5361 | Function Loss:  -3.0812\n",
            "Total loss:  -2.9517 | PDE Loss:  -4.536 | Function Loss:  -3.0827\n",
            "Total loss:  -2.9531 | PDE Loss:  -4.536 | Function Loss:  -3.0846\n",
            "Total loss:  -2.9552 | PDE Loss:  -4.5427 | Function Loss:  -3.0851\n",
            "Total loss:  -2.9574 | PDE Loss:  -4.5518 | Function Loss:  -3.085\n",
            "Total loss:  -2.9592 | PDE Loss:  -4.5554 | Function Loss:  -3.0861\n",
            "Total loss:  -2.9612 | PDE Loss:  -4.5618 | Function Loss:  -3.0866\n",
            "Total loss:  -2.9631 | PDE Loss:  -4.5686 | Function Loss:  -3.0869\n",
            "Total loss:  -2.9649 | PDE Loss:  -4.5714 | Function Loss:  -3.0884\n",
            "Total loss:  -2.9668 | PDE Loss:  -4.5757 | Function Loss:  -3.0895\n",
            "Total loss:  -2.9685 | PDE Loss:  -4.5774 | Function Loss:  -3.0912\n",
            "Total loss:  -2.9698 | PDE Loss:  -4.5778 | Function Loss:  -3.0928\n",
            "Total loss:  -2.9708 | PDE Loss:  -4.5767 | Function Loss:  -3.0945\n",
            "Total loss:  -2.9721 | PDE Loss:  -4.5761 | Function Loss:  -3.0964\n",
            "Total loss:  -2.9731 | PDE Loss:  -4.5743 | Function Loss:  -3.0984\n",
            "Total loss:  -2.9738 | PDE Loss:  -4.5736 | Function Loss:  -3.0996\n",
            "Total loss:  -2.9742 | PDE Loss:  -4.575 | Function Loss:  -3.0996\n",
            "Total loss:  -2.9748 | PDE Loss:  -4.5751 | Function Loss:  -3.1003\n",
            "Total loss:  -2.9755 | PDE Loss:  -4.5754 | Function Loss:  -3.1011\n",
            "Total loss:  -2.976 | PDE Loss:  -4.5778 | Function Loss:  -3.101\n",
            "Total loss:  -2.9765 | PDE Loss:  -4.5786 | Function Loss:  -3.1014\n",
            "Total loss:  -2.9768 | PDE Loss:  -4.5792 | Function Loss:  -3.1017\n",
            "Total loss:  -2.9771 | PDE Loss:  -4.5786 | Function Loss:  -3.1023\n",
            "Total loss:  -2.9774 | PDE Loss:  -4.5771 | Function Loss:  -3.1031\n",
            "Total loss:  -2.9777 | PDE Loss:  -4.5751 | Function Loss:  -3.1042\n",
            "Total loss:  -2.9781 | PDE Loss:  -4.5773 | Function Loss:  -3.104\n",
            "Total loss:  -2.9785 | PDE Loss:  -4.5749 | Function Loss:  -3.1053\n",
            "Total loss:  -2.9791 | PDE Loss:  -4.5727 | Function Loss:  -3.1069\n",
            "Total loss:  -2.9795 | PDE Loss:  -4.5703 | Function Loss:  -3.1083\n",
            "Total loss:  -2.9799 | PDE Loss:  -4.5697 | Function Loss:  -3.1089\n",
            "Total loss:  -2.98 | PDE Loss:  -4.5694 | Function Loss:  -3.1093\n",
            "Total loss:  -2.9802 | PDE Loss:  -4.5702 | Function Loss:  -3.1093\n",
            "Total loss:  -2.9804 | PDE Loss:  -4.5701 | Function Loss:  -3.1096\n",
            "Total loss:  -2.9806 | PDE Loss:  -4.5716 | Function Loss:  -3.1093\n",
            "Total loss:  -2.9808 | PDE Loss:  -4.5721 | Function Loss:  -3.1094\n",
            "Total loss:  -2.9811 | PDE Loss:  -4.5734 | Function Loss:  -3.1093\n",
            "Total loss:  -2.9799 | PDE Loss:  -4.5723 | Function Loss:  -3.1081\n",
            "Total loss:  -2.9812 | PDE Loss:  -4.5736 | Function Loss:  -3.1093\n",
            "Total loss:  -2.9815 | PDE Loss:  -4.5747 | Function Loss:  -3.1094\n",
            "Total loss:  -2.9818 | PDE Loss:  -4.5757 | Function Loss:  -3.1095\n",
            "Total loss:  -2.9822 | PDE Loss:  -4.5759 | Function Loss:  -3.11\n",
            "Total loss:  -2.9825 | PDE Loss:  -4.5759 | Function Loss:  -3.1104\n",
            "Total loss:  -2.9828 | PDE Loss:  -4.5751 | Function Loss:  -3.111\n",
            "Total loss:  -2.983 | PDE Loss:  -4.5743 | Function Loss:  -3.1115\n",
            "Total loss:  -2.9832 | PDE Loss:  -4.573 | Function Loss:  -3.1123\n",
            "Total loss:  -2.9834 | PDE Loss:  -4.5718 | Function Loss:  -3.113\n",
            "Total loss:  -2.9836 | PDE Loss:  -4.5691 | Function Loss:  -3.1143\n",
            "Total loss:  -2.9838 | PDE Loss:  -4.5686 | Function Loss:  -3.1147\n",
            "Total loss:  -2.984 | PDE Loss:  -4.5669 | Function Loss:  -3.1155\n",
            "Total loss:  -2.9841 | PDE Loss:  -4.5666 | Function Loss:  -3.1158\n",
            "Total loss:  -2.9842 | PDE Loss:  -4.5656 | Function Loss:  -3.1163\n",
            "Total loss:  -2.9843 | PDE Loss:  -4.5671 | Function Loss:  -3.1159\n",
            "Total loss:  -2.9844 | PDE Loss:  -4.5658 | Function Loss:  -3.1165\n",
            "Total loss:  -2.9845 | PDE Loss:  -4.5636 | Function Loss:  -3.1174\n",
            "Total loss:  -2.9846 | PDE Loss:  -4.5624 | Function Loss:  -3.1179\n",
            "Total loss:  -2.9847 | PDE Loss:  -4.5615 | Function Loss:  -3.1184\n",
            "Total loss:  -2.9848 | PDE Loss:  -4.5606 | Function Loss:  -3.1189\n",
            "Total loss:  -2.984 | PDE Loss:  -4.5548 | Function Loss:  -3.1199\n",
            "Total loss:  -2.9849 | PDE Loss:  -4.5595 | Function Loss:  -3.1194\n",
            "Total loss:  -2.985 | PDE Loss:  -4.5594 | Function Loss:  -3.1196\n",
            "Total loss:  -2.9852 | PDE Loss:  -4.5591 | Function Loss:  -3.1199\n",
            "Total loss:  -2.9855 | PDE Loss:  -4.5586 | Function Loss:  -3.1205\n",
            "Total loss:  -2.9858 | PDE Loss:  -4.5579 | Function Loss:  -3.1212\n",
            "Total loss:  -2.9862 | PDE Loss:  -4.557 | Function Loss:  -3.1221\n",
            "Total loss:  -2.9867 | PDE Loss:  -4.5565 | Function Loss:  -3.1229\n",
            "Total loss:  -2.9872 | PDE Loss:  -4.5553 | Function Loss:  -3.1241\n",
            "Total loss:  -2.988 | PDE Loss:  -4.5559 | Function Loss:  -3.1249\n",
            "Total loss:  -2.9886 | PDE Loss:  -4.5543 | Function Loss:  -3.1264\n",
            "Total loss:  -2.9896 | PDE Loss:  -4.5548 | Function Loss:  -3.1275\n",
            "Total loss:  -2.9905 | PDE Loss:  -4.5541 | Function Loss:  -3.129\n",
            "Total loss:  -2.9917 | PDE Loss:  -4.5553 | Function Loss:  -3.1302\n",
            "Total loss:  -2.9927 | PDE Loss:  -4.5555 | Function Loss:  -3.1316\n",
            "Total loss:  -2.9938 | PDE Loss:  -4.5583 | Function Loss:  -3.1321\n",
            "Total loss:  -2.995 | PDE Loss:  -4.5596 | Function Loss:  -3.1332\n",
            "Total loss:  -2.9963 | PDE Loss:  -4.5636 | Function Loss:  -3.1335\n",
            "Total loss:  -2.9975 | PDE Loss:  -4.5703 | Function Loss:  -3.1327\n",
            "Total loss:  -2.9985 | PDE Loss:  -4.5731 | Function Loss:  -3.133\n",
            "Total loss:  -2.9998 | PDE Loss:  -4.5769 | Function Loss:  -3.1334\n",
            "Total loss:  -3.0009 | PDE Loss:  -4.5782 | Function Loss:  -3.1344\n",
            "Total loss:  -3.0028 | PDE Loss:  -4.5799 | Function Loss:  -3.1364\n",
            "Total loss:  -3.0041 | PDE Loss:  -4.5774 | Function Loss:  -3.139\n",
            "Total loss:  -3.0048 | PDE Loss:  -4.5784 | Function Loss:  -3.1397\n",
            "Total loss:  -3.0054 | PDE Loss:  -4.5794 | Function Loss:  -3.1401\n",
            "Total loss:  -3.0066 | PDE Loss:  -4.5811 | Function Loss:  -3.1411\n",
            "Total loss:  -3.0079 | PDE Loss:  -4.5846 | Function Loss:  -3.1417\n",
            "Total loss:  -3.0092 | PDE Loss:  -4.5896 | Function Loss:  -3.1416\n",
            "Total loss:  -3.0101 | PDE Loss:  -4.596 | Function Loss:  -3.1405\n",
            "Total loss:  -3.0108 | PDE Loss:  -4.5991 | Function Loss:  -3.1405\n",
            "Total loss:  -3.0115 | PDE Loss:  -4.603 | Function Loss:  -3.14\n",
            "Total loss:  -3.012 | PDE Loss:  -4.6069 | Function Loss:  -3.1393\n",
            "Total loss:  -3.0123 | PDE Loss:  -4.6099 | Function Loss:  -3.1387\n",
            "Total loss:  -3.0125 | PDE Loss:  -4.613 | Function Loss:  -3.138\n",
            "Total loss:  -3.0128 | PDE Loss:  -4.6156 | Function Loss:  -3.1374\n",
            "Total loss:  -3.0129 | PDE Loss:  -4.6174 | Function Loss:  -3.1371\n",
            "Total loss:  -3.0131 | PDE Loss:  -4.6191 | Function Loss:  -3.1367\n",
            "Total loss:  -3.0132 | PDE Loss:  -4.6195 | Function Loss:  -3.1368\n",
            "Total loss:  -3.0134 | PDE Loss:  -4.6201 | Function Loss:  -3.1368\n",
            "Total loss:  -3.0136 | PDE Loss:  -4.6191 | Function Loss:  -3.1374\n",
            "Total loss:  -3.0138 | PDE Loss:  -4.6188 | Function Loss:  -3.1377\n",
            "Total loss:  -3.014 | PDE Loss:  -4.6173 | Function Loss:  -3.1385\n",
            "Total loss:  -3.0142 | PDE Loss:  -4.6155 | Function Loss:  -3.1394\n",
            "Total loss:  -3.0145 | PDE Loss:  -4.6136 | Function Loss:  -3.1404\n",
            "Total loss:  -3.0147 | PDE Loss:  -4.6114 | Function Loss:  -3.1414\n",
            "Total loss:  -3.0149 | PDE Loss:  -4.6101 | Function Loss:  -3.1421\n",
            "Total loss:  -3.015 | PDE Loss:  -4.6086 | Function Loss:  -3.1428\n",
            "Total loss:  -3.0152 | PDE Loss:  -4.608 | Function Loss:  -3.1432\n",
            "Total loss:  -3.0153 | PDE Loss:  -4.6071 | Function Loss:  -3.1438\n",
            "Total loss:  -3.0155 | PDE Loss:  -4.6068 | Function Loss:  -3.1441\n",
            "Total loss:  -3.0157 | PDE Loss:  -4.6068 | Function Loss:  -3.1444\n",
            "Total loss:  -3.0159 | PDE Loss:  -4.6054 | Function Loss:  -3.1451\n",
            "Total loss:  -3.0159 | PDE Loss:  -4.6074 | Function Loss:  -3.1444\n",
            "Total loss:  -3.016 | PDE Loss:  -4.6065 | Function Loss:  -3.1449\n",
            "Total loss:  -3.0161 | PDE Loss:  -4.6061 | Function Loss:  -3.1452\n",
            "Total loss:  -3.0164 | PDE Loss:  -4.607 | Function Loss:  -3.1452\n",
            "Total loss:  -3.0167 | PDE Loss:  -4.6071 | Function Loss:  -3.1456\n",
            "Total loss:  -3.0171 | PDE Loss:  -4.6078 | Function Loss:  -3.146\n",
            "Total loss:  -3.0177 | PDE Loss:  -4.6075 | Function Loss:  -3.1467\n",
            "Total loss:  -3.0183 | PDE Loss:  -4.6084 | Function Loss:  -3.1473\n",
            "Total loss:  -3.019 | PDE Loss:  -4.608 | Function Loss:  -3.1484\n",
            "Total loss:  -3.0199 | PDE Loss:  -4.6102 | Function Loss:  -3.1489\n",
            "Total loss:  -3.0207 | PDE Loss:  -4.6114 | Function Loss:  -3.1495\n",
            "Total loss:  -3.022 | PDE Loss:  -4.6155 | Function Loss:  -3.1498\n",
            "Total loss:  -3.0228 | PDE Loss:  -4.6179 | Function Loss:  -3.1501\n",
            "Total loss:  -3.024 | PDE Loss:  -4.6214 | Function Loss:  -3.1505\n",
            "Total loss:  -3.0253 | PDE Loss:  -4.6248 | Function Loss:  -3.1511\n",
            "Total loss:  -3.0272 | PDE Loss:  -4.6332 | Function Loss:  -3.1509\n",
            "Total loss:  -3.0287 | PDE Loss:  -4.6385 | Function Loss:  -3.1511\n",
            "Total loss:  -3.0297 | PDE Loss:  -4.6427 | Function Loss:  -3.1511\n",
            "Total loss:  -3.0311 | PDE Loss:  -4.6431 | Function Loss:  -3.1528\n",
            "Total loss:  -3.0323 | PDE Loss:  -4.6413 | Function Loss:  -3.1549\n",
            "Total loss:  -3.0338 | PDE Loss:  -4.637 | Function Loss:  -3.1583\n",
            "Total loss:  -3.0352 | PDE Loss:  -4.638 | Function Loss:  -3.1599\n",
            "Total loss:  -3.0364 | PDE Loss:  -4.6337 | Function Loss:  -3.1629\n",
            "Total loss:  -3.0374 | PDE Loss:  -4.634 | Function Loss:  -3.1642\n",
            "Total loss:  -3.0385 | PDE Loss:  -4.6351 | Function Loss:  -3.1652\n",
            "Total loss:  -3.0393 | PDE Loss:  -4.6395 | Function Loss:  -3.1649\n",
            "Total loss:  -3.0397 | PDE Loss:  -4.64 | Function Loss:  -3.1652\n",
            "Total loss:  -3.0406 | PDE Loss:  -4.64 | Function Loss:  -3.1665\n",
            "Total loss:  -3.0412 | PDE Loss:  -4.642 | Function Loss:  -3.1665\n",
            "Total loss:  -3.0417 | PDE Loss:  -4.6437 | Function Loss:  -3.1667\n",
            "Total loss:  -3.0423 | PDE Loss:  -4.6459 | Function Loss:  -3.1667\n",
            "Total loss:  -3.0428 | PDE Loss:  -4.6495 | Function Loss:  -3.1662\n",
            "Total loss:  -3.0428 | PDE Loss:  -4.6598 | Function Loss:  -3.1629\n",
            "Total loss:  -3.0431 | PDE Loss:  -4.6547 | Function Loss:  -3.1649\n",
            "Total loss:  -3.0436 | PDE Loss:  -4.6542 | Function Loss:  -3.1657\n",
            "Total loss:  -3.0441 | PDE Loss:  -4.6576 | Function Loss:  -3.1653\n",
            "Total loss:  -3.0446 | PDE Loss:  -4.6587 | Function Loss:  -3.1657\n",
            "Total loss:  -3.0452 | PDE Loss:  -4.6607 | Function Loss:  -3.1658\n",
            "Total loss:  -3.0457 | PDE Loss:  -4.6615 | Function Loss:  -3.1661\n",
            "Total loss:  -3.0462 | PDE Loss:  -4.6634 | Function Loss:  -3.1662\n",
            "Total loss:  -3.0466 | PDE Loss:  -4.6648 | Function Loss:  -3.1663\n",
            "Total loss:  -3.0466 | PDE Loss:  -4.6653 | Function Loss:  -3.1662\n",
            "Total loss:  -3.0468 | PDE Loss:  -4.6653 | Function Loss:  -3.1664\n",
            "Total loss:  -3.0472 | PDE Loss:  -4.6697 | Function Loss:  -3.1655\n",
            "Total loss:  -3.0475 | PDE Loss:  -4.6708 | Function Loss:  -3.1656\n",
            "Total loss:  -3.048 | PDE Loss:  -4.6723 | Function Loss:  -3.1658\n",
            "Total loss:  -3.0485 | PDE Loss:  -4.6725 | Function Loss:  -3.1663\n",
            "Total loss:  -3.0488 | PDE Loss:  -4.6728 | Function Loss:  -3.1667\n",
            "Total loss:  -3.0491 | PDE Loss:  -4.673 | Function Loss:  -3.167\n",
            "Total loss:  -3.0494 | PDE Loss:  -4.6719 | Function Loss:  -3.1677\n",
            "Total loss:  -3.0497 | PDE Loss:  -4.6722 | Function Loss:  -3.168\n",
            "Total loss:  -3.0499 | PDE Loss:  -4.6723 | Function Loss:  -3.1683\n",
            "Total loss:  -3.0501 | PDE Loss:  -4.6731 | Function Loss:  -3.1682\n",
            "Total loss:  -3.0503 | PDE Loss:  -4.6732 | Function Loss:  -3.1685\n",
            "Total loss:  -3.0493 | PDE Loss:  -4.679 | Function Loss:  -3.1654\n",
            "Total loss:  -3.0503 | PDE Loss:  -4.6745 | Function Loss:  -3.1681\n",
            "Total loss:  -3.0505 | PDE Loss:  -4.675 | Function Loss:  -3.1682\n",
            "Total loss:  -3.0507 | PDE Loss:  -4.6757 | Function Loss:  -3.1682\n",
            "Total loss:  -3.0509 | PDE Loss:  -4.6767 | Function Loss:  -3.1681\n",
            "Total loss:  -3.0512 | PDE Loss:  -4.6757 | Function Loss:  -3.1689\n",
            "Total loss:  -3.0513 | PDE Loss:  -4.6763 | Function Loss:  -3.1689\n",
            "Total loss:  -3.0516 | PDE Loss:  -4.6767 | Function Loss:  -3.1691\n",
            "Total loss:  -3.0517 | PDE Loss:  -4.6764 | Function Loss:  -3.1693\n",
            "Total loss:  -3.0518 | PDE Loss:  -4.6762 | Function Loss:  -3.1696\n",
            "Total loss:  -3.0519 | PDE Loss:  -4.6761 | Function Loss:  -3.1698\n",
            "Total loss:  -3.0521 | PDE Loss:  -4.6759 | Function Loss:  -3.17\n",
            "Total loss:  -3.0522 | PDE Loss:  -4.6766 | Function Loss:  -3.1699\n",
            "Total loss:  -3.0524 | PDE Loss:  -4.6779 | Function Loss:  -3.1698\n",
            "Total loss:  -3.0527 | PDE Loss:  -4.6802 | Function Loss:  -3.1694\n",
            "Total loss:  -3.053 | PDE Loss:  -4.6807 | Function Loss:  -3.1697\n",
            "Total loss:  -3.0534 | PDE Loss:  -4.6885 | Function Loss:  -3.1678\n",
            "Total loss:  -3.0533 | PDE Loss:  -4.6815 | Function Loss:  -3.1698\n",
            "Total loss:  -3.0538 | PDE Loss:  -4.6859 | Function Loss:  -3.1691\n",
            "Total loss:  -3.0541 | PDE Loss:  -4.6854 | Function Loss:  -3.1697\n",
            "Total loss:  -3.0554 | PDE Loss:  -4.6953 | Function Loss:  -3.1684\n",
            "Total loss:  -3.0565 | PDE Loss:  -4.694 | Function Loss:  -3.1702\n",
            "Total loss:  -3.0575 | PDE Loss:  -4.6917 | Function Loss:  -3.1722\n",
            "Total loss:  -3.0585 | PDE Loss:  -4.6881 | Function Loss:  -3.1746\n",
            "Total loss:  -3.0593 | PDE Loss:  -4.6851 | Function Loss:  -3.1766\n",
            "Total loss:  -3.0602 | PDE Loss:  -4.6806 | Function Loss:  -3.1792\n",
            "Total loss:  -3.0611 | PDE Loss:  -4.6775 | Function Loss:  -3.1813\n",
            "Total loss:  -3.0619 | PDE Loss:  -4.6728 | Function Loss:  -3.1839\n",
            "Total loss:  -3.0627 | PDE Loss:  -4.6701 | Function Loss:  -3.1859\n",
            "Total loss:  -3.0636 | PDE Loss:  -4.6665 | Function Loss:  -3.1882\n",
            "Total loss:  -3.0645 | PDE Loss:  -4.665 | Function Loss:  -3.19\n",
            "Total loss:  -3.0655 | PDE Loss:  -4.6615 | Function Loss:  -3.1925\n",
            "Total loss:  -3.0664 | PDE Loss:  -4.6608 | Function Loss:  -3.194\n",
            "Total loss:  -3.0674 | PDE Loss:  -4.6602 | Function Loss:  -3.1954\n",
            "Total loss:  -3.0686 | PDE Loss:  -4.6611 | Function Loss:  -3.1967\n",
            "Total loss:  -3.0697 | PDE Loss:  -4.6592 | Function Loss:  -3.1989\n",
            "Total loss:  -3.0707 | PDE Loss:  -4.6607 | Function Loss:  -3.1998\n",
            "Total loss:  -3.0717 | PDE Loss:  -4.6594 | Function Loss:  -3.2015\n",
            "Total loss:  -3.0734 | PDE Loss:  -4.659 | Function Loss:  -3.204\n",
            "Total loss:  -3.0755 | PDE Loss:  -4.6532 | Function Loss:  -3.2088\n",
            "Total loss:  -3.0771 | PDE Loss:  -4.6519 | Function Loss:  -3.2116\n",
            "Total loss:  -3.0786 | PDE Loss:  -4.6496 | Function Loss:  -3.2144\n",
            "Total loss:  -3.0798 | PDE Loss:  -4.6444 | Function Loss:  -3.218\n",
            "Total loss:  -3.0809 | PDE Loss:  -4.6397 | Function Loss:  -3.2213\n",
            "Total loss:  -3.0822 | PDE Loss:  -4.6392 | Function Loss:  -3.2232\n",
            "Total loss:  -3.0831 | PDE Loss:  -4.6377 | Function Loss:  -3.2251\n",
            "Total loss:  -3.084 | PDE Loss:  -4.6371 | Function Loss:  -3.2266\n",
            "Total loss:  -3.0847 | PDE Loss:  -4.6383 | Function Loss:  -3.2271\n",
            "Total loss:  -3.0856 | PDE Loss:  -4.6392 | Function Loss:  -3.2279\n",
            "Total loss:  -3.0865 | PDE Loss:  -4.6398 | Function Loss:  -3.229\n",
            "Total loss:  -3.0876 | PDE Loss:  -4.6448 | Function Loss:  -3.2286\n",
            "Total loss:  -3.0884 | PDE Loss:  -4.6437 | Function Loss:  -3.2302\n",
            "Total loss:  -3.089 | PDE Loss:  -4.6448 | Function Loss:  -3.2306\n",
            "Total loss:  -3.0896 | PDE Loss:  -4.6471 | Function Loss:  -3.2304\n",
            "Total loss:  -3.09 | PDE Loss:  -4.6464 | Function Loss:  -3.2313\n",
            "Total loss:  -3.0904 | PDE Loss:  -4.6473 | Function Loss:  -3.2315\n",
            "Total loss:  -3.091 | PDE Loss:  -4.6492 | Function Loss:  -3.2316\n",
            "Total loss:  -3.0918 | PDE Loss:  -4.6508 | Function Loss:  -3.2321\n",
            "Total loss:  -3.0924 | PDE Loss:  -4.6522 | Function Loss:  -3.2324\n",
            "Total loss:  -3.0932 | PDE Loss:  -4.6549 | Function Loss:  -3.2325\n",
            "Total loss:  -3.0941 | PDE Loss:  -4.6563 | Function Loss:  -3.2331\n",
            "Total loss:  -3.0946 | PDE Loss:  -4.6578 | Function Loss:  -3.2334\n",
            "Total loss:  -3.0952 | PDE Loss:  -4.6592 | Function Loss:  -3.2336\n",
            "Total loss:  -3.0957 | PDE Loss:  -4.6598 | Function Loss:  -3.2341\n",
            "Total loss:  -3.0962 | PDE Loss:  -4.6627 | Function Loss:  -3.2337\n",
            "Total loss:  -3.0968 | PDE Loss:  -4.6617 | Function Loss:  -3.2349\n",
            "Total loss:  -3.0974 | PDE Loss:  -4.6622 | Function Loss:  -3.2355\n",
            "Total loss:  -3.0983 | PDE Loss:  -4.66 | Function Loss:  -3.2376\n",
            "Total loss:  -3.0996 | PDE Loss:  -4.6587 | Function Loss:  -3.2399\n",
            "Total loss:  -3.1005 | PDE Loss:  -4.6577 | Function Loss:  -3.2414\n",
            "Total loss:  -3.101 | PDE Loss:  -4.6573 | Function Loss:  -3.2424\n",
            "Total loss:  -3.1015 | PDE Loss:  -4.6563 | Function Loss:  -3.2434\n",
            "Total loss:  -3.102 | PDE Loss:  -4.657 | Function Loss:  -3.2438\n",
            "Total loss:  -3.1023 | PDE Loss:  -4.6575 | Function Loss:  -3.2441\n",
            "Total loss:  -3.1027 | PDE Loss:  -4.6568 | Function Loss:  -3.2449\n",
            "Total loss:  -3.1029 | PDE Loss:  -4.6576 | Function Loss:  -3.2448\n",
            "Total loss:  -3.103 | PDE Loss:  -4.6585 | Function Loss:  -3.2447\n",
            "Total loss:  -3.1031 | PDE Loss:  -4.6593 | Function Loss:  -3.2445\n",
            "Total loss:  -3.1032 | PDE Loss:  -4.6624 | Function Loss:  -3.2434\n",
            "Total loss:  -3.1033 | PDE Loss:  -4.6662 | Function Loss:  -3.2421\n",
            "Total loss:  -3.1034 | PDE Loss:  -4.6661 | Function Loss:  -3.2423\n",
            "Total loss:  -3.1035 | PDE Loss:  -4.6657 | Function Loss:  -3.2426\n",
            "Total loss:  -3.1036 | PDE Loss:  -4.6664 | Function Loss:  -3.2425\n",
            "Total loss:  -3.1037 | PDE Loss:  -4.6673 | Function Loss:  -3.2423\n",
            "Total loss:  -3.1039 | PDE Loss:  -4.6679 | Function Loss:  -3.2423\n",
            "Total loss:  -3.1039 | PDE Loss:  -4.669 | Function Loss:  -3.242\n",
            "Total loss:  -3.104 | PDE Loss:  -4.669 | Function Loss:  -3.2421\n",
            "Total loss:  -3.1041 | PDE Loss:  -4.6691 | Function Loss:  -3.2421\n",
            "Total loss:  -3.1041 | PDE Loss:  -4.6694 | Function Loss:  -3.2421\n",
            "Total loss:  -3.1042 | PDE Loss:  -4.6685 | Function Loss:  -3.2425\n",
            "Total loss:  -3.1043 | PDE Loss:  -4.6678 | Function Loss:  -3.2429\n",
            "Total loss:  -3.1044 | PDE Loss:  -4.6664 | Function Loss:  -3.2436\n",
            "Total loss:  -3.1046 | PDE Loss:  -4.665 | Function Loss:  -3.2443\n",
            "Total loss:  -3.1047 | PDE Loss:  -4.6636 | Function Loss:  -3.2451\n",
            "Total loss:  -3.1049 | PDE Loss:  -4.663 | Function Loss:  -3.2455\n",
            "Total loss:  -3.1033 | PDE Loss:  -4.6434 | Function Loss:  -3.2511\n",
            "Total loss:  -3.105 | PDE Loss:  -4.6597 | Function Loss:  -3.2469\n",
            "Total loss:  -3.1052 | PDE Loss:  -4.6601 | Function Loss:  -3.2471\n",
            "Total loss:  -3.1055 | PDE Loss:  -4.6608 | Function Loss:  -3.2472\n",
            "Total loss:  -3.1058 | PDE Loss:  -4.6619 | Function Loss:  -3.2472\n",
            "Total loss:  -3.1062 | PDE Loss:  -4.6645 | Function Loss:  -3.2467\n",
            "Total loss:  -3.1065 | PDE Loss:  -4.6654 | Function Loss:  -3.2468\n",
            "Total loss:  -3.1068 | PDE Loss:  -4.6665 | Function Loss:  -3.2469\n",
            "Total loss:  -3.1074 | PDE Loss:  -4.6669 | Function Loss:  -3.2475\n",
            "Total loss:  -3.1057 | PDE Loss:  -4.6668 | Function Loss:  -3.2452\n",
            "Total loss:  -3.1076 | PDE Loss:  -4.6675 | Function Loss:  -3.2476\n",
            "Total loss:  -3.1082 | PDE Loss:  -4.6675 | Function Loss:  -3.2484\n",
            "Total loss:  -3.1089 | PDE Loss:  -4.6668 | Function Loss:  -3.2496\n",
            "Total loss:  -3.1096 | PDE Loss:  -4.6665 | Function Loss:  -3.2507\n",
            "Total loss:  -3.1103 | PDE Loss:  -4.6651 | Function Loss:  -3.2522\n",
            "Total loss:  -3.1111 | PDE Loss:  -4.6638 | Function Loss:  -3.2539\n",
            "Total loss:  -3.1118 | PDE Loss:  -4.6624 | Function Loss:  -3.2553\n",
            "Total loss:  -3.1125 | PDE Loss:  -4.6603 | Function Loss:  -3.2572\n",
            "Total loss:  -3.1134 | PDE Loss:  -4.6584 | Function Loss:  -3.2592\n",
            "Total loss:  -3.1142 | PDE Loss:  -4.656 | Function Loss:  -3.2612\n",
            "Total loss:  -3.1152 | PDE Loss:  -4.6538 | Function Loss:  -3.2636\n",
            "Total loss:  -3.1162 | PDE Loss:  -4.6452 | Function Loss:  -3.2685\n",
            "Total loss:  -3.1174 | PDE Loss:  -4.6423 | Function Loss:  -3.2714\n",
            "Total loss:  -3.1186 | PDE Loss:  -4.6439 | Function Loss:  -3.2724\n",
            "Total loss:  -3.12 | PDE Loss:  -4.6448 | Function Loss:  -3.2741\n",
            "Total loss:  -3.1213 | PDE Loss:  -4.6439 | Function Loss:  -3.2762\n",
            "Total loss:  -3.1224 | PDE Loss:  -4.6461 | Function Loss:  -3.2769\n",
            "Total loss:  -3.123 | PDE Loss:  -4.644 | Function Loss:  -3.2787\n",
            "Total loss:  -3.1248 | PDE Loss:  -4.6426 | Function Loss:  -3.2819\n",
            "Total loss:  -3.1261 | PDE Loss:  -4.6433 | Function Loss:  -3.2835\n",
            "Total loss:  -3.1278 | PDE Loss:  -4.6421 | Function Loss:  -3.2864\n",
            "Total loss:  -3.1301 | PDE Loss:  -4.6377 | Function Loss:  -3.2917\n",
            "Total loss:  -3.1311 | PDE Loss:  -4.6291 | Function Loss:  -3.2971\n",
            "Total loss:  -3.1323 | PDE Loss:  -4.6224 | Function Loss:  -3.3021\n",
            "Total loss:  -3.1335 | PDE Loss:  -4.6249 | Function Loss:  -3.3026\n",
            "Total loss:  -3.1348 | PDE Loss:  -4.6228 | Function Loss:  -3.3056\n",
            "Total loss:  -3.1364 | PDE Loss:  -4.6205 | Function Loss:  -3.3091\n",
            "Total loss:  -3.138 | PDE Loss:  -4.6165 | Function Loss:  -3.3135\n",
            "Total loss:  -3.1392 | PDE Loss:  -4.6125 | Function Loss:  -3.3173\n",
            "Total loss:  -3.1402 | PDE Loss:  -4.6082 | Function Loss:  -3.3209\n",
            "Total loss:  -3.1413 | PDE Loss:  -4.6033 | Function Loss:  -3.3251\n",
            "Total loss:  -3.1422 | PDE Loss:  -4.6005 | Function Loss:  -3.328\n",
            "Total loss:  -3.1431 | PDE Loss:  -4.5978 | Function Loss:  -3.3308\n",
            "Total loss:  -3.144 | PDE Loss:  -4.5947 | Function Loss:  -3.3339\n",
            "Total loss:  -3.1449 | PDE Loss:  -4.5968 | Function Loss:  -3.3341\n",
            "Total loss:  -3.1456 | PDE Loss:  -4.5949 | Function Loss:  -3.3363\n",
            "Total loss:  -3.1464 | PDE Loss:  -4.5917 | Function Loss:  -3.3393\n",
            "Total loss:  -3.1472 | PDE Loss:  -4.5931 | Function Loss:  -3.3398\n",
            "Total loss:  -3.1479 | PDE Loss:  -4.5943 | Function Loss:  -3.3402\n",
            "Total loss:  -3.1489 | PDE Loss:  -4.5948 | Function Loss:  -3.3414\n",
            "Total loss:  -3.1498 | PDE Loss:  -4.5965 | Function Loss:  -3.3419\n",
            "Total loss:  -3.1506 | PDE Loss:  -4.5958 | Function Loss:  -3.3436\n",
            "Total loss:  -3.1514 | PDE Loss:  -4.5984 | Function Loss:  -3.3435\n",
            "Total loss:  -3.1521 | PDE Loss:  -4.5994 | Function Loss:  -3.3439\n",
            "Total loss:  -3.1527 | PDE Loss:  -4.6 | Function Loss:  -3.3446\n",
            "Total loss:  -3.1533 | PDE Loss:  -4.6015 | Function Loss:  -3.3446\n",
            "Total loss:  -3.1537 | PDE Loss:  -4.6052 | Function Loss:  -3.3432\n",
            "Total loss:  -3.154 | PDE Loss:  -4.604 | Function Loss:  -3.3444\n",
            "Total loss:  -3.1544 | PDE Loss:  -4.6045 | Function Loss:  -3.3446\n",
            "Total loss:  -3.1548 | PDE Loss:  -4.6046 | Function Loss:  -3.3452\n",
            "Total loss:  -3.1551 | PDE Loss:  -4.6053 | Function Loss:  -3.3453\n",
            "Total loss:  -3.1553 | PDE Loss:  -4.605 | Function Loss:  -3.3458\n",
            "Total loss:  -3.1555 | PDE Loss:  -4.605 | Function Loss:  -3.3461\n",
            "Total loss:  -3.1556 | PDE Loss:  -4.605 | Function Loss:  -3.3463\n",
            "Total loss:  -3.1559 | PDE Loss:  -4.6049 | Function Loss:  -3.3467\n",
            "Total loss:  -3.1561 | PDE Loss:  -4.6054 | Function Loss:  -3.3468\n",
            "Total loss:  -3.1564 | PDE Loss:  -4.605 | Function Loss:  -3.3474\n",
            "Total loss:  -3.1566 | PDE Loss:  -4.6083 | Function Loss:  -3.346\n",
            "Total loss:  -3.1568 | PDE Loss:  -4.6088 | Function Loss:  -3.3461\n",
            "Total loss:  -3.1572 | PDE Loss:  -4.6093 | Function Loss:  -3.3463\n",
            "Total loss:  -3.1575 | PDE Loss:  -4.6107 | Function Loss:  -3.346\n",
            "Total loss:  -3.1577 | PDE Loss:  -4.612 | Function Loss:  -3.3458\n",
            "Total loss:  -3.158 | PDE Loss:  -4.6139 | Function Loss:  -3.3451\n",
            "Total loss:  -3.1583 | PDE Loss:  -4.6156 | Function Loss:  -3.3447\n",
            "Total loss:  -3.1587 | PDE Loss:  -4.6167 | Function Loss:  -3.3446\n",
            "Total loss:  -3.159 | PDE Loss:  -4.6185 | Function Loss:  -3.3441\n",
            "Total loss:  -3.1592 | PDE Loss:  -4.6192 | Function Loss:  -3.3441\n",
            "Total loss:  -3.1594 | PDE Loss:  -4.6207 | Function Loss:  -3.3437\n",
            "Total loss:  -3.1596 | PDE Loss:  -4.6216 | Function Loss:  -3.3435\n",
            "Total loss:  -3.1598 | PDE Loss:  -4.6226 | Function Loss:  -3.3432\n",
            "Total loss:  -3.16 | PDE Loss:  -4.624 | Function Loss:  -3.3428\n",
            "Total loss:  -3.1603 | PDE Loss:  -4.6253 | Function Loss:  -3.3425\n",
            "Total loss:  -3.1605 | PDE Loss:  -4.6272 | Function Loss:  -3.342\n",
            "Total loss:  -3.1608 | PDE Loss:  -4.6283 | Function Loss:  -3.3418\n",
            "Total loss:  -3.1611 | PDE Loss:  -4.6293 | Function Loss:  -3.3417\n",
            "Total loss:  -3.1614 | PDE Loss:  -4.629 | Function Loss:  -3.3423\n",
            "Total loss:  -3.1617 | PDE Loss:  -4.6295 | Function Loss:  -3.3426\n",
            "Total loss:  -3.162 | PDE Loss:  -4.6295 | Function Loss:  -3.343\n",
            "Total loss:  -3.1613 | PDE Loss:  -4.6349 | Function Loss:  -3.3392\n",
            "Total loss:  -3.1622 | PDE Loss:  -4.6313 | Function Loss:  -3.3424\n",
            "Total loss:  -3.1627 | PDE Loss:  -4.6307 | Function Loss:  -3.3434\n",
            "Total loss:  -3.1633 | PDE Loss:  -4.6303 | Function Loss:  -3.3446\n",
            "Total loss:  -3.1639 | PDE Loss:  -4.6298 | Function Loss:  -3.3456\n",
            "Total loss:  -3.1644 | PDE Loss:  -4.6292 | Function Loss:  -3.3467\n",
            "Total loss:  -3.1648 | PDE Loss:  -4.629 | Function Loss:  -3.3475\n",
            "Total loss:  -3.1653 | PDE Loss:  -4.6285 | Function Loss:  -3.3485\n",
            "Total loss:  -3.1657 | PDE Loss:  -4.6284 | Function Loss:  -3.3492\n",
            "Total loss:  -3.1662 | PDE Loss:  -4.6282 | Function Loss:  -3.35\n",
            "Total loss:  -3.1666 | PDE Loss:  -4.6284 | Function Loss:  -3.3506\n",
            "Total loss:  -3.167 | PDE Loss:  -4.6287 | Function Loss:  -3.351\n",
            "Total loss:  -3.1674 | PDE Loss:  -4.6293 | Function Loss:  -3.3513\n",
            "Total loss:  -3.1678 | PDE Loss:  -4.6314 | Function Loss:  -3.3508\n",
            "Total loss:  -3.1683 | PDE Loss:  -4.6327 | Function Loss:  -3.3508\n",
            "Total loss:  -3.167 | PDE Loss:  -4.6375 | Function Loss:  -3.3465\n",
            "Total loss:  -3.1685 | PDE Loss:  -4.6346 | Function Loss:  -3.3502\n",
            "Total loss:  -3.1689 | PDE Loss:  -4.6408 | Function Loss:  -3.3476\n",
            "Total loss:  -3.1692 | PDE Loss:  -4.6378 | Function Loss:  -3.3497\n",
            "Total loss:  -3.1695 | PDE Loss:  -4.6399 | Function Loss:  -3.3491\n",
            "Total loss:  -3.1699 | PDE Loss:  -4.6393 | Function Loss:  -3.3499\n",
            "Total loss:  -3.1704 | PDE Loss:  -4.6384 | Function Loss:  -3.3511\n",
            "Total loss:  -3.1708 | PDE Loss:  -4.6369 | Function Loss:  -3.3524\n",
            "Total loss:  -3.1712 | PDE Loss:  -4.6403 | Function Loss:  -3.3513\n",
            "Total loss:  -3.1716 | PDE Loss:  -4.6401 | Function Loss:  -3.3521\n",
            "Total loss:  -3.1722 | PDE Loss:  -4.6382 | Function Loss:  -3.354\n",
            "Total loss:  -3.1729 | PDE Loss:  -4.6395 | Function Loss:  -3.3543\n",
            "Total loss:  -3.1734 | PDE Loss:  -4.6407 | Function Loss:  -3.3545\n",
            "Total loss:  -3.1742 | PDE Loss:  -4.6432 | Function Loss:  -3.3544\n",
            "Total loss:  -3.1747 | PDE Loss:  -4.6467 | Function Loss:  -3.3534\n",
            "Total loss:  -3.1751 | PDE Loss:  -4.6487 | Function Loss:  -3.353\n",
            "Total loss:  -3.1755 | PDE Loss:  -4.6518 | Function Loss:  -3.3521\n",
            "Total loss:  -3.176 | PDE Loss:  -4.6547 | Function Loss:  -3.3512\n",
            "Total loss:  -3.1763 | PDE Loss:  -4.6539 | Function Loss:  -3.3521\n",
            "Total loss:  -3.1767 | PDE Loss:  -4.6533 | Function Loss:  -3.353\n",
            "Total loss:  -3.1771 | PDE Loss:  -4.6511 | Function Loss:  -3.3548\n",
            "Total loss:  -3.1777 | PDE Loss:  -4.6506 | Function Loss:  -3.3559\n",
            "Total loss:  -3.1781 | PDE Loss:  -4.6491 | Function Loss:  -3.3572\n",
            "Total loss:  -3.1782 | PDE Loss:  -4.6495 | Function Loss:  -3.3572\n",
            "Total loss:  -3.1785 | PDE Loss:  -4.649 | Function Loss:  -3.3579\n",
            "Total loss:  -3.1787 | PDE Loss:  -4.649 | Function Loss:  -3.3582\n",
            "Total loss:  -3.1789 | PDE Loss:  -4.6493 | Function Loss:  -3.3583\n",
            "Total loss:  -3.1791 | PDE Loss:  -4.6504 | Function Loss:  -3.3581\n",
            "Total loss:  -3.1793 | PDE Loss:  -4.6516 | Function Loss:  -3.3579\n",
            "Total loss:  -3.1795 | PDE Loss:  -4.6525 | Function Loss:  -3.3577\n",
            "Total loss:  -3.1797 | PDE Loss:  -4.6534 | Function Loss:  -3.3575\n",
            "Total loss:  -3.1799 | PDE Loss:  -4.6536 | Function Loss:  -3.3576\n",
            "Total loss:  -3.18 | PDE Loss:  -4.6533 | Function Loss:  -3.358\n",
            "Total loss:  -3.1729 | PDE Loss:  -4.6624 | Function Loss:  -3.3429\n",
            "Total loss:  -3.18 | PDE Loss:  -4.6543 | Function Loss:  -3.3576\n",
            "Total loss:  -3.1802 | PDE Loss:  -4.6537 | Function Loss:  -3.3581\n",
            "Total loss:  -3.1803 | PDE Loss:  -4.6527 | Function Loss:  -3.3588\n",
            "Total loss:  -3.1805 | PDE Loss:  -4.6516 | Function Loss:  -3.3596\n",
            "Total loss:  -3.1806 | PDE Loss:  -4.6503 | Function Loss:  -3.3605\n",
            "Total loss:  -3.1808 | PDE Loss:  -4.6487 | Function Loss:  -3.3616\n",
            "Total loss:  -3.1811 | PDE Loss:  -4.6467 | Function Loss:  -3.363\n",
            "Total loss:  -3.1813 | PDE Loss:  -4.6449 | Function Loss:  -3.3643\n",
            "Total loss:  -3.1815 | PDE Loss:  -4.6429 | Function Loss:  -3.3657\n",
            "Total loss:  -3.1818 | PDE Loss:  -4.6412 | Function Loss:  -3.367\n",
            "Total loss:  -3.182 | PDE Loss:  -4.6395 | Function Loss:  -3.3682\n",
            "Total loss:  -3.1822 | PDE Loss:  -4.6386 | Function Loss:  -3.369\n",
            "Total loss:  -3.1825 | PDE Loss:  -4.6381 | Function Loss:  -3.3697\n",
            "Total loss:  -3.1829 | PDE Loss:  -4.6381 | Function Loss:  -3.3703\n",
            "Total loss:  -3.1833 | PDE Loss:  -4.6387 | Function Loss:  -3.3707\n",
            "Total loss:  -3.1836 | PDE Loss:  -4.6397 | Function Loss:  -3.3707\n",
            "Total loss:  -3.1841 | PDE Loss:  -4.641 | Function Loss:  -3.3707\n",
            "Total loss:  -3.1846 | PDE Loss:  -4.6412 | Function Loss:  -3.3714\n",
            "Total loss:  -3.1851 | PDE Loss:  -4.6425 | Function Loss:  -3.3714\n",
            "Total loss:  -3.1857 | PDE Loss:  -4.6426 | Function Loss:  -3.3722\n",
            "Total loss:  -3.1863 | PDE Loss:  -4.6426 | Function Loss:  -3.3732\n",
            "Total loss:  -3.1869 | PDE Loss:  -4.6424 | Function Loss:  -3.3741\n",
            "Total loss:  -3.1873 | PDE Loss:  -4.6418 | Function Loss:  -3.3752\n",
            "Total loss:  -3.1878 | PDE Loss:  -4.641 | Function Loss:  -3.3763\n",
            "Total loss:  -3.1886 | PDE Loss:  -4.6397 | Function Loss:  -3.3782\n",
            "Total loss:  -3.1725 | PDE Loss:  -4.6458 | Function Loss:  -3.3504\n",
            "Total loss:  -3.1889 | PDE Loss:  -4.6412 | Function Loss:  -3.3779\n",
            "Total loss:  -3.1895 | PDE Loss:  -4.639 | Function Loss:  -3.38\n",
            "Total loss:  -3.19 | PDE Loss:  -4.6374 | Function Loss:  -3.3817\n",
            "Total loss:  -3.1903 | PDE Loss:  -4.6372 | Function Loss:  -3.3823\n",
            "Total loss:  -3.1906 | PDE Loss:  -4.636 | Function Loss:  -3.3834\n",
            "Total loss:  -3.1909 | PDE Loss:  -4.6352 | Function Loss:  -3.3844\n",
            "Total loss:  -3.1914 | PDE Loss:  -4.6336 | Function Loss:  -3.3861\n",
            "Total loss:  -3.192 | PDE Loss:  -4.6299 | Function Loss:  -3.3892\n",
            "Total loss:  -3.1926 | PDE Loss:  -4.6298 | Function Loss:  -3.39\n",
            "Total loss:  -3.1932 | PDE Loss:  -4.6285 | Function Loss:  -3.3918\n",
            "Total loss:  -3.1941 | PDE Loss:  -4.6331 | Function Loss:  -3.3906\n",
            "Total loss:  -3.1949 | PDE Loss:  -4.6316 | Function Loss:  -3.3928\n",
            "Total loss:  -3.1956 | PDE Loss:  -4.6324 | Function Loss:  -3.3934\n",
            "Total loss:  -3.1964 | PDE Loss:  -4.6361 | Function Loss:  -3.3925\n",
            "Total loss:  -3.197 | PDE Loss:  -4.6377 | Function Loss:  -3.3926\n",
            "Total loss:  -3.1976 | PDE Loss:  -4.6404 | Function Loss:  -3.392\n",
            "Total loss:  -3.1983 | PDE Loss:  -4.642 | Function Loss:  -3.3921\n",
            "Total loss:  -3.199 | PDE Loss:  -4.6421 | Function Loss:  -3.3932\n",
            "Total loss:  -3.1997 | PDE Loss:  -4.6443 | Function Loss:  -3.393\n",
            "Total loss:  -3.2001 | PDE Loss:  -4.6453 | Function Loss:  -3.3931\n",
            "Total loss:  -3.2005 | PDE Loss:  -4.6451 | Function Loss:  -3.3938\n",
            "Total loss:  -3.2008 | PDE Loss:  -4.6465 | Function Loss:  -3.3935\n",
            "Total loss:  -3.2012 | PDE Loss:  -4.6452 | Function Loss:  -3.3948\n",
            "Total loss:  -3.2015 | PDE Loss:  -4.6461 | Function Loss:  -3.3948\n",
            "Total loss:  -3.2018 | PDE Loss:  -4.6462 | Function Loss:  -3.3953\n",
            "Total loss:  -3.2022 | PDE Loss:  -4.646 | Function Loss:  -3.396\n",
            "Total loss:  -3.2023 | PDE Loss:  -4.6495 | Function Loss:  -3.3942\n",
            "Total loss:  -3.2027 | PDE Loss:  -4.6459 | Function Loss:  -3.3968\n",
            "Total loss:  -3.2031 | PDE Loss:  -4.644 | Function Loss:  -3.3985\n",
            "Total loss:  -3.2034 | PDE Loss:  -4.6429 | Function Loss:  -3.3997\n",
            "Total loss:  -3.204 | PDE Loss:  -4.6409 | Function Loss:  -3.4016\n",
            "Total loss:  -3.2045 | PDE Loss:  -4.6408 | Function Loss:  -3.4025\n",
            "Total loss:  -3.2049 | PDE Loss:  -4.6409 | Function Loss:  -3.4031\n",
            "Total loss:  -3.2052 | PDE Loss:  -4.6367 | Function Loss:  -3.4061\n",
            "Total loss:  -3.1984 | PDE Loss:  -4.6584 | Function Loss:  -3.3833\n",
            "Total loss:  -3.2055 | PDE Loss:  -4.6403 | Function Loss:  -3.4043\n",
            "Total loss:  -3.2058 | PDE Loss:  -4.6425 | Function Loss:  -3.4036\n",
            "Total loss:  -3.2061 | PDE Loss:  -4.6434 | Function Loss:  -3.4036\n",
            "Total loss:  -3.2065 | PDE Loss:  -4.6455 | Function Loss:  -3.4029\n",
            "Total loss:  -3.2067 | PDE Loss:  -4.6463 | Function Loss:  -3.4028\n",
            "Total loss:  -3.2069 | PDE Loss:  -4.6469 | Function Loss:  -3.4028\n",
            "Total loss:  -3.2072 | PDE Loss:  -4.6488 | Function Loss:  -3.4023\n",
            "Total loss:  -3.2044 | PDE Loss:  -4.6388 | Function Loss:  -3.4035\n",
            "Total loss:  -3.2074 | PDE Loss:  -4.6478 | Function Loss:  -3.4031\n",
            "Total loss:  -3.2079 | PDE Loss:  -4.6486 | Function Loss:  -3.4034\n",
            "Total loss:  -3.2085 | PDE Loss:  -4.6511 | Function Loss:  -3.403\n",
            "Total loss:  -3.2093 | PDE Loss:  -4.6539 | Function Loss:  -3.4026\n",
            "Total loss:  -3.21 | PDE Loss:  -4.6543 | Function Loss:  -3.4034\n",
            "Total loss:  -3.2108 | PDE Loss:  -4.6553 | Function Loss:  -3.4041\n",
            "Total loss:  -3.2114 | PDE Loss:  -4.6555 | Function Loss:  -3.405\n",
            "Total loss:  -3.2118 | PDE Loss:  -4.6549 | Function Loss:  -3.406\n",
            "Total loss:  -3.2123 | PDE Loss:  -4.6536 | Function Loss:  -3.4075\n",
            "Total loss:  -3.2125 | PDE Loss:  -4.6509 | Function Loss:  -3.4093\n",
            "Total loss:  -3.213 | PDE Loss:  -4.6498 | Function Loss:  -3.4108\n",
            "Total loss:  -3.2135 | PDE Loss:  -4.6496 | Function Loss:  -3.4117\n",
            "Total loss:  -3.2141 | PDE Loss:  -4.6494 | Function Loss:  -3.4127\n",
            "Total loss:  -3.2147 | PDE Loss:  -4.6482 | Function Loss:  -3.4143\n",
            "Total loss:  -3.2152 | PDE Loss:  -4.648 | Function Loss:  -3.4152\n",
            "Total loss:  -3.2156 | PDE Loss:  -4.6488 | Function Loss:  -3.4154\n",
            "Total loss:  -3.2161 | PDE Loss:  -4.6489 | Function Loss:  -3.4162\n",
            "Total loss:  -3.2166 | PDE Loss:  -4.6511 | Function Loss:  -3.4157\n",
            "Total loss:  -3.2106 | PDE Loss:  -4.6102 | Function Loss:  -3.4314\n",
            "Total loss:  -3.2168 | PDE Loss:  -4.6457 | Function Loss:  -3.4192\n",
            "Total loss:  -3.2173 | PDE Loss:  -4.6472 | Function Loss:  -3.419\n",
            "Total loss:  -3.2179 | PDE Loss:  -4.649 | Function Loss:  -3.419\n",
            "Total loss:  -3.2186 | PDE Loss:  -4.6501 | Function Loss:  -3.4194\n",
            "Total loss:  -3.2192 | PDE Loss:  -4.6492 | Function Loss:  -3.4209\n",
            "Total loss:  -3.2197 | PDE Loss:  -4.6496 | Function Loss:  -3.4215\n",
            "Total loss:  -3.2202 | PDE Loss:  -4.6473 | Function Loss:  -3.4236\n",
            "Total loss:  -3.2208 | PDE Loss:  -4.6451 | Function Loss:  -3.4259\n",
            "Total loss:  -3.2214 | PDE Loss:  -4.6426 | Function Loss:  -3.4284\n",
            "Total loss:  -3.222 | PDE Loss:  -4.6404 | Function Loss:  -3.4307\n",
            "Total loss:  -3.2227 | PDE Loss:  -4.6391 | Function Loss:  -3.4327\n",
            "Total loss:  -3.2234 | PDE Loss:  -4.6395 | Function Loss:  -3.4335\n",
            "Total loss:  -3.224 | PDE Loss:  -4.6396 | Function Loss:  -3.4345\n",
            "Total loss:  -3.2247 | PDE Loss:  -4.6416 | Function Loss:  -3.4343\n",
            "Total loss:  -3.2254 | PDE Loss:  -4.6443 | Function Loss:  -3.4337\n",
            "Total loss:  -3.2222 | PDE Loss:  -4.6671 | Function Loss:  -3.4153\n",
            "Total loss:  -3.2256 | PDE Loss:  -4.6501 | Function Loss:  -3.4307\n",
            "Total loss:  -3.2269 | PDE Loss:  -4.652 | Function Loss:  -3.4315\n",
            "Total loss:  -3.2281 | PDE Loss:  -4.6559 | Function Loss:  -3.4311\n",
            "Total loss:  -3.2294 | PDE Loss:  -4.662 | Function Loss:  -3.4296\n",
            "Total loss:  -3.2308 | PDE Loss:  -4.6647 | Function Loss:  -3.4302\n",
            "Total loss:  -3.2316 | PDE Loss:  -4.6709 | Function Loss:  -3.4279\n",
            "Total loss:  -3.2329 | PDE Loss:  -4.6738 | Function Loss:  -3.4283\n",
            "Total loss:  -3.2343 | PDE Loss:  -4.6723 | Function Loss:  -3.4313\n",
            "Total loss:  -3.2353 | PDE Loss:  -4.6731 | Function Loss:  -3.4324\n",
            "Total loss:  -3.2359 | PDE Loss:  -4.6747 | Function Loss:  -3.4325\n",
            "Total loss:  -3.2365 | PDE Loss:  -4.6762 | Function Loss:  -3.4325\n",
            "Total loss:  -3.237 | PDE Loss:  -4.6777 | Function Loss:  -3.4325\n",
            "Total loss:  -3.2376 | PDE Loss:  -4.6827 | Function Loss:  -3.4306\n",
            "Total loss:  -3.2383 | PDE Loss:  -4.6837 | Function Loss:  -3.4311\n",
            "Total loss:  -3.2389 | PDE Loss:  -4.6941 | Function Loss:  -3.4263\n",
            "Total loss:  -3.2394 | PDE Loss:  -4.6949 | Function Loss:  -3.4268\n",
            "Total loss:  -3.2401 | PDE Loss:  -4.6946 | Function Loss:  -3.428\n",
            "Total loss:  -3.2408 | PDE Loss:  -4.6916 | Function Loss:  -3.4307\n",
            "Total loss:  -3.2413 | PDE Loss:  -4.6892 | Function Loss:  -3.4327\n",
            "Total loss:  -3.2421 | PDE Loss:  -4.6864 | Function Loss:  -3.4357\n",
            "Total loss:  -3.2428 | PDE Loss:  -4.6797 | Function Loss:  -3.4405\n",
            "Total loss:  -3.2434 | PDE Loss:  -4.6777 | Function Loss:  -3.4426\n",
            "Total loss:  -3.244 | PDE Loss:  -4.674 | Function Loss:  -3.4457\n",
            "Total loss:  -3.2448 | PDE Loss:  -4.6723 | Function Loss:  -3.448\n",
            "Total loss:  -3.2455 | PDE Loss:  -4.6678 | Function Loss:  -3.4518\n",
            "Total loss:  -3.2458 | PDE Loss:  -4.6637 | Function Loss:  -3.4549\n",
            "Total loss:  -3.2465 | PDE Loss:  -4.6676 | Function Loss:  -3.4535\n",
            "Total loss:  -3.2475 | PDE Loss:  -4.6736 | Function Loss:  -3.4515\n",
            "Total loss:  -3.2484 | PDE Loss:  -4.6797 | Function Loss:  -3.4493\n",
            "Total loss:  -3.2491 | PDE Loss:  -4.6843 | Function Loss:  -3.4478\n",
            "Total loss:  -3.2498 | PDE Loss:  -4.6875 | Function Loss:  -3.447\n",
            "Total loss:  -3.2501 | PDE Loss:  -4.6878 | Function Loss:  -3.4474\n",
            "Total loss:  -3.2507 | PDE Loss:  -4.6869 | Function Loss:  -3.4488\n",
            "Total loss:  -3.2511 | PDE Loss:  -4.6836 | Function Loss:  -3.4514\n",
            "Total loss:  -3.2514 | PDE Loss:  -4.6819 | Function Loss:  -3.4529\n",
            "Total loss:  -3.2517 | PDE Loss:  -4.6793 | Function Loss:  -3.4549\n",
            "Total loss:  -3.252 | PDE Loss:  -4.6773 | Function Loss:  -3.4565\n",
            "Total loss:  -3.2523 | PDE Loss:  -4.6759 | Function Loss:  -3.4579\n",
            "Total loss:  -3.2527 | PDE Loss:  -4.6745 | Function Loss:  -3.4594\n",
            "Total loss:  -3.2532 | PDE Loss:  -4.6751 | Function Loss:  -3.4597\n",
            "Total loss:  -3.2535 | PDE Loss:  -4.6753 | Function Loss:  -3.4602\n",
            "Total loss:  -3.2538 | PDE Loss:  -4.6776 | Function Loss:  -3.4592\n",
            "Total loss:  -3.2524 | PDE Loss:  -4.679 | Function Loss:  -3.4561\n",
            "Total loss:  -3.254 | PDE Loss:  -4.6784 | Function Loss:  -3.459\n",
            "Total loss:  -3.2542 | PDE Loss:  -4.6784 | Function Loss:  -3.4594\n",
            "Total loss:  -3.2539 | PDE Loss:  -4.6827 | Function Loss:  -3.4562\n",
            "Total loss:  -3.2545 | PDE Loss:  -4.6804 | Function Loss:  -3.4587\n",
            "Total loss:  -3.255 | PDE Loss:  -4.6806 | Function Loss:  -3.4593\n",
            "Total loss:  -3.2557 | PDE Loss:  -4.6822 | Function Loss:  -3.4595\n",
            "Total loss:  -3.2564 | PDE Loss:  -4.6831 | Function Loss:  -3.4601\n",
            "Total loss:  -3.257 | PDE Loss:  -4.6859 | Function Loss:  -3.4594\n",
            "Total loss:  -3.2574 | PDE Loss:  -4.6856 | Function Loss:  -3.4602\n",
            "Total loss:  -3.2578 | PDE Loss:  -4.6852 | Function Loss:  -3.461\n",
            "Total loss:  -3.2582 | PDE Loss:  -4.6856 | Function Loss:  -3.4614\n",
            "Total loss:  -3.2586 | PDE Loss:  -4.6861 | Function Loss:  -3.4618\n",
            "Total loss:  -3.2582 | PDE Loss:  -4.6816 | Function Loss:  -3.464\n",
            "Total loss:  -3.2588 | PDE Loss:  -4.6845 | Function Loss:  -3.4631\n",
            "Total loss:  -3.2591 | PDE Loss:  -4.6862 | Function Loss:  -3.4626\n",
            "Total loss:  -3.2596 | PDE Loss:  -4.6892 | Function Loss:  -3.4615\n",
            "Total loss:  -3.2601 | PDE Loss:  -4.6912 | Function Loss:  -3.4611\n",
            "Total loss:  -3.2607 | PDE Loss:  -4.6949 | Function Loss:  -3.4599\n",
            "Total loss:  -3.2612 | PDE Loss:  -4.6962 | Function Loss:  -3.46\n",
            "Total loss:  -3.2616 | PDE Loss:  -4.6991 | Function Loss:  -3.4589\n",
            "Total loss:  -3.2619 | PDE Loss:  -4.6991 | Function Loss:  -3.4594\n",
            "Total loss:  -3.2622 | PDE Loss:  -4.6976 | Function Loss:  -3.4608\n",
            "Total loss:  -3.2626 | PDE Loss:  -4.6962 | Function Loss:  -3.4621\n",
            "Total loss:  -3.2629 | PDE Loss:  -4.6945 | Function Loss:  -3.4636\n",
            "Total loss:  -3.263 | PDE Loss:  -4.697 | Function Loss:  -3.4623\n",
            "Total loss:  -3.2634 | PDE Loss:  -4.6952 | Function Loss:  -3.464\n",
            "Total loss:  -3.2637 | PDE Loss:  -4.6921 | Function Loss:  -3.4664\n",
            "Total loss:  -3.2639 | PDE Loss:  -4.6942 | Function Loss:  -3.4655\n",
            "Total loss:  -3.2642 | PDE Loss:  -4.6952 | Function Loss:  -3.4654\n",
            "Total loss:  -3.2633 | PDE Loss:  -4.6877 | Function Loss:  -3.4683\n",
            "Total loss:  -3.2643 | PDE Loss:  -4.6936 | Function Loss:  -3.4664\n",
            "Total loss:  -3.2646 | PDE Loss:  -4.6983 | Function Loss:  -3.4641\n",
            "Total loss:  -3.2648 | PDE Loss:  -4.6987 | Function Loss:  -3.4642\n",
            "Total loss:  -3.265 | PDE Loss:  -4.6991 | Function Loss:  -3.4643\n",
            "Total loss:  -3.2652 | PDE Loss:  -4.7004 | Function Loss:  -3.4639\n",
            "Total loss:  -3.2654 | PDE Loss:  -4.7014 | Function Loss:  -3.4636\n",
            "Total loss:  -3.2655 | PDE Loss:  -4.7001 | Function Loss:  -3.4645\n",
            "Total loss:  -3.2656 | PDE Loss:  -4.7013 | Function Loss:  -3.4641\n",
            "Total loss:  -3.2657 | PDE Loss:  -4.7008 | Function Loss:  -3.4645\n",
            "Total loss:  -3.2658 | PDE Loss:  -4.7009 | Function Loss:  -3.4646\n",
            "Total loss:  -3.266 | PDE Loss:  -4.7024 | Function Loss:  -3.4639\n",
            "Total loss:  -3.2662 | PDE Loss:  -4.7035 | Function Loss:  -3.4636\n",
            "Total loss:  -3.2544 | PDE Loss:  -4.7111 | Function Loss:  -3.4411\n",
            "Total loss:  -3.2663 | PDE Loss:  -4.7048 | Function Loss:  -3.463\n",
            "Total loss:  -3.2666 | PDE Loss:  -4.7056 | Function Loss:  -3.4631\n",
            "Total loss:  -3.2669 | PDE Loss:  -4.7063 | Function Loss:  -3.4631\n",
            "Total loss:  -3.2672 | PDE Loss:  -4.7065 | Function Loss:  -3.4634\n",
            "Total loss:  -3.2674 | PDE Loss:  -4.7067 | Function Loss:  -3.4638\n",
            "Total loss:  -3.2676 | PDE Loss:  -4.706 | Function Loss:  -3.4645\n",
            "Total loss:  -3.2678 | PDE Loss:  -4.7062 | Function Loss:  -3.4646\n",
            "Total loss:  -3.268 | PDE Loss:  -4.7059 | Function Loss:  -3.4651\n",
            "Total loss:  -3.2681 | PDE Loss:  -4.7056 | Function Loss:  -3.4655\n",
            "Total loss:  -3.2683 | PDE Loss:  -4.7059 | Function Loss:  -3.4656\n",
            "Total loss:  -3.2685 | PDE Loss:  -4.706 | Function Loss:  -3.4659\n",
            "Total loss:  -3.2687 | PDE Loss:  -4.7068 | Function Loss:  -3.4657\n",
            "Total loss:  -3.2688 | PDE Loss:  -4.7079 | Function Loss:  -3.4653\n",
            "Total loss:  -3.269 | PDE Loss:  -4.7093 | Function Loss:  -3.4647\n",
            "Total loss:  -3.2692 | PDE Loss:  -4.7113 | Function Loss:  -3.4639\n",
            "Total loss:  -3.2693 | PDE Loss:  -4.713 | Function Loss:  -3.4631\n",
            "Total loss:  -3.2694 | PDE Loss:  -4.7149 | Function Loss:  -3.4622\n",
            "Total loss:  -3.2695 | PDE Loss:  -4.7161 | Function Loss:  -3.4617\n",
            "Total loss:  -3.2697 | PDE Loss:  -4.7176 | Function Loss:  -3.4611\n",
            "Total loss:  -3.2698 | PDE Loss:  -4.7191 | Function Loss:  -3.4605\n",
            "Total loss:  -3.2699 | PDE Loss:  -4.72 | Function Loss:  -3.4601\n",
            "Total loss:  -3.27 | PDE Loss:  -4.7208 | Function Loss:  -3.4599\n",
            "Total loss:  -3.2701 | PDE Loss:  -4.7231 | Function Loss:  -3.4588\n",
            "Total loss:  -3.2703 | PDE Loss:  -4.7194 | Function Loss:  -3.461\n",
            "Total loss:  -3.2704 | PDE Loss:  -4.7201 | Function Loss:  -3.461\n",
            "Total loss:  -3.2707 | PDE Loss:  -4.721 | Function Loss:  -3.4608\n",
            "Total loss:  -3.2709 | PDE Loss:  -4.7208 | Function Loss:  -3.4613\n",
            "Total loss:  -3.2712 | PDE Loss:  -4.7202 | Function Loss:  -3.462\n",
            "Total loss:  -3.2715 | PDE Loss:  -4.7196 | Function Loss:  -3.4628\n",
            "Total loss:  -3.2615 | PDE Loss:  -4.7222 | Function Loss:  -3.4461\n",
            "Total loss:  -3.2716 | PDE Loss:  -4.7204 | Function Loss:  -3.4625\n",
            "Total loss:  -3.2718 | PDE Loss:  -4.7184 | Function Loss:  -3.464\n",
            "Total loss:  -3.272 | PDE Loss:  -4.7175 | Function Loss:  -3.4649\n",
            "Total loss:  -3.2722 | PDE Loss:  -4.7162 | Function Loss:  -3.4659\n",
            "Total loss:  -3.2724 | PDE Loss:  -4.7157 | Function Loss:  -3.4664\n",
            "Total loss:  -3.2725 | PDE Loss:  -4.7163 | Function Loss:  -3.4663\n",
            "Total loss:  -3.2727 | PDE Loss:  -4.7163 | Function Loss:  -3.4666\n",
            "Total loss:  -3.2728 | PDE Loss:  -4.7169 | Function Loss:  -3.4664\n",
            "Total loss:  -3.2729 | PDE Loss:  -4.7174 | Function Loss:  -3.4663\n",
            "Total loss:  -3.273 | PDE Loss:  -4.718 | Function Loss:  -3.4661\n",
            "Total loss:  -3.2731 | PDE Loss:  -4.7184 | Function Loss:  -3.466\n",
            "Total loss:  -3.2733 | PDE Loss:  -4.7188 | Function Loss:  -3.4661\n",
            "Total loss:  -3.2734 | PDE Loss:  -4.7177 | Function Loss:  -3.4669\n",
            "Total loss:  -3.2731 | PDE Loss:  -4.7244 | Function Loss:  -3.4628\n",
            "Total loss:  -3.2736 | PDE Loss:  -4.7204 | Function Loss:  -3.4658\n",
            "Total loss:  -3.2738 | PDE Loss:  -4.7209 | Function Loss:  -3.4658\n",
            "Total loss:  -3.2746 | PDE Loss:  -4.7218 | Function Loss:  -3.4665\n",
            "Total loss:  -3.2754 | PDE Loss:  -4.7218 | Function Loss:  -3.4677\n",
            "Total loss:  -3.2761 | PDE Loss:  -4.7212 | Function Loss:  -3.4692\n",
            "Total loss:  -3.2769 | PDE Loss:  -4.7202 | Function Loss:  -3.4709\n",
            "Total loss:  -3.2775 | PDE Loss:  -4.7188 | Function Loss:  -3.4727\n",
            "Total loss:  -3.278 | PDE Loss:  -4.7186 | Function Loss:  -3.4736\n",
            "Total loss:  -3.2784 | PDE Loss:  -4.7163 | Function Loss:  -3.4756\n",
            "Total loss:  -3.2788 | PDE Loss:  -4.7168 | Function Loss:  -3.4759\n",
            "Total loss:  -3.2791 | PDE Loss:  -4.7198 | Function Loss:  -3.4746\n",
            "Total loss:  -3.2793 | PDE Loss:  -4.7204 | Function Loss:  -3.4746\n",
            "Total loss:  -3.2797 | PDE Loss:  -4.7215 | Function Loss:  -3.4745\n",
            "Total loss:  -3.28 | PDE Loss:  -4.7219 | Function Loss:  -3.4749\n",
            "Total loss:  -3.2804 | PDE Loss:  -4.7225 | Function Loss:  -3.4752\n",
            "Total loss:  -3.2808 | PDE Loss:  -4.7234 | Function Loss:  -3.4753\n",
            "Total loss:  -3.2812 | PDE Loss:  -4.7238 | Function Loss:  -3.4756\n",
            "Total loss:  -3.2817 | PDE Loss:  -4.7255 | Function Loss:  -3.4755\n",
            "Total loss:  -3.2823 | PDE Loss:  -4.7271 | Function Loss:  -3.4755\n",
            "Total loss:  -3.2828 | PDE Loss:  -4.7271 | Function Loss:  -3.4763\n",
            "Total loss:  -3.2832 | PDE Loss:  -4.7312 | Function Loss:  -3.4747\n",
            "Total loss:  -3.2839 | PDE Loss:  -4.735 | Function Loss:  -3.4736\n",
            "Total loss:  -3.2847 | PDE Loss:  -4.7371 | Function Loss:  -3.4737\n",
            "Total loss:  -3.2854 | PDE Loss:  -4.7383 | Function Loss:  -3.4741\n",
            "Total loss:  -3.286 | PDE Loss:  -4.7415 | Function Loss:  -3.4733\n",
            "Total loss:  -3.2865 | PDE Loss:  -4.7406 | Function Loss:  -3.4745\n",
            "Total loss:  -3.2871 | PDE Loss:  -4.7377 | Function Loss:  -3.4771\n",
            "Total loss:  -3.2879 | PDE Loss:  -4.7362 | Function Loss:  -3.4791\n",
            "Total loss:  -3.2885 | PDE Loss:  -4.7382 | Function Loss:  -3.4789\n",
            "Total loss:  -3.2891 | PDE Loss:  -4.7406 | Function Loss:  -3.4786\n",
            "Total loss:  -3.2899 | PDE Loss:  -4.7411 | Function Loss:  -3.4795\n",
            "Total loss:  -3.291 | PDE Loss:  -4.7449 | Function Loss:  -3.4792\n",
            "Total loss:  -3.2919 | PDE Loss:  -4.7476 | Function Loss:  -3.4792\n",
            "Total loss:  -3.293 | PDE Loss:  -4.7466 | Function Loss:  -3.4814\n",
            "Total loss:  -3.2931 | PDE Loss:  -4.7546 | Function Loss:  -3.4772\n",
            "Total loss:  -3.2938 | PDE Loss:  -4.7513 | Function Loss:  -3.48\n",
            "Total loss:  -3.2944 | PDE Loss:  -4.7512 | Function Loss:  -3.481\n",
            "Total loss:  -3.2952 | PDE Loss:  -4.75 | Function Loss:  -3.4829\n",
            "Total loss:  -3.2959 | PDE Loss:  -4.7491 | Function Loss:  -3.4844\n",
            "Total loss:  -3.2964 | PDE Loss:  -4.7499 | Function Loss:  -3.4848\n",
            "Total loss:  -3.2967 | PDE Loss:  -4.7491 | Function Loss:  -3.4857\n",
            "Total loss:  -3.2972 | PDE Loss:  -4.749 | Function Loss:  -3.4865\n",
            "Total loss:  -3.2977 | PDE Loss:  -4.7477 | Function Loss:  -3.4881\n",
            "Total loss:  -3.2982 | PDE Loss:  -4.7476 | Function Loss:  -3.4888\n",
            "Total loss:  -3.2992 | PDE Loss:  -4.7477 | Function Loss:  -3.4904\n",
            "Total loss:  -3.3002 | PDE Loss:  -4.7489 | Function Loss:  -3.4912\n",
            "Total loss:  -3.3013 | PDE Loss:  -4.7497 | Function Loss:  -3.4926\n",
            "Total loss:  -3.3028 | PDE Loss:  -4.7509 | Function Loss:  -3.4942\n",
            "Total loss:  -3.3042 | PDE Loss:  -4.752 | Function Loss:  -3.4958\n",
            "Total loss:  -3.3055 | PDE Loss:  -4.7515 | Function Loss:  -3.498\n",
            "Total loss:  -3.3066 | PDE Loss:  -4.7514 | Function Loss:  -3.4998\n",
            "Total loss:  -3.3074 | PDE Loss:  -4.7542 | Function Loss:  -3.4995\n",
            "Total loss:  -3.3089 | PDE Loss:  -4.7544 | Function Loss:  -3.5017\n",
            "Total loss:  -3.3099 | PDE Loss:  -4.7556 | Function Loss:  -3.5027\n",
            "Total loss:  -3.3106 | PDE Loss:  -4.7552 | Function Loss:  -3.504\n",
            "Total loss:  -3.3119 | PDE Loss:  -4.7556 | Function Loss:  -3.5057\n",
            "Total loss:  -3.3128 | PDE Loss:  -4.7621 | Function Loss:  -3.5036\n",
            "Total loss:  -3.314 | PDE Loss:  -4.7657 | Function Loss:  -3.5033\n",
            "Total loss:  -3.3158 | PDE Loss:  -4.7721 | Function Loss:  -3.5027\n",
            "Total loss:  -3.317 | PDE Loss:  -4.7776 | Function Loss:  -3.5016\n",
            "Total loss:  -3.3178 | PDE Loss:  -4.7823 | Function Loss:  -3.5003\n",
            "Total loss:  -3.3183 | PDE Loss:  -4.7856 | Function Loss:  -3.4994\n",
            "Total loss:  -3.3188 | PDE Loss:  -4.7881 | Function Loss:  -3.4989\n",
            "Total loss:  -3.3193 | PDE Loss:  -4.7887 | Function Loss:  -3.4994\n",
            "Total loss:  -3.32 | PDE Loss:  -4.7902 | Function Loss:  -3.4995\n",
            "Total loss:  -3.3205 | PDE Loss:  -4.7899 | Function Loss:  -3.5005\n",
            "Total loss:  -3.3184 | PDE Loss:  -4.7894 | Function Loss:  -3.4976\n",
            "Total loss:  -3.3206 | PDE Loss:  -4.7901 | Function Loss:  -3.5005\n",
            "Total loss:  -3.321 | PDE Loss:  -4.7922 | Function Loss:  -3.5001\n",
            "Total loss:  -3.3213 | PDE Loss:  -4.793 | Function Loss:  -3.5002\n",
            "Total loss:  -3.3217 | PDE Loss:  -4.7933 | Function Loss:  -3.5006\n",
            "Total loss:  -3.322 | PDE Loss:  -4.7956 | Function Loss:  -3.4999\n",
            "Total loss:  -3.3224 | PDE Loss:  -4.7956 | Function Loss:  -3.5004\n",
            "Total loss:  -3.3227 | PDE Loss:  -4.7969 | Function Loss:  -3.5003\n",
            "Total loss:  -3.3232 | PDE Loss:  -4.7976 | Function Loss:  -3.5007\n",
            "Total loss:  -3.3237 | PDE Loss:  -4.7976 | Function Loss:  -3.5014\n",
            "Total loss:  -3.3242 | PDE Loss:  -4.7982 | Function Loss:  -3.5019\n",
            "Total loss:  -3.3248 | PDE Loss:  -4.7982 | Function Loss:  -3.5028\n",
            "Total loss:  -3.3253 | PDE Loss:  -4.7987 | Function Loss:  -3.5033\n",
            "Total loss:  -3.3259 | PDE Loss:  -4.7987 | Function Loss:  -3.5041\n",
            "Total loss:  -3.2874 | PDE Loss:  -4.7814 | Function Loss:  -3.4553\n",
            "Total loss:  -3.3259 | PDE Loss:  -4.7994 | Function Loss:  -3.5039\n",
            "Total loss:  -3.3265 | PDE Loss:  -4.8003 | Function Loss:  -3.5043\n",
            "Total loss:  -3.3272 | PDE Loss:  -4.8029 | Function Loss:  -3.5039\n",
            "Total loss:  -3.3278 | PDE Loss:  -4.8054 | Function Loss:  -3.5036\n",
            "Total loss:  -3.3283 | PDE Loss:  -4.8077 | Function Loss:  -3.5033\n",
            "Total loss:  -3.3291 | PDE Loss:  -4.8088 | Function Loss:  -3.5039\n",
            "Total loss:  -3.3299 | PDE Loss:  -4.813 | Function Loss:  -3.503\n",
            "Total loss:  -3.3306 | PDE Loss:  -4.8202 | Function Loss:  -3.5005\n",
            "Total loss:  -3.331 | PDE Loss:  -4.8196 | Function Loss:  -3.5015\n",
            "Total loss:  -3.3314 | PDE Loss:  -4.816 | Function Loss:  -3.5037\n",
            "Total loss:  -3.3317 | PDE Loss:  -4.8142 | Function Loss:  -3.5052\n",
            "Total loss:  -3.332 | PDE Loss:  -4.813 | Function Loss:  -3.5061\n",
            "Total loss:  -3.3322 | PDE Loss:  -4.8118 | Function Loss:  -3.5071\n",
            "Total loss:  -3.3325 | PDE Loss:  -4.8126 | Function Loss:  -3.5071\n",
            "Total loss:  -3.3327 | PDE Loss:  -4.8128 | Function Loss:  -3.5072\n",
            "Total loss:  -3.3323 | PDE Loss:  -4.8184 | Function Loss:  -3.504\n",
            "Total loss:  -3.3327 | PDE Loss:  -4.8147 | Function Loss:  -3.5064\n",
            "Total loss:  -3.3329 | PDE Loss:  -4.815 | Function Loss:  -3.5065\n",
            "Total loss:  -3.3331 | PDE Loss:  -4.8157 | Function Loss:  -3.5065\n",
            "Total loss:  -3.3333 | PDE Loss:  -4.8155 | Function Loss:  -3.5068\n",
            "Total loss:  -3.3334 | PDE Loss:  -4.816 | Function Loss:  -3.5068\n",
            "Total loss:  -3.3335 | PDE Loss:  -4.8157 | Function Loss:  -3.5071\n",
            "Total loss:  -3.3336 | PDE Loss:  -4.8158 | Function Loss:  -3.5072\n",
            "Total loss:  -3.3337 | PDE Loss:  -4.8157 | Function Loss:  -3.5074\n",
            "Total loss:  -3.3338 | PDE Loss:  -4.8159 | Function Loss:  -3.5074\n",
            "Total loss:  -3.3339 | PDE Loss:  -4.8158 | Function Loss:  -3.5076\n",
            "Total loss:  -3.3324 | PDE Loss:  -4.8243 | Function Loss:  -3.5012\n",
            "Total loss:  -3.3339 | PDE Loss:  -4.8167 | Function Loss:  -3.5071\n",
            "Total loss:  -3.334 | PDE Loss:  -4.8163 | Function Loss:  -3.5075\n",
            "Total loss:  -3.3341 | PDE Loss:  -4.8161 | Function Loss:  -3.5078\n",
            "Total loss:  -3.3342 | PDE Loss:  -4.8156 | Function Loss:  -3.5082\n",
            "Total loss:  -3.3343 | PDE Loss:  -4.8163 | Function Loss:  -3.508\n",
            "Total loss:  -3.3345 | PDE Loss:  -4.8166 | Function Loss:  -3.5081\n",
            "Total loss:  -3.3346 | PDE Loss:  -4.8174 | Function Loss:  -3.5079\n",
            "Total loss:  -3.3347 | PDE Loss:  -4.8184 | Function Loss:  -3.5076\n",
            "Total loss:  -3.3348 | PDE Loss:  -4.8189 | Function Loss:  -3.5075\n",
            "Total loss:  -3.335 | PDE Loss:  -4.819 | Function Loss:  -3.5076\n",
            "Total loss:  -3.3351 | PDE Loss:  -4.8198 | Function Loss:  -3.5075\n",
            "Total loss:  -3.3352 | PDE Loss:  -4.8191 | Function Loss:  -3.508\n",
            "Total loss:  -3.3353 | PDE Loss:  -4.8182 | Function Loss:  -3.5086\n",
            "Total loss:  -3.3355 | PDE Loss:  -4.817 | Function Loss:  -3.5094\n",
            "Total loss:  -3.3356 | PDE Loss:  -4.8162 | Function Loss:  -3.5099\n",
            "Total loss:  -3.3358 | PDE Loss:  -4.8126 | Function Loss:  -3.512\n",
            "Total loss:  -3.3359 | PDE Loss:  -4.8121 | Function Loss:  -3.5125\n",
            "Total loss:  -3.336 | PDE Loss:  -4.8118 | Function Loss:  -3.5128\n",
            "Total loss:  -3.3362 | PDE Loss:  -4.8122 | Function Loss:  -3.5129\n",
            "Total loss:  -3.3364 | PDE Loss:  -4.8127 | Function Loss:  -3.513\n",
            "Total loss:  -3.3366 | PDE Loss:  -4.8136 | Function Loss:  -3.5127\n",
            "Total loss:  -3.3368 | PDE Loss:  -4.8146 | Function Loss:  -3.5125\n",
            "Total loss:  -3.337 | PDE Loss:  -4.8161 | Function Loss:  -3.5122\n",
            "Total loss:  -3.3373 | PDE Loss:  -4.8172 | Function Loss:  -3.512\n",
            "Total loss:  -3.3376 | PDE Loss:  -4.822 | Function Loss:  -3.5101\n",
            "Total loss:  -3.338 | PDE Loss:  -4.8237 | Function Loss:  -3.5098\n",
            "Total loss:  -3.3382 | PDE Loss:  -4.824 | Function Loss:  -3.51\n",
            "Total loss:  -3.3388 | PDE Loss:  -4.8235 | Function Loss:  -3.5111\n",
            "Total loss:  -3.3392 | PDE Loss:  -4.8228 | Function Loss:  -3.5122\n",
            "Total loss:  -3.3397 | PDE Loss:  -4.8213 | Function Loss:  -3.5135\n",
            "Total loss:  -3.3401 | PDE Loss:  -4.8201 | Function Loss:  -3.5148\n",
            "Total loss:  -3.3405 | PDE Loss:  -4.8188 | Function Loss:  -3.516\n",
            "Total loss:  -3.341 | PDE Loss:  -4.8188 | Function Loss:  -3.5167\n",
            "Total loss:  -3.3414 | PDE Loss:  -4.8184 | Function Loss:  -3.5176\n",
            "Total loss:  -3.342 | PDE Loss:  -4.8188 | Function Loss:  -3.5183\n",
            "Total loss:  -3.3428 | PDE Loss:  -4.8197 | Function Loss:  -3.519\n",
            "Total loss:  -3.3435 | PDE Loss:  -4.8206 | Function Loss:  -3.5196\n",
            "Total loss:  -3.3442 | PDE Loss:  -4.821 | Function Loss:  -3.5204\n",
            "Total loss:  -3.3446 | PDE Loss:  -4.8215 | Function Loss:  -3.5208\n",
            "Total loss:  -3.345 | PDE Loss:  -4.8216 | Function Loss:  -3.5214\n",
            "Total loss:  -3.3455 | PDE Loss:  -4.8217 | Function Loss:  -3.522\n",
            "Total loss:  -3.3458 | PDE Loss:  -4.8243 | Function Loss:  -3.5212\n",
            "Total loss:  -3.3463 | PDE Loss:  -4.8241 | Function Loss:  -3.5221\n",
            "Total loss:  -3.3467 | PDE Loss:  -4.8242 | Function Loss:  -3.5226\n",
            "Total loss:  -3.3472 | PDE Loss:  -4.826 | Function Loss:  -3.5224\n",
            "Total loss:  -3.3476 | PDE Loss:  -4.8282 | Function Loss:  -3.5219\n",
            "Total loss:  -3.3479 | PDE Loss:  -4.8303 | Function Loss:  -3.5213\n",
            "Total loss:  -3.3481 | PDE Loss:  -4.8326 | Function Loss:  -3.5205\n",
            "Total loss:  -3.3482 | PDE Loss:  -4.8342 | Function Loss:  -3.52\n",
            "Total loss:  -3.3484 | PDE Loss:  -4.8355 | Function Loss:  -3.5196\n",
            "Total loss:  -3.3486 | PDE Loss:  -4.8364 | Function Loss:  -3.5194\n",
            "Total loss:  -3.3487 | PDE Loss:  -4.8367 | Function Loss:  -3.5195\n",
            "Total loss:  -3.3489 | PDE Loss:  -4.8378 | Function Loss:  -3.5193\n",
            "Total loss:  -3.3492 | PDE Loss:  -4.8378 | Function Loss:  -3.5196\n",
            "Total loss:  -3.3494 | PDE Loss:  -4.837 | Function Loss:  -3.5204\n",
            "Total loss:  -3.3496 | PDE Loss:  -4.8361 | Function Loss:  -3.5211\n",
            "Total loss:  -3.3498 | PDE Loss:  -4.8347 | Function Loss:  -3.5221\n",
            "Total loss:  -3.35 | PDE Loss:  -4.8335 | Function Loss:  -3.523\n",
            "Total loss:  -3.3503 | PDE Loss:  -4.8326 | Function Loss:  -3.5239\n",
            "Total loss:  -3.3507 | PDE Loss:  -4.8323 | Function Loss:  -3.5246\n",
            "Total loss:  -3.3511 | PDE Loss:  -4.8329 | Function Loss:  -3.5249\n",
            "Total loss:  -3.3516 | PDE Loss:  -4.8347 | Function Loss:  -3.5248\n",
            "Total loss:  -3.3522 | PDE Loss:  -4.8374 | Function Loss:  -3.5243\n",
            "Total loss:  -3.3528 | PDE Loss:  -4.8413 | Function Loss:  -3.5233\n",
            "Total loss:  -3.3533 | PDE Loss:  -4.8452 | Function Loss:  -3.5222\n",
            "Total loss:  -3.3539 | PDE Loss:  -4.849 | Function Loss:  -3.5213\n",
            "Total loss:  -3.3543 | PDE Loss:  -4.8515 | Function Loss:  -3.5207\n",
            "Total loss:  -3.3547 | PDE Loss:  -4.8527 | Function Loss:  -3.5207\n",
            "Total loss:  -3.3552 | PDE Loss:  -4.853 | Function Loss:  -3.5213\n",
            "Total loss:  -3.3557 | PDE Loss:  -4.8515 | Function Loss:  -3.5227\n",
            "Total loss:  -3.3563 | PDE Loss:  -4.8493 | Function Loss:  -3.5247\n",
            "Total loss:  -3.357 | PDE Loss:  -4.8456 | Function Loss:  -3.5275\n",
            "Total loss:  -3.356 | PDE Loss:  -4.8349 | Function Loss:  -3.5312\n",
            "Total loss:  -3.3573 | PDE Loss:  -4.8429 | Function Loss:  -3.5292\n",
            "Total loss:  -3.3577 | PDE Loss:  -4.8411 | Function Loss:  -3.5308\n",
            "Total loss:  -3.3586 | PDE Loss:  -4.8381 | Function Loss:  -3.5335\n",
            "Total loss:  -3.3593 | PDE Loss:  -4.8366 | Function Loss:  -3.5352\n",
            "Total loss:  -3.3598 | PDE Loss:  -4.8363 | Function Loss:  -3.5362\n",
            "Total loss:  -3.3601 | PDE Loss:  -4.8367 | Function Loss:  -3.5365\n",
            "Total loss:  -3.3605 | PDE Loss:  -4.8377 | Function Loss:  -3.5365\n",
            "Total loss:  -3.3609 | PDE Loss:  -4.8396 | Function Loss:  -3.5362\n",
            "Total loss:  -3.3606 | PDE Loss:  -4.8447 | Function Loss:  -3.5333\n",
            "Total loss:  -3.3612 | PDE Loss:  -4.842 | Function Loss:  -3.5355\n",
            "Total loss:  -3.3623 | PDE Loss:  -4.8479 | Function Loss:  -3.5343\n",
            "Total loss:  -3.3631 | PDE Loss:  -4.8503 | Function Loss:  -3.5343\n",
            "Total loss:  -3.365 | PDE Loss:  -4.8542 | Function Loss:  -3.5352\n",
            "Total loss:  -3.367 | PDE Loss:  -4.858 | Function Loss:  -3.5362\n",
            "Total loss:  -3.3684 | PDE Loss:  -4.861 | Function Loss:  -3.5369\n",
            "Total loss:  -3.3696 | PDE Loss:  -4.8614 | Function Loss:  -3.5386\n",
            "Total loss:  -3.3704 | PDE Loss:  -4.8604 | Function Loss:  -3.5402\n",
            "Total loss:  -3.3716 | PDE Loss:  -4.8586 | Function Loss:  -3.5429\n",
            "Total loss:  -3.3727 | PDE Loss:  -4.8566 | Function Loss:  -3.5454\n",
            "Total loss:  -3.3728 | PDE Loss:  -4.8511 | Function Loss:  -3.5483\n",
            "Total loss:  -3.3713 | PDE Loss:  -4.8416 | Function Loss:  -3.5508\n",
            "Total loss:  -3.374 | PDE Loss:  -4.848 | Function Loss:  -3.5517\n",
            "Total loss:  -3.375 | PDE Loss:  -4.8503 | Function Loss:  -3.552\n",
            "Total loss:  -3.3762 | PDE Loss:  -4.8534 | Function Loss:  -3.5522\n",
            "Total loss:  -3.3776 | PDE Loss:  -4.8581 | Function Loss:  -3.5521\n",
            "Total loss:  -3.3791 | PDE Loss:  -4.8627 | Function Loss:  -3.5521\n",
            "Total loss:  -3.3807 | PDE Loss:  -4.8664 | Function Loss:  -3.5525\n",
            "Total loss:  -3.3822 | PDE Loss:  -4.8704 | Function Loss:  -3.5528\n",
            "Total loss:  -3.3831 | PDE Loss:  -4.8706 | Function Loss:  -3.5542\n",
            "Total loss:  -3.3841 | PDE Loss:  -4.8713 | Function Loss:  -3.5553\n",
            "Total loss:  -3.3849 | PDE Loss:  -4.8682 | Function Loss:  -3.5579\n",
            "Total loss:  -3.3858 | PDE Loss:  -4.8653 | Function Loss:  -3.5607\n",
            "Total loss:  -3.3865 | PDE Loss:  -4.8633 | Function Loss:  -3.5628\n",
            "Total loss:  -3.3872 | PDE Loss:  -4.8618 | Function Loss:  -3.5645\n",
            "Total loss:  -3.3876 | PDE Loss:  -4.8666 | Function Loss:  -3.5628\n",
            "Total loss:  -3.3883 | PDE Loss:  -4.8642 | Function Loss:  -3.565\n",
            "Total loss:  -3.389 | PDE Loss:  -4.8637 | Function Loss:  -3.5664\n",
            "Total loss:  -3.3899 | PDE Loss:  -4.8631 | Function Loss:  -3.568\n",
            "Total loss:  -3.3908 | PDE Loss:  -4.8648 | Function Loss:  -3.5685\n",
            "Total loss:  -3.3916 | PDE Loss:  -4.8684 | Function Loss:  -3.5679\n",
            "Total loss:  -3.3921 | PDE Loss:  -4.8698 | Function Loss:  -3.5679\n",
            "Total loss:  -3.3927 | PDE Loss:  -4.8719 | Function Loss:  -3.5677\n",
            "Total loss:  -3.3932 | PDE Loss:  -4.8749 | Function Loss:  -3.567\n",
            "Total loss:  -3.394 | PDE Loss:  -4.876 | Function Loss:  -3.5677\n",
            "Total loss:  -3.3946 | PDE Loss:  -4.8765 | Function Loss:  -3.5684\n",
            "Total loss:  -3.3951 | PDE Loss:  -4.8759 | Function Loss:  -3.5694\n",
            "Total loss:  -3.3955 | PDE Loss:  -4.8746 | Function Loss:  -3.5706\n",
            "Total loss:  -3.3958 | PDE Loss:  -4.8743 | Function Loss:  -3.5713\n",
            "Total loss:  -3.3963 | PDE Loss:  -4.8742 | Function Loss:  -3.572\n",
            "Total loss:  -3.3967 | PDE Loss:  -4.8745 | Function Loss:  -3.5725\n",
            "Total loss:  -3.397 | PDE Loss:  -4.8759 | Function Loss:  -3.5723\n",
            "Total loss:  -3.3973 | PDE Loss:  -4.8771 | Function Loss:  -3.5721\n",
            "Total loss:  -3.3975 | PDE Loss:  -4.8782 | Function Loss:  -3.5718\n",
            "Total loss:  -3.3977 | PDE Loss:  -4.8798 | Function Loss:  -3.5713\n",
            "Total loss:  -3.3979 | PDE Loss:  -4.8802 | Function Loss:  -3.5714\n",
            "Total loss:  -3.3981 | PDE Loss:  -4.8815 | Function Loss:  -3.5711\n",
            "Total loss:  -3.3981 | PDE Loss:  -4.8804 | Function Loss:  -3.5716\n",
            "Total loss:  -3.3983 | PDE Loss:  -4.8811 | Function Loss:  -3.5715\n",
            "Total loss:  -3.3986 | PDE Loss:  -4.8806 | Function Loss:  -3.5722\n",
            "Total loss:  -3.3988 | PDE Loss:  -4.8812 | Function Loss:  -3.5723\n",
            "Total loss:  -3.3991 | PDE Loss:  -4.8813 | Function Loss:  -3.5727\n",
            "Total loss:  -3.3995 | PDE Loss:  -4.8802 | Function Loss:  -3.5739\n",
            "Total loss:  -3.3999 | PDE Loss:  -4.8802 | Function Loss:  -3.5744\n",
            "Total loss:  -3.4002 | PDE Loss:  -4.8808 | Function Loss:  -3.5745\n",
            "Total loss:  -3.4005 | PDE Loss:  -4.8817 | Function Loss:  -3.5746\n",
            "Total loss:  -3.4001 | PDE Loss:  -4.8879 | Function Loss:  -3.571\n",
            "Total loss:  -3.4006 | PDE Loss:  -4.884 | Function Loss:  -3.5737\n",
            "Total loss:  -3.4009 | PDE Loss:  -4.886 | Function Loss:  -3.5731\n",
            "Total loss:  -3.4014 | PDE Loss:  -4.8897 | Function Loss:  -3.572\n",
            "Total loss:  -3.4017 | PDE Loss:  -4.8929 | Function Loss:  -3.571\n",
            "Total loss:  -3.4021 | PDE Loss:  -4.8964 | Function Loss:  -3.5698\n",
            "Total loss:  -3.4025 | PDE Loss:  -4.8997 | Function Loss:  -3.5688\n",
            "Total loss:  -3.4028 | PDE Loss:  -4.9022 | Function Loss:  -3.5681\n",
            "Total loss:  -3.4031 | PDE Loss:  -4.9047 | Function Loss:  -3.5674\n",
            "Total loss:  -3.4033 | PDE Loss:  -4.9057 | Function Loss:  -3.5673\n",
            "Total loss:  -3.4035 | PDE Loss:  -4.9064 | Function Loss:  -3.5673\n",
            "Total loss:  -3.4037 | PDE Loss:  -4.9034 | Function Loss:  -3.5689\n",
            "Total loss:  -3.4038 | PDE Loss:  -4.9042 | Function Loss:  -3.5687\n",
            "Total loss:  -3.404 | PDE Loss:  -4.9032 | Function Loss:  -3.5695\n",
            "Total loss:  -3.4042 | PDE Loss:  -4.9023 | Function Loss:  -3.5701\n",
            "Total loss:  -3.4043 | PDE Loss:  -4.9014 | Function Loss:  -3.5708\n",
            "Total loss:  -3.4046 | PDE Loss:  -4.9006 | Function Loss:  -3.5715\n",
            "Total loss:  -3.4048 | PDE Loss:  -4.9008 | Function Loss:  -3.5718\n",
            "Total loss:  -3.4052 | PDE Loss:  -4.8944 | Function Loss:  -3.5754\n",
            "Total loss:  -3.4056 | PDE Loss:  -4.8969 | Function Loss:  -3.5747\n",
            "Total loss:  -3.4062 | PDE Loss:  -4.9004 | Function Loss:  -3.574\n",
            "Total loss:  -3.4068 | PDE Loss:  -4.9037 | Function Loss:  -3.5733\n",
            "Total loss:  -3.4073 | PDE Loss:  -4.9058 | Function Loss:  -3.5731\n",
            "Total loss:  -3.4077 | PDE Loss:  -4.9075 | Function Loss:  -3.5729\n",
            "Total loss:  -3.4081 | PDE Loss:  -4.9078 | Function Loss:  -3.5733\n",
            "Total loss:  -3.4084 | PDE Loss:  -4.9086 | Function Loss:  -3.5734\n",
            "Total loss:  -3.4089 | PDE Loss:  -4.9083 | Function Loss:  -3.5743\n",
            "Total loss:  -3.4095 | PDE Loss:  -4.9086 | Function Loss:  -3.575\n",
            "Total loss:  -3.4102 | PDE Loss:  -4.9085 | Function Loss:  -3.576\n",
            "Total loss:  -3.4111 | PDE Loss:  -4.9085 | Function Loss:  -3.5773\n",
            "Total loss:  -3.4118 | PDE Loss:  -4.9096 | Function Loss:  -3.578\n",
            "Total loss:  -3.4123 | PDE Loss:  -4.9092 | Function Loss:  -3.5789\n",
            "Total loss:  -3.4127 | PDE Loss:  -4.9103 | Function Loss:  -3.5789\n",
            "Total loss:  -3.4129 | PDE Loss:  -4.9105 | Function Loss:  -3.5791\n",
            "Total loss:  -3.4131 | PDE Loss:  -4.9107 | Function Loss:  -3.5793\n",
            "Total loss:  -3.4133 | PDE Loss:  -4.9111 | Function Loss:  -3.5795\n",
            "Total loss:  -3.4137 | PDE Loss:  -4.912 | Function Loss:  -3.5796\n",
            "Total loss:  -3.4142 | PDE Loss:  -4.912 | Function Loss:  -3.5803\n",
            "Total loss:  -3.4146 | PDE Loss:  -4.9147 | Function Loss:  -3.5797\n",
            "Total loss:  -3.4151 | PDE Loss:  -4.9168 | Function Loss:  -3.5794\n",
            "Total loss:  -3.4155 | PDE Loss:  -4.9172 | Function Loss:  -3.5798\n",
            "Total loss:  -3.4165 | PDE Loss:  -4.9187 | Function Loss:  -3.5806\n",
            "Total loss:  -3.4172 | PDE Loss:  -4.92 | Function Loss:  -3.5811\n",
            "Total loss:  -3.4177 | PDE Loss:  -4.9213 | Function Loss:  -3.5812\n",
            "Total loss:  -3.4181 | PDE Loss:  -4.9231 | Function Loss:  -3.5809\n",
            "Total loss:  -3.4185 | PDE Loss:  -4.9243 | Function Loss:  -3.5809\n",
            "Total loss:  -3.4188 | PDE Loss:  -4.9258 | Function Loss:  -3.5807\n",
            "Total loss:  -3.4191 | PDE Loss:  -4.9262 | Function Loss:  -3.581\n",
            "Total loss:  -3.4195 | PDE Loss:  -4.9264 | Function Loss:  -3.5814\n",
            "Total loss:  -3.4199 | PDE Loss:  -4.926 | Function Loss:  -3.5822\n",
            "Total loss:  -3.4203 | PDE Loss:  -4.9276 | Function Loss:  -3.582\n",
            "Total loss:  -3.4184 | PDE Loss:  -4.9186 | Function Loss:  -3.5834\n",
            "Total loss:  -3.4205 | PDE Loss:  -4.9258 | Function Loss:  -3.5832\n",
            "Total loss:  -3.4208 | PDE Loss:  -4.9259 | Function Loss:  -3.5835\n",
            "Total loss:  -3.4214 | PDE Loss:  -4.9268 | Function Loss:  -3.584\n",
            "Total loss:  -3.4219 | PDE Loss:  -4.9278 | Function Loss:  -3.5843\n",
            "Total loss:  -3.4223 | PDE Loss:  -4.9285 | Function Loss:  -3.5846\n",
            "Total loss:  -3.4227 | PDE Loss:  -4.9292 | Function Loss:  -3.5847\n",
            "Total loss:  -3.423 | PDE Loss:  -4.9302 | Function Loss:  -3.5848\n",
            "Total loss:  -3.4234 | PDE Loss:  -4.9303 | Function Loss:  -3.5853\n",
            "Total loss:  -3.4238 | PDE Loss:  -4.9322 | Function Loss:  -3.585\n",
            "Total loss:  -3.4242 | PDE Loss:  -4.9332 | Function Loss:  -3.5853\n",
            "Total loss:  -3.425 | PDE Loss:  -4.9417 | Function Loss:  -3.5826\n",
            "Total loss:  -3.4256 | PDE Loss:  -4.9435 | Function Loss:  -3.5827\n",
            "Total loss:  -3.4265 | PDE Loss:  -4.9468 | Function Loss:  -3.5825\n",
            "Total loss:  -3.4275 | PDE Loss:  -4.9542 | Function Loss:  -3.5808\n",
            "Total loss:  -3.4284 | PDE Loss:  -4.9599 | Function Loss:  -3.5797\n",
            "Total loss:  -3.4289 | PDE Loss:  -4.9634 | Function Loss:  -3.579\n",
            "Total loss:  -3.4299 | PDE Loss:  -4.9695 | Function Loss:  -3.5778\n",
            "Total loss:  -3.4309 | PDE Loss:  -4.975 | Function Loss:  -3.577\n",
            "Total loss:  -3.4318 | PDE Loss:  -4.9853 | Function Loss:  -3.5742\n",
            "Total loss:  -3.4326 | PDE Loss:  -4.9881 | Function Loss:  -3.5743\n",
            "Total loss:  -3.4339 | PDE Loss:  -4.9888 | Function Loss:  -3.5757\n",
            "Total loss:  -3.4352 | PDE Loss:  -4.9899 | Function Loss:  -3.5772\n",
            "Total loss:  -3.4363 | PDE Loss:  -4.9873 | Function Loss:  -3.5797\n",
            "Total loss:  -3.4375 | PDE Loss:  -4.9833 | Function Loss:  -3.583\n",
            "Total loss:  -3.4387 | PDE Loss:  -4.982 | Function Loss:  -3.5851\n",
            "Total loss:  -3.4397 | PDE Loss:  -4.9792 | Function Loss:  -3.5876\n",
            "Total loss:  -3.4406 | PDE Loss:  -4.981 | Function Loss:  -3.5882\n",
            "Total loss:  -3.4418 | PDE Loss:  -4.9833 | Function Loss:  -3.5889\n",
            "Total loss:  -3.443 | PDE Loss:  -4.9869 | Function Loss:  -3.5893\n",
            "Total loss:  -3.4441 | PDE Loss:  -4.9929 | Function Loss:  -3.5884\n",
            "Total loss:  -3.4451 | PDE Loss:  -4.9966 | Function Loss:  -3.5882\n",
            "Total loss:  -3.4459 | PDE Loss:  -4.9984 | Function Loss:  -3.5887\n",
            "Total loss:  -3.4469 | PDE Loss:  -5.0022 | Function Loss:  -3.5887\n",
            "Total loss:  -3.4481 | PDE Loss:  -5.0016 | Function Loss:  -3.5905\n",
            "Total loss:  -3.4491 | PDE Loss:  -5.0025 | Function Loss:  -3.5916\n",
            "Total loss:  -3.4501 | PDE Loss:  -5.0038 | Function Loss:  -3.5924\n",
            "Total loss:  -3.4508 | PDE Loss:  -5.001 | Function Loss:  -3.5944\n",
            "Total loss:  -3.4516 | PDE Loss:  -4.9997 | Function Loss:  -3.5962\n",
            "Total loss:  -3.4525 | PDE Loss:  -4.9988 | Function Loss:  -3.5978\n",
            "Total loss:  -3.4533 | PDE Loss:  -4.9991 | Function Loss:  -3.5988\n",
            "Total loss:  -3.454 | PDE Loss:  -5.0 | Function Loss:  -3.5994\n",
            "Total loss:  -3.4545 | PDE Loss:  -5.0012 | Function Loss:  -3.5996\n",
            "Total loss:  -3.4549 | PDE Loss:  -5.003 | Function Loss:  -3.5995\n",
            "Total loss:  -3.4554 | PDE Loss:  -5.0047 | Function Loss:  -3.5994\n",
            "Total loss:  -3.4559 | PDE Loss:  -5.0068 | Function Loss:  -3.5993\n",
            "Total loss:  -3.4565 | PDE Loss:  -5.0087 | Function Loss:  -3.5994\n",
            "Total loss:  -3.4572 | PDE Loss:  -5.01 | Function Loss:  -3.5999\n",
            "Total loss:  -3.4581 | PDE Loss:  -5.0108 | Function Loss:  -3.6008\n",
            "Total loss:  -3.459 | PDE Loss:  -5.0096 | Function Loss:  -3.6025\n",
            "Total loss:  -3.4599 | PDE Loss:  -5.0086 | Function Loss:  -3.6042\n",
            "Total loss:  -3.4609 | PDE Loss:  -5.004 | Function Loss:  -3.6074\n",
            "Total loss:  -3.4616 | PDE Loss:  -5.0014 | Function Loss:  -3.6095\n",
            "Total loss:  -3.4625 | PDE Loss:  -4.9971 | Function Loss:  -3.6125\n",
            "Total loss:  -3.4636 | PDE Loss:  -4.9939 | Function Loss:  -3.6154\n",
            "Total loss:  -3.465 | PDE Loss:  -4.99 | Function Loss:  -3.6189\n",
            "Total loss:  -3.4661 | PDE Loss:  -4.9869 | Function Loss:  -3.6219\n",
            "Total loss:  -3.4673 | PDE Loss:  -4.9857 | Function Loss:  -3.6241\n",
            "Total loss:  -3.4684 | PDE Loss:  -4.9875 | Function Loss:  -3.6249\n",
            "Total loss:  -3.4694 | PDE Loss:  -4.9873 | Function Loss:  -3.6264\n",
            "Total loss:  -3.4705 | PDE Loss:  -4.9911 | Function Loss:  -3.6264\n",
            "Total loss:  -3.4714 | PDE Loss:  -4.9941 | Function Loss:  -3.6264\n",
            "Total loss:  -3.4725 | PDE Loss:  -4.9991 | Function Loss:  -3.6258\n",
            "Total loss:  -3.474 | PDE Loss:  -5.0047 | Function Loss:  -3.6256\n",
            "Total loss:  -3.4756 | PDE Loss:  -5.0079 | Function Loss:  -3.6266\n",
            "Total loss:  -3.4777 | PDE Loss:  -5.0126 | Function Loss:  -3.6275\n",
            "Total loss:  -3.4793 | PDE Loss:  -5.0151 | Function Loss:  -3.6288\n",
            "Total loss:  -3.4816 | PDE Loss:  -5.003 | Function Loss:  -3.6371\n",
            "Total loss:  -3.4827 | PDE Loss:  -5.002 | Function Loss:  -3.6391\n",
            "Total loss:  -3.4855 | PDE Loss:  -5.0034 | Function Loss:  -3.6426\n",
            "Total loss:  -3.488 | PDE Loss:  -5.0025 | Function Loss:  -3.6465\n",
            "Total loss:  -3.4896 | PDE Loss:  -5.0028 | Function Loss:  -3.6487\n",
            "Total loss:  -3.4908 | PDE Loss:  -5.0001 | Function Loss:  -3.6517\n",
            "Total loss:  -3.4918 | PDE Loss:  -4.9998 | Function Loss:  -3.6533\n",
            "Total loss:  -3.4931 | PDE Loss:  -4.9986 | Function Loss:  -3.6556\n",
            "Total loss:  -3.4944 | PDE Loss:  -4.9966 | Function Loss:  -3.6584\n",
            "Total loss:  -3.4955 | PDE Loss:  -4.9937 | Function Loss:  -3.6615\n",
            "Total loss:  -3.4966 | PDE Loss:  -4.9902 | Function Loss:  -3.6647\n",
            "Total loss:  -3.4977 | PDE Loss:  -4.9883 | Function Loss:  -3.6672\n",
            "Total loss:  -3.4993 | PDE Loss:  -4.9862 | Function Loss:  -3.6706\n",
            "Total loss:  -3.5004 | PDE Loss:  -4.9842 | Function Loss:  -3.6732\n",
            "Total loss:  -3.5012 | PDE Loss:  -4.9852 | Function Loss:  -3.674\n",
            "Total loss:  -3.5021 | PDE Loss:  -4.9862 | Function Loss:  -3.6748\n",
            "Total loss:  -3.5033 | PDE Loss:  -4.9914 | Function Loss:  -3.6739\n",
            "Total loss:  -3.5044 | PDE Loss:  -4.9946 | Function Loss:  -3.6742\n",
            "Total loss:  -3.5056 | PDE Loss:  -5.0029 | Function Loss:  -3.672\n",
            "Total loss:  -3.5069 | PDE Loss:  -5.0073 | Function Loss:  -3.6718\n",
            "Total loss:  -3.5074 | PDE Loss:  -5.0086 | Function Loss:  -3.672\n",
            "Total loss:  -3.5081 | PDE Loss:  -5.0115 | Function Loss:  -3.6716\n",
            "Total loss:  -3.5085 | PDE Loss:  -5.0134 | Function Loss:  -3.6713\n",
            "Total loss:  -3.5087 | PDE Loss:  -5.0164 | Function Loss:  -3.6704\n",
            "Total loss:  -3.5092 | PDE Loss:  -5.0187 | Function Loss:  -3.6699\n",
            "Total loss:  -3.5096 | PDE Loss:  -5.0187 | Function Loss:  -3.6706\n",
            "Total loss:  -3.51 | PDE Loss:  -5.0208 | Function Loss:  -3.6703\n",
            "Total loss:  -3.5107 | PDE Loss:  -5.0237 | Function Loss:  -3.6699\n",
            "Total loss:  -3.5112 | PDE Loss:  -5.0281 | Function Loss:  -3.6688\n",
            "Total loss:  -3.5117 | PDE Loss:  -5.0307 | Function Loss:  -3.6683\n",
            "Total loss:  -3.5123 | PDE Loss:  -5.0337 | Function Loss:  -3.6679\n",
            "Total loss:  -3.5133 | PDE Loss:  -5.0382 | Function Loss:  -3.6673\n",
            "Total loss:  -3.5144 | PDE Loss:  -5.0416 | Function Loss:  -3.6674\n",
            "Total loss:  -3.5154 | PDE Loss:  -5.0462 | Function Loss:  -3.6669\n",
            "Total loss:  -3.5164 | PDE Loss:  -5.0478 | Function Loss:  -3.6676\n",
            "Total loss:  -3.5172 | PDE Loss:  -5.0498 | Function Loss:  -3.668\n",
            "Total loss:  -3.5181 | PDE Loss:  -5.0504 | Function Loss:  -3.669\n",
            "Total loss:  -3.5189 | PDE Loss:  -5.0515 | Function Loss:  -3.6697\n",
            "Total loss:  -3.5199 | PDE Loss:  -5.0511 | Function Loss:  -3.6712\n",
            "Total loss:  -3.5209 | PDE Loss:  -5.0544 | Function Loss:  -3.6713\n",
            "Total loss:  -3.5212 | PDE Loss:  -5.0534 | Function Loss:  -3.6722\n",
            "Total loss:  -3.5224 | PDE Loss:  -5.0539 | Function Loss:  -3.6737\n",
            "Total loss:  -3.5237 | PDE Loss:  -5.0584 | Function Loss:  -3.6736\n",
            "Total loss:  -3.5247 | PDE Loss:  -5.0611 | Function Loss:  -3.674\n",
            "Total loss:  -3.5259 | PDE Loss:  -5.0644 | Function Loss:  -3.6743\n",
            "Total loss:  -3.5269 | PDE Loss:  -5.067 | Function Loss:  -3.6747\n",
            "Total loss:  -3.5279 | PDE Loss:  -5.07 | Function Loss:  -3.6747\n",
            "Total loss:  -3.5286 | PDE Loss:  -5.0716 | Function Loss:  -3.6752\n",
            "Total loss:  -3.5296 | PDE Loss:  -5.0722 | Function Loss:  -3.6762\n",
            "Total loss:  -3.5308 | PDE Loss:  -5.0718 | Function Loss:  -3.6781\n",
            "Total loss:  -3.5322 | PDE Loss:  -5.0699 | Function Loss:  -3.6809\n",
            "Total loss:  -3.5338 | PDE Loss:  -5.0662 | Function Loss:  -3.6847\n",
            "Total loss:  -3.5351 | PDE Loss:  -5.0625 | Function Loss:  -3.6881\n",
            "Total loss:  -3.5363 | PDE Loss:  -5.059 | Function Loss:  -3.6913\n",
            "Total loss:  -3.5372 | PDE Loss:  -5.0565 | Function Loss:  -3.6937\n",
            "Total loss:  -3.538 | PDE Loss:  -5.0499 | Function Loss:  -3.6977\n",
            "Total loss:  -3.5391 | PDE Loss:  -5.0499 | Function Loss:  -3.6993\n",
            "Total loss:  -3.54 | PDE Loss:  -5.0498 | Function Loss:  -3.7007\n",
            "Total loss:  -3.5411 | PDE Loss:  -5.0506 | Function Loss:  -3.7019\n",
            "Total loss:  -3.5421 | PDE Loss:  -5.0506 | Function Loss:  -3.7033\n",
            "Total loss:  -3.5428 | PDE Loss:  -5.051 | Function Loss:  -3.7042\n",
            "Total loss:  -3.5434 | PDE Loss:  -5.0509 | Function Loss:  -3.7051\n",
            "Total loss:  -3.5439 | PDE Loss:  -5.0504 | Function Loss:  -3.706\n",
            "Total loss:  -3.5444 | PDE Loss:  -5.0499 | Function Loss:  -3.707\n",
            "Total loss:  -3.545 | PDE Loss:  -5.0489 | Function Loss:  -3.7082\n",
            "Total loss:  -3.5456 | PDE Loss:  -5.0481 | Function Loss:  -3.7096\n",
            "Total loss:  -3.5465 | PDE Loss:  -5.0467 | Function Loss:  -3.7115\n",
            "Total loss:  -3.5476 | PDE Loss:  -5.0441 | Function Loss:  -3.7143\n",
            "Total loss:  -3.5487 | PDE Loss:  -5.0442 | Function Loss:  -3.7159\n",
            "Total loss:  -3.55 | PDE Loss:  -5.0437 | Function Loss:  -3.718\n",
            "Total loss:  -3.5514 | PDE Loss:  -5.0459 | Function Loss:  -3.7191\n",
            "Total loss:  -3.5524 | PDE Loss:  -5.0476 | Function Loss:  -3.7198\n",
            "Total loss:  -3.5536 | PDE Loss:  -5.0513 | Function Loss:  -3.7198\n",
            "Total loss:  -3.5549 | PDE Loss:  -5.058 | Function Loss:  -3.7186\n",
            "Total loss:  -3.5561 | PDE Loss:  -5.0641 | Function Loss:  -3.7176\n",
            "Total loss:  -3.5573 | PDE Loss:  -5.0699 | Function Loss:  -3.7167\n",
            "Total loss:  -3.5586 | PDE Loss:  -5.0767 | Function Loss:  -3.7156\n",
            "Total loss:  -3.5596 | PDE Loss:  -5.0798 | Function Loss:  -3.7157\n",
            "Total loss:  -3.5604 | PDE Loss:  -5.081 | Function Loss:  -3.7164\n",
            "Total loss:  -3.5611 | PDE Loss:  -5.0808 | Function Loss:  -3.7174\n",
            "Total loss:  -3.5617 | PDE Loss:  -5.0788 | Function Loss:  -3.719\n",
            "Total loss:  -3.562 | PDE Loss:  -5.0779 | Function Loss:  -3.7199\n",
            "Total loss:  -3.5623 | PDE Loss:  -5.077 | Function Loss:  -3.7207\n",
            "Total loss:  -3.5627 | PDE Loss:  -5.0758 | Function Loss:  -3.7218\n",
            "Total loss:  -3.563 | PDE Loss:  -5.076 | Function Loss:  -3.7222\n",
            "Total loss:  -3.5635 | PDE Loss:  -5.0772 | Function Loss:  -3.7224\n",
            "Total loss:  -3.5639 | PDE Loss:  -5.0794 | Function Loss:  -3.7221\n",
            "Total loss:  -3.5643 | PDE Loss:  -5.0818 | Function Loss:  -3.7215\n",
            "Total loss:  -3.5645 | PDE Loss:  -5.0829 | Function Loss:  -3.7213\n",
            "Total loss:  -3.5647 | PDE Loss:  -5.0839 | Function Loss:  -3.7212\n",
            "Total loss:  -3.565 | PDE Loss:  -5.0846 | Function Loss:  -3.7213\n",
            "Total loss:  -3.5652 | PDE Loss:  -5.0848 | Function Loss:  -3.7215\n",
            "Total loss:  -3.5654 | PDE Loss:  -5.0834 | Function Loss:  -3.7224\n",
            "Total loss:  -3.5656 | PDE Loss:  -5.0868 | Function Loss:  -3.7212\n",
            "Total loss:  -3.5659 | PDE Loss:  -5.0851 | Function Loss:  -3.7223\n",
            "Total loss:  -3.5661 | PDE Loss:  -5.084 | Function Loss:  -3.7232\n",
            "Total loss:  -3.5665 | PDE Loss:  -5.0838 | Function Loss:  -3.7239\n",
            "Total loss:  -3.5668 | PDE Loss:  -5.0842 | Function Loss:  -3.724\n",
            "Total loss:  -3.5669 | PDE Loss:  -5.0853 | Function Loss:  -3.7238\n",
            "Total loss:  -3.5669 | PDE Loss:  -5.0831 | Function Loss:  -3.7246\n",
            "Total loss:  -3.567 | PDE Loss:  -5.0845 | Function Loss:  -3.7243\n",
            "Total loss:  -3.5672 | PDE Loss:  -5.086 | Function Loss:  -3.7238\n",
            "Total loss:  -3.5673 | PDE Loss:  -5.087 | Function Loss:  -3.7236\n",
            "Total loss:  -3.5675 | PDE Loss:  -5.0883 | Function Loss:  -3.7233\n",
            "Total loss:  -3.5677 | PDE Loss:  -5.0899 | Function Loss:  -3.7228\n",
            "Total loss:  -3.5679 | PDE Loss:  -5.0915 | Function Loss:  -3.7224\n",
            "Total loss:  -3.568 | PDE Loss:  -5.0935 | Function Loss:  -3.7218\n",
            "Total loss:  -3.5682 | PDE Loss:  -5.0938 | Function Loss:  -3.7219\n",
            "Total loss:  -3.5683 | PDE Loss:  -5.0942 | Function Loss:  -3.7219\n",
            "Total loss:  -3.5685 | PDE Loss:  -5.0941 | Function Loss:  -3.7222\n",
            "Total loss:  -3.5687 | PDE Loss:  -5.094 | Function Loss:  -3.7226\n",
            "Total loss:  -3.5689 | PDE Loss:  -5.0941 | Function Loss:  -3.7228\n",
            "Total loss:  -3.5691 | PDE Loss:  -5.0938 | Function Loss:  -3.7232\n",
            "Total loss:  -3.5693 | PDE Loss:  -5.0937 | Function Loss:  -3.7236\n",
            "Total loss:  -3.5696 | PDE Loss:  -5.0935 | Function Loss:  -3.724\n",
            "Total loss:  -3.5698 | PDE Loss:  -5.0933 | Function Loss:  -3.7245\n",
            "Total loss:  -3.57 | PDE Loss:  -5.0931 | Function Loss:  -3.7248\n",
            "Total loss:  -3.5702 | PDE Loss:  -5.0923 | Function Loss:  -3.7254\n",
            "Total loss:  -3.5703 | PDE Loss:  -5.0927 | Function Loss:  -3.7254\n",
            "Total loss:  -3.5705 | PDE Loss:  -5.0931 | Function Loss:  -3.7255\n",
            "Total loss:  -3.5706 | PDE Loss:  -5.0938 | Function Loss:  -3.7254\n",
            "Total loss:  -3.5708 | PDE Loss:  -5.0944 | Function Loss:  -3.7254\n",
            "Total loss:  -3.5709 | PDE Loss:  -5.095 | Function Loss:  -3.7253\n",
            "Total loss:  -3.5709 | PDE Loss:  -5.0952 | Function Loss:  -3.7252\n",
            "Total loss:  -3.571 | PDE Loss:  -5.0954 | Function Loss:  -3.7253\n",
            "Total loss:  -3.5711 | PDE Loss:  -5.0953 | Function Loss:  -3.7254\n",
            "Total loss:  -3.5711 | PDE Loss:  -5.0953 | Function Loss:  -3.7255\n",
            "Total loss:  -3.5712 | PDE Loss:  -5.0951 | Function Loss:  -3.7257\n",
            "Total loss:  -3.5714 | PDE Loss:  -5.0953 | Function Loss:  -3.7258\n",
            "Total loss:  -3.5715 | PDE Loss:  -5.0955 | Function Loss:  -3.726\n",
            "Total loss:  -3.5716 | PDE Loss:  -5.0965 | Function Loss:  -3.7257\n",
            "Total loss:  -3.5718 | PDE Loss:  -5.0974 | Function Loss:  -3.7255\n",
            "Total loss:  -3.5719 | PDE Loss:  -5.0984 | Function Loss:  -3.7253\n",
            "Total loss:  -3.5721 | PDE Loss:  -5.0994 | Function Loss:  -3.7251\n",
            "Total loss:  -3.5723 | PDE Loss:  -5.1008 | Function Loss:  -3.7247\n",
            "Total loss:  -3.5724 | PDE Loss:  -5.1019 | Function Loss:  -3.7244\n",
            "Total loss:  -3.5725 | PDE Loss:  -5.1036 | Function Loss:  -3.7239\n",
            "Total loss:  -3.5726 | PDE Loss:  -5.1048 | Function Loss:  -3.7236\n",
            "Total loss:  -3.5728 | PDE Loss:  -5.106 | Function Loss:  -3.7233\n",
            "Total loss:  -3.5729 | PDE Loss:  -5.1071 | Function Loss:  -3.7231\n",
            "Total loss:  -3.5731 | PDE Loss:  -5.1075 | Function Loss:  -3.7232\n",
            "Total loss:  -3.5656 | PDE Loss:  -5.1125 | Function Loss:  -3.7106\n",
            "Total loss:  -3.5731 | PDE Loss:  -5.1086 | Function Loss:  -3.7228\n",
            "Total loss:  -3.5733 | PDE Loss:  -5.1087 | Function Loss:  -3.723\n",
            "Total loss:  -3.5735 | PDE Loss:  -5.1085 | Function Loss:  -3.7233\n",
            "Total loss:  -3.57 | PDE Loss:  -5.1122 | Function Loss:  -3.7169\n",
            "Total loss:  -3.5736 | PDE Loss:  -5.109 | Function Loss:  -3.7232\n",
            "Total loss:  -3.5738 | PDE Loss:  -5.1089 | Function Loss:  -3.7236\n",
            "Total loss:  -3.5742 | PDE Loss:  -5.1085 | Function Loss:  -3.7242\n",
            "Total loss:  -3.5745 | PDE Loss:  -5.1092 | Function Loss:  -3.7244\n",
            "Total loss:  -3.5748 | PDE Loss:  -5.1097 | Function Loss:  -3.7247\n",
            "Total loss:  -3.5751 | PDE Loss:  -5.1106 | Function Loss:  -3.7247\n",
            "Total loss:  -3.5755 | PDE Loss:  -5.1124 | Function Loss:  -3.7245\n",
            "Total loss:  -3.5758 | PDE Loss:  -5.1145 | Function Loss:  -3.7241\n",
            "Total loss:  -3.576 | PDE Loss:  -5.1162 | Function Loss:  -3.7237\n",
            "Total loss:  -3.5762 | PDE Loss:  -5.118 | Function Loss:  -3.7233\n",
            "Total loss:  -3.5764 | PDE Loss:  -5.1191 | Function Loss:  -3.723\n",
            "Total loss:  -3.5765 | PDE Loss:  -5.1197 | Function Loss:  -3.723\n",
            "Total loss:  -3.5767 | PDE Loss:  -5.1197 | Function Loss:  -3.7233\n",
            "Total loss:  -3.5769 | PDE Loss:  -5.1188 | Function Loss:  -3.7238\n",
            "Total loss:  -3.5768 | PDE Loss:  -5.1247 | Function Loss:  -3.7215\n",
            "Total loss:  -3.577 | PDE Loss:  -5.1217 | Function Loss:  -3.7229\n",
            "Total loss:  -3.5773 | PDE Loss:  -5.12 | Function Loss:  -3.724\n",
            "Total loss:  -3.5775 | PDE Loss:  -5.1181 | Function Loss:  -3.7251\n",
            "Total loss:  -3.5778 | PDE Loss:  -5.1159 | Function Loss:  -3.7264\n",
            "Total loss:  -3.5781 | PDE Loss:  -5.1135 | Function Loss:  -3.7278\n",
            "Total loss:  -3.5784 | PDE Loss:  -5.1121 | Function Loss:  -3.7287\n",
            "Total loss:  -3.5786 | PDE Loss:  -5.111 | Function Loss:  -3.7295\n",
            "Total loss:  -3.5789 | PDE Loss:  -5.1105 | Function Loss:  -3.7301\n",
            "Total loss:  -3.5792 | PDE Loss:  -5.1106 | Function Loss:  -3.7305\n",
            "Total loss:  -3.5794 | PDE Loss:  -5.1111 | Function Loss:  -3.7305\n",
            "Total loss:  -3.5795 | PDE Loss:  -5.1116 | Function Loss:  -3.7305\n",
            "Total loss:  -3.5796 | PDE Loss:  -5.1123 | Function Loss:  -3.7304\n",
            "Total loss:  -3.5797 | PDE Loss:  -5.1127 | Function Loss:  -3.7303\n",
            "Total loss:  -3.5798 | PDE Loss:  -5.1132 | Function Loss:  -3.7303\n",
            "Total loss:  -3.58 | PDE Loss:  -5.114 | Function Loss:  -3.7302\n",
            "Total loss:  -3.5802 | PDE Loss:  -5.1155 | Function Loss:  -3.7299\n",
            "Total loss:  -3.5806 | PDE Loss:  -5.115 | Function Loss:  -3.7306\n",
            "Total loss:  -3.5795 | PDE Loss:  -5.1299 | Function Loss:  -3.7232\n",
            "Total loss:  -3.5808 | PDE Loss:  -5.1196 | Function Loss:  -3.729\n",
            "Total loss:  -3.581 | PDE Loss:  -5.1196 | Function Loss:  -3.7293\n",
            "Total loss:  -3.5815 | PDE Loss:  -5.1191 | Function Loss:  -3.7302\n",
            "Total loss:  -3.5819 | PDE Loss:  -5.1184 | Function Loss:  -3.7311\n",
            "Total loss:  -3.5821 | PDE Loss:  -5.1182 | Function Loss:  -3.7315\n",
            "Total loss:  -3.5823 | PDE Loss:  -5.1178 | Function Loss:  -3.7319\n",
            "Total loss:  -3.5826 | PDE Loss:  -5.1155 | Function Loss:  -3.7333\n",
            "Total loss:  -3.5829 | PDE Loss:  -5.1175 | Function Loss:  -3.7328\n",
            "Total loss:  -3.5823 | PDE Loss:  -5.1042 | Function Loss:  -3.7376\n",
            "Total loss:  -3.583 | PDE Loss:  -5.1137 | Function Loss:  -3.7346\n",
            "Total loss:  -3.5832 | PDE Loss:  -5.1143 | Function Loss:  -3.7346\n",
            "Total loss:  -3.5836 | PDE Loss:  -5.1156 | Function Loss:  -3.7346\n",
            "Total loss:  -3.5839 | PDE Loss:  -5.1165 | Function Loss:  -3.7347\n",
            "Total loss:  -3.5842 | PDE Loss:  -5.1172 | Function Loss:  -3.7348\n",
            "Total loss:  -3.5844 | PDE Loss:  -5.1171 | Function Loss:  -3.7352\n",
            "Total loss:  -3.5846 | PDE Loss:  -5.1168 | Function Loss:  -3.7356\n",
            "Total loss:  -3.5849 | PDE Loss:  -5.1161 | Function Loss:  -3.7362\n",
            "Total loss:  -3.5852 | PDE Loss:  -5.1151 | Function Loss:  -3.7372\n",
            "Total loss:  -3.5856 | PDE Loss:  -5.1134 | Function Loss:  -3.7385\n",
            "Total loss:  -3.586 | PDE Loss:  -5.1118 | Function Loss:  -3.7397\n",
            "Total loss:  -3.5865 | PDE Loss:  -5.1095 | Function Loss:  -3.7413\n",
            "Total loss:  -3.5869 | PDE Loss:  -5.1072 | Function Loss:  -3.743\n",
            "Total loss:  -3.5875 | PDE Loss:  -5.1043 | Function Loss:  -3.7451\n",
            "Total loss:  -3.5882 | PDE Loss:  -5.102 | Function Loss:  -3.7471\n",
            "Total loss:  -3.5887 | PDE Loss:  -5.101 | Function Loss:  -3.7482\n",
            "Total loss:  -3.5894 | PDE Loss:  -5.1015 | Function Loss:  -3.749\n",
            "Total loss:  -3.59 | PDE Loss:  -5.1027 | Function Loss:  -3.7494\n",
            "Total loss:  -3.5906 | PDE Loss:  -5.1049 | Function Loss:  -3.7492\n",
            "Total loss:  -3.591 | PDE Loss:  -5.105 | Function Loss:  -3.7498\n",
            "Total loss:  -3.5913 | PDE Loss:  -5.105 | Function Loss:  -3.7502\n",
            "Total loss:  -3.5918 | PDE Loss:  -5.1032 | Function Loss:  -3.7518\n",
            "Total loss:  -3.5923 | PDE Loss:  -5.1033 | Function Loss:  -3.7524\n",
            "Total loss:  -3.5927 | PDE Loss:  -5.1033 | Function Loss:  -3.753\n",
            "Total loss:  -3.5931 | PDE Loss:  -5.104 | Function Loss:  -3.7532\n",
            "Total loss:  -3.5935 | PDE Loss:  -5.1048 | Function Loss:  -3.7534\n",
            "Total loss:  -3.593 | PDE Loss:  -5.1038 | Function Loss:  -3.7532\n",
            "Total loss:  -3.5936 | PDE Loss:  -5.1046 | Function Loss:  -3.7537\n",
            "Total loss:  -3.5939 | PDE Loss:  -5.1057 | Function Loss:  -3.7537\n",
            "Total loss:  -3.5943 | PDE Loss:  -5.1075 | Function Loss:  -3.7534\n",
            "Total loss:  -3.5947 | PDE Loss:  -5.1097 | Function Loss:  -3.753\n",
            "Total loss:  -3.595 | PDE Loss:  -5.1118 | Function Loss:  -3.7525\n",
            "Total loss:  -3.5952 | PDE Loss:  -5.1131 | Function Loss:  -3.7523\n",
            "Total loss:  -3.5955 | PDE Loss:  -5.1145 | Function Loss:  -3.7521\n",
            "Total loss:  -3.5959 | PDE Loss:  -5.1157 | Function Loss:  -3.7521\n",
            "Total loss:  -3.5962 | PDE Loss:  -5.1165 | Function Loss:  -3.7522\n",
            "Total loss:  -3.5965 | PDE Loss:  -5.1132 | Function Loss:  -3.754\n",
            "Total loss:  -3.5969 | PDE Loss:  -5.1153 | Function Loss:  -3.7538\n",
            "Total loss:  -3.5974 | PDE Loss:  -5.1182 | Function Loss:  -3.7531\n",
            "Total loss:  -3.5977 | PDE Loss:  -5.1204 | Function Loss:  -3.7527\n",
            "Total loss:  -3.5981 | PDE Loss:  -5.1232 | Function Loss:  -3.752\n",
            "Total loss:  -3.5984 | PDE Loss:  -5.1253 | Function Loss:  -3.7515\n",
            "Total loss:  -3.5986 | PDE Loss:  -5.1276 | Function Loss:  -3.7509\n",
            "Total loss:  -3.5988 | PDE Loss:  -5.1293 | Function Loss:  -3.7505\n",
            "Total loss:  -3.599 | PDE Loss:  -5.1306 | Function Loss:  -3.7503\n",
            "Total loss:  -3.5993 | PDE Loss:  -5.1315 | Function Loss:  -3.7502\n",
            "Total loss:  -3.5995 | PDE Loss:  -5.1322 | Function Loss:  -3.7503\n",
            "Total loss:  -3.5997 | PDE Loss:  -5.1323 | Function Loss:  -3.7505\n",
            "Total loss:  -3.5999 | PDE Loss:  -5.1336 | Function Loss:  -3.7503\n",
            "Total loss:  -3.6001 | PDE Loss:  -5.1338 | Function Loss:  -3.7504\n",
            "Total loss:  -3.6004 | PDE Loss:  -5.134 | Function Loss:  -3.7508\n",
            "Total loss:  -3.594 | PDE Loss:  -5.117 | Function Loss:  -3.7488\n",
            "Total loss:  -3.6004 | PDE Loss:  -5.1333 | Function Loss:  -3.7511\n",
            "Total loss:  -3.6008 | PDE Loss:  -5.1337 | Function Loss:  -3.7515\n",
            "Total loss:  -3.6012 | PDE Loss:  -5.1348 | Function Loss:  -3.7516\n",
            "Total loss:  -3.6015 | PDE Loss:  -5.1347 | Function Loss:  -3.752\n",
            "Total loss:  -3.6019 | PDE Loss:  -5.1345 | Function Loss:  -3.7527\n",
            "Total loss:  -3.6023 | PDE Loss:  -5.1339 | Function Loss:  -3.7534\n",
            "Total loss:  -3.6025 | PDE Loss:  -5.1351 | Function Loss:  -3.7532\n",
            "Total loss:  -3.6026 | PDE Loss:  -5.1311 | Function Loss:  -3.7552\n",
            "Total loss:  -3.6029 | PDE Loss:  -5.1314 | Function Loss:  -3.7554\n",
            "Total loss:  -3.6031 | PDE Loss:  -5.1316 | Function Loss:  -3.7556\n",
            "Total loss:  -3.6034 | PDE Loss:  -5.1313 | Function Loss:  -3.7561\n",
            "Total loss:  -3.6036 | PDE Loss:  -5.1304 | Function Loss:  -3.7569\n",
            "Total loss:  -3.6039 | PDE Loss:  -5.1297 | Function Loss:  -3.7576\n",
            "Total loss:  -3.6043 | PDE Loss:  -5.1283 | Function Loss:  -3.7588\n",
            "Total loss:  -3.6047 | PDE Loss:  -5.1279 | Function Loss:  -3.7595\n",
            "Total loss:  -3.6051 | PDE Loss:  -5.1275 | Function Loss:  -3.7602\n",
            "Total loss:  -3.6054 | PDE Loss:  -5.1279 | Function Loss:  -3.7605\n",
            "Total loss:  -3.6057 | PDE Loss:  -5.1289 | Function Loss:  -3.7605\n",
            "Total loss:  -3.6061 | PDE Loss:  -5.1302 | Function Loss:  -3.7605\n",
            "Total loss:  -3.6065 | PDE Loss:  -5.1327 | Function Loss:  -3.76\n",
            "Total loss:  -3.607 | PDE Loss:  -5.1344 | Function Loss:  -3.7599\n",
            "Total loss:  -3.6074 | PDE Loss:  -5.1376 | Function Loss:  -3.7593\n",
            "Total loss:  -3.608 | PDE Loss:  -5.1396 | Function Loss:  -3.7592\n",
            "Total loss:  -3.6087 | PDE Loss:  -5.1418 | Function Loss:  -3.7593\n",
            "Total loss:  -3.6094 | PDE Loss:  -5.1424 | Function Loss:  -3.7601\n",
            "Total loss:  -3.6101 | PDE Loss:  -5.1429 | Function Loss:  -3.7608\n",
            "Total loss:  -3.6106 | PDE Loss:  -5.1419 | Function Loss:  -3.7619\n",
            "Total loss:  -3.611 | PDE Loss:  -5.1413 | Function Loss:  -3.7628\n",
            "Total loss:  -3.6113 | PDE Loss:  -5.1405 | Function Loss:  -3.7636\n",
            "Total loss:  -3.6116 | PDE Loss:  -5.1401 | Function Loss:  -3.7641\n",
            "Total loss:  -3.6118 | PDE Loss:  -5.1398 | Function Loss:  -3.7646\n",
            "Total loss:  -3.612 | PDE Loss:  -5.1397 | Function Loss:  -3.7649\n",
            "Total loss:  -3.6123 | PDE Loss:  -5.1398 | Function Loss:  -3.7652\n",
            "Total loss:  -3.6112 | PDE Loss:  -5.1372 | Function Loss:  -3.7648\n",
            "Total loss:  -3.6125 | PDE Loss:  -5.1397 | Function Loss:  -3.7655\n",
            "Total loss:  -3.6129 | PDE Loss:  -5.1396 | Function Loss:  -3.7661\n",
            "Total loss:  -3.6134 | PDE Loss:  -5.1402 | Function Loss:  -3.7667\n",
            "Total loss:  -3.614 | PDE Loss:  -5.1378 | Function Loss:  -3.7685\n",
            "Total loss:  -3.6145 | PDE Loss:  -5.1382 | Function Loss:  -3.769\n",
            "Total loss:  -3.615 | PDE Loss:  -5.139 | Function Loss:  -3.7695\n",
            "Total loss:  -3.6155 | PDE Loss:  -5.138 | Function Loss:  -3.7705\n",
            "Total loss:  -3.6157 | PDE Loss:  -5.137 | Function Loss:  -3.7713\n",
            "Total loss:  -3.6162 | PDE Loss:  -5.1379 | Function Loss:  -3.7716\n",
            "Total loss:  -3.6168 | PDE Loss:  -5.1355 | Function Loss:  -3.7736\n",
            "Total loss:  -3.6172 | PDE Loss:  -5.135 | Function Loss:  -3.7744\n",
            "Total loss:  -3.6177 | PDE Loss:  -5.1352 | Function Loss:  -3.7749\n",
            "Total loss:  -3.6182 | PDE Loss:  -5.1358 | Function Loss:  -3.7753\n",
            "Total loss:  -3.6186 | PDE Loss:  -5.1369 | Function Loss:  -3.7755\n",
            "Total loss:  -3.619 | PDE Loss:  -5.1386 | Function Loss:  -3.7753\n",
            "Total loss:  -3.6193 | PDE Loss:  -5.1404 | Function Loss:  -3.775\n",
            "Total loss:  -3.6197 | PDE Loss:  -5.1428 | Function Loss:  -3.7746\n",
            "Total loss:  -3.6202 | PDE Loss:  -5.1458 | Function Loss:  -3.774\n",
            "Total loss:  -3.6209 | PDE Loss:  -5.1489 | Function Loss:  -3.7735\n",
            "Total loss:  -3.62 | PDE Loss:  -5.1587 | Function Loss:  -3.7683\n",
            "Total loss:  -3.6212 | PDE Loss:  -5.1529 | Function Loss:  -3.7724\n",
            "Total loss:  -3.6216 | PDE Loss:  -5.155 | Function Loss:  -3.7721\n",
            "Total loss:  -3.622 | PDE Loss:  -5.156 | Function Loss:  -3.7723\n",
            "Total loss:  -3.6224 | PDE Loss:  -5.1561 | Function Loss:  -3.7728\n",
            "Total loss:  -3.6228 | PDE Loss:  -5.1559 | Function Loss:  -3.7734\n",
            "Total loss:  -3.6232 | PDE Loss:  -5.1552 | Function Loss:  -3.7743\n",
            "Total loss:  -3.6236 | PDE Loss:  -5.1544 | Function Loss:  -3.7751\n",
            "Total loss:  -3.6239 | PDE Loss:  -5.154 | Function Loss:  -3.7758\n",
            "Total loss:  -3.6243 | PDE Loss:  -5.1536 | Function Loss:  -3.7764\n",
            "Total loss:  -3.6247 | PDE Loss:  -5.1536 | Function Loss:  -3.777\n",
            "Total loss:  -3.6251 | PDE Loss:  -5.1538 | Function Loss:  -3.7775\n",
            "Total loss:  -3.6255 | PDE Loss:  -5.1543 | Function Loss:  -3.7779\n",
            "Total loss:  -3.6258 | PDE Loss:  -5.1545 | Function Loss:  -3.7783\n",
            "Total loss:  -3.6261 | PDE Loss:  -5.1564 | Function Loss:  -3.7778\n",
            "Total loss:  -3.6264 | PDE Loss:  -5.1562 | Function Loss:  -3.7783\n",
            "Total loss:  -3.6266 | PDE Loss:  -5.1558 | Function Loss:  -3.7788\n",
            "Total loss:  -3.6269 | PDE Loss:  -5.1554 | Function Loss:  -3.7795\n",
            "Total loss:  -3.6272 | PDE Loss:  -5.155 | Function Loss:  -3.78\n",
            "Total loss:  -3.6275 | PDE Loss:  -5.1547 | Function Loss:  -3.7805\n",
            "Total loss:  -3.6277 | PDE Loss:  -5.1543 | Function Loss:  -3.7811\n",
            "Total loss:  -3.628 | PDE Loss:  -5.1538 | Function Loss:  -3.7816\n",
            "Total loss:  -3.6282 | PDE Loss:  -5.1532 | Function Loss:  -3.7822\n",
            "Total loss:  -3.6284 | PDE Loss:  -5.1532 | Function Loss:  -3.7824\n",
            "Total loss:  -3.6273 | PDE Loss:  -5.1464 | Function Loss:  -3.7838\n",
            "Total loss:  -3.6284 | PDE Loss:  -5.1522 | Function Loss:  -3.783\n",
            "Total loss:  -3.6286 | PDE Loss:  -5.1502 | Function Loss:  -3.784\n",
            "Total loss:  -3.6287 | PDE Loss:  -5.1506 | Function Loss:  -3.784\n",
            "Total loss:  -3.629 | PDE Loss:  -5.152 | Function Loss:  -3.7839\n",
            "Total loss:  -3.6294 | PDE Loss:  -5.1528 | Function Loss:  -3.784\n",
            "Total loss:  -3.6297 | PDE Loss:  -5.1541 | Function Loss:  -3.7839\n",
            "Total loss:  -3.6301 | PDE Loss:  -5.1559 | Function Loss:  -3.7837\n",
            "Total loss:  -3.6305 | PDE Loss:  -5.1577 | Function Loss:  -3.7835\n",
            "Total loss:  -3.6308 | PDE Loss:  -5.1581 | Function Loss:  -3.7838\n",
            "Total loss:  -3.6312 | PDE Loss:  -5.1584 | Function Loss:  -3.7842\n",
            "Total loss:  -3.6316 | PDE Loss:  -5.1581 | Function Loss:  -3.785\n",
            "Total loss:  -3.6319 | PDE Loss:  -5.1564 | Function Loss:  -3.7861\n",
            "Total loss:  -3.6323 | PDE Loss:  -5.1571 | Function Loss:  -3.7863\n",
            "Total loss:  -3.6326 | PDE Loss:  -5.1566 | Function Loss:  -3.787\n",
            "Total loss:  -3.6332 | PDE Loss:  -5.1576 | Function Loss:  -3.7875\n",
            "Total loss:  -3.6339 | PDE Loss:  -5.1588 | Function Loss:  -3.7879\n",
            "Total loss:  -3.6344 | PDE Loss:  -5.161 | Function Loss:  -3.7878\n",
            "Total loss:  -3.6348 | PDE Loss:  -5.162 | Function Loss:  -3.7878\n",
            "Total loss:  -3.6353 | PDE Loss:  -5.1645 | Function Loss:  -3.7875\n",
            "Total loss:  -3.6358 | PDE Loss:  -5.1665 | Function Loss:  -3.7873\n",
            "Total loss:  -3.6361 | PDE Loss:  -5.1679 | Function Loss:  -3.7872\n",
            "Total loss:  -3.6364 | PDE Loss:  -5.1683 | Function Loss:  -3.7875\n",
            "Total loss:  -3.6352 | PDE Loss:  -5.1586 | Function Loss:  -3.7899\n",
            "Total loss:  -3.6366 | PDE Loss:  -5.1662 | Function Loss:  -3.7886\n",
            "Total loss:  -3.637 | PDE Loss:  -5.1661 | Function Loss:  -3.7893\n",
            "Total loss:  -3.6375 | PDE Loss:  -5.1659 | Function Loss:  -3.7901\n",
            "Total loss:  -3.6381 | PDE Loss:  -5.1659 | Function Loss:  -3.791\n",
            "Total loss:  -3.6389 | PDE Loss:  -5.1652 | Function Loss:  -3.7923\n",
            "Total loss:  -3.6394 | PDE Loss:  -5.1655 | Function Loss:  -3.7929\n",
            "Total loss:  -3.6404 | PDE Loss:  -5.1666 | Function Loss:  -3.7939\n",
            "Total loss:  -3.6413 | PDE Loss:  -5.1678 | Function Loss:  -3.7946\n",
            "Total loss:  -3.6418 | PDE Loss:  -5.1689 | Function Loss:  -3.7949\n",
            "Total loss:  -3.6422 | PDE Loss:  -5.1696 | Function Loss:  -3.7952\n",
            "Total loss:  -3.6424 | PDE Loss:  -5.1699 | Function Loss:  -3.7954\n",
            "Total loss:  -3.6429 | PDE Loss:  -5.1702 | Function Loss:  -3.7959\n",
            "Total loss:  -3.6433 | PDE Loss:  -5.1707 | Function Loss:  -3.7963\n",
            "Total loss:  -3.6437 | PDE Loss:  -5.1697 | Function Loss:  -3.7973\n",
            "Total loss:  -3.644 | PDE Loss:  -5.17 | Function Loss:  -3.7976\n",
            "Total loss:  -3.6435 | PDE Loss:  -5.1639 | Function Loss:  -3.7995\n",
            "Total loss:  -3.6444 | PDE Loss:  -5.1679 | Function Loss:  -3.799\n",
            "Total loss:  -3.6446 | PDE Loss:  -5.1673 | Function Loss:  -3.7996\n",
            "Total loss:  -3.6451 | PDE Loss:  -5.1662 | Function Loss:  -3.8007\n",
            "Total loss:  -3.6455 | PDE Loss:  -5.1648 | Function Loss:  -3.8019\n",
            "Total loss:  -3.6458 | PDE Loss:  -5.1659 | Function Loss:  -3.802\n",
            "Total loss:  -3.6462 | PDE Loss:  -5.1642 | Function Loss:  -3.8032\n",
            "Total loss:  -3.6464 | PDE Loss:  -5.1645 | Function Loss:  -3.8033\n",
            "Total loss:  -3.6467 | PDE Loss:  -5.1648 | Function Loss:  -3.8036\n",
            "Total loss:  -3.6469 | PDE Loss:  -5.1661 | Function Loss:  -3.8034\n",
            "Total loss:  -3.6471 | PDE Loss:  -5.1672 | Function Loss:  -3.8032\n",
            "Total loss:  -3.6474 | PDE Loss:  -5.1688 | Function Loss:  -3.8029\n",
            "Total loss:  -3.6477 | PDE Loss:  -5.1712 | Function Loss:  -3.8024\n",
            "Total loss:  -3.648 | PDE Loss:  -5.1722 | Function Loss:  -3.8023\n",
            "Total loss:  -3.6484 | PDE Loss:  -5.1739 | Function Loss:  -3.8023\n",
            "Total loss:  -3.6489 | PDE Loss:  -5.1753 | Function Loss:  -3.8023\n",
            "Total loss:  -3.6492 | PDE Loss:  -5.1763 | Function Loss:  -3.8024\n",
            "Total loss:  -3.6496 | PDE Loss:  -5.177 | Function Loss:  -3.8025\n",
            "Total loss:  -3.6499 | PDE Loss:  -5.1774 | Function Loss:  -3.8028\n",
            "Total loss:  -3.6501 | PDE Loss:  -5.1777 | Function Loss:  -3.8031\n",
            "Total loss:  -3.6504 | PDE Loss:  -5.1776 | Function Loss:  -3.8035\n",
            "Total loss:  -3.6506 | PDE Loss:  -5.1778 | Function Loss:  -3.8037\n",
            "Total loss:  -3.6508 | PDE Loss:  -5.1772 | Function Loss:  -3.8042\n",
            "Total loss:  -3.651 | PDE Loss:  -5.1776 | Function Loss:  -3.8043\n",
            "Total loss:  -3.6513 | PDE Loss:  -5.1775 | Function Loss:  -3.8047\n",
            "Total loss:  -3.6516 | PDE Loss:  -5.1779 | Function Loss:  -3.805\n",
            "Total loss:  -3.6519 | PDE Loss:  -5.1781 | Function Loss:  -3.8054\n",
            "Total loss:  -3.6522 | PDE Loss:  -5.1784 | Function Loss:  -3.8057\n",
            "Total loss:  -3.6525 | PDE Loss:  -5.1789 | Function Loss:  -3.8058\n",
            "Total loss:  -3.6529 | PDE Loss:  -5.1792 | Function Loss:  -3.8063\n",
            "Total loss:  -3.6532 | PDE Loss:  -5.1787 | Function Loss:  -3.8069\n",
            "Total loss:  -3.6534 | PDE Loss:  -5.1798 | Function Loss:  -3.8069\n",
            "Total loss:  -3.6537 | PDE Loss:  -5.1797 | Function Loss:  -3.8073\n",
            "Total loss:  -3.654 | PDE Loss:  -5.1801 | Function Loss:  -3.8075\n",
            "Total loss:  -3.6543 | PDE Loss:  -5.1808 | Function Loss:  -3.8077\n",
            "Total loss:  -3.6544 | PDE Loss:  -5.1814 | Function Loss:  -3.8076\n",
            "Total loss:  -3.6547 | PDE Loss:  -5.183 | Function Loss:  -3.8073\n",
            "Total loss:  -3.6549 | PDE Loss:  -5.1844 | Function Loss:  -3.807\n",
            "Total loss:  -3.6551 | PDE Loss:  -5.1863 | Function Loss:  -3.8065\n",
            "Total loss:  -3.6553 | PDE Loss:  -5.1882 | Function Loss:  -3.806\n",
            "Total loss:  -3.6555 | PDE Loss:  -5.1881 | Function Loss:  -3.8063\n",
            "Total loss:  -3.6557 | PDE Loss:  -5.1881 | Function Loss:  -3.8066\n",
            "Total loss:  -3.6559 | PDE Loss:  -5.1879 | Function Loss:  -3.8069\n",
            "Total loss:  -3.656 | PDE Loss:  -5.1879 | Function Loss:  -3.8071\n",
            "Total loss:  -3.6562 | PDE Loss:  -5.1879 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6563 | PDE Loss:  -5.1881 | Function Loss:  -3.8075\n",
            "Total loss:  -3.6565 | PDE Loss:  -5.1891 | Function Loss:  -3.8073\n",
            "Total loss:  -3.6566 | PDE Loss:  -5.1892 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6567 | PDE Loss:  -5.1897 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6569 | PDE Loss:  -5.1907 | Function Loss:  -3.8072\n",
            "Total loss:  -3.657 | PDE Loss:  -5.1907 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6572 | PDE Loss:  -5.1911 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6573 | PDE Loss:  -5.1908 | Function Loss:  -3.8077\n",
            "Total loss:  -3.6574 | PDE Loss:  -5.1912 | Function Loss:  -3.8077\n",
            "Total loss:  -3.6575 | PDE Loss:  -5.1922 | Function Loss:  -3.8074\n",
            "Total loss:  -3.6574 | PDE Loss:  -5.1887 | Function Loss:  -3.8087\n",
            "Total loss:  -3.6576 | PDE Loss:  -5.1911 | Function Loss:  -3.808\n",
            "Total loss:  -3.6577 | PDE Loss:  -5.1923 | Function Loss:  -3.8076\n",
            "Total loss:  -3.6578 | PDE Loss:  -5.194 | Function Loss:  -3.8071\n",
            "Total loss:  -3.6579 | PDE Loss:  -5.1948 | Function Loss:  -3.8069\n",
            "Total loss:  -3.6579 | PDE Loss:  -5.1961 | Function Loss:  -3.8065\n",
            "Total loss:  -3.658 | PDE Loss:  -5.1967 | Function Loss:  -3.8063\n",
            "Total loss:  -3.6581 | PDE Loss:  -5.1971 | Function Loss:  -3.8063\n",
            "Total loss:  -3.6582 | PDE Loss:  -5.1972 | Function Loss:  -3.8064\n",
            "Total loss:  -3.6583 | PDE Loss:  -5.1971 | Function Loss:  -3.8066\n",
            "Total loss:  -3.6584 | PDE Loss:  -5.1968 | Function Loss:  -3.8069\n",
            "Total loss:  -3.6585 | PDE Loss:  -5.1962 | Function Loss:  -3.8072\n",
            "Total loss:  -3.6586 | PDE Loss:  -5.1958 | Function Loss:  -3.8076\n",
            "Total loss:  -3.6587 | PDE Loss:  -5.195 | Function Loss:  -3.808\n",
            "Total loss:  -3.6588 | PDE Loss:  -5.1943 | Function Loss:  -3.8084\n",
            "Total loss:  -3.6589 | PDE Loss:  -5.1939 | Function Loss:  -3.8087\n",
            "Total loss:  -3.659 | PDE Loss:  -5.1937 | Function Loss:  -3.8089\n",
            "Total loss:  -3.6591 | PDE Loss:  -5.1932 | Function Loss:  -3.8093\n",
            "Total loss:  -3.6593 | PDE Loss:  -5.194 | Function Loss:  -3.8092\n",
            "Total loss:  -3.6594 | PDE Loss:  -5.1944 | Function Loss:  -3.8092\n",
            "Total loss:  -3.6595 | PDE Loss:  -5.1947 | Function Loss:  -3.8093\n",
            "Total loss:  -3.6597 | PDE Loss:  -5.1955 | Function Loss:  -3.8091\n",
            "Total loss:  -3.6599 | PDE Loss:  -5.1965 | Function Loss:  -3.809\n",
            "Total loss:  -3.6599 | PDE Loss:  -5.1948 | Function Loss:  -3.8098\n",
            "Total loss:  -3.6602 | PDE Loss:  -5.1956 | Function Loss:  -3.8098\n",
            "Total loss:  -3.6604 | PDE Loss:  -5.1962 | Function Loss:  -3.8098\n",
            "Total loss:  -3.6606 | PDE Loss:  -5.1962 | Function Loss:  -3.8102\n",
            "Total loss:  -3.6609 | PDE Loss:  -5.1963 | Function Loss:  -3.8105\n",
            "Total loss:  -3.6458 | PDE Loss:  -5.1726 | Function Loss:  -3.7991\n",
            "Total loss:  -3.6609 | PDE Loss:  -5.1956 | Function Loss:  -3.8109\n",
            "Total loss:  -3.6611 | PDE Loss:  -5.1956 | Function Loss:  -3.8112\n",
            "Total loss:  -3.6613 | PDE Loss:  -5.1952 | Function Loss:  -3.8116\n",
            "Total loss:  -3.6615 | PDE Loss:  -5.1945 | Function Loss:  -3.8122\n",
            "Total loss:  -3.6617 | PDE Loss:  -5.1934 | Function Loss:  -3.8129\n",
            "Total loss:  -3.6619 | PDE Loss:  -5.1922 | Function Loss:  -3.8136\n",
            "Total loss:  -3.6621 | PDE Loss:  -5.1903 | Function Loss:  -3.8148\n",
            "Total loss:  -3.6625 | PDE Loss:  -5.1874 | Function Loss:  -3.8165\n",
            "Total loss:  -3.6628 | PDE Loss:  -5.1849 | Function Loss:  -3.8181\n",
            "Total loss:  -3.6631 | PDE Loss:  -5.1828 | Function Loss:  -3.8193\n",
            "Total loss:  -3.6633 | PDE Loss:  -5.1813 | Function Loss:  -3.8204\n",
            "Total loss:  -3.6637 | PDE Loss:  -5.1798 | Function Loss:  -3.8215\n",
            "Total loss:  -3.6641 | PDE Loss:  -5.1794 | Function Loss:  -3.8223\n",
            "Total loss:  -3.6645 | PDE Loss:  -5.1764 | Function Loss:  -3.8243\n",
            "Total loss:  -3.6526 | PDE Loss:  -5.1605 | Function Loss:  -3.8141\n",
            "Total loss:  -3.6651 | PDE Loss:  -5.1749 | Function Loss:  -3.8257\n",
            "Total loss:  -3.6656 | PDE Loss:  -5.177 | Function Loss:  -3.8255\n",
            "Total loss:  -3.6672 | PDE Loss:  -5.1836 | Function Loss:  -3.8249\n",
            "Total loss:  -3.669 | PDE Loss:  -5.1875 | Function Loss:  -3.8259\n",
            "Total loss:  -3.6703 | PDE Loss:  -5.1908 | Function Loss:  -3.8263\n",
            "Total loss:  -3.6716 | PDE Loss:  -5.1934 | Function Loss:  -3.827\n",
            "Total loss:  -3.6725 | PDE Loss:  -5.1964 | Function Loss:  -3.827\n",
            "Total loss:  -3.6733 | PDE Loss:  -5.1955 | Function Loss:  -3.8285\n",
            "Total loss:  -3.674 | PDE Loss:  -5.1949 | Function Loss:  -3.8298\n",
            "Total loss:  -3.6748 | PDE Loss:  -5.1937 | Function Loss:  -3.8314\n",
            "Total loss:  -3.6756 | PDE Loss:  -5.1934 | Function Loss:  -3.8327\n",
            "Total loss:  -3.6763 | PDE Loss:  -5.1935 | Function Loss:  -3.8337\n",
            "Total loss:  -3.6771 | PDE Loss:  -5.1923 | Function Loss:  -3.8354\n",
            "Total loss:  -3.678 | PDE Loss:  -5.1937 | Function Loss:  -3.836\n",
            "Total loss:  -3.6787 | PDE Loss:  -5.1934 | Function Loss:  -3.8371\n",
            "Total loss:  -3.6794 | PDE Loss:  -5.1934 | Function Loss:  -3.8382\n",
            "Total loss:  -3.68 | PDE Loss:  -5.1945 | Function Loss:  -3.8385\n",
            "Total loss:  -3.6804 | PDE Loss:  -5.1954 | Function Loss:  -3.8387\n",
            "Total loss:  -3.6809 | PDE Loss:  -5.1972 | Function Loss:  -3.8386\n",
            "Total loss:  -3.6813 | PDE Loss:  -5.1986 | Function Loss:  -3.8387\n",
            "Total loss:  -3.6818 | PDE Loss:  -5.1999 | Function Loss:  -3.8388\n",
            "Total loss:  -3.6799 | PDE Loss:  -5.1924 | Function Loss:  -3.8393\n",
            "Total loss:  -3.6823 | PDE Loss:  -5.1979 | Function Loss:  -3.8403\n",
            "Total loss:  -3.683 | PDE Loss:  -5.1989 | Function Loss:  -3.841\n",
            "Total loss:  -3.6839 | PDE Loss:  -5.2001 | Function Loss:  -3.8417\n",
            "Total loss:  -3.6847 | PDE Loss:  -5.2001 | Function Loss:  -3.8428\n",
            "Total loss:  -3.6852 | PDE Loss:  -5.2024 | Function Loss:  -3.8426\n",
            "Total loss:  -3.6857 | PDE Loss:  -5.2019 | Function Loss:  -3.8435\n",
            "Total loss:  -3.6862 | PDE Loss:  -5.2028 | Function Loss:  -3.8438\n",
            "Total loss:  -3.6866 | PDE Loss:  -5.2042 | Function Loss:  -3.8437\n",
            "Total loss:  -3.6869 | PDE Loss:  -5.2066 | Function Loss:  -3.8432\n",
            "Total loss:  -3.6872 | PDE Loss:  -5.2075 | Function Loss:  -3.8433\n",
            "Total loss:  -3.6876 | PDE Loss:  -5.2085 | Function Loss:  -3.8433\n",
            "Total loss:  -3.6879 | PDE Loss:  -5.2086 | Function Loss:  -3.8437\n",
            "Total loss:  -3.6881 | PDE Loss:  -5.2069 | Function Loss:  -3.8448\n",
            "Total loss:  -3.6883 | PDE Loss:  -5.207 | Function Loss:  -3.845\n",
            "Total loss:  -3.6885 | PDE Loss:  -5.2067 | Function Loss:  -3.8454\n",
            "Total loss:  -3.6888 | PDE Loss:  -5.2061 | Function Loss:  -3.8461\n",
            "Total loss:  -3.689 | PDE Loss:  -5.2054 | Function Loss:  -3.8467\n",
            "Total loss:  -3.6892 | PDE Loss:  -5.2044 | Function Loss:  -3.8474\n",
            "Total loss:  -3.6896 | PDE Loss:  -5.2032 | Function Loss:  -3.8485\n",
            "Total loss:  -3.6898 | PDE Loss:  -5.2028 | Function Loss:  -3.8491\n",
            "Total loss:  -3.6903 | PDE Loss:  -5.2018 | Function Loss:  -3.8501\n",
            "Total loss:  -3.6907 | PDE Loss:  -5.2012 | Function Loss:  -3.851\n",
            "Total loss:  -3.691 | PDE Loss:  -5.201 | Function Loss:  -3.8515\n",
            "Total loss:  -3.6913 | PDE Loss:  -5.2008 | Function Loss:  -3.8521\n",
            "Total loss:  -3.6915 | PDE Loss:  -5.2009 | Function Loss:  -3.8523\n",
            "Total loss:  -3.6918 | PDE Loss:  -5.2011 | Function Loss:  -3.8527\n",
            "Total loss:  -3.6922 | PDE Loss:  -5.2014 | Function Loss:  -3.8531\n",
            "Total loss:  -3.6925 | PDE Loss:  -5.2018 | Function Loss:  -3.8533\n",
            "Total loss:  -3.6927 | PDE Loss:  -5.2019 | Function Loss:  -3.8536\n",
            "Total loss:  -3.6929 | PDE Loss:  -5.2024 | Function Loss:  -3.8537\n",
            "Total loss:  -3.6927 | PDE Loss:  -5.1999 | Function Loss:  -3.8545\n",
            "Total loss:  -3.693 | PDE Loss:  -5.2016 | Function Loss:  -3.8542\n",
            "Total loss:  -3.6931 | PDE Loss:  -5.2019 | Function Loss:  -3.8542\n",
            "Total loss:  -3.6934 | PDE Loss:  -5.2027 | Function Loss:  -3.8542\n",
            "Total loss:  -3.6937 | PDE Loss:  -5.2039 | Function Loss:  -3.8542\n",
            "Total loss:  -3.6941 | PDE Loss:  -5.2055 | Function Loss:  -3.8539\n",
            "Total loss:  -3.6944 | PDE Loss:  -5.2068 | Function Loss:  -3.8538\n",
            "Total loss:  -3.6946 | PDE Loss:  -5.2082 | Function Loss:  -3.8536\n",
            "Total loss:  -3.695 | PDE Loss:  -5.2098 | Function Loss:  -3.8533\n",
            "Total loss:  -3.6954 | PDE Loss:  -5.2113 | Function Loss:  -3.8533\n",
            "Total loss:  -3.6958 | PDE Loss:  -5.2129 | Function Loss:  -3.8532\n",
            "Total loss:  -3.6962 | PDE Loss:  -5.214 | Function Loss:  -3.8533\n",
            "Total loss:  -3.6966 | PDE Loss:  -5.2144 | Function Loss:  -3.8536\n",
            "Total loss:  -3.6969 | PDE Loss:  -5.2145 | Function Loss:  -3.8541\n",
            "Total loss:  -3.6974 | PDE Loss:  -5.2142 | Function Loss:  -3.8549\n",
            "Total loss:  -3.6978 | PDE Loss:  -5.2135 | Function Loss:  -3.8558\n",
            "Total loss:  -3.6982 | PDE Loss:  -5.2126 | Function Loss:  -3.8568\n",
            "Total loss:  -3.6987 | PDE Loss:  -5.2116 | Function Loss:  -3.858\n",
            "Total loss:  -3.6992 | PDE Loss:  -5.2103 | Function Loss:  -3.8592\n",
            "Total loss:  -3.6998 | PDE Loss:  -5.2093 | Function Loss:  -3.8605\n",
            "Total loss:  -3.7006 | PDE Loss:  -5.2085 | Function Loss:  -3.862\n",
            "Total loss:  -3.7017 | PDE Loss:  -5.2078 | Function Loss:  -3.8639\n",
            "Total loss:  -3.7028 | PDE Loss:  -5.2076 | Function Loss:  -3.8657\n",
            "Total loss:  -3.7043 | PDE Loss:  -5.208 | Function Loss:  -3.8678\n",
            "Total loss:  -3.7055 | PDE Loss:  -5.2086 | Function Loss:  -3.8691\n",
            "Total loss:  -3.707 | PDE Loss:  -5.2112 | Function Loss:  -3.8702\n",
            "Total loss:  -3.7088 | PDE Loss:  -5.2153 | Function Loss:  -3.8709\n",
            "Total loss:  -3.7108 | PDE Loss:  -5.2205 | Function Loss:  -3.8715\n",
            "Total loss:  -3.7066 | PDE Loss:  -5.2276 | Function Loss:  -3.8624\n",
            "Total loss:  -3.7121 | PDE Loss:  -5.2254 | Function Loss:  -3.8712\n",
            "Total loss:  -3.7131 | PDE Loss:  -5.2276 | Function Loss:  -3.8717\n",
            "Total loss:  -3.7145 | PDE Loss:  -5.2288 | Function Loss:  -3.8731\n",
            "Total loss:  -3.7154 | PDE Loss:  -5.2306 | Function Loss:  -3.8736\n",
            "Total loss:  -3.7166 | PDE Loss:  -5.232 | Function Loss:  -3.8747\n",
            "Total loss:  -3.7173 | PDE Loss:  -5.2303 | Function Loss:  -3.8765\n",
            "Total loss:  -3.718 | PDE Loss:  -5.2321 | Function Loss:  -3.8767\n",
            "Total loss:  -3.7185 | PDE Loss:  -5.234 | Function Loss:  -3.8766\n",
            "Total loss:  -3.7194 | PDE Loss:  -5.2368 | Function Loss:  -3.8767\n",
            "Total loss:  -3.7202 | PDE Loss:  -5.2385 | Function Loss:  -3.8771\n",
            "Total loss:  -3.721 | PDE Loss:  -5.2412 | Function Loss:  -3.877\n",
            "Total loss:  -3.7216 | PDE Loss:  -5.2427 | Function Loss:  -3.8772\n",
            "Total loss:  -3.7223 | PDE Loss:  -5.2462 | Function Loss:  -3.8767\n",
            "Total loss:  -3.7228 | PDE Loss:  -5.2475 | Function Loss:  -3.8769\n",
            "Total loss:  -3.7236 | PDE Loss:  -5.2497 | Function Loss:  -3.8771\n",
            "Total loss:  -3.7242 | PDE Loss:  -5.2499 | Function Loss:  -3.8779\n",
            "Total loss:  -3.7248 | PDE Loss:  -5.2502 | Function Loss:  -3.8786\n",
            "Total loss:  -3.7252 | PDE Loss:  -5.2494 | Function Loss:  -3.8796\n",
            "Total loss:  -3.7257 | PDE Loss:  -5.2489 | Function Loss:  -3.8805\n",
            "Total loss:  -3.7264 | PDE Loss:  -5.2487 | Function Loss:  -3.8816\n",
            "Total loss:  -3.7274 | PDE Loss:  -5.2483 | Function Loss:  -3.8831\n",
            "Total loss:  -3.7283 | PDE Loss:  -5.2495 | Function Loss:  -3.8839\n",
            "Total loss:  -3.729 | PDE Loss:  -5.2496 | Function Loss:  -3.8849\n",
            "Total loss:  -3.7297 | PDE Loss:  -5.2495 | Function Loss:  -3.8859\n",
            "Total loss:  -3.7303 | PDE Loss:  -5.2507 | Function Loss:  -3.8862\n",
            "Total loss:  -3.7308 | PDE Loss:  -5.2515 | Function Loss:  -3.8866\n",
            "Total loss:  -3.7313 | PDE Loss:  -5.2538 | Function Loss:  -3.8864\n",
            "Total loss:  -3.7313 | PDE Loss:  -5.2571 | Function Loss:  -3.885\n",
            "Total loss:  -3.7317 | PDE Loss:  -5.2559 | Function Loss:  -3.8861\n",
            "Total loss:  -3.7324 | PDE Loss:  -5.2576 | Function Loss:  -3.8863\n",
            "Total loss:  -3.7333 | PDE Loss:  -5.2602 | Function Loss:  -3.8865\n",
            "Total loss:  -3.7341 | PDE Loss:  -5.2621 | Function Loss:  -3.8869\n",
            "Total loss:  -3.7349 | PDE Loss:  -5.2638 | Function Loss:  -3.8873\n",
            "Total loss:  -3.7357 | PDE Loss:  -5.2652 | Function Loss:  -3.8878\n",
            "Total loss:  -3.7364 | PDE Loss:  -5.2659 | Function Loss:  -3.8885\n",
            "Total loss:  -3.7372 | PDE Loss:  -5.2667 | Function Loss:  -3.8894\n",
            "Total loss:  -3.7382 | PDE Loss:  -5.2679 | Function Loss:  -3.8902\n",
            "Total loss:  -3.739 | PDE Loss:  -5.2678 | Function Loss:  -3.8914\n",
            "Total loss:  -3.7398 | PDE Loss:  -5.2699 | Function Loss:  -3.8916\n",
            "Total loss:  -3.7403 | PDE Loss:  -5.2642 | Function Loss:  -3.8948\n",
            "Total loss:  -3.7412 | PDE Loss:  -5.2664 | Function Loss:  -3.8951\n",
            "Total loss:  -3.742 | PDE Loss:  -5.2696 | Function Loss:  -3.8949\n",
            "Total loss:  -3.7427 | PDE Loss:  -5.2714 | Function Loss:  -3.8951\n",
            "Total loss:  -3.7432 | PDE Loss:  -5.2721 | Function Loss:  -3.8956\n",
            "Total loss:  -3.744 | PDE Loss:  -5.2715 | Function Loss:  -3.897\n",
            "Total loss:  -3.7448 | PDE Loss:  -5.2771 | Function Loss:  -3.8957\n",
            "Total loss:  -3.7457 | PDE Loss:  -5.2746 | Function Loss:  -3.898\n",
            "Total loss:  -3.7465 | PDE Loss:  -5.2742 | Function Loss:  -3.8993\n",
            "Total loss:  -3.7475 | PDE Loss:  -5.2754 | Function Loss:  -3.9003\n",
            "Total loss:  -3.7484 | PDE Loss:  -5.2775 | Function Loss:  -3.9007\n",
            "Total loss:  -3.7491 | PDE Loss:  -5.2773 | Function Loss:  -3.9017\n",
            "Total loss:  -3.7496 | PDE Loss:  -5.2814 | Function Loss:  -3.9008\n",
            "Total loss:  -3.7502 | PDE Loss:  -5.2846 | Function Loss:  -3.9002\n",
            "Total loss:  -3.7508 | PDE Loss:  -5.2899 | Function Loss:  -3.8989\n",
            "Total loss:  -3.7513 | PDE Loss:  -5.2939 | Function Loss:  -3.898\n",
            "Total loss:  -3.7516 | PDE Loss:  -5.2963 | Function Loss:  -3.8976\n",
            "Total loss:  -3.7519 | PDE Loss:  -5.2977 | Function Loss:  -3.8974\n",
            "Total loss:  -3.7523 | PDE Loss:  -5.2994 | Function Loss:  -3.8973\n",
            "Total loss:  -3.7527 | PDE Loss:  -5.2994 | Function Loss:  -3.8978\n",
            "Total loss:  -3.7531 | PDE Loss:  -5.2999 | Function Loss:  -3.8981\n",
            "Total loss:  -3.7534 | PDE Loss:  -5.2995 | Function Loss:  -3.8987\n",
            "Total loss:  -3.7537 | PDE Loss:  -5.2996 | Function Loss:  -3.8991\n",
            "Total loss:  -3.754 | PDE Loss:  -5.2998 | Function Loss:  -3.8994\n",
            "Total loss:  -3.7543 | PDE Loss:  -5.3004 | Function Loss:  -3.8996\n",
            "Total loss:  -3.7545 | PDE Loss:  -5.2998 | Function Loss:  -3.9001\n",
            "Total loss:  -3.7552 | PDE Loss:  -5.3013 | Function Loss:  -3.9005\n",
            "Total loss:  -3.7555 | PDE Loss:  -5.3015 | Function Loss:  -3.9009\n",
            "Total loss:  -3.756 | PDE Loss:  -5.3029 | Function Loss:  -3.9011\n",
            "Total loss:  -3.7566 | PDE Loss:  -5.302 | Function Loss:  -3.9022\n",
            "Total loss:  -3.7524 | PDE Loss:  -5.3157 | Function Loss:  -3.891\n",
            "Total loss:  -3.7569 | PDE Loss:  -5.3052 | Function Loss:  -3.9014\n",
            "Total loss:  -3.7572 | PDE Loss:  -5.3054 | Function Loss:  -3.9016\n",
            "Total loss:  -3.7574 | PDE Loss:  -5.3054 | Function Loss:  -3.902\n",
            "Total loss:  -3.7576 | PDE Loss:  -5.3046 | Function Loss:  -3.9026\n",
            "Total loss:  -3.7578 | PDE Loss:  -5.304 | Function Loss:  -3.9031\n",
            "Total loss:  -3.7581 | PDE Loss:  -5.3034 | Function Loss:  -3.9037\n",
            "Total loss:  -3.7576 | PDE Loss:  -5.3037 | Function Loss:  -3.9029\n",
            "Total loss:  -3.7582 | PDE Loss:  -5.3038 | Function Loss:  -3.9037\n",
            "Total loss:  -3.7584 | PDE Loss:  -5.3039 | Function Loss:  -3.904\n",
            "Total loss:  -3.7586 | PDE Loss:  -5.3043 | Function Loss:  -3.9041\n",
            "Total loss:  -3.7588 | PDE Loss:  -5.3051 | Function Loss:  -3.9041\n",
            "Total loss:  -3.759 | PDE Loss:  -5.3058 | Function Loss:  -3.904\n",
            "Total loss:  -3.7592 | PDE Loss:  -5.3069 | Function Loss:  -3.9039\n",
            "Total loss:  -3.7594 | PDE Loss:  -5.3076 | Function Loss:  -3.9038\n",
            "Total loss:  -3.7595 | PDE Loss:  -5.3091 | Function Loss:  -3.9035\n",
            "Total loss:  -3.7598 | PDE Loss:  -5.3107 | Function Loss:  -3.9032\n",
            "Total loss:  -3.7601 | PDE Loss:  -5.3126 | Function Loss:  -3.9028\n",
            "Total loss:  -3.7603 | PDE Loss:  -5.3143 | Function Loss:  -3.9025\n",
            "Total loss:  -3.7605 | PDE Loss:  -5.3155 | Function Loss:  -3.9023\n",
            "Total loss:  -3.7606 | PDE Loss:  -5.3165 | Function Loss:  -3.9021\n",
            "Total loss:  -3.7608 | PDE Loss:  -5.3174 | Function Loss:  -3.9019\n",
            "Total loss:  -3.7609 | PDE Loss:  -5.3184 | Function Loss:  -3.9018\n",
            "Total loss:  -3.761 | PDE Loss:  -5.3185 | Function Loss:  -3.9019\n",
            "Total loss:  -3.7611 | PDE Loss:  -5.3181 | Function Loss:  -3.9022\n",
            "Total loss:  -3.7613 | PDE Loss:  -5.3174 | Function Loss:  -3.9026\n",
            "Total loss:  -3.7614 | PDE Loss:  -5.3165 | Function Loss:  -3.9032\n",
            "Total loss:  -3.7616 | PDE Loss:  -5.3157 | Function Loss:  -3.9038\n",
            "Total loss:  -3.7617 | PDE Loss:  -5.315 | Function Loss:  -3.9042\n",
            "Total loss:  -3.7619 | PDE Loss:  -5.3148 | Function Loss:  -3.9045\n",
            "Total loss:  -3.762 | PDE Loss:  -5.3147 | Function Loss:  -3.9048\n",
            "Total loss:  -3.7622 | PDE Loss:  -5.3148 | Function Loss:  -3.905\n",
            "Total loss:  -3.7623 | PDE Loss:  -5.315 | Function Loss:  -3.9051\n",
            "Total loss:  -3.7626 | PDE Loss:  -5.316 | Function Loss:  -3.905\n",
            "Total loss:  -3.7628 | PDE Loss:  -5.3165 | Function Loss:  -3.9051\n",
            "Total loss:  -3.763 | PDE Loss:  -5.3166 | Function Loss:  -3.9054\n",
            "Total loss:  -3.7634 | PDE Loss:  -5.3169 | Function Loss:  -3.9058\n",
            "Total loss:  -3.7637 | PDE Loss:  -5.3172 | Function Loss:  -3.9061\n",
            "Total loss:  -3.764 | PDE Loss:  -5.3166 | Function Loss:  -3.9068\n",
            "Total loss:  -3.7644 | PDE Loss:  -5.3161 | Function Loss:  -3.9075\n",
            "Total loss:  -3.7649 | PDE Loss:  -5.315 | Function Loss:  -3.9086\n",
            "Total loss:  -3.7653 | PDE Loss:  -5.3138 | Function Loss:  -3.9096\n",
            "Total loss:  -3.7659 | PDE Loss:  -5.312 | Function Loss:  -3.9112\n",
            "Total loss:  -3.7666 | PDE Loss:  -5.3098 | Function Loss:  -3.9131\n",
            "Total loss:  -3.7672 | PDE Loss:  -5.3075 | Function Loss:  -3.9149\n",
            "Total loss:  -3.7678 | PDE Loss:  -5.3061 | Function Loss:  -3.9162\n",
            "Total loss:  -3.7681 | PDE Loss:  -5.3048 | Function Loss:  -3.9173\n",
            "Total loss:  -3.7685 | PDE Loss:  -5.3044 | Function Loss:  -3.9179\n",
            "Total loss:  -3.769 | PDE Loss:  -5.3045 | Function Loss:  -3.9186\n",
            "Total loss:  -3.7696 | PDE Loss:  -5.3047 | Function Loss:  -3.9193\n",
            "Total loss:  -3.7693 | PDE Loss:  -5.3007 | Function Loss:  -3.9206\n",
            "Total loss:  -3.77 | PDE Loss:  -5.3036 | Function Loss:  -3.9204\n",
            "Total loss:  -3.7703 | PDE Loss:  -5.31 | Function Loss:  -3.9182\n",
            "Total loss:  -3.7708 | PDE Loss:  -5.3077 | Function Loss:  -3.9198\n",
            "Total loss:  -3.7716 | PDE Loss:  -5.3051 | Function Loss:  -3.922\n",
            "Total loss:  -3.7726 | PDE Loss:  -5.3032 | Function Loss:  -3.9243\n",
            "Total loss:  -3.7738 | PDE Loss:  -5.3016 | Function Loss:  -3.9266\n",
            "Total loss:  -3.7747 | PDE Loss:  -5.3 | Function Loss:  -3.9286\n",
            "Total loss:  -3.7757 | PDE Loss:  -5.2989 | Function Loss:  -3.9305\n",
            "Total loss:  -3.7764 | PDE Loss:  -5.2991 | Function Loss:  -3.9315\n",
            "Total loss:  -3.7779 | PDE Loss:  -5.2985 | Function Loss:  -3.9338\n",
            "Total loss:  -3.7791 | PDE Loss:  -5.3003 | Function Loss:  -3.9347\n",
            "Total loss:  -3.7803 | PDE Loss:  -5.3007 | Function Loss:  -3.9363\n",
            "Total loss:  -3.7816 | PDE Loss:  -5.301 | Function Loss:  -3.938\n",
            "Total loss:  -3.7827 | PDE Loss:  -5.301 | Function Loss:  -3.9396\n",
            "Total loss:  -3.784 | PDE Loss:  -5.3023 | Function Loss:  -3.9409\n",
            "Total loss:  -3.7847 | PDE Loss:  -5.3026 | Function Loss:  -3.9417\n",
            "Total loss:  -3.7862 | PDE Loss:  -5.3043 | Function Loss:  -3.9432\n",
            "Total loss:  -3.7872 | PDE Loss:  -5.3055 | Function Loss:  -3.9441\n",
            "Total loss:  -3.7881 | PDE Loss:  -5.3059 | Function Loss:  -3.9452\n",
            "Total loss:  -3.7889 | PDE Loss:  -5.3076 | Function Loss:  -3.9456\n",
            "Total loss:  -3.7899 | PDE Loss:  -5.3089 | Function Loss:  -3.9464\n",
            "Total loss:  -3.7911 | PDE Loss:  -5.3111 | Function Loss:  -3.9472\n",
            "Total loss:  -3.7923 | PDE Loss:  -5.3132 | Function Loss:  -3.948\n",
            "Total loss:  -3.7934 | PDE Loss:  -5.315 | Function Loss:  -3.9489\n",
            "Total loss:  -3.7943 | PDE Loss:  -5.3177 | Function Loss:  -3.949\n",
            "Total loss:  -3.795 | PDE Loss:  -5.319 | Function Loss:  -3.9494\n",
            "Total loss:  -3.7954 | PDE Loss:  -5.3191 | Function Loss:  -3.95\n",
            "Total loss:  -3.796 | PDE Loss:  -5.3187 | Function Loss:  -3.9509\n",
            "Total loss:  -3.7964 | PDE Loss:  -5.3185 | Function Loss:  -3.9516\n",
            "Total loss:  -3.7967 | PDE Loss:  -5.3179 | Function Loss:  -3.9523\n",
            "Total loss:  -3.7969 | PDE Loss:  -5.3175 | Function Loss:  -3.9528\n",
            "Total loss:  -3.7972 | PDE Loss:  -5.3171 | Function Loss:  -3.9533\n",
            "Total loss:  -3.7974 | PDE Loss:  -5.3171 | Function Loss:  -3.9536\n",
            "Total loss:  -3.7976 | PDE Loss:  -5.3164 | Function Loss:  -3.9543\n",
            "Total loss:  -3.798 | PDE Loss:  -5.3166 | Function Loss:  -3.9547\n",
            "Total loss:  -3.7985 | PDE Loss:  -5.3166 | Function Loss:  -3.9555\n",
            "Total loss:  -3.7992 | PDE Loss:  -5.3182 | Function Loss:  -3.9557\n",
            "Total loss:  -3.7998 | PDE Loss:  -5.3183 | Function Loss:  -3.9566\n",
            "Total loss:  -3.8004 | PDE Loss:  -5.319 | Function Loss:  -3.9571\n",
            "Total loss:  -3.8011 | PDE Loss:  -5.3197 | Function Loss:  -3.9578\n",
            "Total loss:  -3.8019 | PDE Loss:  -5.3207 | Function Loss:  -3.9585\n",
            "Total loss:  -3.8026 | PDE Loss:  -5.3212 | Function Loss:  -3.9594\n",
            "Total loss:  -3.8033 | PDE Loss:  -5.3213 | Function Loss:  -3.9603\n",
            "Total loss:  -3.8038 | PDE Loss:  -5.321 | Function Loss:  -3.9612\n",
            "Total loss:  -3.8043 | PDE Loss:  -5.3211 | Function Loss:  -3.9619\n",
            "Total loss:  -3.8048 | PDE Loss:  -5.3208 | Function Loss:  -3.9627\n",
            "Total loss:  -3.8055 | PDE Loss:  -5.3213 | Function Loss:  -3.9634\n",
            "Total loss:  -3.8063 | PDE Loss:  -5.3216 | Function Loss:  -3.9644\n",
            "Total loss:  -3.807 | PDE Loss:  -5.3223 | Function Loss:  -3.9652\n",
            "Total loss:  -3.8077 | PDE Loss:  -5.3229 | Function Loss:  -3.966\n",
            "Total loss:  -3.8088 | PDE Loss:  -5.3241 | Function Loss:  -3.967\n",
            "Total loss:  -3.8092 | PDE Loss:  -5.3256 | Function Loss:  -3.9669\n",
            "Total loss:  -3.8102 | PDE Loss:  -5.3262 | Function Loss:  -3.968\n",
            "Total loss:  -3.8112 | PDE Loss:  -5.327 | Function Loss:  -3.9692\n",
            "Total loss:  -3.8124 | PDE Loss:  -5.3277 | Function Loss:  -3.9706\n",
            "Total loss:  -3.8133 | PDE Loss:  -5.3294 | Function Loss:  -3.9712\n",
            "Total loss:  -3.8141 | PDE Loss:  -5.3312 | Function Loss:  -3.9715\n",
            "Total loss:  -3.815 | PDE Loss:  -5.3335 | Function Loss:  -3.9718\n",
            "Total loss:  -3.8157 | PDE Loss:  -5.3363 | Function Loss:  -3.9715\n",
            "Total loss:  -3.8161 | PDE Loss:  -5.3375 | Function Loss:  -3.9716\n",
            "Total loss:  -3.8165 | PDE Loss:  -5.338 | Function Loss:  -3.9719\n",
            "Total loss:  -3.8171 | PDE Loss:  -5.3392 | Function Loss:  -3.9723\n",
            "Total loss:  -3.8178 | PDE Loss:  -5.3394 | Function Loss:  -3.9732\n",
            "Total loss:  -3.8183 | PDE Loss:  -5.3404 | Function Loss:  -3.9736\n",
            "Total loss:  -3.8189 | PDE Loss:  -5.3409 | Function Loss:  -3.9742\n",
            "Total loss:  -3.8197 | PDE Loss:  -5.3423 | Function Loss:  -3.9746\n",
            "Total loss:  -3.8206 | PDE Loss:  -5.3441 | Function Loss:  -3.9753\n",
            "Total loss:  -3.8213 | PDE Loss:  -5.3455 | Function Loss:  -3.9757\n",
            "Total loss:  -3.8224 | PDE Loss:  -5.3477 | Function Loss:  -3.9762\n",
            "Total loss:  -3.8233 | PDE Loss:  -5.3503 | Function Loss:  -3.9765\n",
            "Total loss:  -3.8241 | PDE Loss:  -5.3519 | Function Loss:  -3.9769\n",
            "Total loss:  -3.8247 | PDE Loss:  -5.3526 | Function Loss:  -3.9775\n",
            "Total loss:  -3.8256 | PDE Loss:  -5.3538 | Function Loss:  -3.9783\n",
            "Total loss:  -3.8268 | PDE Loss:  -5.3543 | Function Loss:  -3.9798\n",
            "Total loss:  -3.8283 | PDE Loss:  -5.356 | Function Loss:  -3.9811\n",
            "Total loss:  -3.8298 | PDE Loss:  -5.3584 | Function Loss:  -3.9822\n",
            "Total loss:  -3.8312 | PDE Loss:  -5.3596 | Function Loss:  -3.9837\n",
            "Total loss:  -3.8323 | PDE Loss:  -5.3638 | Function Loss:  -3.9836\n",
            "Total loss:  -3.8334 | PDE Loss:  -5.3665 | Function Loss:  -3.9841\n",
            "Total loss:  -3.8348 | PDE Loss:  -5.3691 | Function Loss:  -3.9849\n",
            "Total loss:  -3.8362 | PDE Loss:  -5.3714 | Function Loss:  -3.9859\n",
            "Total loss:  -3.8373 | PDE Loss:  -5.3723 | Function Loss:  -3.9871\n",
            "Total loss:  -3.8385 | PDE Loss:  -5.3724 | Function Loss:  -3.9888\n",
            "Total loss:  -3.8396 | PDE Loss:  -5.3722 | Function Loss:  -3.9905\n",
            "Total loss:  -3.8403 | PDE Loss:  -5.3715 | Function Loss:  -3.9917\n",
            "Total loss:  -3.8412 | PDE Loss:  -5.3706 | Function Loss:  -3.9933\n",
            "Total loss:  -3.8419 | PDE Loss:  -5.3727 | Function Loss:  -3.9935\n",
            "Total loss:  -3.8422 | PDE Loss:  -5.3656 | Function Loss:  -3.9969\n",
            "Total loss:  -3.8427 | PDE Loss:  -5.3681 | Function Loss:  -3.9966\n",
            "Total loss:  -3.8432 | PDE Loss:  -5.3704 | Function Loss:  -3.9963\n",
            "Total loss:  -3.8436 | PDE Loss:  -5.3717 | Function Loss:  -3.9962\n",
            "Total loss:  -3.8439 | PDE Loss:  -5.3732 | Function Loss:  -3.9961\n",
            "Total loss:  -3.8443 | PDE Loss:  -5.3745 | Function Loss:  -3.9961\n",
            "Total loss:  -3.845 | PDE Loss:  -5.3764 | Function Loss:  -3.9963\n",
            "Total loss:  -3.8458 | PDE Loss:  -5.3788 | Function Loss:  -3.9964\n",
            "Total loss:  -3.8465 | PDE Loss:  -5.3802 | Function Loss:  -3.9968\n",
            "Total loss:  -3.8474 | PDE Loss:  -5.3821 | Function Loss:  -3.9973\n",
            "Total loss:  -3.8483 | PDE Loss:  -5.3835 | Function Loss:  -3.9981\n",
            "Total loss:  -3.8492 | PDE Loss:  -5.3857 | Function Loss:  -3.9984\n",
            "Total loss:  -3.8498 | PDE Loss:  -5.3865 | Function Loss:  -3.999\n",
            "Total loss:  -3.8503 | PDE Loss:  -5.3866 | Function Loss:  -3.9996\n",
            "Total loss:  -3.8507 | PDE Loss:  -5.3872 | Function Loss:  -3.9998\n",
            "Total loss:  -3.8511 | PDE Loss:  -5.3868 | Function Loss:  -4.0006\n",
            "Total loss:  -3.8514 | PDE Loss:  -5.3869 | Function Loss:  -4.001\n",
            "Total loss:  -3.8518 | PDE Loss:  -5.3863 | Function Loss:  -4.0018\n",
            "Total loss:  -3.852 | PDE Loss:  -5.3865 | Function Loss:  -4.0021\n",
            "Total loss:  -3.8523 | PDE Loss:  -5.3858 | Function Loss:  -4.0027\n",
            "Total loss:  -3.8526 | PDE Loss:  -5.3861 | Function Loss:  -4.003\n",
            "Total loss:  -3.8529 | PDE Loss:  -5.3859 | Function Loss:  -4.0035\n",
            "Total loss:  -3.8532 | PDE Loss:  -5.386 | Function Loss:  -4.0039\n",
            "Total loss:  -3.8534 | PDE Loss:  -5.3863 | Function Loss:  -4.004\n",
            "Total loss:  -3.8536 | PDE Loss:  -5.3864 | Function Loss:  -4.0043\n",
            "Total loss:  -3.8539 | PDE Loss:  -5.3869 | Function Loss:  -4.0045\n",
            "Total loss:  -3.8541 | PDE Loss:  -5.3872 | Function Loss:  -4.0047\n",
            "Total loss:  -3.8543 | PDE Loss:  -5.3877 | Function Loss:  -4.0048\n",
            "Total loss:  -3.8546 | PDE Loss:  -5.3884 | Function Loss:  -4.0049\n",
            "Total loss:  -3.8549 | PDE Loss:  -5.3892 | Function Loss:  -4.0051\n",
            "Total loss:  -3.8553 | PDE Loss:  -5.3906 | Function Loss:  -4.005\n",
            "Total loss:  -3.8556 | PDE Loss:  -5.3912 | Function Loss:  -4.0052\n",
            "Total loss:  -3.8559 | PDE Loss:  -5.3918 | Function Loss:  -4.0054\n",
            "Total loss:  -3.8563 | PDE Loss:  -5.392 | Function Loss:  -4.0058\n",
            "Total loss:  -3.8567 | PDE Loss:  -5.3922 | Function Loss:  -4.0063\n",
            "Total loss:  -3.857 | PDE Loss:  -5.3924 | Function Loss:  -4.0066\n",
            "Total loss:  -3.8574 | PDE Loss:  -5.3927 | Function Loss:  -4.007\n",
            "Total loss:  -3.8578 | PDE Loss:  -5.3935 | Function Loss:  -4.0073\n",
            "Total loss:  -3.8582 | PDE Loss:  -5.3941 | Function Loss:  -4.0077\n",
            "Total loss:  -3.8587 | PDE Loss:  -5.395 | Function Loss:  -4.008\n",
            "Total loss:  -3.8592 | PDE Loss:  -5.3957 | Function Loss:  -4.0084\n",
            "Total loss:  -3.8595 | PDE Loss:  -5.3961 | Function Loss:  -4.0087\n",
            "Total loss:  -3.8599 | PDE Loss:  -5.3964 | Function Loss:  -4.0091\n",
            "Total loss:  -3.8601 | PDE Loss:  -5.3968 | Function Loss:  -4.0092\n",
            "Total loss:  -3.8604 | PDE Loss:  -5.3977 | Function Loss:  -4.0092\n",
            "Total loss:  -3.8606 | PDE Loss:  -5.3986 | Function Loss:  -4.0091\n",
            "Total loss:  -3.8607 | PDE Loss:  -5.4 | Function Loss:  -4.0088\n",
            "Total loss:  -3.8609 | PDE Loss:  -5.401 | Function Loss:  -4.0086\n",
            "Total loss:  -3.8611 | PDE Loss:  -5.404 | Function Loss:  -4.0077\n",
            "Total loss:  -3.8576 | PDE Loss:  -5.3956 | Function Loss:  -4.0061\n",
            "Total loss:  -3.8612 | PDE Loss:  -5.4034 | Function Loss:  -4.0081\n",
            "Total loss:  -3.8613 | PDE Loss:  -5.4044 | Function Loss:  -4.0079\n",
            "Total loss:  -3.8616 | PDE Loss:  -5.4065 | Function Loss:  -4.0074\n",
            "Total loss:  -3.8619 | PDE Loss:  -5.4081 | Function Loss:  -4.0071\n",
            "Total loss:  -3.8621 | PDE Loss:  -5.4087 | Function Loss:  -4.0072\n",
            "Total loss:  -3.8623 | PDE Loss:  -5.4091 | Function Loss:  -4.0073\n",
            "Total loss:  -3.8624 | PDE Loss:  -5.4091 | Function Loss:  -4.0075\n",
            "Total loss:  -3.8629 | PDE Loss:  -5.4094 | Function Loss:  -4.008\n",
            "Total loss:  -3.8632 | PDE Loss:  -5.4092 | Function Loss:  -4.0086\n",
            "Total loss:  -3.8636 | PDE Loss:  -5.4087 | Function Loss:  -4.0093\n",
            "Total loss:  -3.864 | PDE Loss:  -5.4082 | Function Loss:  -4.0101\n",
            "Total loss:  -3.8643 | PDE Loss:  -5.4071 | Function Loss:  -4.011\n",
            "Total loss:  -3.8646 | PDE Loss:  -5.4065 | Function Loss:  -4.0116\n",
            "Total loss:  -3.8649 | PDE Loss:  -5.4058 | Function Loss:  -4.0123\n",
            "Total loss:  -3.8651 | PDE Loss:  -5.4053 | Function Loss:  -4.0127\n",
            "Total loss:  -3.8652 | PDE Loss:  -5.4054 | Function Loss:  -4.0129\n",
            "Total loss:  -3.8645 | PDE Loss:  -5.4044 | Function Loss:  -4.0123\n",
            "Total loss:  -3.8653 | PDE Loss:  -5.4054 | Function Loss:  -4.013\n",
            "Total loss:  -3.8654 | PDE Loss:  -5.4058 | Function Loss:  -4.013\n",
            "Total loss:  -3.8655 | PDE Loss:  -5.4063 | Function Loss:  -4.013\n",
            "Total loss:  -3.8656 | PDE Loss:  -5.4065 | Function Loss:  -4.013\n",
            "Total loss:  -3.8657 | PDE Loss:  -5.4067 | Function Loss:  -4.013\n",
            "Total loss:  -3.8657 | PDE Loss:  -5.4068 | Function Loss:  -4.0131\n",
            "Total loss:  -3.8658 | PDE Loss:  -5.4068 | Function Loss:  -4.0131\n",
            "Total loss:  -3.8658 | PDE Loss:  -5.4069 | Function Loss:  -4.0132\n",
            "Total loss:  -3.8659 | PDE Loss:  -5.406 | Function Loss:  -4.0137\n",
            "Total loss:  -3.866 | PDE Loss:  -5.4061 | Function Loss:  -4.0137\n",
            "Total loss:  -3.8661 | PDE Loss:  -5.4059 | Function Loss:  -4.0139\n",
            "Total loss:  -3.8662 | PDE Loss:  -5.4054 | Function Loss:  -4.0143\n",
            "Total loss:  -3.8663 | PDE Loss:  -5.4051 | Function Loss:  -4.0146\n",
            "Total loss:  -3.8662 | PDE Loss:  -5.407 | Function Loss:  -4.0136\n",
            "Total loss:  -3.8663 | PDE Loss:  -5.4058 | Function Loss:  -4.0143\n",
            "Total loss:  -3.8665 | PDE Loss:  -5.4049 | Function Loss:  -4.0149\n",
            "Total loss:  -3.8666 | PDE Loss:  -5.4047 | Function Loss:  -4.0151\n",
            "Total loss:  -3.8667 | PDE Loss:  -5.4044 | Function Loss:  -4.0155\n",
            "Total loss:  -3.8668 | PDE Loss:  -5.4044 | Function Loss:  -4.0156\n",
            "Total loss:  -3.867 | PDE Loss:  -5.4043 | Function Loss:  -4.0158\n",
            "Total loss:  -3.8671 | PDE Loss:  -5.4045 | Function Loss:  -4.0159\n",
            "Total loss:  -3.8672 | PDE Loss:  -5.4047 | Function Loss:  -4.0159\n",
            "Total loss:  -3.8673 | PDE Loss:  -5.405 | Function Loss:  -4.016\n",
            "Total loss:  -3.8675 | PDE Loss:  -5.4052 | Function Loss:  -4.0162\n",
            "Total loss:  -3.8677 | PDE Loss:  -5.4054 | Function Loss:  -4.0164\n",
            "Total loss:  -3.8679 | PDE Loss:  -5.4056 | Function Loss:  -4.0166\n",
            "Total loss:  -3.8675 | PDE Loss:  -5.4037 | Function Loss:  -4.0168\n",
            "Total loss:  -3.8679 | PDE Loss:  -5.4052 | Function Loss:  -4.0168\n",
            "Total loss:  -3.8684 | PDE Loss:  -5.4052 | Function Loss:  -4.0175\n",
            "Total loss:  -3.8686 | PDE Loss:  -5.4053 | Function Loss:  -4.0178\n",
            "Total loss:  -3.8694 | PDE Loss:  -5.4056 | Function Loss:  -4.0187\n",
            "Total loss:  -3.8699 | PDE Loss:  -5.4055 | Function Loss:  -4.0195\n",
            "Total loss:  -3.8704 | PDE Loss:  -5.4055 | Function Loss:  -4.0201\n",
            "Total loss:  -3.8708 | PDE Loss:  -5.4056 | Function Loss:  -4.0207\n",
            "Total loss:  -3.8712 | PDE Loss:  -5.4062 | Function Loss:  -4.021\n",
            "Total loss:  -3.8716 | PDE Loss:  -5.4068 | Function Loss:  -4.0213\n",
            "Total loss:  -3.8719 | PDE Loss:  -5.4072 | Function Loss:  -4.0215\n",
            "Total loss:  -3.8721 | PDE Loss:  -5.4084 | Function Loss:  -4.0214\n",
            "Total loss:  -3.8723 | PDE Loss:  -5.4099 | Function Loss:  -4.0211\n",
            "Total loss:  -3.8726 | PDE Loss:  -5.4114 | Function Loss:  -4.0209\n",
            "Total loss:  -3.8729 | PDE Loss:  -5.4125 | Function Loss:  -4.0208\n",
            "Total loss:  -3.8733 | PDE Loss:  -5.4137 | Function Loss:  -4.0209\n",
            "Total loss:  -3.8738 | PDE Loss:  -5.4147 | Function Loss:  -4.0212\n",
            "Total loss:  -3.8743 | PDE Loss:  -5.4153 | Function Loss:  -4.0217\n",
            "Total loss:  -3.8749 | PDE Loss:  -5.4159 | Function Loss:  -4.0223\n",
            "Total loss:  -3.8756 | PDE Loss:  -5.416 | Function Loss:  -4.0232\n",
            "Total loss:  -3.8763 | PDE Loss:  -5.4162 | Function Loss:  -4.0241\n",
            "Total loss:  -3.8769 | PDE Loss:  -5.4158 | Function Loss:  -4.0252\n",
            "Total loss:  -3.8774 | PDE Loss:  -5.4162 | Function Loss:  -4.0257\n",
            "Total loss:  -3.8778 | PDE Loss:  -5.416 | Function Loss:  -4.0262\n",
            "Total loss:  -3.8785 | PDE Loss:  -5.4149 | Function Loss:  -4.0277\n",
            "Total loss:  -3.8726 | PDE Loss:  -5.4021 | Function Loss:  -4.0247\n",
            "Total loss:  -3.8787 | PDE Loss:  -5.4137 | Function Loss:  -4.0285\n",
            "Total loss:  -3.8798 | PDE Loss:  -5.4124 | Function Loss:  -4.0306\n",
            "Total loss:  -3.8809 | PDE Loss:  -5.4089 | Function Loss:  -4.0335\n",
            "Total loss:  -3.8819 | PDE Loss:  -5.4073 | Function Loss:  -4.0357\n",
            "Total loss:  -3.8829 | PDE Loss:  -5.4042 | Function Loss:  -4.0385\n",
            "Total loss:  -3.884 | PDE Loss:  -5.4017 | Function Loss:  -4.0411\n",
            "Total loss:  -3.885 | PDE Loss:  -5.4005 | Function Loss:  -4.0431\n",
            "Total loss:  -3.8856 | PDE Loss:  -5.3994 | Function Loss:  -4.0445\n",
            "Total loss:  -3.8862 | PDE Loss:  -5.3985 | Function Loss:  -4.0458\n",
            "Total loss:  -3.8867 | PDE Loss:  -5.3982 | Function Loss:  -4.0466\n",
            "Total loss:  -3.8872 | PDE Loss:  -5.3984 | Function Loss:  -4.0472\n",
            "Total loss:  -3.8876 | PDE Loss:  -5.3984 | Function Loss:  -4.0478\n",
            "Total loss:  -3.888 | PDE Loss:  -5.399 | Function Loss:  -4.0481\n",
            "Total loss:  -3.8882 | PDE Loss:  -5.3965 | Function Loss:  -4.0496\n",
            "Total loss:  -3.8891 | PDE Loss:  -5.3987 | Function Loss:  -4.0498\n",
            "Total loss:  -3.8895 | PDE Loss:  -5.3999 | Function Loss:  -4.0499\n",
            "Total loss:  -3.8903 | PDE Loss:  -5.4016 | Function Loss:  -4.0503\n",
            "Total loss:  -3.891 | PDE Loss:  -5.4015 | Function Loss:  -4.0513\n",
            "Total loss:  -3.8915 | PDE Loss:  -5.4011 | Function Loss:  -4.0523\n",
            "Total loss:  -3.8921 | PDE Loss:  -5.4006 | Function Loss:  -4.0533\n",
            "Total loss:  -3.8925 | PDE Loss:  -5.398 | Function Loss:  -4.0551\n",
            "Total loss:  -3.893 | PDE Loss:  -5.398 | Function Loss:  -4.0557\n",
            "Total loss:  -3.8934 | PDE Loss:  -5.3978 | Function Loss:  -4.0564\n",
            "Total loss:  -3.894 | PDE Loss:  -5.3979 | Function Loss:  -4.0573\n",
            "Total loss:  -3.8946 | PDE Loss:  -5.3984 | Function Loss:  -4.0579\n",
            "Total loss:  -3.8954 | PDE Loss:  -5.3983 | Function Loss:  -4.0591\n",
            "Total loss:  -3.8961 | PDE Loss:  -5.3993 | Function Loss:  -4.0597\n",
            "Total loss:  -3.8971 | PDE Loss:  -5.4007 | Function Loss:  -4.0604\n",
            "Total loss:  -3.8979 | PDE Loss:  -5.4031 | Function Loss:  -4.0606\n",
            "Total loss:  -3.8987 | PDE Loss:  -5.4041 | Function Loss:  -4.0612\n",
            "Total loss:  -3.8994 | PDE Loss:  -5.4057 | Function Loss:  -4.0616\n",
            "Total loss:  -3.9002 | PDE Loss:  -5.4064 | Function Loss:  -4.0625\n",
            "Total loss:  -3.9013 | PDE Loss:  -5.4082 | Function Loss:  -4.0633\n",
            "Total loss:  -3.9021 | PDE Loss:  -5.4085 | Function Loss:  -4.0643\n",
            "Total loss:  -3.9033 | PDE Loss:  -5.4077 | Function Loss:  -4.0664\n",
            "Total loss:  -3.9041 | PDE Loss:  -5.4071 | Function Loss:  -4.0678\n",
            "Total loss:  -3.9047 | PDE Loss:  -5.4067 | Function Loss:  -4.0688\n",
            "Total loss:  -3.9052 | PDE Loss:  -5.4064 | Function Loss:  -4.0697\n",
            "Total loss:  -3.9057 | PDE Loss:  -5.4063 | Function Loss:  -4.0705\n",
            "Total loss:  -3.9062 | PDE Loss:  -5.4063 | Function Loss:  -4.0712\n",
            "Total loss:  -3.9065 | PDE Loss:  -5.4063 | Function Loss:  -4.0718\n",
            "Total loss:  -3.907 | PDE Loss:  -5.4062 | Function Loss:  -4.0724\n",
            "Total loss:  -3.9073 | PDE Loss:  -5.4059 | Function Loss:  -4.073\n",
            "Total loss:  -3.9076 | PDE Loss:  -5.4056 | Function Loss:  -4.0737\n",
            "Total loss:  -3.908 | PDE Loss:  -5.4051 | Function Loss:  -4.0744\n",
            "Total loss:  -3.9084 | PDE Loss:  -5.4049 | Function Loss:  -4.0751\n",
            "Total loss:  -3.9084 | PDE Loss:  -5.4027 | Function Loss:  -4.0761\n",
            "Total loss:  -3.9086 | PDE Loss:  -5.404 | Function Loss:  -4.0758\n",
            "Total loss:  -3.9089 | PDE Loss:  -5.4042 | Function Loss:  -4.0762\n",
            "Total loss:  -3.9091 | PDE Loss:  -5.4043 | Function Loss:  -4.0764\n",
            "Total loss:  -3.9093 | PDE Loss:  -5.4045 | Function Loss:  -4.0766\n",
            "Total loss:  -3.9096 | PDE Loss:  -5.4047 | Function Loss:  -4.0769\n",
            "Total loss:  -3.9097 | PDE Loss:  -5.4053 | Function Loss:  -4.0769\n",
            "Total loss:  -3.9099 | PDE Loss:  -5.4055 | Function Loss:  -4.077\n",
            "Total loss:  -3.9101 | PDE Loss:  -5.4058 | Function Loss:  -4.0772\n",
            "Total loss:  -3.9104 | PDE Loss:  -5.408 | Function Loss:  -4.0766\n",
            "Total loss:  -3.9106 | PDE Loss:  -5.4084 | Function Loss:  -4.0767\n",
            "Total loss:  -3.9108 | PDE Loss:  -5.408 | Function Loss:  -4.0772\n",
            "Total loss:  -3.911 | PDE Loss:  -5.4086 | Function Loss:  -4.0773\n",
            "Total loss:  -3.9114 | PDE Loss:  -5.4098 | Function Loss:  -4.0772\n",
            "Total loss:  -3.9117 | PDE Loss:  -5.4106 | Function Loss:  -4.0773\n",
            "Total loss:  -3.912 | PDE Loss:  -5.4115 | Function Loss:  -4.0774\n",
            "Total loss:  -3.9124 | PDE Loss:  -5.413 | Function Loss:  -4.0772\n",
            "Total loss:  -3.9128 | PDE Loss:  -5.4145 | Function Loss:  -4.0771\n",
            "Total loss:  -3.9131 | PDE Loss:  -5.4159 | Function Loss:  -4.077\n",
            "Total loss:  -3.9136 | PDE Loss:  -5.4173 | Function Loss:  -4.0769\n",
            "Total loss:  -3.9143 | PDE Loss:  -5.4206 | Function Loss:  -4.0765\n",
            "Total loss:  -3.9151 | PDE Loss:  -5.4227 | Function Loss:  -4.0767\n",
            "Total loss:  -3.9159 | PDE Loss:  -5.4249 | Function Loss:  -4.0769\n",
            "Total loss:  -3.9165 | PDE Loss:  -5.4262 | Function Loss:  -4.0772\n",
            "Total loss:  -3.917 | PDE Loss:  -5.4266 | Function Loss:  -4.0777\n",
            "Total loss:  -3.9173 | PDE Loss:  -5.4269 | Function Loss:  -4.078\n",
            "Total loss:  -3.9177 | PDE Loss:  -5.4267 | Function Loss:  -4.0787\n",
            "Total loss:  -3.9181 | PDE Loss:  -5.4269 | Function Loss:  -4.0792\n",
            "Total loss:  -3.9177 | PDE Loss:  -5.4297 | Function Loss:  -4.0773\n",
            "Total loss:  -3.9183 | PDE Loss:  -5.4282 | Function Loss:  -4.0789\n",
            "Total loss:  -3.9186 | PDE Loss:  -5.428 | Function Loss:  -4.0794\n",
            "Total loss:  -3.919 | PDE Loss:  -5.429 | Function Loss:  -4.0796\n",
            "Total loss:  -3.9196 | PDE Loss:  -5.4302 | Function Loss:  -4.0799\n",
            "Total loss:  -3.9202 | PDE Loss:  -5.433 | Function Loss:  -4.0795\n",
            "Total loss:  -3.9207 | PDE Loss:  -5.4353 | Function Loss:  -4.0792\n",
            "Total loss:  -3.9211 | PDE Loss:  -5.4382 | Function Loss:  -4.0786\n",
            "Total loss:  -3.9215 | PDE Loss:  -5.4407 | Function Loss:  -4.0781\n",
            "Total loss:  -3.9219 | PDE Loss:  -5.4431 | Function Loss:  -4.0775\n",
            "Total loss:  -3.9221 | PDE Loss:  -5.4452 | Function Loss:  -4.077\n",
            "Total loss:  -3.9209 | PDE Loss:  -5.4675 | Function Loss:  -4.066\n",
            "Total loss:  -3.923 | PDE Loss:  -5.4549 | Function Loss:  -4.074\n",
            "Total loss:  -3.9235 | PDE Loss:  -5.4531 | Function Loss:  -4.0756\n",
            "Total loss:  -3.9244 | PDE Loss:  -5.4522 | Function Loss:  -4.0772\n",
            "Total loss:  -3.9258 | PDE Loss:  -5.4515 | Function Loss:  -4.0796\n",
            "Total loss:  -3.927 | PDE Loss:  -5.4523 | Function Loss:  -4.0809\n",
            "Total loss:  -3.9278 | PDE Loss:  -5.4549 | Function Loss:  -4.081\n",
            "Total loss:  -3.9284 | PDE Loss:  -5.4563 | Function Loss:  -4.0812\n",
            "Total loss:  -3.9292 | PDE Loss:  -5.4589 | Function Loss:  -4.0813\n",
            "Total loss:  -3.9303 | PDE Loss:  -5.4628 | Function Loss:  -4.0811\n",
            "Total loss:  -3.9314 | PDE Loss:  -5.4654 | Function Loss:  -4.0816\n",
            "Total loss:  -3.9323 | PDE Loss:  -5.4694 | Function Loss:  -4.0813\n",
            "Total loss:  -3.9333 | PDE Loss:  -5.4717 | Function Loss:  -4.0817\n",
            "Total loss:  -3.934 | PDE Loss:  -5.472 | Function Loss:  -4.0826\n",
            "Total loss:  -3.9348 | PDE Loss:  -5.4747 | Function Loss:  -4.0826\n",
            "Total loss:  -3.9353 | PDE Loss:  -5.4739 | Function Loss:  -4.0837\n",
            "Total loss:  -3.9359 | PDE Loss:  -5.4733 | Function Loss:  -4.0847\n",
            "Total loss:  -3.9363 | PDE Loss:  -5.4721 | Function Loss:  -4.0858\n",
            "Total loss:  -3.9368 | PDE Loss:  -5.4719 | Function Loss:  -4.0866\n",
            "Total loss:  -3.9372 | PDE Loss:  -5.4721 | Function Loss:  -4.087\n",
            "Total loss:  -3.9376 | PDE Loss:  -5.4727 | Function Loss:  -4.0874\n",
            "Total loss:  -3.938 | PDE Loss:  -5.4737 | Function Loss:  -4.0875\n",
            "Total loss:  -3.9382 | PDE Loss:  -5.4725 | Function Loss:  -4.0882\n",
            "Total loss:  -3.9385 | PDE Loss:  -5.4734 | Function Loss:  -4.0884\n",
            "Total loss:  -3.9388 | PDE Loss:  -5.4747 | Function Loss:  -4.0882\n",
            "Total loss:  -3.939 | PDE Loss:  -5.4754 | Function Loss:  -4.0883\n",
            "Total loss:  -3.9393 | PDE Loss:  -5.4761 | Function Loss:  -4.0883\n",
            "Total loss:  -3.9395 | PDE Loss:  -5.4767 | Function Loss:  -4.0884\n",
            "Total loss:  -3.9399 | PDE Loss:  -5.4773 | Function Loss:  -4.0887\n",
            "Total loss:  -3.9403 | PDE Loss:  -5.4777 | Function Loss:  -4.0891\n",
            "Total loss:  -3.9406 | PDE Loss:  -5.4818 | Function Loss:  -4.0879\n",
            "Total loss:  -3.9409 | PDE Loss:  -5.4817 | Function Loss:  -4.0884\n",
            "Total loss:  -3.9413 | PDE Loss:  -5.4814 | Function Loss:  -4.0891\n",
            "Total loss:  -3.9416 | PDE Loss:  -5.4822 | Function Loss:  -4.0891\n",
            "Total loss:  -3.9417 | PDE Loss:  -5.4822 | Function Loss:  -4.0893\n",
            "Total loss:  -3.9419 | PDE Loss:  -5.483 | Function Loss:  -4.0892\n",
            "Total loss:  -3.942 | PDE Loss:  -5.4834 | Function Loss:  -4.0892\n",
            "Total loss:  -3.9421 | PDE Loss:  -5.4836 | Function Loss:  -4.0893\n",
            "Total loss:  -3.9423 | PDE Loss:  -5.4842 | Function Loss:  -4.0893\n",
            "Total loss:  -3.9425 | PDE Loss:  -5.4847 | Function Loss:  -4.0893\n",
            "Total loss:  -3.9426 | PDE Loss:  -5.4848 | Function Loss:  -4.0896\n",
            "Total loss:  -3.9428 | PDE Loss:  -5.4848 | Function Loss:  -4.0898\n",
            "Total loss:  -3.943 | PDE Loss:  -5.485 | Function Loss:  -4.09\n",
            "Total loss:  -3.9432 | PDE Loss:  -5.4847 | Function Loss:  -4.0904\n",
            "Total loss:  -3.9434 | PDE Loss:  -5.4851 | Function Loss:  -4.0905\n",
            "Total loss:  -3.9435 | PDE Loss:  -5.4852 | Function Loss:  -4.0906\n",
            "Total loss:  -3.9437 | PDE Loss:  -5.4857 | Function Loss:  -4.0906\n",
            "Total loss:  -3.9439 | PDE Loss:  -5.4868 | Function Loss:  -4.0905\n",
            "Total loss:  -3.9441 | PDE Loss:  -5.4881 | Function Loss:  -4.0903\n",
            "Total loss:  -3.9443 | PDE Loss:  -5.4896 | Function Loss:  -4.09\n",
            "Total loss:  -3.9445 | PDE Loss:  -5.4918 | Function Loss:  -4.0894\n",
            "Total loss:  -3.9447 | PDE Loss:  -5.4934 | Function Loss:  -4.089\n",
            "Total loss:  -3.9449 | PDE Loss:  -5.4952 | Function Loss:  -4.0886\n",
            "Total loss:  -3.9451 | PDE Loss:  -5.4963 | Function Loss:  -4.0884\n",
            "Total loss:  -3.9453 | PDE Loss:  -5.497 | Function Loss:  -4.0884\n",
            "Total loss:  -3.9417 | PDE Loss:  -5.5036 | Function Loss:  -4.0809\n",
            "Total loss:  -3.9455 | PDE Loss:  -5.4991 | Function Loss:  -4.0879\n",
            "Total loss:  -3.9457 | PDE Loss:  -5.4989 | Function Loss:  -4.0882\n",
            "Total loss:  -3.9462 | PDE Loss:  -5.4979 | Function Loss:  -4.0894\n",
            "Total loss:  -3.9467 | PDE Loss:  -5.4978 | Function Loss:  -4.09\n",
            "Total loss:  -3.947 | PDE Loss:  -5.4975 | Function Loss:  -4.0906\n",
            "Total loss:  -3.9473 | PDE Loss:  -5.4983 | Function Loss:  -4.0907\n",
            "Total loss:  -3.9476 | PDE Loss:  -5.4991 | Function Loss:  -4.0907\n",
            "Total loss:  -3.9478 | PDE Loss:  -5.5005 | Function Loss:  -4.0905\n",
            "Total loss:  -3.9479 | PDE Loss:  -5.5016 | Function Loss:  -4.0903\n",
            "Total loss:  -3.9481 | PDE Loss:  -5.5027 | Function Loss:  -4.09\n",
            "Total loss:  -3.9482 | PDE Loss:  -5.5039 | Function Loss:  -4.0898\n",
            "Total loss:  -3.9484 | PDE Loss:  -5.5064 | Function Loss:  -4.0891\n",
            "Total loss:  -3.9486 | PDE Loss:  -5.5063 | Function Loss:  -4.0894\n",
            "Total loss:  -3.9491 | PDE Loss:  -5.5057 | Function Loss:  -4.0903\n",
            "Total loss:  -3.9496 | PDE Loss:  -5.5054 | Function Loss:  -4.0911\n",
            "Total loss:  -3.95 | PDE Loss:  -5.5044 | Function Loss:  -4.0921\n",
            "Total loss:  -3.9503 | PDE Loss:  -5.5038 | Function Loss:  -4.0928\n",
            "Total loss:  -3.9505 | PDE Loss:  -5.5031 | Function Loss:  -4.0933\n",
            "Total loss:  -3.9507 | PDE Loss:  -5.5036 | Function Loss:  -4.0933\n",
            "Total loss:  -3.9509 | PDE Loss:  -5.504 | Function Loss:  -4.0934\n",
            "Total loss:  -3.9512 | PDE Loss:  -5.5052 | Function Loss:  -4.0934\n",
            "Total loss:  -3.9515 | PDE Loss:  -5.5069 | Function Loss:  -4.0932\n",
            "Total loss:  -3.9518 | PDE Loss:  -5.5082 | Function Loss:  -4.0931\n",
            "Total loss:  -3.9521 | PDE Loss:  -5.5092 | Function Loss:  -4.093\n",
            "Total loss:  -3.9525 | PDE Loss:  -5.5103 | Function Loss:  -4.0933\n",
            "Total loss:  -3.9529 | PDE Loss:  -5.5121 | Function Loss:  -4.0932\n",
            "Total loss:  -3.9534 | PDE Loss:  -5.5134 | Function Loss:  -4.0934\n",
            "Total loss:  -3.954 | PDE Loss:  -5.5152 | Function Loss:  -4.0934\n",
            "Total loss:  -3.9545 | PDE Loss:  -5.5159 | Function Loss:  -4.0939\n",
            "Total loss:  -3.9546 | PDE Loss:  -5.5146 | Function Loss:  -4.0945\n",
            "Total loss:  -3.9551 | PDE Loss:  -5.5158 | Function Loss:  -4.0948\n",
            "Total loss:  -3.9556 | PDE Loss:  -5.514 | Function Loss:  -4.0961\n",
            "Total loss:  -3.9559 | PDE Loss:  -5.5142 | Function Loss:  -4.0964\n",
            "Total loss:  -3.9563 | PDE Loss:  -5.515 | Function Loss:  -4.0967\n",
            "Total loss:  -3.9566 | PDE Loss:  -5.5147 | Function Loss:  -4.0973\n",
            "Total loss:  -3.957 | PDE Loss:  -5.5145 | Function Loss:  -4.0979\n",
            "Total loss:  -3.9573 | PDE Loss:  -5.5139 | Function Loss:  -4.0985\n",
            "Total loss:  -3.9576 | PDE Loss:  -5.5135 | Function Loss:  -4.099\n",
            "Total loss:  -3.9578 | PDE Loss:  -5.513 | Function Loss:  -4.0996\n",
            "Total loss:  -3.958 | PDE Loss:  -5.5125 | Function Loss:  -4.1\n",
            "Total loss:  -3.9582 | PDE Loss:  -5.5117 | Function Loss:  -4.1006\n",
            "Total loss:  -3.9584 | PDE Loss:  -5.5109 | Function Loss:  -4.1011\n",
            "Total loss:  -3.9585 | PDE Loss:  -5.51 | Function Loss:  -4.1017\n",
            "Total loss:  -3.9571 | PDE Loss:  -5.5087 | Function Loss:  -4.1003\n",
            "Total loss:  -3.9585 | PDE Loss:  -5.51 | Function Loss:  -4.1017\n",
            "Total loss:  -3.9587 | PDE Loss:  -5.5087 | Function Loss:  -4.1025\n",
            "Total loss:  -3.9589 | PDE Loss:  -5.5082 | Function Loss:  -4.103\n",
            "Total loss:  -3.9592 | PDE Loss:  -5.5081 | Function Loss:  -4.1034\n",
            "Total loss:  -3.9595 | PDE Loss:  -5.5087 | Function Loss:  -4.1036\n",
            "Total loss:  -3.9598 | PDE Loss:  -5.5102 | Function Loss:  -4.1034\n",
            "Total loss:  -3.96 | PDE Loss:  -5.5119 | Function Loss:  -4.1031\n",
            "Total loss:  -3.9603 | PDE Loss:  -5.5141 | Function Loss:  -4.1025\n",
            "Total loss:  -3.9605 | PDE Loss:  -5.5158 | Function Loss:  -4.1021\n",
            "Total loss:  -3.9605 | PDE Loss:  -5.5212 | Function Loss:  -4.1001\n",
            "Total loss:  -3.9607 | PDE Loss:  -5.5205 | Function Loss:  -4.1006\n",
            "Total loss:  -3.9608 | PDE Loss:  -5.5195 | Function Loss:  -4.1012\n",
            "Total loss:  -3.9609 | PDE Loss:  -5.519 | Function Loss:  -4.1015\n",
            "Total loss:  -3.961 | PDE Loss:  -5.5181 | Function Loss:  -4.102\n",
            "Total loss:  -3.9611 | PDE Loss:  -5.5177 | Function Loss:  -4.1023\n",
            "Total loss:  -3.9612 | PDE Loss:  -5.5176 | Function Loss:  -4.1025\n",
            "Total loss:  -3.9613 | PDE Loss:  -5.5178 | Function Loss:  -4.1026\n",
            "Total loss:  -3.9614 | PDE Loss:  -5.5183 | Function Loss:  -4.1025\n",
            "Total loss:  -3.9615 | PDE Loss:  -5.5192 | Function Loss:  -4.1023\n",
            "Total loss:  -3.9616 | PDE Loss:  -5.5202 | Function Loss:  -4.102\n",
            "Total loss:  -3.9616 | PDE Loss:  -5.5215 | Function Loss:  -4.1016\n",
            "Total loss:  -3.9617 | PDE Loss:  -5.5228 | Function Loss:  -4.1012\n",
            "Total loss:  -3.9618 | PDE Loss:  -5.5243 | Function Loss:  -4.1008\n",
            "Total loss:  -3.9619 | PDE Loss:  -5.5255 | Function Loss:  -4.1004\n",
            "Total loss:  -3.962 | PDE Loss:  -5.5265 | Function Loss:  -4.1002\n",
            "Total loss:  -3.9621 | PDE Loss:  -5.5272 | Function Loss:  -4.1\n",
            "Total loss:  -3.9622 | PDE Loss:  -5.5276 | Function Loss:  -4.1\n",
            "Total loss:  -3.9623 | PDE Loss:  -5.5277 | Function Loss:  -4.1002\n",
            "Total loss:  -3.9624 | PDE Loss:  -5.5274 | Function Loss:  -4.1005\n",
            "Total loss:  -3.9626 | PDE Loss:  -5.5271 | Function Loss:  -4.1008\n",
            "Total loss:  -3.9627 | PDE Loss:  -5.5262 | Function Loss:  -4.1013\n",
            "Total loss:  -3.9628 | PDE Loss:  -5.5255 | Function Loss:  -4.1017\n",
            "Total loss:  -3.963 | PDE Loss:  -5.5257 | Function Loss:  -4.1018\n",
            "Total loss:  -3.963 | PDE Loss:  -5.5257 | Function Loss:  -4.102\n",
            "Total loss:  -3.9632 | PDE Loss:  -5.5253 | Function Loss:  -4.1024\n",
            "Total loss:  -3.9635 | PDE Loss:  -5.5248 | Function Loss:  -4.1029\n",
            "Total loss:  -3.9637 | PDE Loss:  -5.5242 | Function Loss:  -4.1034\n",
            "Total loss:  -3.9639 | PDE Loss:  -5.5239 | Function Loss:  -4.1039\n",
            "Total loss:  -3.9642 | PDE Loss:  -5.5225 | Function Loss:  -4.1048\n",
            "Total loss:  -3.9645 | PDE Loss:  -5.5221 | Function Loss:  -4.1054\n",
            "Total loss:  -3.9648 | PDE Loss:  -5.5211 | Function Loss:  -4.1062\n",
            "Total loss:  -3.9651 | PDE Loss:  -5.5206 | Function Loss:  -4.1068\n",
            "Total loss:  -3.9654 | PDE Loss:  -5.5202 | Function Loss:  -4.1074\n",
            "Total loss:  -3.9657 | PDE Loss:  -5.5202 | Function Loss:  -4.1077\n",
            "Total loss:  -3.966 | PDE Loss:  -5.5202 | Function Loss:  -4.1081\n",
            "Total loss:  -3.9662 | PDE Loss:  -5.5208 | Function Loss:  -4.1082\n",
            "Total loss:  -3.9665 | PDE Loss:  -5.5214 | Function Loss:  -4.1084\n",
            "Total loss:  -3.9669 | PDE Loss:  -5.5221 | Function Loss:  -4.1086\n",
            "Total loss:  -3.9673 | PDE Loss:  -5.5232 | Function Loss:  -4.1087\n",
            "Total loss:  -3.9677 | PDE Loss:  -5.524 | Function Loss:  -4.109\n",
            "Total loss:  -3.9682 | PDE Loss:  -5.5245 | Function Loss:  -4.1095\n",
            "Total loss:  -3.9686 | PDE Loss:  -5.5261 | Function Loss:  -4.1095\n",
            "Total loss:  -3.9691 | PDE Loss:  -5.5264 | Function Loss:  -4.11\n",
            "Total loss:  -3.9693 | PDE Loss:  -5.5267 | Function Loss:  -4.1102\n",
            "Total loss:  -3.9697 | PDE Loss:  -5.5275 | Function Loss:  -4.1104\n",
            "Total loss:  -3.97 | PDE Loss:  -5.5276 | Function Loss:  -4.1109\n",
            "Total loss:  -3.9704 | PDE Loss:  -5.5285 | Function Loss:  -4.111\n",
            "Total loss:  -3.9708 | PDE Loss:  -5.529 | Function Loss:  -4.1114\n",
            "Total loss:  -3.9712 | PDE Loss:  -5.5302 | Function Loss:  -4.1116\n",
            "Total loss:  -3.9718 | PDE Loss:  -5.5317 | Function Loss:  -4.1118\n",
            "Total loss:  -3.9724 | PDE Loss:  -5.5334 | Function Loss:  -4.1119\n",
            "Total loss:  -3.9728 | PDE Loss:  -5.5346 | Function Loss:  -4.1121\n",
            "Total loss:  -3.9734 | PDE Loss:  -5.5356 | Function Loss:  -4.1124\n",
            "Total loss:  -3.974 | PDE Loss:  -5.5363 | Function Loss:  -4.1131\n",
            "Total loss:  -3.9746 | PDE Loss:  -5.5369 | Function Loss:  -4.1136\n",
            "Total loss:  -3.9735 | PDE Loss:  -5.5307 | Function Loss:  -4.1145\n",
            "Total loss:  -3.975 | PDE Loss:  -5.5355 | Function Loss:  -4.1147\n",
            "Total loss:  -3.9754 | PDE Loss:  -5.5376 | Function Loss:  -4.1145\n",
            "Total loss:  -3.9758 | PDE Loss:  -5.5365 | Function Loss:  -4.1154\n",
            "Total loss:  -3.9762 | PDE Loss:  -5.5358 | Function Loss:  -4.1163\n",
            "Total loss:  -3.9767 | PDE Loss:  -5.5349 | Function Loss:  -4.1173\n",
            "Total loss:  -3.977 | PDE Loss:  -5.5343 | Function Loss:  -4.1179\n",
            "Total loss:  -3.9773 | PDE Loss:  -5.5336 | Function Loss:  -4.1187\n",
            "Total loss:  -3.9777 | PDE Loss:  -5.5341 | Function Loss:  -4.119\n",
            "Total loss:  -3.9772 | PDE Loss:  -5.5288 | Function Loss:  -4.1204\n",
            "Total loss:  -3.978 | PDE Loss:  -5.5326 | Function Loss:  -4.12\n",
            "Total loss:  -3.9783 | PDE Loss:  -5.5333 | Function Loss:  -4.1201\n",
            "Total loss:  -3.9789 | PDE Loss:  -5.5353 | Function Loss:  -4.1202\n",
            "Total loss:  -3.9796 | PDE Loss:  -5.5375 | Function Loss:  -4.1203\n",
            "Total loss:  -3.9801 | PDE Loss:  -5.5395 | Function Loss:  -4.1203\n",
            "Total loss:  -3.9806 | PDE Loss:  -5.541 | Function Loss:  -4.1203\n",
            "Total loss:  -3.9809 | PDE Loss:  -5.5419 | Function Loss:  -4.1205\n",
            "Total loss:  -3.9812 | PDE Loss:  -5.5423 | Function Loss:  -4.1207\n",
            "Total loss:  -3.9815 | PDE Loss:  -5.5426 | Function Loss:  -4.1211\n",
            "Total loss:  -3.9819 | PDE Loss:  -5.5426 | Function Loss:  -4.1215\n",
            "Total loss:  -3.9822 | PDE Loss:  -5.5423 | Function Loss:  -4.1221\n",
            "Total loss:  -3.9826 | PDE Loss:  -5.5423 | Function Loss:  -4.1226\n",
            "Total loss:  -3.9828 | PDE Loss:  -5.5429 | Function Loss:  -4.1227\n",
            "Total loss:  -3.9832 | PDE Loss:  -5.5418 | Function Loss:  -4.1237\n",
            "Total loss:  -3.9836 | PDE Loss:  -5.5438 | Function Loss:  -4.1235\n",
            "Total loss:  -3.984 | PDE Loss:  -5.5446 | Function Loss:  -4.1236\n",
            "Total loss:  -3.9843 | PDE Loss:  -5.5456 | Function Loss:  -4.1238\n",
            "Total loss:  -3.9846 | PDE Loss:  -5.5462 | Function Loss:  -4.124\n",
            "Total loss:  -3.9849 | PDE Loss:  -5.5463 | Function Loss:  -4.1243\n",
            "Total loss:  -3.9852 | PDE Loss:  -5.5465 | Function Loss:  -4.1246\n",
            "Total loss:  -3.9854 | PDE Loss:  -5.5461 | Function Loss:  -4.1251\n",
            "Total loss:  -3.9857 | PDE Loss:  -5.5456 | Function Loss:  -4.1256\n",
            "Total loss:  -3.9858 | PDE Loss:  -5.5449 | Function Loss:  -4.1261\n",
            "Total loss:  -3.986 | PDE Loss:  -5.5443 | Function Loss:  -4.1266\n",
            "Total loss:  -3.9863 | PDE Loss:  -5.5434 | Function Loss:  -4.1273\n",
            "Total loss:  -3.9866 | PDE Loss:  -5.5427 | Function Loss:  -4.128\n",
            "Total loss:  -3.987 | PDE Loss:  -5.5417 | Function Loss:  -4.1289\n",
            "Total loss:  -3.9874 | PDE Loss:  -5.5404 | Function Loss:  -4.13\n",
            "Total loss:  -3.9878 | PDE Loss:  -5.5396 | Function Loss:  -4.131\n",
            "Total loss:  -3.9882 | PDE Loss:  -5.5384 | Function Loss:  -4.1319\n",
            "Total loss:  -3.9886 | PDE Loss:  -5.5389 | Function Loss:  -4.1322\n",
            "Total loss:  -3.9889 | PDE Loss:  -5.5391 | Function Loss:  -4.1326\n",
            "Total loss:  -3.9891 | PDE Loss:  -5.5397 | Function Loss:  -4.1327\n",
            "Total loss:  -3.9895 | PDE Loss:  -5.5411 | Function Loss:  -4.1327\n",
            "Total loss:  -3.99 | PDE Loss:  -5.5428 | Function Loss:  -4.1327\n",
            "Total loss:  -3.9905 | PDE Loss:  -5.5446 | Function Loss:  -4.1327\n",
            "Total loss:  -3.991 | PDE Loss:  -5.5478 | Function Loss:  -4.1321\n",
            "Total loss:  -3.9913 | PDE Loss:  -5.5475 | Function Loss:  -4.1327\n",
            "Total loss:  -3.9916 | PDE Loss:  -5.547 | Function Loss:  -4.1333\n",
            "Total loss:  -3.992 | PDE Loss:  -5.5457 | Function Loss:  -4.1343\n",
            "Total loss:  -3.9923 | PDE Loss:  -5.5447 | Function Loss:  -4.1351\n",
            "Total loss:  -3.9926 | PDE Loss:  -5.544 | Function Loss:  -4.1358\n",
            "Total loss:  -3.9929 | PDE Loss:  -5.5437 | Function Loss:  -4.1364\n",
            "Total loss:  -3.9911 | PDE Loss:  -5.5426 | Function Loss:  -4.1342\n",
            "Total loss:  -3.993 | PDE Loss:  -5.5439 | Function Loss:  -4.1364\n",
            "Total loss:  -3.9933 | PDE Loss:  -5.5437 | Function Loss:  -4.137\n",
            "Total loss:  -3.9937 | PDE Loss:  -5.5441 | Function Loss:  -4.1374\n",
            "Total loss:  -3.9944 | PDE Loss:  -5.5485 | Function Loss:  -4.1366\n",
            "Total loss:  -3.9949 | PDE Loss:  -5.549 | Function Loss:  -4.1371\n",
            "Total loss:  -3.9959 | PDE Loss:  -5.5513 | Function Loss:  -4.1375\n",
            "Total loss:  -3.997 | PDE Loss:  -5.5513 | Function Loss:  -4.139\n",
            "Total loss:  -3.9979 | PDE Loss:  -5.5598 | Function Loss:  -4.1372\n",
            "Total loss:  -3.9986 | PDE Loss:  -5.5591 | Function Loss:  -4.1383\n",
            "Total loss:  -3.9992 | PDE Loss:  -5.5598 | Function Loss:  -4.1388\n",
            "Total loss:  -4.0001 | PDE Loss:  -5.5625 | Function Loss:  -4.139\n",
            "Total loss:  -4.0007 | PDE Loss:  -5.5646 | Function Loss:  -4.1392\n",
            "Total loss:  -4.0012 | PDE Loss:  -5.5666 | Function Loss:  -4.1391\n",
            "Total loss:  -4.0017 | PDE Loss:  -5.5685 | Function Loss:  -4.1391\n",
            "Total loss:  -4.0023 | PDE Loss:  -5.57 | Function Loss:  -4.1393\n",
            "Total loss:  -4.0028 | PDE Loss:  -5.5709 | Function Loss:  -4.1396\n",
            "Total loss:  -4.0031 | PDE Loss:  -5.5697 | Function Loss:  -4.1405\n",
            "Total loss:  -4.0034 | PDE Loss:  -5.5706 | Function Loss:  -4.1407\n",
            "Total loss:  -4.0037 | PDE Loss:  -5.5704 | Function Loss:  -4.1411\n",
            "Total loss:  -4.004 | PDE Loss:  -5.5703 | Function Loss:  -4.1416\n",
            "Total loss:  -4.0044 | PDE Loss:  -5.5696 | Function Loss:  -4.1423\n",
            "Total loss:  -4.0047 | PDE Loss:  -5.5689 | Function Loss:  -4.143\n",
            "Total loss:  -4.0051 | PDE Loss:  -5.5669 | Function Loss:  -4.1443\n",
            "Total loss:  -4.0055 | PDE Loss:  -5.5664 | Function Loss:  -4.1451\n",
            "Total loss:  -3.9991 | PDE Loss:  -5.5432 | Function Loss:  -4.1451\n",
            "Total loss:  -4.0056 | PDE Loss:  -5.5645 | Function Loss:  -4.146\n",
            "Total loss:  -4.006 | PDE Loss:  -5.5633 | Function Loss:  -4.1469\n",
            "Total loss:  -4.0064 | PDE Loss:  -5.5627 | Function Loss:  -4.1477\n",
            "Total loss:  -4.0067 | PDE Loss:  -5.5614 | Function Loss:  -4.1487\n",
            "Total loss:  -4.0071 | PDE Loss:  -5.5606 | Function Loss:  -4.1494\n",
            "Total loss:  -4.0073 | PDE Loss:  -5.5602 | Function Loss:  -4.1499\n",
            "Total loss:  -4.0077 | PDE Loss:  -5.5594 | Function Loss:  -4.1508\n",
            "Total loss:  -4.008 | PDE Loss:  -5.5589 | Function Loss:  -4.1514\n",
            "Total loss:  -4.0082 | PDE Loss:  -5.559 | Function Loss:  -4.1517\n",
            "Total loss:  -4.0084 | PDE Loss:  -5.5601 | Function Loss:  -4.1515\n",
            "Total loss:  -4.0086 | PDE Loss:  -5.5601 | Function Loss:  -4.1518\n",
            "Total loss:  -4.0089 | PDE Loss:  -5.5596 | Function Loss:  -4.1523\n",
            "Total loss:  -4.0092 | PDE Loss:  -5.5602 | Function Loss:  -4.1526\n",
            "Total loss:  -4.0096 | PDE Loss:  -5.5606 | Function Loss:  -4.153\n",
            "Total loss:  -4.01 | PDE Loss:  -5.5615 | Function Loss:  -4.1532\n",
            "Total loss:  -4.0104 | PDE Loss:  -5.5625 | Function Loss:  -4.1534\n",
            "Total loss:  -4.0109 | PDE Loss:  -5.5636 | Function Loss:  -4.1536\n",
            "Total loss:  -4.0113 | PDE Loss:  -5.5649 | Function Loss:  -4.1537\n",
            "Total loss:  -4.0117 | PDE Loss:  -5.5661 | Function Loss:  -4.1538\n",
            "Total loss:  -4.0118 | PDE Loss:  -5.5697 | Function Loss:  -4.1525\n",
            "Total loss:  -4.0119 | PDE Loss:  -5.5681 | Function Loss:  -4.1533\n",
            "Total loss:  -4.0124 | PDE Loss:  -5.5691 | Function Loss:  -4.1536\n",
            "Total loss:  -4.0128 | PDE Loss:  -5.5693 | Function Loss:  -4.1541\n",
            "Total loss:  -4.0131 | PDE Loss:  -5.5688 | Function Loss:  -4.1547\n",
            "Total loss:  -4.0135 | PDE Loss:  -5.5692 | Function Loss:  -4.1551\n",
            "Total loss:  -4.0138 | PDE Loss:  -5.5692 | Function Loss:  -4.1555\n",
            "Total loss:  -4.014 | PDE Loss:  -5.5701 | Function Loss:  -4.1554\n",
            "Total loss:  -4.0142 | PDE Loss:  -5.571 | Function Loss:  -4.1554\n",
            "Total loss:  -4.0145 | PDE Loss:  -5.5727 | Function Loss:  -4.155\n",
            "Total loss:  -4.0148 | PDE Loss:  -5.5743 | Function Loss:  -4.1549\n",
            "Total loss:  -4.0151 | PDE Loss:  -5.577 | Function Loss:  -4.1543\n",
            "Total loss:  -4.0154 | PDE Loss:  -5.5795 | Function Loss:  -4.1538\n",
            "Total loss:  -4.0158 | PDE Loss:  -5.5823 | Function Loss:  -4.1532\n",
            "Total loss:  -4.016 | PDE Loss:  -5.583 | Function Loss:  -4.1534\n",
            "Total loss:  -4.0164 | PDE Loss:  -5.5851 | Function Loss:  -4.1531\n",
            "Total loss:  -4.0168 | PDE Loss:  -5.5868 | Function Loss:  -4.1529\n",
            "Total loss:  -4.0172 | PDE Loss:  -5.5876 | Function Loss:  -4.1532\n",
            "Total loss:  -4.0175 | PDE Loss:  -5.5883 | Function Loss:  -4.1534\n",
            "Total loss:  -4.0179 | PDE Loss:  -5.5881 | Function Loss:  -4.154\n",
            "Total loss:  -4.0183 | PDE Loss:  -5.5884 | Function Loss:  -4.1544\n",
            "Total loss:  -4.0188 | PDE Loss:  -5.5886 | Function Loss:  -4.155\n",
            "Total loss:  -4.0194 | PDE Loss:  -5.5893 | Function Loss:  -4.1556\n",
            "Total loss:  -4.02 | PDE Loss:  -5.5903 | Function Loss:  -4.1561\n",
            "Total loss:  -4.0207 | PDE Loss:  -5.5907 | Function Loss:  -4.1569\n",
            "Total loss:  -4.0214 | PDE Loss:  -5.591 | Function Loss:  -4.1577\n",
            "Total loss:  -4.0221 | PDE Loss:  -5.5918 | Function Loss:  -4.1584\n",
            "Total loss:  -4.0217 | PDE Loss:  -5.5901 | Function Loss:  -4.1585\n",
            "Total loss:  -4.0226 | PDE Loss:  -5.5913 | Function Loss:  -4.1593\n",
            "Total loss:  -4.0232 | PDE Loss:  -5.5919 | Function Loss:  -4.1598\n",
            "Total loss:  -4.0236 | PDE Loss:  -5.5927 | Function Loss:  -4.1601\n",
            "Total loss:  -4.0241 | PDE Loss:  -5.5938 | Function Loss:  -4.1605\n",
            "Total loss:  -4.0247 | PDE Loss:  -5.5971 | Function Loss:  -4.16\n",
            "Total loss:  -4.0253 | PDE Loss:  -5.5959 | Function Loss:  -4.1613\n",
            "Total loss:  -4.0259 | PDE Loss:  -5.5984 | Function Loss:  -4.1612\n",
            "Total loss:  -4.0269 | PDE Loss:  -5.6022 | Function Loss:  -4.1611\n",
            "Total loss:  -4.028 | PDE Loss:  -5.6059 | Function Loss:  -4.1613\n",
            "Total loss:  -4.0287 | PDE Loss:  -5.6088 | Function Loss:  -4.1612\n",
            "Total loss:  -4.0291 | PDE Loss:  -5.6116 | Function Loss:  -4.1608\n",
            "Total loss:  -4.0294 | PDE Loss:  -5.6127 | Function Loss:  -4.1607\n",
            "Total loss:  -4.0295 | PDE Loss:  -5.613 | Function Loss:  -4.1608\n",
            "Total loss:  -4.0297 | PDE Loss:  -5.6131 | Function Loss:  -4.1611\n",
            "Total loss:  -4.03 | PDE Loss:  -5.6127 | Function Loss:  -4.1616\n",
            "Total loss:  -4.0304 | PDE Loss:  -5.6132 | Function Loss:  -4.162\n",
            "Total loss:  -4.0305 | PDE Loss:  -5.6186 | Function Loss:  -4.1602\n",
            "Total loss:  -4.0308 | PDE Loss:  -5.6176 | Function Loss:  -4.161\n",
            "Total loss:  -4.031 | PDE Loss:  -5.6163 | Function Loss:  -4.1617\n",
            "Total loss:  -4.0312 | PDE Loss:  -5.6144 | Function Loss:  -4.1626\n",
            "Total loss:  -4.0314 | PDE Loss:  -5.6131 | Function Loss:  -4.1633\n",
            "Total loss:  -4.0316 | PDE Loss:  -5.6118 | Function Loss:  -4.1641\n",
            "Total loss:  -4.0319 | PDE Loss:  -5.6097 | Function Loss:  -4.1652\n",
            "Total loss:  -4.0321 | PDE Loss:  -5.6091 | Function Loss:  -4.1658\n",
            "Total loss:  -4.0324 | PDE Loss:  -5.6083 | Function Loss:  -4.1664\n",
            "Total loss:  -4.0326 | PDE Loss:  -5.6078 | Function Loss:  -4.1669\n",
            "Total loss:  -4.0328 | PDE Loss:  -5.6079 | Function Loss:  -4.1672\n",
            "Total loss:  -4.0331 | PDE Loss:  -5.6076 | Function Loss:  -4.1676\n",
            "Total loss:  -4.0333 | PDE Loss:  -5.6069 | Function Loss:  -4.1681\n",
            "Total loss:  -4.0334 | PDE Loss:  -5.6067 | Function Loss:  -4.1684\n",
            "Total loss:  -4.0337 | PDE Loss:  -5.6063 | Function Loss:  -4.169\n",
            "Total loss:  -4.0343 | PDE Loss:  -5.6047 | Function Loss:  -4.1703\n",
            "Total loss:  -4.0348 | PDE Loss:  -5.6029 | Function Loss:  -4.1717\n",
            "Total loss:  -4.0355 | PDE Loss:  -5.5992 | Function Loss:  -4.174\n",
            "Total loss:  -4.0297 | PDE Loss:  -5.5962 | Function Loss:  -4.1672\n",
            "Total loss:  -4.0357 | PDE Loss:  -5.6 | Function Loss:  -4.1739\n",
            "Total loss:  -4.0364 | PDE Loss:  -5.5969 | Function Loss:  -4.1761\n",
            "Total loss:  -4.0372 | PDE Loss:  -5.5946 | Function Loss:  -4.1781\n",
            "Total loss:  -4.0382 | PDE Loss:  -5.5931 | Function Loss:  -4.1801\n",
            "Total loss:  -4.039 | PDE Loss:  -5.5933 | Function Loss:  -4.1811\n",
            "Total loss:  -4.0397 | PDE Loss:  -5.5965 | Function Loss:  -4.1809\n",
            "Total loss:  -4.0403 | PDE Loss:  -5.5987 | Function Loss:  -4.1809\n",
            "Total loss:  -4.0409 | PDE Loss:  -5.6023 | Function Loss:  -4.1803\n",
            "Total loss:  -4.0418 | PDE Loss:  -5.6063 | Function Loss:  -4.18\n",
            "Total loss:  -4.0426 | PDE Loss:  -5.6096 | Function Loss:  -4.1798\n",
            "Total loss:  -4.0434 | PDE Loss:  -5.6105 | Function Loss:  -4.1806\n",
            "Total loss:  -4.0433 | PDE Loss:  -5.6179 | Function Loss:  -4.1778\n",
            "Total loss:  -4.0437 | PDE Loss:  -5.6144 | Function Loss:  -4.1797\n",
            "Total loss:  -4.0443 | PDE Loss:  -5.6163 | Function Loss:  -4.1797\n",
            "Total loss:  -4.0448 | PDE Loss:  -5.6172 | Function Loss:  -4.1802\n",
            "Total loss:  -4.0454 | PDE Loss:  -5.6175 | Function Loss:  -4.1808\n",
            "Total loss:  -4.0458 | PDE Loss:  -5.6169 | Function Loss:  -4.1816\n",
            "Total loss:  -4.0462 | PDE Loss:  -5.6163 | Function Loss:  -4.1823\n",
            "Total loss:  -4.0465 | PDE Loss:  -5.6158 | Function Loss:  -4.1829\n",
            "Total loss:  -4.047 | PDE Loss:  -5.6165 | Function Loss:  -4.1834\n",
            "Total loss:  -4.0477 | PDE Loss:  -5.6167 | Function Loss:  -4.1842\n",
            "Total loss:  -4.0483 | PDE Loss:  -5.6183 | Function Loss:  -4.1844\n",
            "Total loss:  -4.0488 | PDE Loss:  -5.6199 | Function Loss:  -4.1846\n",
            "Total loss:  -4.0495 | PDE Loss:  -5.6229 | Function Loss:  -4.1844\n",
            "Total loss:  -4.0504 | PDE Loss:  -5.6288 | Function Loss:  -4.1835\n",
            "Total loss:  -4.0511 | PDE Loss:  -5.6314 | Function Loss:  -4.1836\n",
            "Total loss:  -4.0518 | PDE Loss:  -5.635 | Function Loss:  -4.1832\n",
            "Total loss:  -4.0523 | PDE Loss:  -5.6372 | Function Loss:  -4.1831\n",
            "Total loss:  -4.0532 | PDE Loss:  -5.6392 | Function Loss:  -4.1836\n",
            "Total loss:  -4.054 | PDE Loss:  -5.6408 | Function Loss:  -4.1841\n",
            "Total loss:  -4.0545 | PDE Loss:  -5.6418 | Function Loss:  -4.1845\n",
            "Total loss:  -4.0553 | PDE Loss:  -5.6436 | Function Loss:  -4.1849\n",
            "Total loss:  -4.0564 | PDE Loss:  -5.6429 | Function Loss:  -4.1866\n",
            "Total loss:  -4.0577 | PDE Loss:  -5.6461 | Function Loss:  -4.1873\n",
            "Total loss:  -4.0591 | PDE Loss:  -5.6458 | Function Loss:  -4.1892\n",
            "Total loss:  -4.0602 | PDE Loss:  -5.6452 | Function Loss:  -4.191\n",
            "Total loss:  -4.0616 | PDE Loss:  -5.6468 | Function Loss:  -4.1923\n",
            "Total loss:  -4.0631 | PDE Loss:  -5.6468 | Function Loss:  -4.1943\n",
            "Total loss:  -4.0644 | PDE Loss:  -5.6506 | Function Loss:  -4.1948\n",
            "Total loss:  -4.0658 | PDE Loss:  -5.653 | Function Loss:  -4.1958\n",
            "Total loss:  -4.067 | PDE Loss:  -5.6589 | Function Loss:  -4.1954\n",
            "Total loss:  -4.0681 | PDE Loss:  -5.6626 | Function Loss:  -4.1956\n",
            "Total loss:  -4.0693 | PDE Loss:  -5.6686 | Function Loss:  -4.1952\n",
            "Total loss:  -4.0702 | PDE Loss:  -5.6715 | Function Loss:  -4.1954\n",
            "Total loss:  -4.071 | PDE Loss:  -5.6758 | Function Loss:  -4.1951\n",
            "Total loss:  -4.0718 | PDE Loss:  -5.6781 | Function Loss:  -4.1954\n",
            "Total loss:  -4.0727 | PDE Loss:  -5.6789 | Function Loss:  -4.1963\n",
            "Total loss:  -4.0739 | PDE Loss:  -5.6822 | Function Loss:  -4.1967\n",
            "Total loss:  -4.075 | PDE Loss:  -5.6822 | Function Loss:  -4.1982\n",
            "Total loss:  -4.0761 | PDE Loss:  -5.6865 | Function Loss:  -4.1983\n",
            "Total loss:  -4.0772 | PDE Loss:  -5.6877 | Function Loss:  -4.1993\n",
            "Total loss:  -4.0782 | PDE Loss:  -5.6907 | Function Loss:  -4.1998\n",
            "Total loss:  -4.0793 | PDE Loss:  -5.6941 | Function Loss:  -4.2\n",
            "Total loss:  -4.0802 | PDE Loss:  -5.6974 | Function Loss:  -4.2002\n",
            "Total loss:  -4.0809 | PDE Loss:  -5.7018 | Function Loss:  -4.1997\n",
            "Total loss:  -4.0818 | PDE Loss:  -5.706 | Function Loss:  -4.1996\n",
            "Total loss:  -4.0826 | PDE Loss:  -5.7102 | Function Loss:  -4.1994\n",
            "Total loss:  -4.0832 | PDE Loss:  -5.7145 | Function Loss:  -4.1988\n",
            "Total loss:  -4.0836 | PDE Loss:  -5.7178 | Function Loss:  -4.1983\n",
            "Total loss:  -4.084 | PDE Loss:  -5.7228 | Function Loss:  -4.1974\n",
            "Total loss:  -4.0843 | PDE Loss:  -5.7277 | Function Loss:  -4.1963\n",
            "Total loss:  -4.0846 | PDE Loss:  -5.7316 | Function Loss:  -4.1956\n",
            "Total loss:  -4.0853 | PDE Loss:  -5.7342 | Function Loss:  -4.1957\n",
            "Total loss:  -4.0858 | PDE Loss:  -5.7353 | Function Loss:  -4.196\n",
            "Total loss:  -4.0866 | PDE Loss:  -5.7388 | Function Loss:  -4.196\n",
            "Total loss:  -4.0872 | PDE Loss:  -5.7415 | Function Loss:  -4.1961\n",
            "Total loss:  -4.088 | PDE Loss:  -5.7459 | Function Loss:  -4.1957\n",
            "Total loss:  -4.0888 | PDE Loss:  -5.7496 | Function Loss:  -4.1957\n",
            "Total loss:  -4.0896 | PDE Loss:  -5.7529 | Function Loss:  -4.1959\n",
            "Total loss:  -4.0905 | PDE Loss:  -5.7552 | Function Loss:  -4.1965\n",
            "Total loss:  -4.0916 | PDE Loss:  -5.7567 | Function Loss:  -4.1975\n",
            "Total loss:  -4.093 | PDE Loss:  -5.7573 | Function Loss:  -4.199\n",
            "Total loss:  -4.0943 | PDE Loss:  -5.7574 | Function Loss:  -4.2006\n",
            "Total loss:  -4.0956 | PDE Loss:  -5.7575 | Function Loss:  -4.2023\n",
            "Total loss:  -4.0967 | PDE Loss:  -5.7577 | Function Loss:  -4.2036\n",
            "Total loss:  -4.0977 | PDE Loss:  -5.7573 | Function Loss:  -4.2051\n",
            "Total loss:  -4.0985 | PDE Loss:  -5.7578 | Function Loss:  -4.206\n",
            "Total loss:  -4.0995 | PDE Loss:  -5.7592 | Function Loss:  -4.2068\n",
            "Total loss:  -4.0926 | PDE Loss:  -5.7587 | Function Loss:  -4.1982\n",
            "Total loss:  -4.0999 | PDE Loss:  -5.7602 | Function Loss:  -4.207\n",
            "Total loss:  -4.1008 | PDE Loss:  -5.7598 | Function Loss:  -4.2084\n",
            "Total loss:  -4.1018 | PDE Loss:  -5.7665 | Function Loss:  -4.2078\n",
            "Total loss:  -4.1029 | PDE Loss:  -5.7709 | Function Loss:  -4.2078\n",
            "Total loss:  -4.1041 | PDE Loss:  -5.7781 | Function Loss:  -4.2074\n",
            "Total loss:  -4.1055 | PDE Loss:  -5.785 | Function Loss:  -4.2075\n",
            "Total loss:  -4.1071 | PDE Loss:  -5.7915 | Function Loss:  -4.2077\n",
            "Total loss:  -4.1089 | PDE Loss:  -5.7979 | Function Loss:  -4.2084\n",
            "Total loss:  -4.1108 | PDE Loss:  -5.8002 | Function Loss:  -4.2101\n",
            "Total loss:  -4.1121 | PDE Loss:  -5.8024 | Function Loss:  -4.2112\n",
            "Total loss:  -4.1144 | PDE Loss:  -5.8041 | Function Loss:  -4.2137\n",
            "Total loss:  -4.1162 | PDE Loss:  -5.7982 | Function Loss:  -4.2175\n",
            "Total loss:  -4.1177 | PDE Loss:  -5.7983 | Function Loss:  -4.2194\n",
            "Total loss:  -4.1192 | PDE Loss:  -5.7987 | Function Loss:  -4.2211\n",
            "Total loss:  -4.1206 | PDE Loss:  -5.8016 | Function Loss:  -4.2222\n",
            "Total loss:  -4.122 | PDE Loss:  -5.8042 | Function Loss:  -4.2231\n",
            "Total loss:  -4.123 | PDE Loss:  -5.809 | Function Loss:  -4.2233\n",
            "Total loss:  -4.1237 | PDE Loss:  -5.812 | Function Loss:  -4.2233\n",
            "Total loss:  -4.1244 | PDE Loss:  -5.8151 | Function Loss:  -4.2233\n",
            "Total loss:  -4.1251 | PDE Loss:  -5.8189 | Function Loss:  -4.2234\n",
            "Total loss:  -4.1261 | PDE Loss:  -5.8241 | Function Loss:  -4.2233\n",
            "Total loss:  -4.1272 | PDE Loss:  -5.8283 | Function Loss:  -4.2236\n",
            "Total loss:  -4.1283 | PDE Loss:  -5.8319 | Function Loss:  -4.224\n",
            "Total loss:  -4.1292 | PDE Loss:  -5.8351 | Function Loss:  -4.2244\n",
            "Total loss:  -4.13 | PDE Loss:  -5.8359 | Function Loss:  -4.2251\n",
            "Total loss:  -4.1306 | PDE Loss:  -5.8359 | Function Loss:  -4.226\n",
            "Total loss:  -4.1313 | PDE Loss:  -5.8364 | Function Loss:  -4.2267\n",
            "Total loss:  -4.132 | PDE Loss:  -5.836 | Function Loss:  -4.2277\n",
            "Total loss:  -4.1327 | PDE Loss:  -5.8371 | Function Loss:  -4.2283\n",
            "Total loss:  -4.1336 | PDE Loss:  -5.835 | Function Loss:  -4.2299\n",
            "Total loss:  -4.133 | PDE Loss:  -5.8437 | Function Loss:  -4.227\n",
            "Total loss:  -4.1341 | PDE Loss:  -5.8397 | Function Loss:  -4.2294\n",
            "Total loss:  -4.135 | PDE Loss:  -5.841 | Function Loss:  -4.2301\n",
            "Total loss:  -4.1369 | PDE Loss:  -5.846 | Function Loss:  -4.2313\n",
            "Total loss:  -4.1394 | PDE Loss:  -5.8563 | Function Loss:  -4.2319\n",
            "Total loss:  -4.1415 | PDE Loss:  -5.8625 | Function Loss:  -4.2331\n",
            "Total loss:  -4.1432 | PDE Loss:  -5.8664 | Function Loss:  -4.2342\n",
            "Total loss:  -4.1453 | PDE Loss:  -5.8691 | Function Loss:  -4.2362\n",
            "Total loss:  -4.1473 | PDE Loss:  -5.8668 | Function Loss:  -4.2392\n",
            "Total loss:  -4.149 | PDE Loss:  -5.863 | Function Loss:  -4.2423\n",
            "Total loss:  -4.151 | PDE Loss:  -5.8554 | Function Loss:  -4.2466\n",
            "Total loss:  -4.1526 | PDE Loss:  -5.8473 | Function Loss:  -4.2506\n",
            "Total loss:  -4.1536 | PDE Loss:  -5.8319 | Function Loss:  -4.2559\n",
            "Total loss:  -4.1549 | PDE Loss:  -5.8253 | Function Loss:  -4.2592\n",
            "Total loss:  -4.1562 | PDE Loss:  -5.8287 | Function Loss:  -4.26\n",
            "Total loss:  -4.1577 | PDE Loss:  -5.8314 | Function Loss:  -4.2612\n",
            "Total loss:  -4.1599 | PDE Loss:  -5.8373 | Function Loss:  -4.2624\n",
            "Total loss:  -4.1615 | PDE Loss:  -5.839 | Function Loss:  -4.2639\n",
            "Total loss:  -4.1626 | PDE Loss:  -5.8423 | Function Loss:  -4.2644\n",
            "Total loss:  -4.1637 | PDE Loss:  -5.8463 | Function Loss:  -4.2648\n",
            "Total loss:  -4.1647 | PDE Loss:  -5.8495 | Function Loss:  -4.2652\n",
            "Total loss:  -4.1656 | PDE Loss:  -5.8483 | Function Loss:  -4.2666\n",
            "Total loss:  -4.1663 | PDE Loss:  -5.8483 | Function Loss:  -4.2675\n",
            "Total loss:  -4.1667 | PDE Loss:  -5.8465 | Function Loss:  -4.2686\n",
            "Total loss:  -4.1666 | PDE Loss:  -5.8457 | Function Loss:  -4.2686\n",
            "Total loss:  -4.1674 | PDE Loss:  -5.8469 | Function Loss:  -4.2693\n",
            "Total loss:  -4.1678 | PDE Loss:  -5.8469 | Function Loss:  -4.2698\n",
            "Total loss:  -4.1691 | PDE Loss:  -5.8476 | Function Loss:  -4.2713\n",
            "Total loss:  -4.1704 | PDE Loss:  -5.8501 | Function Loss:  -4.2722\n",
            "Total loss:  -4.1714 | PDE Loss:  -5.8514 | Function Loss:  -4.2732\n",
            "Total loss:  -4.1725 | PDE Loss:  -5.8616 | Function Loss:  -4.2719\n",
            "Total loss:  -4.1733 | PDE Loss:  -5.8619 | Function Loss:  -4.2729\n",
            "Total loss:  -4.174 | PDE Loss:  -5.8631 | Function Loss:  -4.2735\n",
            "Total loss:  -4.1748 | PDE Loss:  -5.8629 | Function Loss:  -4.2744\n",
            "Total loss:  -4.1754 | PDE Loss:  -5.8622 | Function Loss:  -4.2754\n",
            "Total loss:  -4.1759 | PDE Loss:  -5.8616 | Function Loss:  -4.2762\n",
            "Total loss:  -4.1763 | PDE Loss:  -5.8603 | Function Loss:  -4.277\n",
            "Total loss:  -4.1767 | PDE Loss:  -5.8583 | Function Loss:  -4.2781\n",
            "Total loss:  -4.1772 | PDE Loss:  -5.8563 | Function Loss:  -4.2792\n",
            "Total loss:  -4.1777 | PDE Loss:  -5.8557 | Function Loss:  -4.28\n",
            "Total loss:  -4.1767 | PDE Loss:  -5.8614 | Function Loss:  -4.2773\n",
            "Total loss:  -4.1779 | PDE Loss:  -5.8578 | Function Loss:  -4.2797\n",
            "Total loss:  -4.1779 | PDE Loss:  -5.8527 | Function Loss:  -4.281\n",
            "Total loss:  -4.1783 | PDE Loss:  -5.8556 | Function Loss:  -4.2808\n",
            "Total loss:  -4.1788 | PDE Loss:  -5.8576 | Function Loss:  -4.2809\n",
            "Total loss:  -4.1795 | PDE Loss:  -5.8607 | Function Loss:  -4.2809\n",
            "Total loss:  -4.1802 | PDE Loss:  -5.8654 | Function Loss:  -4.2806\n",
            "Total loss:  -4.181 | PDE Loss:  -5.8723 | Function Loss:  -4.2799\n",
            "Total loss:  -4.1816 | PDE Loss:  -5.8773 | Function Loss:  -4.2794\n",
            "Total loss:  -4.1825 | PDE Loss:  -5.8893 | Function Loss:  -4.2774\n",
            "Total loss:  -4.1832 | PDE Loss:  -5.8894 | Function Loss:  -4.2783\n",
            "Total loss:  -4.1841 | PDE Loss:  -5.8903 | Function Loss:  -4.2792\n",
            "Total loss:  -4.1847 | PDE Loss:  -5.8899 | Function Loss:  -4.2801\n",
            "Total loss:  -4.1852 | PDE Loss:  -5.8895 | Function Loss:  -4.2807\n",
            "Total loss:  -4.1855 | PDE Loss:  -5.8899 | Function Loss:  -4.281\n",
            "Total loss:  -4.1857 | PDE Loss:  -5.8899 | Function Loss:  -4.2813\n",
            "Total loss:  -4.1859 | PDE Loss:  -5.8907 | Function Loss:  -4.2814\n",
            "Total loss:  -4.1862 | PDE Loss:  -5.8917 | Function Loss:  -4.2815\n",
            "Total loss:  -4.1867 | PDE Loss:  -5.8929 | Function Loss:  -4.2818\n",
            "Total loss:  -4.1874 | PDE Loss:  -5.8948 | Function Loss:  -4.2822\n",
            "Total loss:  -4.1878 | PDE Loss:  -5.8976 | Function Loss:  -4.2821\n",
            "Total loss:  -4.1888 | PDE Loss:  -5.8978 | Function Loss:  -4.2832\n",
            "Total loss:  -4.1892 | PDE Loss:  -5.8963 | Function Loss:  -4.2841\n",
            "Total loss:  -4.1897 | PDE Loss:  -5.8958 | Function Loss:  -4.2849\n",
            "Total loss:  -4.1901 | PDE Loss:  -5.8948 | Function Loss:  -4.2856\n",
            "Total loss:  -4.1904 | PDE Loss:  -5.8938 | Function Loss:  -4.2862\n",
            "Total loss:  -4.1907 | PDE Loss:  -5.8922 | Function Loss:  -4.287\n",
            "Total loss:  -4.1911 | PDE Loss:  -5.8903 | Function Loss:  -4.288\n",
            "Total loss:  -4.1915 | PDE Loss:  -5.8898 | Function Loss:  -4.2886\n",
            "Total loss:  -4.1919 | PDE Loss:  -5.8893 | Function Loss:  -4.2892\n",
            "Total loss:  -4.1923 | PDE Loss:  -5.8902 | Function Loss:  -4.2895\n",
            "Total loss:  -4.1928 | PDE Loss:  -5.8921 | Function Loss:  -4.2897\n",
            "Total loss:  -4.1934 | PDE Loss:  -5.8952 | Function Loss:  -4.2895\n",
            "Total loss:  -4.1939 | PDE Loss:  -5.9003 | Function Loss:  -4.289\n",
            "Total loss:  -4.1945 | PDE Loss:  -5.9052 | Function Loss:  -4.2885\n",
            "Total loss:  -4.1948 | PDE Loss:  -5.9125 | Function Loss:  -4.2871\n",
            "Total loss:  -4.1952 | PDE Loss:  -5.9138 | Function Loss:  -4.2873\n",
            "Total loss:  -4.1956 | PDE Loss:  -5.9162 | Function Loss:  -4.2872\n",
            "Total loss:  -4.1959 | PDE Loss:  -5.9172 | Function Loss:  -4.2874\n",
            "Total loss:  -4.1961 | PDE Loss:  -5.919 | Function Loss:  -4.2873\n",
            "Total loss:  -4.1964 | PDE Loss:  -5.9186 | Function Loss:  -4.2877\n",
            "Total loss:  -4.1967 | PDE Loss:  -5.9181 | Function Loss:  -4.2882\n",
            "Total loss:  -4.1971 | PDE Loss:  -5.9161 | Function Loss:  -4.2891\n",
            "Total loss:  -4.1973 | PDE Loss:  -5.9149 | Function Loss:  -4.2897\n",
            "Total loss:  -4.1976 | PDE Loss:  -5.9138 | Function Loss:  -4.2903\n",
            "Total loss:  -4.1979 | PDE Loss:  -5.9127 | Function Loss:  -4.291\n",
            "Total loss:  -4.1982 | PDE Loss:  -5.9126 | Function Loss:  -4.2913\n",
            "Total loss:  -4.1984 | PDE Loss:  -5.9137 | Function Loss:  -4.2913\n",
            "Total loss:  -4.1987 | PDE Loss:  -5.9139 | Function Loss:  -4.2916\n",
            "Total loss:  -4.1989 | PDE Loss:  -5.9163 | Function Loss:  -4.2913\n",
            "Total loss:  -4.1992 | PDE Loss:  -5.9205 | Function Loss:  -4.2907\n",
            "Total loss:  -4.1996 | PDE Loss:  -5.923 | Function Loss:  -4.2906\n",
            "Total loss:  -4.1998 | PDE Loss:  -5.928 | Function Loss:  -4.2898\n",
            "Total loss:  -4.2001 | PDE Loss:  -5.9308 | Function Loss:  -4.2894\n",
            "Total loss:  -4.2002 | PDE Loss:  -5.9331 | Function Loss:  -4.2891\n",
            "Total loss:  -4.2005 | PDE Loss:  -5.9336 | Function Loss:  -4.2892\n",
            "Total loss:  -4.2007 | PDE Loss:  -5.9348 | Function Loss:  -4.2892\n",
            "Total loss:  -4.2009 | PDE Loss:  -5.9346 | Function Loss:  -4.2895\n",
            "Total loss:  -4.2011 | PDE Loss:  -5.9351 | Function Loss:  -4.2896\n",
            "Total loss:  -4.2014 | PDE Loss:  -5.9357 | Function Loss:  -4.2899\n",
            "Total loss:  -4.2014 | PDE Loss:  -5.9411 | Function Loss:  -4.2888\n",
            "Total loss:  -4.2018 | PDE Loss:  -5.942 | Function Loss:  -4.289\n",
            "Total loss:  -4.2022 | PDE Loss:  -5.9434 | Function Loss:  -4.2891\n",
            "Total loss:  -4.2024 | PDE Loss:  -5.9444 | Function Loss:  -4.2892\n",
            "Total loss:  -4.2027 | PDE Loss:  -5.9467 | Function Loss:  -4.2891\n",
            "Total loss:  -4.2031 | PDE Loss:  -5.949 | Function Loss:  -4.289\n",
            "Total loss:  -4.2031 | PDE Loss:  -5.9621 | Function Loss:  -4.2862\n",
            "Total loss:  -4.2033 | PDE Loss:  -5.9559 | Function Loss:  -4.2878\n",
            "Total loss:  -4.2036 | PDE Loss:  -5.9574 | Function Loss:  -4.2878\n",
            "Total loss:  -4.2039 | PDE Loss:  -5.9586 | Function Loss:  -4.288\n",
            "Total loss:  -4.2042 | PDE Loss:  -5.9605 | Function Loss:  -4.2879\n",
            "Total loss:  -4.2045 | PDE Loss:  -5.9616 | Function Loss:  -4.288\n",
            "Total loss:  -4.2047 | PDE Loss:  -5.9621 | Function Loss:  -4.2881\n",
            "Total loss:  -4.2049 | PDE Loss:  -5.9624 | Function Loss:  -4.2883\n",
            "Total loss:  -4.2052 | PDE Loss:  -5.9617 | Function Loss:  -4.2888\n",
            "Total loss:  -4.2055 | PDE Loss:  -5.9604 | Function Loss:  -4.2894\n",
            "Total loss:  -4.2056 | PDE Loss:  -5.9591 | Function Loss:  -4.2899\n",
            "Total loss:  -4.2058 | PDE Loss:  -5.9573 | Function Loss:  -4.2905\n",
            "Total loss:  -4.2059 | PDE Loss:  -5.9562 | Function Loss:  -4.2908\n",
            "Total loss:  -4.206 | PDE Loss:  -5.9552 | Function Loss:  -4.2912\n",
            "Total loss:  -4.206 | PDE Loss:  -5.9546 | Function Loss:  -4.2914\n",
            "Total loss:  -4.2061 | PDE Loss:  -5.9546 | Function Loss:  -4.2915\n",
            "Total loss:  -4.2063 | PDE Loss:  -5.9543 | Function Loss:  -4.2917\n",
            "Total loss:  -4.2062 | PDE Loss:  -5.9571 | Function Loss:  -4.2911\n",
            "Total loss:  -4.2063 | PDE Loss:  -5.9556 | Function Loss:  -4.2915\n",
            "Total loss:  -4.2065 | PDE Loss:  -5.9557 | Function Loss:  -4.2917\n",
            "Total loss:  -4.2066 | PDE Loss:  -5.9559 | Function Loss:  -4.2918\n",
            "Total loss:  -4.2068 | PDE Loss:  -5.9565 | Function Loss:  -4.2919\n",
            "Total loss:  -4.207 | PDE Loss:  -5.9571 | Function Loss:  -4.292\n",
            "Total loss:  -4.2071 | PDE Loss:  -5.9574 | Function Loss:  -4.2921\n",
            "Total loss:  -4.2072 | PDE Loss:  -5.9584 | Function Loss:  -4.292\n",
            "Total loss:  -4.2074 | PDE Loss:  -5.9594 | Function Loss:  -4.292\n",
            "Total loss:  -4.2076 | PDE Loss:  -5.9584 | Function Loss:  -4.2925\n",
            "Total loss:  -4.2078 | PDE Loss:  -5.9593 | Function Loss:  -4.2926\n",
            "Total loss:  -4.2083 | PDE Loss:  -5.9602 | Function Loss:  -4.2929\n",
            "Total loss:  -4.2088 | PDE Loss:  -5.9606 | Function Loss:  -4.2935\n",
            "Total loss:  -4.2095 | PDE Loss:  -5.9593 | Function Loss:  -4.2945\n",
            "Total loss:  -4.21 | PDE Loss:  -5.9592 | Function Loss:  -4.2952\n",
            "Total loss:  -4.2106 | PDE Loss:  -5.9589 | Function Loss:  -4.296\n",
            "Total loss:  -4.2111 | PDE Loss:  -5.958 | Function Loss:  -4.2968\n",
            "Total loss:  -4.2114 | PDE Loss:  -5.957 | Function Loss:  -4.2974\n",
            "Total loss:  -4.2117 | PDE Loss:  -5.9569 | Function Loss:  -4.2978\n",
            "Total loss:  -4.2119 | PDE Loss:  -5.9565 | Function Loss:  -4.2982\n",
            "Total loss:  -4.2121 | PDE Loss:  -5.9568 | Function Loss:  -4.2983\n",
            "Total loss:  -4.2123 | PDE Loss:  -5.9571 | Function Loss:  -4.2985\n",
            "Total loss:  -4.2125 | PDE Loss:  -5.9579 | Function Loss:  -4.2985\n",
            "Total loss:  -4.2093 | PDE Loss:  -5.9592 | Function Loss:  -4.2944\n",
            "Total loss:  -4.2125 | PDE Loss:  -5.9583 | Function Loss:  -4.2984\n",
            "Total loss:  -4.2127 | PDE Loss:  -5.9591 | Function Loss:  -4.2986\n",
            "Total loss:  -4.213 | PDE Loss:  -5.96 | Function Loss:  -4.2986\n",
            "Total loss:  -4.2132 | PDE Loss:  -5.9605 | Function Loss:  -4.2988\n",
            "Total loss:  -4.2135 | PDE Loss:  -5.9616 | Function Loss:  -4.2989\n",
            "Total loss:  -4.2137 | PDE Loss:  -5.9618 | Function Loss:  -4.2992\n",
            "Total loss:  -4.2141 | PDE Loss:  -5.9625 | Function Loss:  -4.2995\n",
            "Total loss:  -4.2147 | PDE Loss:  -5.9635 | Function Loss:  -4.3\n",
            "Total loss:  -4.2155 | PDE Loss:  -5.9649 | Function Loss:  -4.3007\n",
            "Total loss:  -4.2164 | PDE Loss:  -5.9662 | Function Loss:  -4.3015\n",
            "Total loss:  -4.2171 | PDE Loss:  -5.9655 | Function Loss:  -4.3025\n",
            "Total loss:  -4.2183 | PDE Loss:  -5.9648 | Function Loss:  -4.304\n",
            "Total loss:  -4.2188 | PDE Loss:  -5.9636 | Function Loss:  -4.305\n",
            "Total loss:  -4.2193 | PDE Loss:  -5.9633 | Function Loss:  -4.3057\n",
            "Total loss:  -4.22 | PDE Loss:  -5.9647 | Function Loss:  -4.3062\n",
            "Total loss:  -4.2205 | PDE Loss:  -5.9642 | Function Loss:  -4.3069\n",
            "Total loss:  -4.2208 | PDE Loss:  -5.9658 | Function Loss:  -4.3069\n",
            "Total loss:  -4.221 | PDE Loss:  -5.9662 | Function Loss:  -4.3071\n",
            "Total loss:  -4.2212 | PDE Loss:  -5.9686 | Function Loss:  -4.3068\n",
            "Total loss:  -4.2214 | PDE Loss:  -5.971 | Function Loss:  -4.3066\n",
            "Total loss:  -4.2217 | PDE Loss:  -5.9737 | Function Loss:  -4.3063\n",
            "Total loss:  -4.2219 | PDE Loss:  -5.9758 | Function Loss:  -4.3061\n",
            "Total loss:  -4.222 | PDE Loss:  -5.9771 | Function Loss:  -4.306\n",
            "Total loss:  -4.2222 | PDE Loss:  -5.981 | Function Loss:  -4.3053\n",
            "Total loss:  -4.2221 | PDE Loss:  -5.9817 | Function Loss:  -4.3051\n",
            "Total loss:  -4.2222 | PDE Loss:  -5.9814 | Function Loss:  -4.3053\n",
            "Total loss:  -4.2224 | PDE Loss:  -5.982 | Function Loss:  -4.3054\n",
            "Total loss:  -4.2227 | PDE Loss:  -5.9829 | Function Loss:  -4.3056\n",
            "Total loss:  -4.223 | PDE Loss:  -5.9837 | Function Loss:  -4.3058\n",
            "Total loss:  -4.2234 | PDE Loss:  -5.9847 | Function Loss:  -4.306\n",
            "Total loss:  -4.2237 | PDE Loss:  -5.9852 | Function Loss:  -4.3063\n",
            "Total loss:  -4.224 | PDE Loss:  -5.9862 | Function Loss:  -4.3065\n",
            "Total loss:  -4.2245 | PDE Loss:  -5.987 | Function Loss:  -4.3068\n",
            "Total loss:  -4.225 | PDE Loss:  -5.9882 | Function Loss:  -4.3073\n",
            "Total loss:  -4.2257 | PDE Loss:  -5.9888 | Function Loss:  -4.3079\n",
            "Total loss:  -4.2263 | PDE Loss:  -5.9899 | Function Loss:  -4.3084\n",
            "Total loss:  -4.2269 | PDE Loss:  -5.9902 | Function Loss:  -4.3091\n",
            "Total loss:  -4.2273 | PDE Loss:  -5.9912 | Function Loss:  -4.3094\n",
            "Total loss:  -4.2277 | PDE Loss:  -5.9918 | Function Loss:  -4.3097\n",
            "Total loss:  -4.2279 | PDE Loss:  -5.9922 | Function Loss:  -4.3099\n",
            "Total loss:  -4.2282 | PDE Loss:  -5.9931 | Function Loss:  -4.3101\n",
            "Total loss:  -4.2286 | PDE Loss:  -5.9938 | Function Loss:  -4.3104\n",
            "Total loss:  -4.2291 | PDE Loss:  -5.9962 | Function Loss:  -4.3105\n",
            "Total loss:  -4.2294 | PDE Loss:  -5.9983 | Function Loss:  -4.3105\n",
            "Total loss:  -4.2301 | PDE Loss:  -6.0016 | Function Loss:  -4.3106\n",
            "Total loss:  -4.2307 | PDE Loss:  -6.0047 | Function Loss:  -4.3108\n",
            "Total loss:  -4.2313 | PDE Loss:  -6.0069 | Function Loss:  -4.311\n",
            "Total loss:  -4.2318 | PDE Loss:  -6.0085 | Function Loss:  -4.3113\n",
            "Total loss:  -4.2323 | PDE Loss:  -6.0099 | Function Loss:  -4.3116\n",
            "Total loss:  -4.2327 | PDE Loss:  -6.0107 | Function Loss:  -4.3119\n",
            "Total loss:  -4.233 | PDE Loss:  -6.0112 | Function Loss:  -4.3122\n",
            "Total loss:  -4.2334 | PDE Loss:  -6.0112 | Function Loss:  -4.3127\n",
            "Total loss:  -4.2339 | PDE Loss:  -6.0109 | Function Loss:  -4.3133\n",
            "Total loss:  -4.2343 | PDE Loss:  -6.01 | Function Loss:  -4.3139\n",
            "Total loss:  -4.2346 | PDE Loss:  -6.0093 | Function Loss:  -4.3145\n",
            "Total loss:  -4.2349 | PDE Loss:  -6.0085 | Function Loss:  -4.315\n",
            "Total loss:  -4.2353 | PDE Loss:  -6.0078 | Function Loss:  -4.3157\n",
            "Total loss:  -4.2357 | PDE Loss:  -6.0069 | Function Loss:  -4.3163\n",
            "Total loss:  -4.2361 | PDE Loss:  -6.0058 | Function Loss:  -4.3169\n",
            "Total loss:  -4.2363 | PDE Loss:  -6.0043 | Function Loss:  -4.3176\n",
            "Total loss:  -4.2366 | PDE Loss:  -6.0031 | Function Loss:  -4.3181\n",
            "Total loss:  -4.2368 | PDE Loss:  -6.002 | Function Loss:  -4.3186\n",
            "Total loss:  -4.2303 | PDE Loss:  -5.9731 | Function Loss:  -4.3169\n",
            "Total loss:  -4.2369 | PDE Loss:  -6.0002 | Function Loss:  -4.3191\n",
            "Total loss:  -4.2373 | PDE Loss:  -5.9999 | Function Loss:  -4.3196\n",
            "Total loss:  -4.2377 | PDE Loss:  -5.9996 | Function Loss:  -4.3202\n",
            "Total loss:  -4.2381 | PDE Loss:  -5.999 | Function Loss:  -4.3209\n",
            "Total loss:  -4.2386 | PDE Loss:  -5.9988 | Function Loss:  -4.3214\n",
            "Total loss:  -4.239 | PDE Loss:  -5.9989 | Function Loss:  -4.3219\n",
            "Total loss:  -4.2395 | PDE Loss:  -5.9989 | Function Loss:  -4.3225\n",
            "Total loss:  -4.2401 | PDE Loss:  -6.0001 | Function Loss:  -4.323\n",
            "Total loss:  -4.2408 | PDE Loss:  -6.0012 | Function Loss:  -4.3236\n",
            "Total loss:  -4.2416 | PDE Loss:  -6.0036 | Function Loss:  -4.3241\n",
            "Total loss:  -4.2425 | PDE Loss:  -6.0046 | Function Loss:  -4.325\n",
            "Total loss:  -4.2434 | PDE Loss:  -6.0063 | Function Loss:  -4.3257\n",
            "Total loss:  -4.2439 | PDE Loss:  -6.0088 | Function Loss:  -4.3258\n",
            "Total loss:  -4.2446 | PDE Loss:  -6.0091 | Function Loss:  -4.3265\n",
            "Total loss:  -4.2453 | PDE Loss:  -6.0074 | Function Loss:  -4.3278\n",
            "Total loss:  -4.2461 | PDE Loss:  -6.0042 | Function Loss:  -4.3294\n",
            "Total loss:  -4.2465 | PDE Loss:  -5.9998 | Function Loss:  -4.3308\n",
            "Total loss:  -4.2468 | PDE Loss:  -5.996 | Function Loss:  -4.332\n",
            "Total loss:  -4.2471 | PDE Loss:  -5.9927 | Function Loss:  -4.333\n",
            "Total loss:  -4.2474 | PDE Loss:  -5.9907 | Function Loss:  -4.3339\n",
            "Total loss:  -4.2477 | PDE Loss:  -5.9842 | Function Loss:  -4.3357\n",
            "Total loss:  -4.248 | PDE Loss:  -5.9838 | Function Loss:  -4.3362\n",
            "Total loss:  -4.2483 | PDE Loss:  -5.9842 | Function Loss:  -4.3365\n",
            "Total loss:  -4.2487 | PDE Loss:  -5.9853 | Function Loss:  -4.3367\n",
            "Total loss:  -4.249 | PDE Loss:  -5.9862 | Function Loss:  -4.3368\n",
            "Total loss:  -4.2492 | PDE Loss:  -5.9867 | Function Loss:  -4.3369\n",
            "Total loss:  -4.2493 | PDE Loss:  -5.9868 | Function Loss:  -4.3371\n",
            "Total loss:  -4.2496 | PDE Loss:  -5.987 | Function Loss:  -4.3374\n",
            "Total loss:  -4.2497 | PDE Loss:  -5.982 | Function Loss:  -4.3387\n",
            "Total loss:  -4.25 | PDE Loss:  -5.9839 | Function Loss:  -4.3386\n",
            "Total loss:  -4.2503 | PDE Loss:  -5.9844 | Function Loss:  -4.3389\n",
            "Total loss:  -4.2508 | PDE Loss:  -5.9845 | Function Loss:  -4.3394\n",
            "Total loss:  -4.2513 | PDE Loss:  -5.9836 | Function Loss:  -4.3403\n",
            "Total loss:  -4.252 | PDE Loss:  -5.9813 | Function Loss:  -4.3417\n",
            "Total loss:  -4.2526 | PDE Loss:  -5.9789 | Function Loss:  -4.343\n",
            "Total loss:  -4.2533 | PDE Loss:  -5.9753 | Function Loss:  -4.3446\n",
            "Total loss:  -4.2542 | PDE Loss:  -5.972 | Function Loss:  -4.3465\n",
            "Total loss:  -4.2487 | PDE Loss:  -5.9488 | Function Loss:  -4.3454\n",
            "Total loss:  -4.2547 | PDE Loss:  -5.9694 | Function Loss:  -4.3478\n",
            "Total loss:  -4.2558 | PDE Loss:  -5.9639 | Function Loss:  -4.3505\n",
            "Total loss:  -4.2575 | PDE Loss:  -5.96 | Function Loss:  -4.3535\n",
            "Total loss:  -4.2592 | PDE Loss:  -5.9554 | Function Loss:  -4.3568\n",
            "Total loss:  -4.2602 | PDE Loss:  -5.954 | Function Loss:  -4.3584\n",
            "Total loss:  -4.2614 | PDE Loss:  -5.9519 | Function Loss:  -4.3605\n",
            "Total loss:  -4.2622 | PDE Loss:  -5.95 | Function Loss:  -4.362\n",
            "Total loss:  -4.2633 | PDE Loss:  -5.9511 | Function Loss:  -4.3631\n",
            "Total loss:  -4.2645 | PDE Loss:  -5.9537 | Function Loss:  -4.3639\n",
            "Total loss:  -4.2657 | PDE Loss:  -5.9563 | Function Loss:  -4.3647\n",
            "Total loss:  -4.2666 | PDE Loss:  -5.9568 | Function Loss:  -4.3657\n",
            "Total loss:  -4.2673 | PDE Loss:  -5.9575 | Function Loss:  -4.3665\n",
            "Total loss:  -4.268 | PDE Loss:  -5.9566 | Function Loss:  -4.3675\n",
            "Total loss:  -4.2683 | PDE Loss:  -5.9563 | Function Loss:  -4.368\n",
            "Total loss:  -4.2688 | PDE Loss:  -5.9562 | Function Loss:  -4.3686\n",
            "Total loss:  -4.2692 | PDE Loss:  -5.9565 | Function Loss:  -4.369\n",
            "Total loss:  -4.2697 | PDE Loss:  -5.9564 | Function Loss:  -4.3697\n",
            "Total loss:  -4.2702 | PDE Loss:  -5.9573 | Function Loss:  -4.3701\n",
            "Total loss:  -4.2706 | PDE Loss:  -5.9587 | Function Loss:  -4.3703\n",
            "Total loss:  -4.2627 | PDE Loss:  -5.9516 | Function Loss:  -4.3621\n",
            "Total loss:  -4.2707 | PDE Loss:  -5.9588 | Function Loss:  -4.3704\n",
            "Total loss:  -4.2712 | PDE Loss:  -5.9609 | Function Loss:  -4.3704\n",
            "Total loss:  -4.2718 | PDE Loss:  -5.9624 | Function Loss:  -4.3708\n",
            "Total loss:  -4.2724 | PDE Loss:  -5.9678 | Function Loss:  -4.3703\n",
            "Total loss:  -4.2731 | PDE Loss:  -5.969 | Function Loss:  -4.3707\n",
            "Total loss:  -4.2738 | PDE Loss:  -5.9716 | Function Loss:  -4.371\n",
            "Total loss:  -4.2749 | PDE Loss:  -5.974 | Function Loss:  -4.3718\n",
            "Total loss:  -4.2761 | PDE Loss:  -5.9755 | Function Loss:  -4.3729\n",
            "Total loss:  -4.2773 | PDE Loss:  -5.9764 | Function Loss:  -4.3741\n",
            "Total loss:  -4.2781 | PDE Loss:  -5.9765 | Function Loss:  -4.3752\n",
            "Total loss:  -4.2793 | PDE Loss:  -5.9756 | Function Loss:  -4.3768\n",
            "Total loss:  -4.2807 | PDE Loss:  -5.9756 | Function Loss:  -4.3786\n",
            "Total loss:  -4.2804 | PDE Loss:  -5.9678 | Function Loss:  -4.3802\n",
            "Total loss:  -4.2814 | PDE Loss:  -5.9731 | Function Loss:  -4.3802\n",
            "Total loss:  -4.283 | PDE Loss:  -5.9737 | Function Loss:  -4.382\n",
            "Total loss:  -4.2851 | PDE Loss:  -5.9767 | Function Loss:  -4.3838\n",
            "Total loss:  -4.2872 | PDE Loss:  -5.9811 | Function Loss:  -4.3853\n",
            "Total loss:  -4.2887 | PDE Loss:  -5.9844 | Function Loss:  -4.3864\n",
            "Total loss:  -4.2902 | PDE Loss:  -5.9889 | Function Loss:  -4.3871\n",
            "Total loss:  -4.2916 | PDE Loss:  -5.995 | Function Loss:  -4.3874\n",
            "Total loss:  -4.2927 | PDE Loss:  -5.9994 | Function Loss:  -4.3877\n",
            "Total loss:  -4.2936 | PDE Loss:  -6.0054 | Function Loss:  -4.3873\n",
            "Total loss:  -4.2943 | PDE Loss:  -6.0103 | Function Loss:  -4.3871\n",
            "Total loss:  -4.2954 | PDE Loss:  -6.0126 | Function Loss:  -4.3878\n",
            "Total loss:  -4.2954 | PDE Loss:  -6.0442 | Function Loss:  -4.3807\n",
            "Total loss:  -4.2967 | PDE Loss:  -6.0292 | Function Loss:  -4.3856\n",
            "Total loss:  -4.2974 | PDE Loss:  -6.0331 | Function Loss:  -4.3856\n",
            "Total loss:  -4.2987 | PDE Loss:  -6.0329 | Function Loss:  -4.3872\n",
            "Total loss:  -4.2997 | PDE Loss:  -6.0378 | Function Loss:  -4.3873\n",
            "Total loss:  -4.3004 | PDE Loss:  -6.0413 | Function Loss:  -4.3875\n",
            "Total loss:  -4.3017 | PDE Loss:  -6.0358 | Function Loss:  -4.3902\n",
            "Total loss:  -4.3029 | PDE Loss:  -6.0324 | Function Loss:  -4.3925\n",
            "Total loss:  -4.3049 | PDE Loss:  -6.0294 | Function Loss:  -4.3957\n",
            "Total loss:  -4.3067 | PDE Loss:  -6.0256 | Function Loss:  -4.3987\n",
            "Total loss:  -4.3083 | PDE Loss:  -6.0266 | Function Loss:  -4.4006\n",
            "Total loss:  -4.3098 | PDE Loss:  -6.0296 | Function Loss:  -4.4016\n",
            "Total loss:  -4.3112 | PDE Loss:  -6.0327 | Function Loss:  -4.4026\n",
            "Total loss:  -4.3122 | PDE Loss:  -6.0379 | Function Loss:  -4.4027\n",
            "Total loss:  -4.3137 | PDE Loss:  -6.0492 | Function Loss:  -4.4019\n",
            "Total loss:  -4.3147 | PDE Loss:  -6.0612 | Function Loss:  -4.4005\n",
            "Total loss:  -4.3154 | PDE Loss:  -6.0654 | Function Loss:  -4.4005\n",
            "Total loss:  -4.3163 | PDE Loss:  -6.0698 | Function Loss:  -4.4006\n",
            "Total loss:  -4.317 | PDE Loss:  -6.0731 | Function Loss:  -4.4008\n",
            "Total loss:  -4.3175 | PDE Loss:  -6.075 | Function Loss:  -4.4009\n",
            "Total loss:  -4.3179 | PDE Loss:  -6.0759 | Function Loss:  -4.4012\n",
            "Total loss:  -4.3182 | PDE Loss:  -6.0764 | Function Loss:  -4.4015\n",
            "Total loss:  -4.3186 | PDE Loss:  -6.0761 | Function Loss:  -4.402\n",
            "Total loss:  -4.3188 | PDE Loss:  -6.0768 | Function Loss:  -4.4021\n",
            "Total loss:  -4.319 | PDE Loss:  -6.075 | Function Loss:  -4.4028\n",
            "Total loss:  -4.3193 | PDE Loss:  -6.0758 | Function Loss:  -4.4029\n",
            "Total loss:  -4.3194 | PDE Loss:  -6.0758 | Function Loss:  -4.403\n",
            "Total loss:  -4.3196 | PDE Loss:  -6.0756 | Function Loss:  -4.4033\n",
            "Total loss:  -4.3197 | PDE Loss:  -6.0757 | Function Loss:  -4.4035\n",
            "Total loss:  -4.3199 | PDE Loss:  -6.0757 | Function Loss:  -4.4036\n",
            "Total loss:  -4.32 | PDE Loss:  -6.0746 | Function Loss:  -4.404\n",
            "Total loss:  -4.3135 | PDE Loss:  -6.0719 | Function Loss:  -4.3967\n",
            "Total loss:  -4.3201 | PDE Loss:  -6.0758 | Function Loss:  -4.4039\n",
            "Total loss:  -4.3202 | PDE Loss:  -6.0757 | Function Loss:  -4.404\n",
            "Total loss:  -4.3203 | PDE Loss:  -6.0755 | Function Loss:  -4.4043\n",
            "Total loss:  -4.3205 | PDE Loss:  -6.0761 | Function Loss:  -4.4043\n",
            "Total loss:  -4.3207 | PDE Loss:  -6.0783 | Function Loss:  -4.4041\n",
            "Total loss:  -4.3207 | PDE Loss:  -6.079 | Function Loss:  -4.404\n",
            "Total loss:  -4.3208 | PDE Loss:  -6.0803 | Function Loss:  -4.4038\n",
            "Total loss:  -4.3209 | PDE Loss:  -6.0815 | Function Loss:  -4.4037\n",
            "Total loss:  -4.3209 | PDE Loss:  -6.0829 | Function Loss:  -4.4034\n",
            "Total loss:  -4.321 | PDE Loss:  -6.0837 | Function Loss:  -4.4033\n",
            "Total loss:  -4.3211 | PDE Loss:  -6.0843 | Function Loss:  -4.4033\n",
            "Total loss:  -4.3211 | PDE Loss:  -6.085 | Function Loss:  -4.4032\n",
            "Total loss:  -4.3211 | PDE Loss:  -6.0852 | Function Loss:  -4.4032\n",
            "Total loss:  -4.3212 | PDE Loss:  -6.0853 | Function Loss:  -4.4032\n",
            "Total loss:  -4.3212 | PDE Loss:  -6.0854 | Function Loss:  -4.4032\n",
            "Total loss:  -4.3213 | PDE Loss:  -6.0854 | Function Loss:  -4.4033\n",
            "Total loss:  -4.3213 | PDE Loss:  -6.0851 | Function Loss:  -4.4034\n",
            "Total loss:  -4.3213 | PDE Loss:  -6.0851 | Function Loss:  -4.4035\n",
            "Total loss:  -4.3214 | PDE Loss:  -6.0858 | Function Loss:  -4.4034\n",
            "Total loss:  -4.3214 | PDE Loss:  -6.0833 | Function Loss:  -4.4039\n",
            "Total loss:  -4.3214 | PDE Loss:  -6.0844 | Function Loss:  -4.4037\n",
            "Total loss:  -4.3215 | PDE Loss:  -6.0846 | Function Loss:  -4.4038\n",
            "Total loss:  -4.3216 | PDE Loss:  -6.0852 | Function Loss:  -4.4037\n",
            "Total loss:  -4.3217 | PDE Loss:  -6.085 | Function Loss:  -4.4039\n",
            "Total loss:  -4.3218 | PDE Loss:  -6.0851 | Function Loss:  -4.404\n",
            "Total loss:  -4.3219 | PDE Loss:  -6.085 | Function Loss:  -4.4042\n",
            "Total loss:  -4.3221 | PDE Loss:  -6.0846 | Function Loss:  -4.4044\n",
            "Total loss:  -4.3222 | PDE Loss:  -6.0845 | Function Loss:  -4.4046\n",
            "Total loss:  -4.3223 | PDE Loss:  -6.0841 | Function Loss:  -4.4049\n",
            "Total loss:  -4.3225 | PDE Loss:  -6.0836 | Function Loss:  -4.4052\n",
            "Total loss:  -4.3226 | PDE Loss:  -6.0831 | Function Loss:  -4.4054\n",
            "Total loss:  -4.3227 | PDE Loss:  -6.083 | Function Loss:  -4.4056\n",
            "Total loss:  -4.3225 | PDE Loss:  -6.08 | Function Loss:  -4.406\n",
            "Total loss:  -4.3228 | PDE Loss:  -6.0822 | Function Loss:  -4.4059\n",
            "Total loss:  -4.3229 | PDE Loss:  -6.082 | Function Loss:  -4.406\n",
            "Total loss:  -4.3232 | PDE Loss:  -6.0824 | Function Loss:  -4.4063\n",
            "Total loss:  -4.3235 | PDE Loss:  -6.0832 | Function Loss:  -4.4064\n",
            "Total loss:  -4.3237 | PDE Loss:  -6.0846 | Function Loss:  -4.4065\n",
            "Total loss:  -4.324 | PDE Loss:  -6.0862 | Function Loss:  -4.4064\n",
            "Total loss:  -4.3244 | PDE Loss:  -6.0882 | Function Loss:  -4.4065\n",
            "Total loss:  -4.3247 | PDE Loss:  -6.0899 | Function Loss:  -4.4065\n",
            "Total loss:  -4.325 | PDE Loss:  -6.0918 | Function Loss:  -4.4065\n",
            "Total loss:  -4.3254 | PDE Loss:  -6.0923 | Function Loss:  -4.4068\n",
            "Total loss:  -4.3256 | PDE Loss:  -6.0934 | Function Loss:  -4.4069\n",
            "Total loss:  -4.3259 | PDE Loss:  -6.0929 | Function Loss:  -4.4074\n",
            "Total loss:  -4.3262 | PDE Loss:  -6.0923 | Function Loss:  -4.4078\n",
            "Total loss:  -4.3265 | PDE Loss:  -6.0911 | Function Loss:  -4.4085\n",
            "Total loss:  -4.3268 | PDE Loss:  -6.0892 | Function Loss:  -4.4092\n",
            "Total loss:  -4.327 | PDE Loss:  -6.0898 | Function Loss:  -4.4093\n",
            "Total loss:  -4.3273 | PDE Loss:  -6.0878 | Function Loss:  -4.4101\n",
            "Total loss:  -4.3275 | PDE Loss:  -6.087 | Function Loss:  -4.4105\n",
            "Total loss:  -4.3277 | PDE Loss:  -6.0865 | Function Loss:  -4.4108\n",
            "Total loss:  -4.3279 | PDE Loss:  -6.086 | Function Loss:  -4.4112\n",
            "Total loss:  -4.3282 | PDE Loss:  -6.0855 | Function Loss:  -4.4116\n",
            "Total loss:  -4.3284 | PDE Loss:  -6.0849 | Function Loss:  -4.412\n",
            "Total loss:  -4.3286 | PDE Loss:  -6.0851 | Function Loss:  -4.4122\n",
            "Total loss:  -4.3288 | PDE Loss:  -6.0854 | Function Loss:  -4.4125\n",
            "Total loss:  -4.3292 | PDE Loss:  -6.0861 | Function Loss:  -4.4127\n",
            "Total loss:  -4.3295 | PDE Loss:  -6.0858 | Function Loss:  -4.4131\n",
            "Total loss:  -4.3298 | PDE Loss:  -6.0861 | Function Loss:  -4.4135\n",
            "Total loss:  -4.33 | PDE Loss:  -6.0859 | Function Loss:  -4.4138\n",
            "Total loss:  -4.3303 | PDE Loss:  -6.0861 | Function Loss:  -4.414\n",
            "Total loss:  -4.3305 | PDE Loss:  -6.0862 | Function Loss:  -4.4143\n",
            "Total loss:  -4.3307 | PDE Loss:  -6.0869 | Function Loss:  -4.4144\n",
            "Total loss:  -4.3308 | PDE Loss:  -6.0886 | Function Loss:  -4.4142\n",
            "Total loss:  -4.331 | PDE Loss:  -6.0905 | Function Loss:  -4.414\n",
            "Total loss:  -4.3312 | PDE Loss:  -6.0927 | Function Loss:  -4.4137\n",
            "Total loss:  -4.3313 | PDE Loss:  -6.0937 | Function Loss:  -4.4137\n",
            "Total loss:  -4.3314 | PDE Loss:  -6.0953 | Function Loss:  -4.4135\n",
            "Total loss:  -4.3315 | PDE Loss:  -6.0959 | Function Loss:  -4.4135\n",
            "Total loss:  -4.3317 | PDE Loss:  -6.0961 | Function Loss:  -4.4136\n",
            "Total loss:  -4.3318 | PDE Loss:  -6.0964 | Function Loss:  -4.4137\n",
            "Total loss:  -4.332 | PDE Loss:  -6.096 | Function Loss:  -4.414\n",
            "Total loss:  -4.3321 | PDE Loss:  -6.0957 | Function Loss:  -4.4143\n",
            "Total loss:  -4.3323 | PDE Loss:  -6.0948 | Function Loss:  -4.4146\n",
            "Total loss:  -4.3324 | PDE Loss:  -6.0943 | Function Loss:  -4.415\n",
            "Total loss:  -4.3326 | PDE Loss:  -6.0935 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3328 | PDE Loss:  -6.0952 | Function Loss:  -4.4152\n",
            "Total loss:  -4.333 | PDE Loss:  -6.0957 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3332 | PDE Loss:  -6.0973 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3334 | PDE Loss:  -6.0984 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3336 | PDE Loss:  -6.0993 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3337 | PDE Loss:  -6.1001 | Function Loss:  -4.4153\n",
            "Total loss:  -4.3339 | PDE Loss:  -6.1005 | Function Loss:  -4.4154\n",
            "Total loss:  -4.334 | PDE Loss:  -6.1009 | Function Loss:  -4.4155\n",
            "Total loss:  -4.3342 | PDE Loss:  -6.1013 | Function Loss:  -4.4157\n",
            "Total loss:  -4.3344 | PDE Loss:  -6.1012 | Function Loss:  -4.4159\n",
            "Total loss:  -4.3347 | PDE Loss:  -6.1006 | Function Loss:  -4.4163\n",
            "Total loss:  -4.3349 | PDE Loss:  -6.1004 | Function Loss:  -4.4167\n",
            "Total loss:  -4.3353 | PDE Loss:  -6.0999 | Function Loss:  -4.4173\n",
            "Total loss:  -4.3357 | PDE Loss:  -6.0993 | Function Loss:  -4.4179\n",
            "Total loss:  -4.3361 | PDE Loss:  -6.0983 | Function Loss:  -4.4185\n",
            "Total loss:  -4.3364 | PDE Loss:  -6.0977 | Function Loss:  -4.419\n",
            "Total loss:  -4.3366 | PDE Loss:  -6.0967 | Function Loss:  -4.4195\n",
            "Total loss:  -4.3368 | PDE Loss:  -6.0961 | Function Loss:  -4.4198\n",
            "Total loss:  -4.337 | PDE Loss:  -6.096 | Function Loss:  -4.4201\n",
            "Total loss:  -4.3372 | PDE Loss:  -6.0955 | Function Loss:  -4.4204\n",
            "Total loss:  -4.3373 | PDE Loss:  -6.0955 | Function Loss:  -4.4206\n",
            "Total loss:  -4.3374 | PDE Loss:  -6.0932 | Function Loss:  -4.4212\n",
            "Total loss:  -4.3377 | PDE Loss:  -6.0932 | Function Loss:  -4.4216\n",
            "Total loss:  -4.3379 | PDE Loss:  -6.0938 | Function Loss:  -4.4217\n",
            "Total loss:  -4.3381 | PDE Loss:  -6.0938 | Function Loss:  -4.422\n",
            "Total loss:  -4.3386 | PDE Loss:  -6.0934 | Function Loss:  -4.4226\n",
            "Total loss:  -4.339 | PDE Loss:  -6.0924 | Function Loss:  -4.4233\n",
            "Total loss:  -4.3394 | PDE Loss:  -6.0921 | Function Loss:  -4.4238\n",
            "Total loss:  -4.3397 | PDE Loss:  -6.0913 | Function Loss:  -4.4243\n",
            "Total loss:  -4.3401 | PDE Loss:  -6.0911 | Function Loss:  -4.4249\n",
            "Total loss:  -4.3405 | PDE Loss:  -6.0911 | Function Loss:  -4.4254\n",
            "Total loss:  -4.341 | PDE Loss:  -6.0912 | Function Loss:  -4.4259\n",
            "Total loss:  -4.3413 | PDE Loss:  -6.0922 | Function Loss:  -4.4261\n",
            "Total loss:  -4.3417 | PDE Loss:  -6.093 | Function Loss:  -4.4264\n",
            "Total loss:  -4.342 | PDE Loss:  -6.0942 | Function Loss:  -4.4265\n",
            "Total loss:  -4.3423 | PDE Loss:  -6.0942 | Function Loss:  -4.4269\n",
            "Total loss:  -4.3426 | PDE Loss:  -6.0942 | Function Loss:  -4.4273\n",
            "Total loss:  -4.3429 | PDE Loss:  -6.0933 | Function Loss:  -4.4278\n",
            "Total loss:  -4.3433 | PDE Loss:  -6.0908 | Function Loss:  -4.4288\n",
            "Total loss:  -4.3436 | PDE Loss:  -6.0886 | Function Loss:  -4.4298\n",
            "Total loss:  -4.344 | PDE Loss:  -6.0853 | Function Loss:  -4.431\n",
            "Total loss:  -4.3447 | PDE Loss:  -6.08 | Function Loss:  -4.433\n",
            "Total loss:  -4.3426 | PDE Loss:  -6.0543 | Function Loss:  -4.4363\n",
            "Total loss:  -4.3451 | PDE Loss:  -6.0731 | Function Loss:  -4.4351\n",
            "Total loss:  -4.3456 | PDE Loss:  -6.0662 | Function Loss:  -4.4373\n",
            "Total loss:  -4.3463 | PDE Loss:  -6.0657 | Function Loss:  -4.4383\n",
            "Total loss:  -4.3468 | PDE Loss:  -6.066 | Function Loss:  -4.4388\n",
            "Total loss:  -4.3475 | PDE Loss:  -6.0674 | Function Loss:  -4.4394\n",
            "Total loss:  -4.3481 | PDE Loss:  -6.0688 | Function Loss:  -4.4398\n",
            "Total loss:  -4.3485 | PDE Loss:  -6.0715 | Function Loss:  -4.4395\n",
            "Total loss:  -4.3491 | PDE Loss:  -6.0754 | Function Loss:  -4.4394\n",
            "Total loss:  -4.3499 | PDE Loss:  -6.0808 | Function Loss:  -4.4392\n",
            "Total loss:  -4.3509 | PDE Loss:  -6.0862 | Function Loss:  -4.4392\n",
            "Total loss:  -4.3518 | PDE Loss:  -6.0937 | Function Loss:  -4.4387\n",
            "Total loss:  -4.3528 | PDE Loss:  -6.0992 | Function Loss:  -4.4386\n",
            "Total loss:  -4.3539 | PDE Loss:  -6.105 | Function Loss:  -4.4387\n",
            "Total loss:  -4.3552 | PDE Loss:  -6.1109 | Function Loss:  -4.439\n",
            "Total loss:  -4.3564 | PDE Loss:  -6.1162 | Function Loss:  -4.4394\n",
            "Total loss:  -4.3571 | PDE Loss:  -6.1169 | Function Loss:  -4.4401\n",
            "Total loss:  -4.3579 | PDE Loss:  -6.1188 | Function Loss:  -4.4406\n",
            "Total loss:  -4.3584 | PDE Loss:  -6.1178 | Function Loss:  -4.4414\n",
            "Total loss:  -4.3589 | PDE Loss:  -6.118 | Function Loss:  -4.442\n",
            "Total loss:  -4.3584 | PDE Loss:  -6.1133 | Function Loss:  -4.4424\n",
            "Total loss:  -4.3591 | PDE Loss:  -6.1168 | Function Loss:  -4.4425\n",
            "Total loss:  -4.358 | PDE Loss:  -6.1283 | Function Loss:  -4.4388\n",
            "Total loss:  -4.3599 | PDE Loss:  -6.1225 | Function Loss:  -4.4422\n",
            "Total loss:  -4.3602 | PDE Loss:  -6.1235 | Function Loss:  -4.4424\n",
            "Total loss:  -4.3613 | PDE Loss:  -6.1269 | Function Loss:  -4.443\n",
            "Total loss:  -4.3623 | PDE Loss:  -6.1299 | Function Loss:  -4.4437\n",
            "Total loss:  -4.363 | PDE Loss:  -6.1329 | Function Loss:  -4.4439\n",
            "Total loss:  -4.3639 | PDE Loss:  -6.1361 | Function Loss:  -4.4443\n",
            "Total loss:  -4.3648 | PDE Loss:  -6.139 | Function Loss:  -4.4448\n",
            "Total loss:  -4.3662 | PDE Loss:  -6.1412 | Function Loss:  -4.446\n",
            "Total loss:  -4.3677 | PDE Loss:  -6.1424 | Function Loss:  -4.4475\n",
            "Total loss:  -4.3693 | PDE Loss:  -6.1386 | Function Loss:  -4.4503\n",
            "Total loss:  -4.3705 | PDE Loss:  -6.1379 | Function Loss:  -4.4519\n",
            "Total loss:  -4.3713 | PDE Loss:  -6.1332 | Function Loss:  -4.4538\n",
            "Total loss:  -4.3724 | PDE Loss:  -6.1257 | Function Loss:  -4.4567\n",
            "Total loss:  -4.3731 | PDE Loss:  -6.1227 | Function Loss:  -4.4582\n",
            "Total loss:  -4.3739 | PDE Loss:  -6.1151 | Function Loss:  -4.4609\n",
            "Total loss:  -4.3747 | PDE Loss:  -6.1136 | Function Loss:  -4.4622\n",
            "Total loss:  -4.3754 | PDE Loss:  -6.1165 | Function Loss:  -4.4624\n",
            "Total loss:  -4.3761 | PDE Loss:  -6.1139 | Function Loss:  -4.4638\n",
            "Total loss:  -4.3765 | PDE Loss:  -6.1186 | Function Loss:  -4.4633\n",
            "Total loss:  -4.377 | PDE Loss:  -6.1259 | Function Loss:  -4.4623\n",
            "Total loss:  -4.3774 | PDE Loss:  -6.1304 | Function Loss:  -4.4618\n",
            "Total loss:  -4.3777 | PDE Loss:  -6.1342 | Function Loss:  -4.4614\n",
            "Total loss:  -4.3777 | PDE Loss:  -6.1346 | Function Loss:  -4.4612\n",
            "Total loss:  -4.3779 | PDE Loss:  -6.1346 | Function Loss:  -4.4615\n",
            "Total loss:  -4.3782 | PDE Loss:  -6.136 | Function Loss:  -4.4615\n",
            "Total loss:  -4.3785 | PDE Loss:  -6.1372 | Function Loss:  -4.4617\n",
            "Total loss:  -4.3789 | PDE Loss:  -6.1367 | Function Loss:  -4.4623\n",
            "Total loss:  -4.3793 | PDE Loss:  -6.1362 | Function Loss:  -4.4629\n",
            "Total loss:  -4.3798 | PDE Loss:  -6.1352 | Function Loss:  -4.4637\n",
            "Total loss:  -4.3803 | PDE Loss:  -6.1343 | Function Loss:  -4.4645\n",
            "Total loss:  -4.3807 | PDE Loss:  -6.1341 | Function Loss:  -4.465\n",
            "Total loss:  -4.3811 | PDE Loss:  -6.1347 | Function Loss:  -4.4654\n",
            "Total loss:  -4.3815 | PDE Loss:  -6.1366 | Function Loss:  -4.4654\n",
            "Total loss:  -4.3819 | PDE Loss:  -6.1396 | Function Loss:  -4.4653\n",
            "Total loss:  -4.3823 | PDE Loss:  -6.1423 | Function Loss:  -4.4653\n",
            "Total loss:  -4.3827 | PDE Loss:  -6.1454 | Function Loss:  -4.4651\n",
            "Total loss:  -4.3832 | PDE Loss:  -6.1482 | Function Loss:  -4.465\n",
            "Total loss:  -4.3836 | PDE Loss:  -6.1505 | Function Loss:  -4.4651\n",
            "Total loss:  -4.384 | PDE Loss:  -6.1518 | Function Loss:  -4.4653\n",
            "Total loss:  -4.3845 | PDE Loss:  -6.1536 | Function Loss:  -4.4655\n",
            "Total loss:  -4.3848 | PDE Loss:  -6.1527 | Function Loss:  -4.466\n",
            "Total loss:  -4.385 | PDE Loss:  -6.153 | Function Loss:  -4.4663\n",
            "Total loss:  -4.3854 | PDE Loss:  -6.1527 | Function Loss:  -4.4668\n",
            "Total loss:  -4.3858 | PDE Loss:  -6.1535 | Function Loss:  -4.4671\n",
            "Total loss:  -4.3861 | PDE Loss:  -6.1534 | Function Loss:  -4.4675\n",
            "Total loss:  -4.3864 | PDE Loss:  -6.1544 | Function Loss:  -4.4676\n",
            "Total loss:  -4.3867 | PDE Loss:  -6.1564 | Function Loss:  -4.4676\n",
            "Total loss:  -4.3869 | PDE Loss:  -6.1586 | Function Loss:  -4.4674\n",
            "Total loss:  -4.3872 | PDE Loss:  -6.1604 | Function Loss:  -4.4673\n",
            "Total loss:  -4.3873 | PDE Loss:  -6.1628 | Function Loss:  -4.4671\n",
            "Total loss:  -4.3875 | PDE Loss:  -6.1642 | Function Loss:  -4.4669\n",
            "Total loss:  -4.3877 | PDE Loss:  -6.164 | Function Loss:  -4.4672\n",
            "Total loss:  -4.3879 | PDE Loss:  -6.1641 | Function Loss:  -4.4675\n",
            "Total loss:  -4.3878 | PDE Loss:  -6.1648 | Function Loss:  -4.4672\n",
            "Total loss:  -4.388 | PDE Loss:  -6.1645 | Function Loss:  -4.4675\n",
            "Total loss:  -4.3881 | PDE Loss:  -6.1655 | Function Loss:  -4.4675\n",
            "Total loss:  -4.3883 | PDE Loss:  -6.1626 | Function Loss:  -4.4682\n",
            "Total loss:  -4.3884 | PDE Loss:  -6.1631 | Function Loss:  -4.4683\n",
            "Total loss:  -4.3885 | PDE Loss:  -6.1633 | Function Loss:  -4.4684\n",
            "Total loss:  -4.3887 | PDE Loss:  -6.1637 | Function Loss:  -4.4685\n",
            "Total loss:  -4.3889 | PDE Loss:  -6.1647 | Function Loss:  -4.4685\n",
            "Total loss:  -4.389 | PDE Loss:  -6.1656 | Function Loss:  -4.4685\n",
            "Total loss:  -4.3892 | PDE Loss:  -6.167 | Function Loss:  -4.4685\n",
            "Total loss:  -4.3894 | PDE Loss:  -6.1681 | Function Loss:  -4.4684\n",
            "Total loss:  -4.3896 | PDE Loss:  -6.1687 | Function Loss:  -4.4685\n",
            "Total loss:  -4.3894 | PDE Loss:  -6.1666 | Function Loss:  -4.4688\n",
            "Total loss:  -4.3896 | PDE Loss:  -6.1682 | Function Loss:  -4.4687\n",
            "Total loss:  -4.3898 | PDE Loss:  -6.1687 | Function Loss:  -4.4688\n",
            "Total loss:  -4.39 | PDE Loss:  -6.1696 | Function Loss:  -4.4689\n",
            "Total loss:  -4.3902 | PDE Loss:  -6.1693 | Function Loss:  -4.4692\n",
            "Total loss:  -4.3905 | PDE Loss:  -6.1692 | Function Loss:  -4.4696\n",
            "Total loss:  -4.3908 | PDE Loss:  -6.1683 | Function Loss:  -4.4701\n",
            "Total loss:  -4.3911 | PDE Loss:  -6.1677 | Function Loss:  -4.4706\n",
            "Total loss:  -4.3914 | PDE Loss:  -6.1665 | Function Loss:  -4.4712\n",
            "Total loss:  -4.3916 | PDE Loss:  -6.1656 | Function Loss:  -4.4716\n",
            "Total loss:  -4.3918 | PDE Loss:  -6.1643 | Function Loss:  -4.4721\n",
            "Total loss:  -4.3921 | PDE Loss:  -6.1633 | Function Loss:  -4.4727\n",
            "Total loss:  -4.3924 | PDE Loss:  -6.1618 | Function Loss:  -4.4733\n",
            "Total loss:  -4.3927 | PDE Loss:  -6.161 | Function Loss:  -4.4739\n",
            "Total loss:  -4.3931 | PDE Loss:  -6.1602 | Function Loss:  -4.4745\n",
            "Total loss:  -4.3934 | PDE Loss:  -6.1602 | Function Loss:  -4.4749\n",
            "Total loss:  -4.3937 | PDE Loss:  -6.1605 | Function Loss:  -4.4752\n",
            "Total loss:  -4.3941 | PDE Loss:  -6.1608 | Function Loss:  -4.4756\n",
            "Total loss:  -4.3946 | PDE Loss:  -6.1609 | Function Loss:  -4.4762\n",
            "Total loss:  -4.395 | PDE Loss:  -6.1604 | Function Loss:  -4.4768\n",
            "Total loss:  -4.3954 | PDE Loss:  -6.1595 | Function Loss:  -4.4775\n",
            "Total loss:  -4.3958 | PDE Loss:  -6.1583 | Function Loss:  -4.4782\n",
            "Total loss:  -4.3964 | PDE Loss:  -6.1564 | Function Loss:  -4.4793\n",
            "Total loss:  -4.3968 | PDE Loss:  -6.1554 | Function Loss:  -4.4801\n",
            "Total loss:  -4.3969 | PDE Loss:  -6.16 | Function Loss:  -4.4792\n",
            "Total loss:  -4.3975 | PDE Loss:  -6.1581 | Function Loss:  -4.4803\n",
            "Total loss:  -4.3978 | PDE Loss:  -6.1572 | Function Loss:  -4.4808\n",
            "Total loss:  -4.3981 | PDE Loss:  -6.157 | Function Loss:  -4.4812\n",
            "Total loss:  -4.3982 | PDE Loss:  -6.1568 | Function Loss:  -4.4814\n",
            "Total loss:  -4.3984 | PDE Loss:  -6.1572 | Function Loss:  -4.4816\n",
            "Total loss:  -4.3986 | PDE Loss:  -6.1579 | Function Loss:  -4.4816\n",
            "Total loss:  -4.3989 | PDE Loss:  -6.1601 | Function Loss:  -4.4815\n",
            "Total loss:  -4.3989 | PDE Loss:  -6.1567 | Function Loss:  -4.4822\n",
            "Total loss:  -4.3992 | PDE Loss:  -6.1585 | Function Loss:  -4.4822\n",
            "Total loss:  -4.3994 | PDE Loss:  -6.1591 | Function Loss:  -4.4824\n",
            "Total loss:  -4.3997 | PDE Loss:  -6.1599 | Function Loss:  -4.4826\n",
            "Total loss:  -4.4 | PDE Loss:  -6.1609 | Function Loss:  -4.4827\n",
            "Total loss:  -4.4003 | PDE Loss:  -6.1611 | Function Loss:  -4.483\n",
            "Total loss:  -4.4005 | PDE Loss:  -6.1619 | Function Loss:  -4.4831\n",
            "Total loss:  -4.4007 | PDE Loss:  -6.1623 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4009 | PDE Loss:  -6.163 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4011 | PDE Loss:  -6.1641 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4012 | PDE Loss:  -6.1649 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4014 | PDE Loss:  -6.1663 | Function Loss:  -4.4832\n",
            "Total loss:  -4.4015 | PDE Loss:  -6.1669 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4016 | PDE Loss:  -6.1681 | Function Loss:  -4.4832\n",
            "Total loss:  -4.4018 | PDE Loss:  -6.1696 | Function Loss:  -4.4831\n",
            "Total loss:  -4.402 | PDE Loss:  -6.1718 | Function Loss:  -4.4829\n",
            "Total loss:  -4.4022 | PDE Loss:  -6.1741 | Function Loss:  -4.4827\n",
            "Total loss:  -4.4024 | PDE Loss:  -6.1762 | Function Loss:  -4.4825\n",
            "Total loss:  -4.4026 | PDE Loss:  -6.1779 | Function Loss:  -4.4824\n",
            "Total loss:  -4.4027 | PDE Loss:  -6.184 | Function Loss:  -4.4812\n",
            "Total loss:  -4.403 | PDE Loss:  -6.1854 | Function Loss:  -4.4813\n",
            "Total loss:  -4.4032 | PDE Loss:  -6.1847 | Function Loss:  -4.4817\n",
            "Total loss:  -4.4035 | PDE Loss:  -6.1834 | Function Loss:  -4.4823\n",
            "Total loss:  -4.4037 | PDE Loss:  -6.1798 | Function Loss:  -4.4833\n",
            "Total loss:  -4.4039 | PDE Loss:  -6.179 | Function Loss:  -4.4837\n",
            "Total loss:  -4.4041 | PDE Loss:  -6.179 | Function Loss:  -4.4839\n",
            "Total loss:  -4.4043 | PDE Loss:  -6.1793 | Function Loss:  -4.4842\n",
            "Total loss:  -4.4045 | PDE Loss:  -6.1794 | Function Loss:  -4.4843\n",
            "Total loss:  -4.4047 | PDE Loss:  -6.1808 | Function Loss:  -4.4843\n",
            "Total loss:  -4.4048 | PDE Loss:  -6.1821 | Function Loss:  -4.4842\n",
            "Total loss:  -4.4049 | PDE Loss:  -6.1829 | Function Loss:  -4.4841\n",
            "Total loss:  -4.405 | PDE Loss:  -6.1839 | Function Loss:  -4.4841\n",
            "Total loss:  -4.4051 | PDE Loss:  -6.1852 | Function Loss:  -4.4839\n",
            "Total loss:  -4.4052 | PDE Loss:  -6.1859 | Function Loss:  -4.4839\n",
            "Total loss:  -4.4053 | PDE Loss:  -6.1867 | Function Loss:  -4.4838\n",
            "Total loss:  -4.4054 | PDE Loss:  -6.187 | Function Loss:  -4.4838\n",
            "Total loss:  -4.4054 | PDE Loss:  -6.1871 | Function Loss:  -4.4839\n",
            "Total loss:  -4.4055 | PDE Loss:  -6.1881 | Function Loss:  -4.4838\n",
            "Total loss:  -4.4056 | PDE Loss:  -6.1879 | Function Loss:  -4.4839\n",
            "Total loss:  -4.4057 | PDE Loss:  -6.188 | Function Loss:  -4.4841\n",
            "Total loss:  -4.4058 | PDE Loss:  -6.1882 | Function Loss:  -4.4841\n",
            "Total loss:  -4.4059 | PDE Loss:  -6.1881 | Function Loss:  -4.4843\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1889 | Function Loss:  -4.4842\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1881 | Function Loss:  -4.4844\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1886 | Function Loss:  -4.4843\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1889 | Function Loss:  -4.4842\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1889 | Function Loss:  -4.4842\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1889 | Function Loss:  -4.4842\n",
            "Total loss:  -4.406 | PDE Loss:  -6.1889 | Function Loss:  -4.4842\n",
            "Final Loss:  -4.406004905700684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9024cea0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "hist = pinn.fit(num_epochs=n_epochs,\n",
        "                optimizer=optimizer_LBFGS,\n",
        "                verbose=True)\n",
        "\n",
        "plt.figure(dpi=150)\n",
        "plt.grid(True, which=\"both\", ls=\":\")\n",
        "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
        "plt.xscale(\"log\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3HG9DQM5fQxN"
      },
      "outputs": [],
      "source": [
        "pinn.plotting()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
